2025-10-15 19:41:18.531 | ===> User
2025-10-15 19:41:18.534 | uid=1000(appuser) gid=1000(appuser) groups=1000(appuser)
2025-10-15 19:41:18.535 | ===> Configuring ...
2025-10-15 19:41:18.541 | Running in Zookeeper mode...
2025-10-15 19:41:21.075 | ===> Running preflight checks ... 
2025-10-15 19:41:21.078 | ===> Check if /var/lib/kafka/data is writable ...
2025-10-15 19:41:21.456 | ===> Check if Zookeeper is healthy ...
2025-10-15 19:41:22.095 | [2025-10-16 00:41:22,094] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:22.095 | [2025-10-16 00:41:22,094] INFO Client environment:host.name=2ae4b23f74a4 (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:22.095 | [2025-10-16 00:41:22,094] INFO Client environment:java.version=11.0.20 (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:22.095 | [2025-10-16 00:41:22,094] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:22.095 | [2025-10-16 00:41:22,094] INFO Client environment:java.home=/usr/lib/jvm/java-11-zulu-openjdk-ca (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:22.095 | [2025-10-16 00:41:22,095] INFO Client environment:java.class.path=/usr/share/java/cp-base-new/minimal-json-0.9.5.jar:/usr/share/java/cp-base-new/kafka-clients-7.5.0-ccs.jar:/usr/share/java/cp-base-new/slf4j-api-1.7.36.jar:/usr/share/java/cp-base-new/jmx_prometheus_javaagent-0.18.0.jar:/usr/share/java/cp-base-new/jackson-annotations-2.14.2.jar:/usr/share/java/cp-base-new/scala-collection-compat_2.13-2.10.0.jar:/usr/share/java/cp-base-new/gson-2.9.0.jar:/usr/share/java/cp-base-new/kafka-server-common-7.5.0-ccs.jar:/usr/share/java/cp-base-new/jose4j-0.9.3.jar:/usr/share/java/cp-base-new/scala-reflect-2.13.10.jar:/usr/share/java/cp-base-new/zstd-jni-1.5.5-1.jar:/usr/share/java/cp-base-new/jackson-datatype-jdk8-2.14.2.jar:/usr/share/java/cp-base-new/kafka-storage-7.5.0-ccs.jar:/usr/share/java/cp-base-new/reload4j-1.2.19.jar:/usr/share/java/cp-base-new/kafka-raft-7.5.0-ccs.jar:/usr/share/java/cp-base-new/logredactor-1.0.12.jar:/usr/share/java/cp-base-new/jackson-module-scala_2.13-2.14.2.jar:/usr/share/java/cp-base-new/paranamer-2.8.jar:/usr/share/java/cp-base-new/utility-belt-7.5.0.jar:/usr/share/java/cp-base-new/snakeyaml-2.0.jar:/usr/share/java/cp-base-new/metrics-core-2.2.0.jar:/usr/share/java/cp-base-new/metrics-core-4.1.12.1.jar:/usr/share/java/cp-base-new/kafka-tools-api-7.5.0-ccs.jar:/usr/share/java/cp-base-new/logredactor-metrics-1.0.12.jar:/usr/share/java/cp-base-new/scala-logging_2.13-3.9.4.jar:/usr/share/java/cp-base-new/jolokia-core-1.7.1.jar:/usr/share/java/cp-base-new/kafka-metadata-7.5.0-ccs.jar:/usr/share/java/cp-base-new/audience-annotations-0.5.0.jar:/usr/share/java/cp-base-new/argparse4j-0.7.0.jar:/usr/share/java/cp-base-new/kafka-storage-api-7.5.0-ccs.jar:/usr/share/java/cp-base-new/jopt-simple-5.0.4.jar:/usr/share/java/cp-base-new/jackson-dataformat-csv-2.14.2.jar:/usr/share/java/cp-base-new/jackson-core-2.14.2.jar:/usr/share/java/cp-base-new/snappy-java-1.1.10.1.jar:/usr/share/java/cp-base-new/scala-java8-compat_2.13-1.0.2.jar:/usr/share/java/cp-base-new/disk-usage-agent-7.5.0.jar:/usr/share/java/cp-base-new/commons-cli-1.4.jar:/usr/share/java/cp-base-new/common-utils-7.5.0.jar:/usr/share/java/cp-base-new/jolokia-jvm-1.7.1.jar:/usr/share/java/cp-base-new/lz4-java-1.8.0.jar:/usr/share/java/cp-base-new/json-simple-1.1.1.jar:/usr/share/java/cp-base-new/zookeeper-3.6.3.jar:/usr/share/java/cp-base-new/kafka_2.13-7.5.0-ccs.jar:/usr/share/java/cp-base-new/jackson-databind-2.14.2.jar:/usr/share/java/cp-base-new/kafka-group-coordinator-7.5.0-ccs.jar:/usr/share/java/cp-base-new/slf4j-reload4j-1.7.36.jar:/usr/share/java/cp-base-new/zookeeper-jute-3.6.3.jar:/usr/share/java/cp-base-new/scala-library-2.13.10.jar:/usr/share/java/cp-base-new/re2j-1.6.jar:/usr/share/java/cp-base-new/jackson-dataformat-yaml-2.14.2.jar (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:22.095 | [2025-10-16 00:41:22,095] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:22.095 | [2025-10-16 00:41:22,095] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:22.095 | [2025-10-16 00:41:22,095] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:22.095 | [2025-10-16 00:41:22,095] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:22.095 | [2025-10-16 00:41:22,095] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:22.095 | [2025-10-16 00:41:22,095] INFO Client environment:os.version=6.6.87.1-microsoft-standard-WSL2 (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:22.095 | [2025-10-16 00:41:22,095] INFO Client environment:user.name=appuser (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:22.095 | [2025-10-16 00:41:22,095] INFO Client environment:user.home=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:22.095 | [2025-10-16 00:41:22,095] INFO Client environment:user.dir=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:22.095 | [2025-10-16 00:41:22,095] INFO Client environment:os.memory.free=112MB (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:22.095 | [2025-10-16 00:41:22,095] INFO Client environment:os.memory.max=1948MB (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:22.095 | [2025-10-16 00:41:22,095] INFO Client environment:os.memory.total=122MB (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:22.099 | [2025-10-16 00:41:22,099] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=40000 watcher=io.confluent.admin.utils.ZookeeperConnectionWatcher@221af3c0 (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:22.103 | [2025-10-16 00:41:22,102] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
2025-10-15 19:41:22.112 | [2025-10-16 00:41:22,112] INFO jute.maxbuffer value is 1048575 Bytes (org.apache.zookeeper.ClientCnxnSocket)
2025-10-15 19:41:22.119 | [2025-10-16 00:41:22,119] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
2025-10-15 19:41:22.155 | [2025-10-16 00:41:22,153] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. (org.apache.zookeeper.ClientCnxn)
2025-10-15 19:41:22.155 | [2025-10-16 00:41:22,155] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-10-15 19:41:22.169 | [2025-10-16 00:41:22,169] INFO Socket connection established, initiating session, client: /172.18.0.3:42154, server: zookeeper/172.18.0.2:2181 (org.apache.zookeeper.ClientCnxn)
2025-10-15 19:41:22.217 | [2025-10-16 00:41:22,217] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, session id = 0x1000011a3f20000, negotiated timeout = 40000 (org.apache.zookeeper.ClientCnxn)
2025-10-15 19:41:22.344 | [2025-10-16 00:41:22,343] INFO Session: 0x1000011a3f20000 closed (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:22.344 | [2025-10-16 00:41:22,343] INFO EventThread shut down for session: 0x1000011a3f20000 (org.apache.zookeeper.ClientCnxn)
2025-10-15 19:41:22.352 | Using log4j config /etc/kafka/log4j.properties
2025-10-15 19:41:22.412 | ===> Launching ... 
2025-10-15 19:41:22.418 | ===> Launching kafka ... 
2025-10-15 19:41:22.946 | [2025-10-16 00:41:22,945] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
2025-10-15 19:41:23.270 | [2025-10-16 00:41:23,270] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
2025-10-15 19:41:23.342 | [2025-10-16 00:41:23,342] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
2025-10-15 19:41:23.343 | [2025-10-16 00:41:23,343] INFO starting (kafka.server.KafkaServer)
2025-10-15 19:41:23.344 | [2025-10-16 00:41:23,343] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
2025-10-15 19:41:23.357 | [2025-10-16 00:41:23,357] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
2025-10-15 19:41:23.362 | [2025-10-16 00:41:23,362] INFO Client environment:zookeeper.version=3.6.4--d65253dcf68e9097c6e95a126463fd5fdeb4521c, built on 12/18/2022 18:10 GMT (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:23.362 | [2025-10-16 00:41:23,362] INFO Client environment:host.name=2ae4b23f74a4 (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:23.362 | [2025-10-16 00:41:23,362] INFO Client environment:java.version=11.0.20 (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:23.362 | [2025-10-16 00:41:23,362] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:23.362 | [2025-10-16 00:41:23,362] INFO Client environment:java.home=/usr/lib/jvm/java-11-zulu-openjdk-ca (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:23.363 | [2025-10-16 00:41:23,362] INFO Client environment:java.class.path=/usr/bin/../share/java/kafka/zookeeper-jute-3.6.4.jar:/usr/bin/../share/java/kafka/jackson-datatype-jdk8-2.13.5.jar:/usr/bin/../share/java/kafka/jakarta.inject-2.6.1.jar:/usr/bin/../share/java/kafka/netty-transport-native-epoll-4.1.96.Final.jar:/usr/bin/../share/java/kafka/kafka-clients-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jline-3.22.0.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.36.jar:/usr/bin/../share/java/kafka/reflections-0.9.12.jar:/usr/bin/../share/java/kafka/scala-collection-compat_2.13-2.10.0.jar:/usr/bin/../share/java/kafka/javassist-3.29.2-GA.jar:/usr/bin/../share/java/kafka/connect-runtime-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jakarta.annotation-api-1.3.5.jar:/usr/bin/../share/java/kafka/jackson-databind-2.13.5.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/kafka-streams-scala_2.13-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/javax.activation-api-1.2.0.jar:/usr/bin/../share/java/kafka/rocksdbjni-7.1.2.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/usr/bin/../share/java/kafka/kafka-server-common-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jose4j-0.9.3.jar:/usr/bin/../share/java/kafka/scala-reflect-2.13.10.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.13.5.jar:/usr/bin/../share/java/kafka/zstd-jni-1.5.5-1.jar:/usr/bin/../share/java/kafka/kafka-storage-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jetty-security-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.39.1.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/kafka-raft-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/netty-transport-native-unix-common-4.1.96.Final.jar:/usr/bin/../share/java/kafka/jersey-server-2.39.1.jar:/usr/bin/../share/java/kafka/paranamer-2.8.jar:/usr/bin/../share/java/kafka/jersey-common-2.39.1.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/netty-transport-4.1.96.Final.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/metrics-core-4.1.12.1.jar:/usr/bin/../share/java/kafka/netty-buffer-4.1.96.Final.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.13.5.jar:/usr/bin/../share/java/kafka/netty-resolver-4.1.96.Final.jar:/usr/bin/../share/java/kafka/kafka-tools-api-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jaxb-api-2.3.1.jar:/usr/bin/../share/java/kafka/jetty-util-ajax-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/scala-logging_2.13-3.9.4.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.6.1.jar:/usr/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/usr/bin/../share/java/kafka/jakarta.xml.bind-api-2.3.3.jar:/usr/bin/../share/java/kafka/kafka-metadata-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/plexus-utils-3.3.0.jar:/usr/bin/../share/java/kafka/jakarta.activation-api-1.2.2.jar:/usr/bin/../share/java/kafka/argparse4j-0.7.0.jar:/usr/bin/../share/java/kafka/hk2-utils-2.6.1.jar:/usr/bin/../share/java/kafka/connect-api-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/connect-mirror-client-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.3.jar:/usr/bin/../share/java/kafka/javax.annotation-api-1.3.2.jar:/usr/bin/../share/java/kafka/jersey-hk2-2.39.1.jar:/usr/bin/../share/java/kafka/kafka-storage-api-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jetty-http-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/trogdor-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/maven-artifact-3.8.4.jar:/usr/bin/../share/java/kafka/connect-json-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/scala-java8-compat_2.13-1.0.2.jar:/usr/bin/../share/java/kafka/jetty-server-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/swagger-annotations-2.2.8.jar:/usr/bin/../share/java/kafka/jetty-util-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/commons-cli-1.4.jar:/usr/bin/../share/java/kafka/jetty-io-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/activation-1.1.1.jar:/usr/bin/../share/java/kafka/lz4-java-1.8.0.jar:/usr/bin/../share/java/kafka/kafka-shell-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/netty-common-4.1.96.Final.jar:/usr/bin/../share/java/kafka/jetty-client-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/jackson-module-scala_2.13-2.13.5.jar:/usr/bin/../share/java/kafka/connect-transforms-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jackson-core-2.13.5.jar:/usr/bin/../share/java/kafka/kafka_2.13-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/netty-codec-4.1.96.Final.jar:/usr/bin/../share/java/kafka/zookeeper-3.6.4.jar:/usr/bin/../share/java/kafka/kafka-streams-test-utils-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/hk2-api-2.6.1.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.39.1.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/reload4j-1.2.25.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.10.0.jar:/usr/bin/../share/java/kafka/netty-transport-classes-epoll-4.1.96.Final.jar:/usr/bin/../share/java/kafka/connect-mirror-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/kafka-streams-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/kafka-group-coordinator-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/connect-basic-auth-extension-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jersey-client-2.39.1.jar:/usr/bin/../share/java/kafka/kafka-tools-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/slf4j-reload4j-1.7.36.jar:/usr/bin/../share/java/kafka/jackson-dataformat-csv-2.13.5.jar:/usr/bin/../share/java/kafka/scala-library-2.13.10.jar:/usr/bin/../share/java/kafka/netty-handler-4.1.96.Final.jar:/usr/bin/../share/java/kafka/jakarta.validation-api-2.0.2.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.13.5.jar:/usr/bin/../share/java/kafka/audience-annotations-0.13.0.jar:/usr/bin/../share/java/kafka/hk2-locator-2.6.1.jar:/usr/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.6.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.13.5.jar:/usr/bin/../share/java/confluent-telemetry/* (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:23.363 | [2025-10-16 00:41:23,362] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:23.363 | [2025-10-16 00:41:23,362] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:23.363 | [2025-10-16 00:41:23,362] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:23.363 | [2025-10-16 00:41:23,362] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:23.363 | [2025-10-16 00:41:23,362] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:23.363 | [2025-10-16 00:41:23,362] INFO Client environment:os.version=6.6.87.1-microsoft-standard-WSL2 (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:23.363 | [2025-10-16 00:41:23,362] INFO Client environment:user.name=appuser (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:23.363 | [2025-10-16 00:41:23,362] INFO Client environment:user.home=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:23.363 | [2025-10-16 00:41:23,362] INFO Client environment:user.dir=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:23.363 | [2025-10-16 00:41:23,362] INFO Client environment:os.memory.free=1009MB (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:23.363 | [2025-10-16 00:41:23,362] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:23.363 | [2025-10-16 00:41:23,362] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:23.365 | [2025-10-16 00:41:23,364] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@13d73fa (org.apache.zookeeper.ZooKeeper)
2025-10-15 19:41:23.368 | [2025-10-16 00:41:23,368] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
2025-10-15 19:41:23.373 | [2025-10-16 00:41:23,373] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
2025-10-15 19:41:23.376 | [2025-10-16 00:41:23,375] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
2025-10-15 19:41:23.382 | [2025-10-16 00:41:23,381] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. (org.apache.zookeeper.ClientCnxn)
2025-10-15 19:41:23.387 | [2025-10-16 00:41:23,386] INFO Socket connection established, initiating session, client: /172.18.0.3:42168, server: zookeeper/172.18.0.2:2181 (org.apache.zookeeper.ClientCnxn)
2025-10-15 19:41:23.399 | [2025-10-16 00:41:23,398] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, session id = 0x1000011a3f20001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
2025-10-15 19:41:23.402 | [2025-10-16 00:41:23,401] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
2025-10-15 19:41:23.698 | [2025-10-16 00:41:23,697] INFO Cluster ID = DgiegCMhTNSyWQSymt96xQ (kafka.server.KafkaServer)
2025-10-15 19:41:23.701 | [2025-10-16 00:41:23,700] WARN No meta.properties file under dir /var/lib/kafka/data/meta.properties (kafka.server.BrokerMetadataCheckpoint)
2025-10-15 19:41:23.740 | [2025-10-16 00:41:23,740] INFO KafkaConfig values: 
2025-10-15 19:41:23.740 | 	advertised.listeners = PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
2025-10-15 19:41:23.740 | 	alter.config.policy.class.name = null
2025-10-15 19:41:23.740 | 	alter.log.dirs.replication.quota.window.num = 11
2025-10-15 19:41:23.740 | 	alter.log.dirs.replication.quota.window.size.seconds = 1
2025-10-15 19:41:23.740 | 	authorizer.class.name = 
2025-10-15 19:41:23.740 | 	auto.create.topics.enable = true
2025-10-15 19:41:23.740 | 	auto.include.jmx.reporter = true
2025-10-15 19:41:23.740 | 	auto.leader.rebalance.enable = true
2025-10-15 19:41:23.740 | 	background.threads = 10
2025-10-15 19:41:23.740 | 	broker.heartbeat.interval.ms = 2000
2025-10-15 19:41:23.740 | 	broker.id = 1
2025-10-15 19:41:23.740 | 	broker.id.generation.enable = true
2025-10-15 19:41:23.740 | 	broker.rack = null
2025-10-15 19:41:23.740 | 	broker.session.timeout.ms = 9000
2025-10-15 19:41:23.740 | 	client.quota.callback.class = null
2025-10-15 19:41:23.740 | 	compression.type = producer
2025-10-15 19:41:23.740 | 	connection.failed.authentication.delay.ms = 100
2025-10-15 19:41:23.740 | 	connections.max.idle.ms = 600000
2025-10-15 19:41:23.740 | 	connections.max.reauth.ms = 0
2025-10-15 19:41:23.740 | 	control.plane.listener.name = null
2025-10-15 19:41:23.740 | 	controlled.shutdown.enable = true
2025-10-15 19:41:23.740 | 	controlled.shutdown.max.retries = 3
2025-10-15 19:41:23.741 | 	controlled.shutdown.retry.backoff.ms = 5000
2025-10-15 19:41:23.741 | 	controller.listener.names = null
2025-10-15 19:41:23.741 | 	controller.quorum.append.linger.ms = 25
2025-10-15 19:41:23.741 | 	controller.quorum.election.backoff.max.ms = 1000
2025-10-15 19:41:23.741 | 	controller.quorum.election.timeout.ms = 1000
2025-10-15 19:41:23.741 | 	controller.quorum.fetch.timeout.ms = 2000
2025-10-15 19:41:23.741 | 	controller.quorum.request.timeout.ms = 2000
2025-10-15 19:41:23.741 | 	controller.quorum.retry.backoff.ms = 20
2025-10-15 19:41:23.741 | 	controller.quorum.voters = []
2025-10-15 19:41:23.741 | 	controller.quota.window.num = 11
2025-10-15 19:41:23.741 | 	controller.quota.window.size.seconds = 1
2025-10-15 19:41:23.741 | 	controller.socket.timeout.ms = 30000
2025-10-15 19:41:23.741 | 	create.topic.policy.class.name = null
2025-10-15 19:41:23.741 | 	default.replication.factor = 1
2025-10-15 19:41:23.741 | 	delegation.token.expiry.check.interval.ms = 3600000
2025-10-15 19:41:23.741 | 	delegation.token.expiry.time.ms = 86400000
2025-10-15 19:41:23.741 | 	delegation.token.master.key = null
2025-10-15 19:41:23.741 | 	delegation.token.max.lifetime.ms = 604800000
2025-10-15 19:41:23.741 | 	delegation.token.secret.key = null
2025-10-15 19:41:23.741 | 	delete.records.purgatory.purge.interval.requests = 1
2025-10-15 19:41:23.741 | 	delete.topic.enable = true
2025-10-15 19:41:23.741 | 	early.start.listeners = null
2025-10-15 19:41:23.741 | 	fetch.max.bytes = 57671680
2025-10-15 19:41:23.741 | 	fetch.purgatory.purge.interval.requests = 1000
2025-10-15 19:41:23.741 | 	group.consumer.assignors = []
2025-10-15 19:41:23.741 | 	group.consumer.heartbeat.interval.ms = 5000
2025-10-15 19:41:23.741 | 	group.consumer.max.heartbeat.interval.ms = 15000
2025-10-15 19:41:23.741 | 	group.consumer.max.session.timeout.ms = 60000
2025-10-15 19:41:23.741 | 	group.consumer.max.size = 2147483647
2025-10-15 19:41:23.741 | 	group.consumer.min.heartbeat.interval.ms = 5000
2025-10-15 19:41:23.741 | 	group.consumer.min.session.timeout.ms = 45000
2025-10-15 19:41:23.741 | 	group.consumer.session.timeout.ms = 45000
2025-10-15 19:41:23.741 | 	group.coordinator.new.enable = false
2025-10-15 19:41:23.741 | 	group.coordinator.threads = 1
2025-10-15 19:41:23.741 | 	group.initial.rebalance.delay.ms = 3000
2025-10-15 19:41:23.741 | 	group.max.session.timeout.ms = 1800000
2025-10-15 19:41:23.741 | 	group.max.size = 2147483647
2025-10-15 19:41:23.741 | 	group.min.session.timeout.ms = 6000
2025-10-15 19:41:23.741 | 	initial.broker.registration.timeout.ms = 60000
2025-10-15 19:41:23.741 | 	inter.broker.listener.name = PLAINTEXT_INTERNAL
2025-10-15 19:41:23.741 | 	inter.broker.protocol.version = 3.5-IV2
2025-10-15 19:41:23.741 | 	kafka.metrics.polling.interval.secs = 10
2025-10-15 19:41:23.741 | 	kafka.metrics.reporters = []
2025-10-15 19:41:23.741 | 	leader.imbalance.check.interval.seconds = 300
2025-10-15 19:41:23.741 | 	leader.imbalance.per.broker.percentage = 10
2025-10-15 19:41:23.741 | 	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
2025-10-15 19:41:23.741 | 	listeners = PLAINTEXT://0.0.0.0:9092,PLAINTEXT_INTERNAL://0.0.0.0:29092
2025-10-15 19:41:23.741 | 	log.cleaner.backoff.ms = 15000
2025-10-15 19:41:23.741 | 	log.cleaner.dedupe.buffer.size = 134217728
2025-10-15 19:41:23.741 | 	log.cleaner.delete.retention.ms = 86400000
2025-10-15 19:41:23.741 | 	log.cleaner.enable = true
2025-10-15 19:41:23.741 | 	log.cleaner.io.buffer.load.factor = 0.9
2025-10-15 19:41:23.741 | 	log.cleaner.io.buffer.size = 524288
2025-10-15 19:41:23.741 | 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
2025-10-15 19:41:23.741 | 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
2025-10-15 19:41:23.741 | 	log.cleaner.min.cleanable.ratio = 0.5
2025-10-15 19:41:23.741 | 	log.cleaner.min.compaction.lag.ms = 0
2025-10-15 19:41:23.741 | 	log.cleaner.threads = 1
2025-10-15 19:41:23.741 | 	log.cleanup.policy = [delete]
2025-10-15 19:41:23.741 | 	log.dir = /tmp/kafka-logs
2025-10-15 19:41:23.741 | 	log.dirs = /var/lib/kafka/data
2025-10-15 19:41:23.741 | 	log.flush.interval.messages = 9223372036854775807
2025-10-15 19:41:23.741 | 	log.flush.interval.ms = null
2025-10-15 19:41:23.741 | 	log.flush.offset.checkpoint.interval.ms = 60000
2025-10-15 19:41:23.741 | 	log.flush.scheduler.interval.ms = 9223372036854775807
2025-10-15 19:41:23.741 | 	log.flush.start.offset.checkpoint.interval.ms = 60000
2025-10-15 19:41:23.741 | 	log.index.interval.bytes = 4096
2025-10-15 19:41:23.741 | 	log.index.size.max.bytes = 10485760
2025-10-15 19:41:23.741 | 	log.message.downconversion.enable = true
2025-10-15 19:41:23.741 | 	log.message.format.version = 3.0-IV1
2025-10-15 19:41:23.741 | 	log.message.timestamp.difference.max.ms = 9223372036854775807
2025-10-15 19:41:23.741 | 	log.message.timestamp.type = CreateTime
2025-10-15 19:41:23.741 | 	log.preallocate = false
2025-10-15 19:41:23.741 | 	log.retention.bytes = -1
2025-10-15 19:41:23.741 | 	log.retention.check.interval.ms = 300000
2025-10-15 19:41:23.741 | 	log.retention.hours = 168
2025-10-15 19:41:23.741 | 	log.retention.minutes = null
2025-10-15 19:41:23.741 | 	log.retention.ms = null
2025-10-15 19:41:23.741 | 	log.roll.hours = 168
2025-10-15 19:41:23.741 | 	log.roll.jitter.hours = 0
2025-10-15 19:41:23.741 | 	log.roll.jitter.ms = null
2025-10-15 19:41:23.741 | 	log.roll.ms = null
2025-10-15 19:41:23.741 | 	log.segment.bytes = 1073741824
2025-10-15 19:41:23.741 | 	log.segment.delete.delay.ms = 60000
2025-10-15 19:41:23.741 | 	max.connection.creation.rate = 2147483647
2025-10-15 19:41:23.741 | 	max.connections = 2147483647
2025-10-15 19:41:23.741 | 	max.connections.per.ip = 2147483647
2025-10-15 19:41:23.741 | 	max.connections.per.ip.overrides = 
2025-10-15 19:41:23.741 | 	max.incremental.fetch.session.cache.slots = 1000
2025-10-15 19:41:23.741 | 	message.max.bytes = 1048588
2025-10-15 19:41:23.741 | 	metadata.log.dir = null
2025-10-15 19:41:23.741 | 	metadata.log.max.record.bytes.between.snapshots = 20971520
2025-10-15 19:41:23.741 | 	metadata.log.max.snapshot.interval.ms = 3600000
2025-10-15 19:41:23.741 | 	metadata.log.segment.bytes = 1073741824
2025-10-15 19:41:23.741 | 	metadata.log.segment.min.bytes = 8388608
2025-10-15 19:41:23.741 | 	metadata.log.segment.ms = 604800000
2025-10-15 19:41:23.741 | 	metadata.max.idle.interval.ms = 500
2025-10-15 19:41:23.741 | 	metadata.max.retention.bytes = 104857600
2025-10-15 19:41:23.741 | 	metadata.max.retention.ms = 604800000
2025-10-15 19:41:23.741 | 	metric.reporters = []
2025-10-15 19:41:23.741 | 	metrics.num.samples = 2
2025-10-15 19:41:23.741 | 	metrics.recording.level = INFO
2025-10-15 19:41:23.741 | 	metrics.sample.window.ms = 30000
2025-10-15 19:41:23.741 | 	min.insync.replicas = 1
2025-10-15 19:41:23.741 | 	node.id = 1
2025-10-15 19:41:23.741 | 	num.io.threads = 8
2025-10-15 19:41:23.741 | 	num.network.threads = 3
2025-10-15 19:41:23.741 | 	num.partitions = 1
2025-10-15 19:41:23.741 | 	num.recovery.threads.per.data.dir = 1
2025-10-15 19:41:23.741 | 	num.replica.alter.log.dirs.threads = null
2025-10-15 19:41:23.741 | 	num.replica.fetchers = 1
2025-10-15 19:41:23.741 | 	offset.metadata.max.bytes = 4096
2025-10-15 19:41:23.741 | 	offsets.commit.required.acks = -1
2025-10-15 19:41:23.741 | 	offsets.commit.timeout.ms = 5000
2025-10-15 19:41:23.741 | 	offsets.load.buffer.size = 5242880
2025-10-15 19:41:23.741 | 	offsets.retention.check.interval.ms = 600000
2025-10-15 19:41:23.741 | 	offsets.retention.minutes = 10080
2025-10-15 19:41:23.741 | 	offsets.topic.compression.codec = 0
2025-10-15 19:41:23.741 | 	offsets.topic.num.partitions = 50
2025-10-15 19:41:23.741 | 	offsets.topic.replication.factor = 1
2025-10-15 19:41:23.741 | 	offsets.topic.segment.bytes = 104857600
2025-10-15 19:41:23.741 | 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
2025-10-15 19:41:23.741 | 	password.encoder.iterations = 4096
2025-10-15 19:41:23.741 | 	password.encoder.key.length = 128
2025-10-15 19:41:23.741 | 	password.encoder.keyfactory.algorithm = null
2025-10-15 19:41:23.741 | 	password.encoder.old.secret = null
2025-10-15 19:41:23.741 | 	password.encoder.secret = null
2025-10-15 19:41:23.741 | 	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
2025-10-15 19:41:23.741 | 	process.roles = []
2025-10-15 19:41:23.741 | 	producer.id.expiration.check.interval.ms = 600000
2025-10-15 19:41:23.741 | 	producer.id.expiration.ms = 86400000
2025-10-15 19:41:23.741 | 	producer.purgatory.purge.interval.requests = 1000
2025-10-15 19:41:23.741 | 	queued.max.request.bytes = -1
2025-10-15 19:41:23.741 | 	queued.max.requests = 500
2025-10-15 19:41:23.741 | 	quota.window.num = 11
2025-10-15 19:41:23.741 | 	quota.window.size.seconds = 1
2025-10-15 19:41:23.741 | 	remote.log.index.file.cache.total.size.bytes = 1073741824
2025-10-15 19:41:23.741 | 	remote.log.manager.task.interval.ms = 30000
2025-10-15 19:41:23.741 | 	remote.log.manager.task.retry.backoff.max.ms = 30000
2025-10-15 19:41:23.741 | 	remote.log.manager.task.retry.backoff.ms = 500
2025-10-15 19:41:23.741 | 	remote.log.manager.task.retry.jitter = 0.2
2025-10-15 19:41:23.741 | 	remote.log.manager.thread.pool.size = 10
2025-10-15 19:41:23.741 | 	remote.log.metadata.manager.class.name = null
2025-10-15 19:41:23.741 | 	remote.log.metadata.manager.class.path = null
2025-10-15 19:41:23.741 | 	remote.log.metadata.manager.impl.prefix = null
2025-10-15 19:41:23.741 | 	remote.log.metadata.manager.listener.name = null
2025-10-15 19:41:23.741 | 	remote.log.reader.max.pending.tasks = 100
2025-10-15 19:41:23.741 | 	remote.log.reader.threads = 10
2025-10-15 19:41:23.741 | 	remote.log.storage.manager.class.name = null
2025-10-15 19:41:23.741 | 	remote.log.storage.manager.class.path = null
2025-10-15 19:41:23.741 | 	remote.log.storage.manager.impl.prefix = null
2025-10-15 19:41:23.741 | 	remote.log.storage.system.enable = false
2025-10-15 19:41:23.741 | 	replica.fetch.backoff.ms = 1000
2025-10-15 19:41:23.741 | 	replica.fetch.max.bytes = 1048576
2025-10-15 19:41:23.741 | 	replica.fetch.min.bytes = 1
2025-10-15 19:41:23.741 | 	replica.fetch.response.max.bytes = 10485760
2025-10-15 19:41:23.741 | 	replica.fetch.wait.max.ms = 500
2025-10-15 19:41:23.741 | 	replica.high.watermark.checkpoint.interval.ms = 5000
2025-10-15 19:41:23.741 | 	replica.lag.time.max.ms = 30000
2025-10-15 19:41:23.741 | 	replica.selector.class = null
2025-10-15 19:41:23.741 | 	replica.socket.receive.buffer.bytes = 65536
2025-10-15 19:41:23.741 | 	replica.socket.timeout.ms = 30000
2025-10-15 19:41:23.741 | 	replication.quota.window.num = 11
2025-10-15 19:41:23.741 | 	replication.quota.window.size.seconds = 1
2025-10-15 19:41:23.741 | 	request.timeout.ms = 30000
2025-10-15 19:41:23.741 | 	reserved.broker.max.id = 1000
2025-10-15 19:41:23.741 | 	sasl.client.callback.handler.class = null
2025-10-15 19:41:23.741 | 	sasl.enabled.mechanisms = [GSSAPI]
2025-10-15 19:41:23.741 | 	sasl.jaas.config = null
2025-10-15 19:41:23.741 | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
2025-10-15 19:41:23.741 | 	sasl.kerberos.min.time.before.relogin = 60000
2025-10-15 19:41:23.741 | 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
2025-10-15 19:41:23.741 | 	sasl.kerberos.service.name = null
2025-10-15 19:41:23.741 | 	sasl.kerberos.ticket.renew.jitter = 0.05
2025-10-15 19:41:23.741 | 	sasl.kerberos.ticket.renew.window.factor = 0.8
2025-10-15 19:41:23.741 | 	sasl.login.callback.handler.class = null
2025-10-15 19:41:23.741 | 	sasl.login.class = null
2025-10-15 19:41:23.741 | 	sasl.login.connect.timeout.ms = null
2025-10-15 19:41:23.741 | 	sasl.login.read.timeout.ms = null
2025-10-15 19:41:23.741 | 	sasl.login.refresh.buffer.seconds = 300
2025-10-15 19:41:23.741 | 	sasl.login.refresh.min.period.seconds = 60
2025-10-15 19:41:23.741 | 	sasl.login.refresh.window.factor = 0.8
2025-10-15 19:41:23.741 | 	sasl.login.refresh.window.jitter = 0.05
2025-10-15 19:41:23.741 | 	sasl.login.retry.backoff.max.ms = 10000
2025-10-15 19:41:23.741 | 	sasl.login.retry.backoff.ms = 100
2025-10-15 19:41:23.741 | 	sasl.mechanism.controller.protocol = GSSAPI
2025-10-15 19:41:23.741 | 	sasl.mechanism.inter.broker.protocol = GSSAPI
2025-10-15 19:41:23.741 | 	sasl.oauthbearer.clock.skew.seconds = 30
2025-10-15 19:41:23.741 | 	sasl.oauthbearer.expected.audience = null
2025-10-15 19:41:23.741 | 	sasl.oauthbearer.expected.issuer = null
2025-10-15 19:41:23.741 | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
2025-10-15 19:41:23.741 | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
2025-10-15 19:41:23.741 | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
2025-10-15 19:41:23.741 | 	sasl.oauthbearer.jwks.endpoint.url = null
2025-10-15 19:41:23.741 | 	sasl.oauthbearer.scope.claim.name = scope
2025-10-15 19:41:23.741 | 	sasl.oauthbearer.sub.claim.name = sub
2025-10-15 19:41:23.741 | 	sasl.oauthbearer.token.endpoint.url = null
2025-10-15 19:41:23.741 | 	sasl.server.callback.handler.class = null
2025-10-15 19:41:23.741 | 	sasl.server.max.receive.size = 524288
2025-10-15 19:41:23.741 | 	security.inter.broker.protocol = PLAINTEXT
2025-10-15 19:41:23.741 | 	security.providers = null
2025-10-15 19:41:23.741 | 	server.max.startup.time.ms = 9223372036854775807
2025-10-15 19:41:23.741 | 	socket.connection.setup.timeout.max.ms = 30000
2025-10-15 19:41:23.741 | 	socket.connection.setup.timeout.ms = 10000
2025-10-15 19:41:23.741 | 	socket.listen.backlog.size = 50
2025-10-15 19:41:23.741 | 	socket.receive.buffer.bytes = 102400
2025-10-15 19:41:23.741 | 	socket.request.max.bytes = 104857600
2025-10-15 19:41:23.741 | 	socket.send.buffer.bytes = 102400
2025-10-15 19:41:23.741 | 	ssl.cipher.suites = []
2025-10-15 19:41:23.741 | 	ssl.client.auth = none
2025-10-15 19:41:23.741 | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
2025-10-15 19:41:23.741 | 	ssl.endpoint.identification.algorithm = https
2025-10-15 19:41:23.741 | 	ssl.engine.factory.class = null
2025-10-15 19:41:23.741 | 	ssl.key.password = null
2025-10-15 19:41:23.741 | 	ssl.keymanager.algorithm = SunX509
2025-10-15 19:41:23.741 | 	ssl.keystore.certificate.chain = null
2025-10-15 19:41:23.741 | 	ssl.keystore.key = null
2025-10-15 19:41:23.741 | 	ssl.keystore.location = null
2025-10-15 19:41:23.741 | 	ssl.keystore.password = null
2025-10-15 19:41:23.741 | 	ssl.keystore.type = JKS
2025-10-15 19:41:23.741 | 	ssl.principal.mapping.rules = DEFAULT
2025-10-15 19:41:23.741 | 	ssl.protocol = TLSv1.3
2025-10-15 19:41:23.741 | 	ssl.provider = null
2025-10-15 19:41:23.741 | 	ssl.secure.random.implementation = null
2025-10-15 19:41:23.741 | 	ssl.trustmanager.algorithm = PKIX
2025-10-15 19:41:23.741 | 	ssl.truststore.certificates = null
2025-10-15 19:41:23.741 | 	ssl.truststore.location = null
2025-10-15 19:41:23.741 | 	ssl.truststore.password = null
2025-10-15 19:41:23.741 | 	ssl.truststore.type = JKS
2025-10-15 19:41:23.741 | 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
2025-10-15 19:41:23.741 | 	transaction.max.timeout.ms = 900000
2025-10-15 19:41:23.741 | 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
2025-10-15 19:41:23.741 | 	transaction.state.log.load.buffer.size = 5242880
2025-10-15 19:41:23.741 | 	transaction.state.log.min.isr = 1
2025-10-15 19:41:23.741 | 	transaction.state.log.num.partitions = 50
2025-10-15 19:41:23.741 | 	transaction.state.log.replication.factor = 1
2025-10-15 19:41:23.741 | 	transaction.state.log.segment.bytes = 104857600
2025-10-15 19:41:23.741 | 	transactional.id.expiration.ms = 604800000
2025-10-15 19:41:23.741 | 	unclean.leader.election.enable = false
2025-10-15 19:41:23.741 | 	unstable.api.versions.enable = false
2025-10-15 19:41:23.741 | 	zookeeper.clientCnxnSocket = null
2025-10-15 19:41:23.741 | 	zookeeper.connect = zookeeper:2181
2025-10-15 19:41:23.741 | 	zookeeper.connection.timeout.ms = null
2025-10-15 19:41:23.741 | 	zookeeper.max.in.flight.requests = 10
2025-10-15 19:41:23.741 | 	zookeeper.metadata.migration.enable = false
2025-10-15 19:41:23.741 | 	zookeeper.session.timeout.ms = 18000
2025-10-15 19:41:23.741 | 	zookeeper.set.acl = false
2025-10-15 19:41:23.741 | 	zookeeper.ssl.cipher.suites = null
2025-10-15 19:41:23.741 | 	zookeeper.ssl.client.enable = false
2025-10-15 19:41:23.741 | 	zookeeper.ssl.crl.enable = false
2025-10-15 19:41:23.741 | 	zookeeper.ssl.enabled.protocols = null
2025-10-15 19:41:23.741 | 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
2025-10-15 19:41:23.741 | 	zookeeper.ssl.keystore.location = null
2025-10-15 19:41:23.741 | 	zookeeper.ssl.keystore.password = null
2025-10-15 19:41:23.741 | 	zookeeper.ssl.keystore.type = null
2025-10-15 19:41:23.741 | 	zookeeper.ssl.ocsp.enable = false
2025-10-15 19:41:23.741 | 	zookeeper.ssl.protocol = TLSv1.2
2025-10-15 19:41:23.741 | 	zookeeper.ssl.truststore.location = null
2025-10-15 19:41:23.741 | 	zookeeper.ssl.truststore.password = null
2025-10-15 19:41:23.741 | 	zookeeper.ssl.truststore.type = null
2025-10-15 19:41:23.741 |  (kafka.server.KafkaConfig)
2025-10-15 19:41:23.770 | [2025-10-16 00:41:23,769] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 19:41:23.771 | [2025-10-16 00:41:23,770] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 19:41:23.772 | [2025-10-16 00:41:23,772] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 19:41:23.775 | [2025-10-16 00:41:23,774] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 19:41:23.806 | [2025-10-16 00:41:23,806] INFO Loading logs from log dirs ArraySeq(/var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 19:41:23.809 | [2025-10-16 00:41:23,809] INFO No logs found to be loaded in /var/lib/kafka/data (kafka.log.LogManager)
2025-10-15 19:41:23.818 | [2025-10-16 00:41:23,818] INFO Loaded 0 logs in 12ms (kafka.log.LogManager)
2025-10-15 19:41:23.820 | [2025-10-16 00:41:23,819] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
2025-10-15 19:41:23.821 | [2025-10-16 00:41:23,821] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
2025-10-15 19:41:23.831 | [2025-10-16 00:41:23,831] INFO Starting the log cleaner (kafka.log.LogCleaner)
2025-10-15 19:41:23.946 | [2025-10-16 00:41:23,945] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
2025-10-15 19:41:23.966 | [2025-10-16 00:41:23,966] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-10-15 19:41:23.983 | [2025-10-16 00:41:23,983] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
2025-10-15 19:41:24.011 | [2025-10-16 00:41:24,010] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
2025-10-15 19:41:24.360 | [2025-10-16 00:41:24,359] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
2025-10-15 19:41:24.387 | [2025-10-16 00:41:24,387] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
2025-10-15 19:41:24.388 | [2025-10-16 00:41:24,387] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
2025-10-15 19:41:24.392 | [2025-10-16 00:41:24,392] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT_INTERNAL) (kafka.network.SocketServer)
2025-10-15 19:41:24.400 | [2025-10-16 00:41:24,399] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
2025-10-15 19:41:24.422 | [2025-10-16 00:41:24,421] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 19:41:24.424 | [2025-10-16 00:41:24,423] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 19:41:24.426 | [2025-10-16 00:41:24,425] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 19:41:24.427 | [2025-10-16 00:41:24,427] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 19:41:24.440 | [2025-10-16 00:41:24,440] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-10-15 19:41:24.460 | [2025-10-16 00:41:24,460] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
2025-10-15 19:41:24.482 | [2025-10-16 00:41:24,482] INFO Stat of the created znode at /brokers/ids/1 is: 27,27,1760575284472,1760575284472,1,0,0,72057669802917889,270,0,27
2025-10-15 19:41:24.482 |  (kafka.zk.KafkaZkClient)
2025-10-15 19:41:24.483 | [2025-10-16 00:41:24,482] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092, czxid (broker epoch): 27 (kafka.zk.KafkaZkClient)
2025-10-15 19:41:24.542 | [2025-10-16 00:41:24,541] INFO [ControllerEventThread controllerId=1] Starting (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-10-15 19:41:24.548 | [2025-10-16 00:41:24,548] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 19:41:24.555 | [2025-10-16 00:41:24,554] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 19:41:24.555 | [2025-10-16 00:41:24,555] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 19:41:24.564 | [2025-10-16 00:41:24,563] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
2025-10-15 19:41:24.570 | [2025-10-16 00:41:24,569] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:41:24.575 | [2025-10-16 00:41:24,574] INFO [Controller id=1] 1 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1 (kafka.controller.KafkaController)
2025-10-15 19:41:24.578 | [2025-10-16 00:41:24,578] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:41:24.580 | [2025-10-16 00:41:24,580] INFO [Controller id=1] Creating FeatureZNode at path: /feature with contents: FeatureZNode(2,Enabled,Map()) (kafka.controller.KafkaController)
2025-10-15 19:41:24.588 | [2025-10-16 00:41:24,587] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
2025-10-15 19:41:24.599 | [2025-10-16 00:41:24,598] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
2025-10-15 19:41:24.605 | [2025-10-16 00:41:24,604] INFO [TxnMarkerSenderThread-1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-10-15 19:41:24.605 | [2025-10-16 00:41:24,604] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
2025-10-15 19:41:24.620 | [2025-10-16 00:41:24,620] INFO [MetadataCache brokerId=1] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0). (kafka.server.metadata.ZkMetadataCache)
2025-10-15 19:41:24.620 | [2025-10-16 00:41:24,620] INFO [Controller id=1] Registering handlers (kafka.controller.KafkaController)
2025-10-15 19:41:24.628 | [2025-10-16 00:41:24,627] INFO [Controller id=1] Deleting log dir event notifications (kafka.controller.KafkaController)
2025-10-15 19:41:24.631 | [2025-10-16 00:41:24,631] INFO [Controller id=1] Deleting isr change notifications (kafka.controller.KafkaController)
2025-10-15 19:41:24.636 | [2025-10-16 00:41:24,635] INFO [Controller id=1] Initializing controller context (kafka.controller.KafkaController)
2025-10-15 19:41:24.643 | [2025-10-16 00:41:24,643] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 19:41:24.655 | [2025-10-16 00:41:24,655] INFO [Controller id=1] Initialized broker epochs cache: HashMap(1 -> 27) (kafka.controller.KafkaController)
2025-10-15 19:41:24.661 | [2025-10-16 00:41:24,661] DEBUG [Controller id=1] Register BrokerModifications handler for Set(1) (kafka.controller.KafkaController)
2025-10-15 19:41:24.668 | [2025-10-16 00:41:24,668] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-10-15 19:41:24.669 | [2025-10-16 00:41:24,668] DEBUG [Channel manager on controller 1]: Controller 1 trying to connect to broker 1 (kafka.controller.ControllerChannelManager)
2025-10-15 19:41:24.680 | [2025-10-16 00:41:24,680] INFO [RequestSendThread controllerId=1] Starting (kafka.controller.RequestSendThread)
2025-10-15 19:41:24.682 | [2025-10-16 00:41:24,682] INFO [Controller id=1] Currently active brokers in the cluster: Set(1) (kafka.controller.KafkaController)
2025-10-15 19:41:24.683 | [2025-10-16 00:41:24,682] INFO [Controller id=1] Currently shutting brokers in the cluster: HashSet() (kafka.controller.KafkaController)
2025-10-15 19:41:24.683 | [2025-10-16 00:41:24,683] INFO [Controller id=1] Current list of topics in the cluster: HashSet() (kafka.controller.KafkaController)
2025-10-15 19:41:24.683 | [2025-10-16 00:41:24,683] INFO [Controller id=1] Fetching topic deletions in progress (kafka.controller.KafkaController)
2025-10-15 19:41:24.687 | [2025-10-16 00:41:24,687] INFO [Controller id=1] List of topics to be deleted:  (kafka.controller.KafkaController)
2025-10-15 19:41:24.688 | [2025-10-16 00:41:24,687] INFO [Controller id=1] List of topics ineligible for deletion:  (kafka.controller.KafkaController)
2025-10-15 19:41:24.688 | [2025-10-16 00:41:24,688] INFO [Controller id=1] Initializing topic deletion manager (kafka.controller.KafkaController)
2025-10-15 19:41:24.688 | [2025-10-16 00:41:24,688] INFO [Topic Deletion Manager 1] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet() (kafka.controller.TopicDeletionManager)
2025-10-15 19:41:24.689 | [2025-10-16 00:41:24,689] INFO [Controller id=1] Sending update metadata request (kafka.controller.KafkaController)
2025-10-15 19:41:24.689 | [2025-10-16 00:41:24,689] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
2025-10-15 19:41:24.694 | [2025-10-16 00:41:24,694] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
2025-10-15 19:41:24.695 | [2025-10-16 00:41:24,694] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to brokers HashSet(1) for 0 partitions (state.change.logger)
2025-10-15 19:41:24.699 | [2025-10-16 00:41:24,698] INFO Awaiting socket connections on 0.0.0.0:29092. (kafka.network.DataPlaneAcceptor)
2025-10-15 19:41:24.712 | [2025-10-16 00:41:24,712] INFO [ReplicaStateMachine controllerId=1] Initializing replica state (kafka.controller.ZkReplicaStateMachine)
2025-10-15 19:41:24.713 | [2025-10-16 00:41:24,712] INFO Kafka version: 7.5.0-ccs (org.apache.kafka.common.utils.AppInfoParser)
2025-10-15 19:41:24.713 | [2025-10-16 00:41:24,712] INFO Kafka commitId: ff3c201baa948d97889dc26c99d7cdc23d038f2e (org.apache.kafka.common.utils.AppInfoParser)
2025-10-15 19:41:24.713 | [2025-10-16 00:41:24,712] INFO Kafka startTimeMs: 1760575284703 (org.apache.kafka.common.utils.AppInfoParser)
2025-10-15 19:41:24.713 | [2025-10-16 00:41:24,713] INFO [ReplicaStateMachine controllerId=1] Triggering online replica state changes (kafka.controller.ZkReplicaStateMachine)
2025-10-15 19:41:24.715 | [2025-10-16 00:41:24,714] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
2025-10-15 19:41:24.719 | [2025-10-16 00:41:24,718] INFO [ReplicaStateMachine controllerId=1] Triggering offline replica state changes (kafka.controller.ZkReplicaStateMachine)
2025-10-15 19:41:24.720 | [2025-10-16 00:41:24,719] DEBUG [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> HashMap() (kafka.controller.ZkReplicaStateMachine)
2025-10-15 19:41:24.720 | [2025-10-16 00:41:24,720] INFO [PartitionStateMachine controllerId=1] Initializing partition state (kafka.controller.ZkPartitionStateMachine)
2025-10-15 19:41:24.723 | [2025-10-16 00:41:24,721] INFO [PartitionStateMachine controllerId=1] Triggering online partition state changes (kafka.controller.ZkPartitionStateMachine)
2025-10-15 19:41:24.728 | [2025-10-16 00:41:24,727] INFO [RequestSendThread controllerId=1] Controller 1 connected to kafka:29092 (id: 1 rack: null) for sending state change requests (kafka.controller.RequestSendThread)
2025-10-15 19:41:24.732 | [2025-10-16 00:41:24,732] DEBUG [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> HashMap() (kafka.controller.ZkPartitionStateMachine)
2025-10-15 19:41:24.733 | [2025-10-16 00:41:24,732] INFO [Controller id=1] Ready to serve as the new controller with epoch 1 (kafka.controller.KafkaController)
2025-10-15 19:41:24.743 | [2025-10-16 00:41:24,743] INFO [Controller id=1] Partitions undergoing preferred replica election:  (kafka.controller.KafkaController)
2025-10-15 19:41:24.743 | [2025-10-16 00:41:24,743] INFO [Controller id=1] Partitions that completed preferred replica election:  (kafka.controller.KafkaController)
2025-10-15 19:41:24.744 | [2025-10-16 00:41:24,744] INFO [Controller id=1] Skipping preferred replica election for partitions due to topic deletion:  (kafka.controller.KafkaController)
2025-10-15 19:41:24.744 | [2025-10-16 00:41:24,744] INFO [Controller id=1] Resuming preferred replica election for partitions:  (kafka.controller.KafkaController)
2025-10-15 19:41:24.746 | [2025-10-16 00:41:24,746] INFO [Controller id=1] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered (kafka.controller.KafkaController)
2025-10-15 19:41:24.763 | [2025-10-16 00:41:24,762] INFO [Controller id=1] Starting the controller scheduler (kafka.controller.KafkaController)
2025-10-15 19:41:24.789 | [2025-10-16 00:41:24,788] TRACE [Controller id=1 epoch=1] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 0 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-10-15 19:41:24.806 | [2025-10-16 00:41:24,806] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Recorded new controller, from now on will use node kafka:29092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
2025-10-15 19:41:24.832 | [2025-10-16 00:41:24,832] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Recorded new controller, from now on will use node kafka:29092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
2025-10-15 19:41:29.764 | [2025-10-16 00:41:29,763] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-15 19:41:29.764 | [2025-10-16 00:41:29,764] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-15 19:44:15.960 | [2025-10-16 00:44:15,950] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:39148-10); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 19:44:15.960 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 19:44:15.960 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 19:44:15.960 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 19:44:15.960 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 19:44:15.960 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 19:44:15.960 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 19:44:15.960 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 19:44:15.960 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 19:44:15.960 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 19:44:15.961 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 19:44:15.967 | [2025-10-16 00:44:15,965] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:39160-10); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 19:44:15.967 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 19:44:15.967 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 19:44:15.967 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 19:44:15.967 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 19:44:15.967 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 19:44:15.967 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 19:44:15.967 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 19:44:15.967 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 19:44:15.967 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 19:44:15.967 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 19:44:15.972 | [2025-10-16 00:44:15,972] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:39162-10); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 19:44:15.972 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 19:44:15.972 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 19:44:15.972 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 19:44:15.972 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 19:44:15.972 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 19:44:15.972 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 19:44:15.972 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 19:44:15.972 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 19:44:15.972 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 19:44:15.972 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 19:44:15.977 | [2025-10-16 00:44:15,976] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:39178-11); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 19:44:15.977 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 19:44:15.977 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 19:44:15.977 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 19:44:15.977 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 19:44:15.977 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 19:44:15.977 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 19:44:15.977 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 19:44:15.977 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 19:44:15.977 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 19:44:15.977 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 19:44:15.981 | [2025-10-16 00:44:15,981] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:39190-11); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 19:44:15.981 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 19:44:15.981 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 19:44:15.981 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 19:44:15.981 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 19:44:15.981 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 19:44:15.981 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 19:44:15.981 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 19:44:15.981 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 19:44:15.981 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 19:44:15.981 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 19:44:15.986 | [2025-10-16 00:44:15,985] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:39202-11); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 19:44:15.986 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 19:44:15.986 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 19:44:15.986 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 19:44:15.986 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 19:44:15.986 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 19:44:15.986 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 19:44:15.986 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 19:44:15.986 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 19:44:15.986 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 19:44:15.986 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 19:44:15.990 | [2025-10-16 00:44:15,990] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:39210-12); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 19:44:15.990 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 19:44:15.990 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 19:44:15.990 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 19:44:15.990 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 19:44:15.990 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 19:44:15.990 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 19:44:15.990 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 19:44:15.990 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 19:44:15.990 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 19:44:15.990 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 19:44:15.994 | [2025-10-16 00:44:15,993] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:39218-12); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 19:44:15.994 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 19:44:15.994 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 19:44:15.994 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 19:44:15.994 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 19:44:15.994 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 19:44:15.994 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 19:44:15.994 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 19:44:15.994 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 19:44:15.994 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 19:44:15.994 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 19:44:15.998 | [2025-10-16 00:44:15,998] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:39222-12); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 19:44:15.998 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 19:44:15.998 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 19:44:15.998 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 19:44:15.998 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 19:44:15.998 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 19:44:15.998 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 19:44:15.998 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 19:44:15.998 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 19:44:15.998 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 19:44:15.998 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 19:44:16.003 | [2025-10-16 00:44:16,002] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:39230-13); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 19:44:16.003 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 19:44:16.003 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 19:44:16.003 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 19:44:16.003 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 19:44:16.003 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 19:44:16.003 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 19:44:16.003 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 19:44:16.003 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 19:44:16.003 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 19:44:16.003 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 19:44:17.893 | [2025-10-16 00:44:17,892] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:39234-13); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 19:44:17.893 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 19:44:17.893 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 19:44:17.893 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 19:44:17.893 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 19:44:17.893 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 19:44:17.893 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 19:44:17.893 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 19:44:17.893 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 19:44:17.893 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 19:44:17.893 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 19:44:17.901 | [2025-10-16 00:44:17,900] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:39238-13); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 19:44:17.901 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 19:44:17.901 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 19:44:17.901 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 19:44:17.901 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 19:44:17.901 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 19:44:17.901 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 19:44:17.901 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 19:44:17.901 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 19:44:17.901 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 19:44:17.901 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 19:44:17.909 | [2025-10-16 00:44:17,908] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:39240-14); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 19:44:17.910 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 19:44:17.910 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 19:44:17.910 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 19:44:17.910 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 19:44:17.910 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 19:44:17.910 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 19:44:17.910 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 19:44:17.910 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 19:44:17.910 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 19:44:17.910 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 19:44:17.918 | [2025-10-16 00:44:17,917] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:39250-14); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 19:44:17.918 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 19:44:17.918 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 19:44:17.918 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 19:44:17.918 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 19:44:17.918 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 19:44:17.918 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 19:44:17.918 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 19:44:17.918 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 19:44:17.918 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 19:44:17.918 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 19:44:17.926 | [2025-10-16 00:44:17,925] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:39266-14); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 19:44:17.926 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 19:44:17.926 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 19:44:17.926 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 19:44:17.926 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 19:44:17.926 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 19:44:17.926 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 19:44:17.926 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 19:44:17.926 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 19:44:17.926 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 19:44:17.926 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 19:44:17.934 | [2025-10-16 00:44:17,933] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:39270-15); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 19:44:17.934 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 19:44:17.934 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 19:44:17.934 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 19:44:17.934 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 19:44:17.934 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 19:44:17.934 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 19:44:17.934 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 19:44:17.934 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 19:44:17.934 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 19:44:17.934 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 19:44:17.941 | [2025-10-16 00:44:17,940] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:39272-15); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 19:44:17.941 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 19:44:17.941 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 19:44:17.941 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 19:44:17.941 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 19:44:17.941 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 19:44:17.941 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 19:44:17.941 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 19:44:17.941 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 19:44:17.941 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 19:44:17.941 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 19:44:17.947 | [2025-10-16 00:44:17,946] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:39286-15); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 19:44:17.947 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 19:44:17.947 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 19:44:17.947 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 19:44:17.947 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 19:44:17.947 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 19:44:17.947 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 19:44:17.947 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 19:44:17.947 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 19:44:17.947 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 19:44:17.947 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 19:44:17.952 | [2025-10-16 00:44:17,951] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:39302-16); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 19:44:17.952 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 19:44:17.952 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 19:44:17.952 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 19:44:17.952 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 19:44:17.952 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 19:44:17.952 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 19:44:17.952 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 19:44:17.952 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 19:44:17.952 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 19:44:17.952 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 19:44:17.957 | [2025-10-16 00:44:17,955] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:39306-16); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 19:44:17.957 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 19:44:17.957 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 19:44:17.957 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 19:44:17.957 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 19:44:17.957 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 19:44:17.957 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 19:44:17.957 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 19:44:17.957 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 19:44:17.957 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 19:44:17.957 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 19:44:18.427 | [2025-10-16 00:44:18,426] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:39310-16); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 19:44:18.427 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 19:44:18.427 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 19:44:18.427 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 19:44:18.427 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 19:44:18.427 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 19:44:18.427 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 19:44:18.427 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 19:44:18.427 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 19:44:18.427 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 19:44:18.427 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 19:44:18.434 | [2025-10-16 00:44:18,434] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:39318-17); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 19:44:18.434 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 19:44:18.434 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 19:44:18.434 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 19:44:18.434 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 19:44:18.434 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 19:44:18.434 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 19:44:18.434 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 19:44:18.434 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 19:44:18.434 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 19:44:18.434 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 19:44:18.439 | [2025-10-16 00:44:18,438] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:39330-17); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 19:44:18.439 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 19:44:18.439 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 19:44:18.439 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 19:44:18.439 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 19:44:18.439 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 19:44:18.439 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 19:44:18.439 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 19:44:18.439 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 19:44:18.439 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 19:44:18.439 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 19:44:18.445 | [2025-10-16 00:44:18,445] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:39346-17); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 19:44:18.446 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 19:44:18.446 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 19:44:18.446 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 19:44:18.446 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 19:44:18.446 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 19:44:18.446 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 19:44:18.446 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 19:44:18.446 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 19:44:18.446 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 19:44:18.446 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 19:44:18.449 | [2025-10-16 00:44:18,449] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:39360-18); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 19:44:18.449 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 19:44:18.449 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 19:44:18.449 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 19:44:18.449 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 19:44:18.449 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 19:44:18.449 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 19:44:18.449 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 19:44:18.449 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 19:44:18.449 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 19:44:18.449 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 19:44:18.454 | [2025-10-16 00:44:18,453] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:39374-18); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 19:44:18.454 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 19:44:18.454 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 19:44:18.454 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 19:44:18.454 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 19:44:18.454 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 19:44:18.454 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 19:44:18.454 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 19:44:18.454 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 19:44:18.454 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 19:44:18.454 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 19:44:18.460 | [2025-10-16 00:44:18,459] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:39388-18); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 19:44:18.460 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 19:44:18.460 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 19:44:18.460 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 19:44:18.460 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 19:44:18.460 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 19:44:18.460 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 19:44:18.460 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 19:44:18.460 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 19:44:18.460 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 19:44:18.460 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 19:44:18.464 | [2025-10-16 00:44:18,463] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:39396-19); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 19:44:18.464 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 19:44:18.464 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 19:44:18.464 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 19:44:18.464 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 19:44:18.464 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 19:44:18.464 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 19:44:18.464 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 19:44:18.464 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 19:44:18.464 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 19:44:18.464 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 19:44:18.467 | [2025-10-16 00:44:18,467] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:39404-19); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 19:44:18.468 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 19:44:18.468 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 19:44:18.468 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 19:44:18.468 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 19:44:18.468 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 19:44:18.468 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 19:44:18.468 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 19:44:18.468 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 19:44:18.468 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 19:44:18.468 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 19:44:18.472 | [2025-10-16 00:44:18,471] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:39418-19); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 19:44:18.472 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 19:44:18.472 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 19:44:18.472 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 19:44:18.472 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 19:44:18.472 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 19:44:18.472 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 19:44:18.472 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 19:44:18.472 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 19:44:18.472 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 19:44:18.472 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 19:45:19.233 | [2025-10-16 00:45:19,233] INFO Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(1), 1 -> ArrayBuffer(1), 2 -> ArrayBuffer(1), 3 -> ArrayBuffer(1), 4 -> ArrayBuffer(1), 5 -> ArrayBuffer(1), 6 -> ArrayBuffer(1), 7 -> ArrayBuffer(1), 8 -> ArrayBuffer(1), 9 -> ArrayBuffer(1), 10 -> ArrayBuffer(1), 11 -> ArrayBuffer(1), 12 -> ArrayBuffer(1), 13 -> ArrayBuffer(1), 14 -> ArrayBuffer(1), 15 -> ArrayBuffer(1), 16 -> ArrayBuffer(1), 17 -> ArrayBuffer(1), 18 -> ArrayBuffer(1), 19 -> ArrayBuffer(1), 20 -> ArrayBuffer(1), 21 -> ArrayBuffer(1), 22 -> ArrayBuffer(1), 23 -> ArrayBuffer(1), 24 -> ArrayBuffer(1), 25 -> ArrayBuffer(1), 26 -> ArrayBuffer(1), 27 -> ArrayBuffer(1), 28 -> ArrayBuffer(1), 29 -> ArrayBuffer(1), 30 -> ArrayBuffer(1), 31 -> ArrayBuffer(1), 32 -> ArrayBuffer(1), 33 -> ArrayBuffer(1), 34 -> ArrayBuffer(1), 35 -> ArrayBuffer(1), 36 -> ArrayBuffer(1), 37 -> ArrayBuffer(1), 38 -> ArrayBuffer(1), 39 -> ArrayBuffer(1), 40 -> ArrayBuffer(1), 41 -> ArrayBuffer(1), 42 -> ArrayBuffer(1), 43 -> ArrayBuffer(1), 44 -> ArrayBuffer(1), 45 -> ArrayBuffer(1), 46 -> ArrayBuffer(1), 47 -> ArrayBuffer(1), 48 -> ArrayBuffer(1), 49 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
2025-10-15 19:45:19.274 | [2025-10-16 00:45:19,274] INFO [Controller id=1] New topics: [Set(__consumer_offsets)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(__consumer_offsets,Some(6ep0dUNwQAaqKr79SJ8ITA),HashMap(__consumer_offsets-22 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-30 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-25 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-35 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-37 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-38 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-13 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-8 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-21 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-4 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-27 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-7 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-9 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-46 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-41 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-33 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-23 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-49 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-47 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-16 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-28 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-31 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-36 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-42 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-3 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-18 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-15 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-24 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-17 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-48 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-19 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-11 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-2 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-43 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-6 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-14 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-20 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-0 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-44 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-39 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-12 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-45 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-1 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-5 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-26 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-29 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-34 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-10 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-32 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-40 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=))))] (kafka.controller.KafkaController)
2025-10-15 19:45:19.275 | [2025-10-16 00:45:19,275] INFO [Controller id=1] New partition creation callback for __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-37,__consumer_offsets-38,__consumer_offsets-13,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40 (kafka.controller.KafkaController)
2025-10-15 19:45:19.278 | [2025-10-16 00:45:19,278] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-22 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.279 | [2025-10-16 00:45:19,278] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-30 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.279 | [2025-10-16 00:45:19,278] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-25 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.279 | [2025-10-16 00:45:19,278] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-35 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.279 | [2025-10-16 00:45:19,278] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-37 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.279 | [2025-10-16 00:45:19,279] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-38 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.279 | [2025-10-16 00:45:19,279] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-13 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.279 | [2025-10-16 00:45:19,279] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-8 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.279 | [2025-10-16 00:45:19,279] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-21 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.279 | [2025-10-16 00:45:19,279] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-4 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.279 | [2025-10-16 00:45:19,279] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-27 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.279 | [2025-10-16 00:45:19,279] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-7 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.279 | [2025-10-16 00:45:19,279] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-9 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.279 | [2025-10-16 00:45:19,279] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-46 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.279 | [2025-10-16 00:45:19,279] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-41 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.279 | [2025-10-16 00:45:19,279] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-33 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.279 | [2025-10-16 00:45:19,279] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-23 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.279 | [2025-10-16 00:45:19,279] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-49 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.279 | [2025-10-16 00:45:19,279] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-47 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.279 | [2025-10-16 00:45:19,279] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-16 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.279 | [2025-10-16 00:45:19,279] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-28 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.280 | [2025-10-16 00:45:19,279] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-31 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.280 | [2025-10-16 00:45:19,280] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-36 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.280 | [2025-10-16 00:45:19,280] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-42 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.280 | [2025-10-16 00:45:19,280] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-3 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.280 | [2025-10-16 00:45:19,280] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-18 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.280 | [2025-10-16 00:45:19,280] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-15 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.280 | [2025-10-16 00:45:19,280] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-24 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.280 | [2025-10-16 00:45:19,280] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-17 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.280 | [2025-10-16 00:45:19,280] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-48 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.280 | [2025-10-16 00:45:19,280] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-19 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.280 | [2025-10-16 00:45:19,280] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-11 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.280 | [2025-10-16 00:45:19,280] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-2 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.280 | [2025-10-16 00:45:19,280] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-43 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.280 | [2025-10-16 00:45:19,280] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-6 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.280 | [2025-10-16 00:45:19,280] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-14 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.280 | [2025-10-16 00:45:19,280] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-20 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.280 | [2025-10-16 00:45:19,280] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.280 | [2025-10-16 00:45:19,280] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-44 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.280 | [2025-10-16 00:45:19,280] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-39 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.280 | [2025-10-16 00:45:19,280] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-12 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.280 | [2025-10-16 00:45:19,280] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-45 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.280 | [2025-10-16 00:45:19,280] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-1 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.280 | [2025-10-16 00:45:19,280] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-5 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.280 | [2025-10-16 00:45:19,280] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-26 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.280 | [2025-10-16 00:45:19,280] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-29 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.280 | [2025-10-16 00:45:19,280] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-34 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.280 | [2025-10-16 00:45:19,280] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-10 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.280 | [2025-10-16 00:45:19,280] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-32 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.280 | [2025-10-16 00:45:19,280] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-40 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:19.281 | [2025-10-16 00:45:19,280] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-10-15 19:45:19.286 | [2025-10-16 00:45:19,286] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-32 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.286 | [2025-10-16 00:45:19,286] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-5 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.286 | [2025-10-16 00:45:19,286] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-44 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.286 | [2025-10-16 00:45:19,286] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-48 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.286 | [2025-10-16 00:45:19,286] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-46 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.286 | [2025-10-16 00:45:19,286] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-20 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.286 | [2025-10-16 00:45:19,286] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-43 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.286 | [2025-10-16 00:45:19,286] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-24 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.286 | [2025-10-16 00:45:19,286] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-6 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.286 | [2025-10-16 00:45:19,286] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-18 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.286 | [2025-10-16 00:45:19,286] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-21 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.286 | [2025-10-16 00:45:19,286] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-1 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.286 | [2025-10-16 00:45:19,286] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-14 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.286 | [2025-10-16 00:45:19,286] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-34 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.286 | [2025-10-16 00:45:19,286] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-16 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.286 | [2025-10-16 00:45:19,286] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-29 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.286 | [2025-10-16 00:45:19,286] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-11 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.286 | [2025-10-16 00:45:19,286] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-0 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.286 | [2025-10-16 00:45:19,286] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-22 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.286 | [2025-10-16 00:45:19,286] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-47 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.286 | [2025-10-16 00:45:19,286] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-36 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.286 | [2025-10-16 00:45:19,286] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-28 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.286 | [2025-10-16 00:45:19,286] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-42 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.286 | [2025-10-16 00:45:19,286] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-9 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.286 | [2025-10-16 00:45:19,286] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-37 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.286 | [2025-10-16 00:45:19,286] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-13 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.286 | [2025-10-16 00:45:19,286] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-30 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.287 | [2025-10-16 00:45:19,286] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-35 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.287 | [2025-10-16 00:45:19,286] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-39 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.287 | [2025-10-16 00:45:19,286] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-12 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.287 | [2025-10-16 00:45:19,286] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-27 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.287 | [2025-10-16 00:45:19,286] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-45 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.287 | [2025-10-16 00:45:19,287] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-19 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.287 | [2025-10-16 00:45:19,287] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-49 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.287 | [2025-10-16 00:45:19,287] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-40 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.287 | [2025-10-16 00:45:19,287] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-41 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.287 | [2025-10-16 00:45:19,287] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-38 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.287 | [2025-10-16 00:45:19,287] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-8 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.288 | [2025-10-16 00:45:19,287] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-7 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.288 | [2025-10-16 00:45:19,287] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-33 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.288 | [2025-10-16 00:45:19,287] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-25 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.288 | [2025-10-16 00:45:19,287] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-31 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.288 | [2025-10-16 00:45:19,288] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-23 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.288 | [2025-10-16 00:45:19,288] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-10 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.288 | [2025-10-16 00:45:19,288] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-2 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.288 | [2025-10-16 00:45:19,288] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-17 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.288 | [2025-10-16 00:45:19,288] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-4 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.288 | [2025-10-16 00:45:19,288] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-15 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.288 | [2025-10-16 00:45:19,288] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-26 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.288 | [2025-10-16 00:45:19,288] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-3 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:19.289 | [2025-10-16 00:45:19,289] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-10-15 19:45:19.451 | [2025-10-16 00:45:19,450] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-22 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.451 | [2025-10-16 00:45:19,451] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-30 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.451 | [2025-10-16 00:45:19,451] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-25 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.451 | [2025-10-16 00:45:19,451] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-35 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.451 | [2025-10-16 00:45:19,451] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-37 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.451 | [2025-10-16 00:45:19,451] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-38 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.451 | [2025-10-16 00:45:19,451] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-13 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.451 | [2025-10-16 00:45:19,451] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-8 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.451 | [2025-10-16 00:45:19,451] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-21 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.451 | [2025-10-16 00:45:19,451] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.451 | [2025-10-16 00:45:19,451] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-27 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.451 | [2025-10-16 00:45:19,451] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-7 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.451 | [2025-10-16 00:45:19,451] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-9 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.451 | [2025-10-16 00:45:19,451] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-46 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.451 | [2025-10-16 00:45:19,451] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-41 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.451 | [2025-10-16 00:45:19,451] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-33 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.451 | [2025-10-16 00:45:19,451] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-23 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.451 | [2025-10-16 00:45:19,451] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-49 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.451 | [2025-10-16 00:45:19,451] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-47 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.451 | [2025-10-16 00:45:19,451] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-16 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.452 | [2025-10-16 00:45:19,451] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-28 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.452 | [2025-10-16 00:45:19,451] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-31 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.452 | [2025-10-16 00:45:19,452] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-36 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.452 | [2025-10-16 00:45:19,452] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-42 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.452 | [2025-10-16 00:45:19,452] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.452 | [2025-10-16 00:45:19,452] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-18 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.452 | [2025-10-16 00:45:19,452] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-15 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.452 | [2025-10-16 00:45:19,452] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-24 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.452 | [2025-10-16 00:45:19,452] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-17 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.452 | [2025-10-16 00:45:19,452] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-48 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.452 | [2025-10-16 00:45:19,452] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-19 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.452 | [2025-10-16 00:45:19,452] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-11 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.452 | [2025-10-16 00:45:19,452] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.452 | [2025-10-16 00:45:19,452] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-43 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.452 | [2025-10-16 00:45:19,452] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-6 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.452 | [2025-10-16 00:45:19,452] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-14 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.452 | [2025-10-16 00:45:19,452] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-20 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.452 | [2025-10-16 00:45:19,452] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.452 | [2025-10-16 00:45:19,452] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-44 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.452 | [2025-10-16 00:45:19,452] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-39 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.452 | [2025-10-16 00:45:19,452] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-12 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.452 | [2025-10-16 00:45:19,452] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-45 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.452 | [2025-10-16 00:45:19,452] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.453 | [2025-10-16 00:45:19,452] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-5 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.453 | [2025-10-16 00:45:19,452] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-26 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.453 | [2025-10-16 00:45:19,453] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-29 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.453 | [2025-10-16 00:45:19,453] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-34 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.453 | [2025-10-16 00:45:19,453] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-10 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.453 | [2025-10-16 00:45:19,453] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-32 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.453 | [2025-10-16 00:45:19,453] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-40 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:19.456 | [2025-10-16 00:45:19,455] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-13 (state.change.logger)
2025-10-15 19:45:19.456 | [2025-10-16 00:45:19,456] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-46 (state.change.logger)
2025-10-15 19:45:19.456 | [2025-10-16 00:45:19,456] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-9 (state.change.logger)
2025-10-15 19:45:19.456 | [2025-10-16 00:45:19,456] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-42 (state.change.logger)
2025-10-15 19:45:19.456 | [2025-10-16 00:45:19,456] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-21 (state.change.logger)
2025-10-15 19:45:19.456 | [2025-10-16 00:45:19,456] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-17 (state.change.logger)
2025-10-15 19:45:19.456 | [2025-10-16 00:45:19,456] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-30 (state.change.logger)
2025-10-15 19:45:19.456 | [2025-10-16 00:45:19,456] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-26 (state.change.logger)
2025-10-15 19:45:19.456 | [2025-10-16 00:45:19,456] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-5 (state.change.logger)
2025-10-15 19:45:19.456 | [2025-10-16 00:45:19,456] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-38 (state.change.logger)
2025-10-15 19:45:19.456 | [2025-10-16 00:45:19,456] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-1 (state.change.logger)
2025-10-15 19:45:19.456 | [2025-10-16 00:45:19,456] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-34 (state.change.logger)
2025-10-15 19:45:19.456 | [2025-10-16 00:45:19,456] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-16 (state.change.logger)
2025-10-15 19:45:19.456 | [2025-10-16 00:45:19,456] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-45 (state.change.logger)
2025-10-15 19:45:19.456 | [2025-10-16 00:45:19,456] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-12 (state.change.logger)
2025-10-15 19:45:19.456 | [2025-10-16 00:45:19,456] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-41 (state.change.logger)
2025-10-15 19:45:19.456 | [2025-10-16 00:45:19,456] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-24 (state.change.logger)
2025-10-15 19:45:19.456 | [2025-10-16 00:45:19,456] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-20 (state.change.logger)
2025-10-15 19:45:19.456 | [2025-10-16 00:45:19,456] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-49 (state.change.logger)
2025-10-15 19:45:19.456 | [2025-10-16 00:45:19,456] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-0 (state.change.logger)
2025-10-15 19:45:19.456 | [2025-10-16 00:45:19,456] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-29 (state.change.logger)
2025-10-15 19:45:19.456 | [2025-10-16 00:45:19,456] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-25 (state.change.logger)
2025-10-15 19:45:19.456 | [2025-10-16 00:45:19,456] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-8 (state.change.logger)
2025-10-15 19:45:19.456 | [2025-10-16 00:45:19,456] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-37 (state.change.logger)
2025-10-15 19:45:19.456 | [2025-10-16 00:45:19,456] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-4 (state.change.logger)
2025-10-15 19:45:19.456 | [2025-10-16 00:45:19,456] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-33 (state.change.logger)
2025-10-15 19:45:19.457 | [2025-10-16 00:45:19,456] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-15 (state.change.logger)
2025-10-15 19:45:19.457 | [2025-10-16 00:45:19,456] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-48 (state.change.logger)
2025-10-15 19:45:19.457 | [2025-10-16 00:45:19,456] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-11 (state.change.logger)
2025-10-15 19:45:19.457 | [2025-10-16 00:45:19,456] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-44 (state.change.logger)
2025-10-15 19:45:19.457 | [2025-10-16 00:45:19,457] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-23 (state.change.logger)
2025-10-15 19:45:19.457 | [2025-10-16 00:45:19,457] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-19 (state.change.logger)
2025-10-15 19:45:19.457 | [2025-10-16 00:45:19,457] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-32 (state.change.logger)
2025-10-15 19:45:19.457 | [2025-10-16 00:45:19,457] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-28 (state.change.logger)
2025-10-15 19:45:19.457 | [2025-10-16 00:45:19,457] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-7 (state.change.logger)
2025-10-15 19:45:19.457 | [2025-10-16 00:45:19,457] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-40 (state.change.logger)
2025-10-15 19:45:19.457 | [2025-10-16 00:45:19,457] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-3 (state.change.logger)
2025-10-15 19:45:19.457 | [2025-10-16 00:45:19,457] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-36 (state.change.logger)
2025-10-15 19:45:19.457 | [2025-10-16 00:45:19,457] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-47 (state.change.logger)
2025-10-15 19:45:19.457 | [2025-10-16 00:45:19,457] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-14 (state.change.logger)
2025-10-15 19:45:19.457 | [2025-10-16 00:45:19,457] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-43 (state.change.logger)
2025-10-15 19:45:19.457 | [2025-10-16 00:45:19,457] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-10 (state.change.logger)
2025-10-15 19:45:19.457 | [2025-10-16 00:45:19,457] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-22 (state.change.logger)
2025-10-15 19:45:19.457 | [2025-10-16 00:45:19,457] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-18 (state.change.logger)
2025-10-15 19:45:19.457 | [2025-10-16 00:45:19,457] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-31 (state.change.logger)
2025-10-15 19:45:19.457 | [2025-10-16 00:45:19,457] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-27 (state.change.logger)
2025-10-15 19:45:19.457 | [2025-10-16 00:45:19,457] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-39 (state.change.logger)
2025-10-15 19:45:19.457 | [2025-10-16 00:45:19,457] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-6 (state.change.logger)
2025-10-15 19:45:19.457 | [2025-10-16 00:45:19,457] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-35 (state.change.logger)
2025-10-15 19:45:19.457 | [2025-10-16 00:45:19,457] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-2 (state.change.logger)
2025-10-15 19:45:19.459 | [2025-10-16 00:45:19,458] INFO [Controller id=1 epoch=1] Sending LeaderAndIsr request to broker 1 with 50 become-leader and 0 become-follower partitions (state.change.logger)
2025-10-15 19:45:19.462 | [2025-10-16 00:45:19,462] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to brokers HashSet(1) for 50 partitions (state.change.logger)
2025-10-15 19:45:19.466 | [2025-10-16 00:45:19,465] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-32 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.466 | [2025-10-16 00:45:19,466] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-5 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.466 | [2025-10-16 00:45:19,466] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-44 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.466 | [2025-10-16 00:45:19,466] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-48 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.466 | [2025-10-16 00:45:19,466] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-46 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.466 | [2025-10-16 00:45:19,466] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-20 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.466 | [2025-10-16 00:45:19,466] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-43 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.466 | [2025-10-16 00:45:19,466] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-24 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.466 | [2025-10-16 00:45:19,466] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-6 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.466 | [2025-10-16 00:45:19,466] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-18 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.466 | [2025-10-16 00:45:19,466] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-21 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.466 | [2025-10-16 00:45:19,466] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-1 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.466 | [2025-10-16 00:45:19,466] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-14 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.466 | [2025-10-16 00:45:19,466] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-34 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.466 | [2025-10-16 00:45:19,466] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-16 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.466 | [2025-10-16 00:45:19,466] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-29 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.466 | [2025-10-16 00:45:19,466] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-11 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.466 | [2025-10-16 00:45:19,466] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-0 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.467 | [2025-10-16 00:45:19,466] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-22 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.467 | [2025-10-16 00:45:19,466] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-47 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.467 | [2025-10-16 00:45:19,467] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-36 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.467 | [2025-10-16 00:45:19,467] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-28 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.467 | [2025-10-16 00:45:19,467] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-42 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.467 | [2025-10-16 00:45:19,467] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-9 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.467 | [2025-10-16 00:45:19,467] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-37 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.467 | [2025-10-16 00:45:19,467] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-13 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.467 | [2025-10-16 00:45:19,467] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-30 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.467 | [2025-10-16 00:45:19,467] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-35 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.467 | [2025-10-16 00:45:19,467] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-39 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.467 | [2025-10-16 00:45:19,467] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-12 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.467 | [2025-10-16 00:45:19,467] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-27 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.467 | [2025-10-16 00:45:19,467] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-45 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.467 | [2025-10-16 00:45:19,467] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-19 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.468 | [2025-10-16 00:45:19,467] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-49 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.468 | [2025-10-16 00:45:19,467] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-40 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.468 | [2025-10-16 00:45:19,467] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-41 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.468 | [2025-10-16 00:45:19,467] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-38 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.468 | [2025-10-16 00:45:19,467] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-8 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.468 | [2025-10-16 00:45:19,468] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-7 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.468 | [2025-10-16 00:45:19,468] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-33 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.468 | [2025-10-16 00:45:19,468] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-25 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.468 | [2025-10-16 00:45:19,468] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-31 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.468 | [2025-10-16 00:45:19,468] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-23 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.468 | [2025-10-16 00:45:19,468] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-10 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.468 | [2025-10-16 00:45:19,468] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-2 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.468 | [2025-10-16 00:45:19,468] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-17 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.468 | [2025-10-16 00:45:19,468] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-4 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.468 | [2025-10-16 00:45:19,468] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-15 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.468 | [2025-10-16 00:45:19,468] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-26 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.468 | [2025-10-16 00:45:19,468] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-3 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:19.468 | [2025-10-16 00:45:19,468] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-10-15 19:45:19.470 | [2025-10-16 00:45:19,469] INFO [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 for 50 partitions (state.change.logger)
2025-10-15 19:45:19.471 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.471 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.471 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.471 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.471 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.471 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.471 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.471 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.471 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.471 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.471 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.471 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.471 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.471 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.471 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.471 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.471 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.471 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.471 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.471 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.471 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.471 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.471 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.471 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.471 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.472 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.472 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.472 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.472 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.472 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.472 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.472 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.472 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.472 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.472 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.472 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.472 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.472 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.472 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.472 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.472 | [2025-10-16 00:45:19,471] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.472 | [2025-10-16 00:45:19,472] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.472 | [2025-10-16 00:45:19,472] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.472 | [2025-10-16 00:45:19,472] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.472 | [2025-10-16 00:45:19,472] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.472 | [2025-10-16 00:45:19,472] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.472 | [2025-10-16 00:45:19,472] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.472 | [2025-10-16 00:45:19,472] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.472 | [2025-10-16 00:45:19,472] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.472 | [2025-10-16 00:45:19,472] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:19.505 | [2025-10-16 00:45:19,505] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-3 (state.change.logger)
2025-10-15 19:45:19.505 | [2025-10-16 00:45:19,505] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-18 (state.change.logger)
2025-10-15 19:45:19.505 | [2025-10-16 00:45:19,505] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-41 (state.change.logger)
2025-10-15 19:45:19.505 | [2025-10-16 00:45:19,505] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-10 (state.change.logger)
2025-10-15 19:45:19.505 | [2025-10-16 00:45:19,505] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-33 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,505] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-48 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,505] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-19 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,505] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-34 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,505] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-4 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,505] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-11 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,505] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-26 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,505] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-49 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,505] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-39 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,505] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-9 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,505] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-24 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,505] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-31 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,505] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-46 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,505] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-1 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,505] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-16 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,505] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-2 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,505] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-25 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,505] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-40 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,505] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-47 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,505] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-17 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,505] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-32 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,505] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-37 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,505] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-7 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,505] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-22 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,505] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-29 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,506] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-44 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,506] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-14 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,506] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-23 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,506] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-38 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,506] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-8 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,506] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-45 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,506] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-15 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,506] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-30 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,506] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-0 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,506] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-35 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,506] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-5 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,506] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-20 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,506] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-27 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,506] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-42 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,506] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-12 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,506] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-21 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,506] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-36 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,506] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-6 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,506] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-43 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,506] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-13 (state.change.logger)
2025-10-15 19:45:19.506 | [2025-10-16 00:45:19,506] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-28 (state.change.logger)
2025-10-15 19:45:19.507 | [2025-10-16 00:45:19,507] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-37, __consumer_offsets-38, __consumer_offsets-13, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
2025-10-15 19:45:19.508 | [2025-10-16 00:45:19,507] INFO [Broker id=1] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 1 epoch 1 as part of the become-leader transition for 50 partitions (state.change.logger)
2025-10-15 19:45:19.570 | [2025-10-16 00:45:19,570] INFO [LogLoader partition=__consumer_offsets-3, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:19.584 | [2025-10-16 00:45:19,584] INFO Created log for partition __consumer_offsets-3 in /var/lib/kafka/data/__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:19.586 | [2025-10-16 00:45:19,585] INFO [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
2025-10-15 19:45:19.587 | [2025-10-16 00:45:19,587] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:19.590 | [2025-10-16 00:45:19,589] INFO [Broker id=1] Leader __consumer_offsets-3 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:19.613 | [2025-10-16 00:45:19,613] INFO [LogLoader partition=__consumer_offsets-18, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:19.614 | [2025-10-16 00:45:19,614] INFO Created log for partition __consumer_offsets-18 in /var/lib/kafka/data/__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:19.614 | [2025-10-16 00:45:19,614] INFO [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
2025-10-15 19:45:19.614 | [2025-10-16 00:45:19,614] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:19.614 | [2025-10-16 00:45:19,614] INFO [Broker id=1] Leader __consumer_offsets-18 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:19.630 | [2025-10-16 00:45:19,630] INFO [LogLoader partition=__consumer_offsets-41, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:19.631 | [2025-10-16 00:45:19,630] INFO Created log for partition __consumer_offsets-41 in /var/lib/kafka/data/__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:19.631 | [2025-10-16 00:45:19,631] INFO [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
2025-10-15 19:45:19.631 | [2025-10-16 00:45:19,631] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:19.631 | [2025-10-16 00:45:19,631] INFO [Broker id=1] Leader __consumer_offsets-41 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:19.647 | [2025-10-16 00:45:19,646] INFO [LogLoader partition=__consumer_offsets-10, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:19.649 | [2025-10-16 00:45:19,648] INFO Created log for partition __consumer_offsets-10 in /var/lib/kafka/data/__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:19.649 | [2025-10-16 00:45:19,649] INFO [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
2025-10-15 19:45:19.649 | [2025-10-16 00:45:19,649] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:19.649 | [2025-10-16 00:45:19,649] INFO [Broker id=1] Leader __consumer_offsets-10 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:19.669 | [2025-10-16 00:45:19,669] INFO [LogLoader partition=__consumer_offsets-33, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:19.670 | [2025-10-16 00:45:19,669] INFO Created log for partition __consumer_offsets-33 in /var/lib/kafka/data/__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:19.670 | [2025-10-16 00:45:19,669] INFO [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
2025-10-15 19:45:19.670 | [2025-10-16 00:45:19,669] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:19.670 | [2025-10-16 00:45:19,669] INFO [Broker id=1] Leader __consumer_offsets-33 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:19.690 | [2025-10-16 00:45:19,690] INFO [LogLoader partition=__consumer_offsets-48, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:19.691 | [2025-10-16 00:45:19,690] INFO Created log for partition __consumer_offsets-48 in /var/lib/kafka/data/__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:19.691 | [2025-10-16 00:45:19,690] INFO [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
2025-10-15 19:45:19.691 | [2025-10-16 00:45:19,690] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:19.691 | [2025-10-16 00:45:19,691] INFO [Broker id=1] Leader __consumer_offsets-48 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:19.711 | [2025-10-16 00:45:19,711] INFO [LogLoader partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:19.712 | [2025-10-16 00:45:19,711] INFO Created log for partition __consumer_offsets-19 in /var/lib/kafka/data/__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:19.712 | [2025-10-16 00:45:19,711] INFO [Partition __consumer_offsets-19 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
2025-10-15 19:45:19.712 | [2025-10-16 00:45:19,711] INFO [Partition __consumer_offsets-19 broker=1] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:19.712 | [2025-10-16 00:45:19,711] INFO [Broker id=1] Leader __consumer_offsets-19 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:19.734 | [2025-10-16 00:45:19,734] INFO [LogLoader partition=__consumer_offsets-34, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:19.735 | [2025-10-16 00:45:19,734] INFO Created log for partition __consumer_offsets-34 in /var/lib/kafka/data/__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:19.735 | [2025-10-16 00:45:19,734] INFO [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
2025-10-15 19:45:19.735 | [2025-10-16 00:45:19,735] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:19.735 | [2025-10-16 00:45:19,735] INFO [Broker id=1] Leader __consumer_offsets-34 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:19.759 | [2025-10-16 00:45:19,758] INFO [LogLoader partition=__consumer_offsets-4, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:19.759 | [2025-10-16 00:45:19,759] INFO Created log for partition __consumer_offsets-4 in /var/lib/kafka/data/__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:19.759 | [2025-10-16 00:45:19,759] INFO [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
2025-10-15 19:45:19.759 | [2025-10-16 00:45:19,759] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:19.759 | [2025-10-16 00:45:19,759] INFO [Broker id=1] Leader __consumer_offsets-4 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:19.788 | [2025-10-16 00:45:19,787] INFO [LogLoader partition=__consumer_offsets-11, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:19.789 | [2025-10-16 00:45:19,788] INFO Created log for partition __consumer_offsets-11 in /var/lib/kafka/data/__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:19.789 | [2025-10-16 00:45:19,789] INFO [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
2025-10-15 19:45:19.789 | [2025-10-16 00:45:19,789] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:19.790 | [2025-10-16 00:45:19,790] INFO [Broker id=1] Leader __consumer_offsets-11 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:19.813 | [2025-10-16 00:45:19,812] INFO [LogLoader partition=__consumer_offsets-26, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:19.813 | [2025-10-16 00:45:19,813] INFO Created log for partition __consumer_offsets-26 in /var/lib/kafka/data/__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:19.813 | [2025-10-16 00:45:19,813] INFO [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
2025-10-15 19:45:19.813 | [2025-10-16 00:45:19,813] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:19.813 | [2025-10-16 00:45:19,813] INFO [Broker id=1] Leader __consumer_offsets-26 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:19.827 | [2025-10-16 00:45:19,826] INFO [LogLoader partition=__consumer_offsets-49, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:19.827 | [2025-10-16 00:45:19,827] INFO Created log for partition __consumer_offsets-49 in /var/lib/kafka/data/__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:19.827 | [2025-10-16 00:45:19,827] INFO [Partition __consumer_offsets-49 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
2025-10-15 19:45:19.827 | [2025-10-16 00:45:19,827] INFO [Partition __consumer_offsets-49 broker=1] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:19.827 | [2025-10-16 00:45:19,827] INFO [Broker id=1] Leader __consumer_offsets-49 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:19.852 | [2025-10-16 00:45:19,852] INFO [LogLoader partition=__consumer_offsets-39, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:19.854 | [2025-10-16 00:45:19,853] INFO Created log for partition __consumer_offsets-39 in /var/lib/kafka/data/__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:19.854 | [2025-10-16 00:45:19,854] INFO [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
2025-10-15 19:45:19.854 | [2025-10-16 00:45:19,854] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:19.855 | [2025-10-16 00:45:19,854] INFO [Broker id=1] Leader __consumer_offsets-39 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:19.881 | [2025-10-16 00:45:19,880] INFO [LogLoader partition=__consumer_offsets-9, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:19.881 | [2025-10-16 00:45:19,881] INFO Created log for partition __consumer_offsets-9 in /var/lib/kafka/data/__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:19.881 | [2025-10-16 00:45:19,881] INFO [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
2025-10-15 19:45:19.881 | [2025-10-16 00:45:19,881] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:19.882 | [2025-10-16 00:45:19,881] INFO [Broker id=1] Leader __consumer_offsets-9 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:19.908 | [2025-10-16 00:45:19,908] INFO [LogLoader partition=__consumer_offsets-24, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:19.910 | [2025-10-16 00:45:19,909] INFO Created log for partition __consumer_offsets-24 in /var/lib/kafka/data/__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:19.910 | [2025-10-16 00:45:19,909] INFO [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
2025-10-15 19:45:19.910 | [2025-10-16 00:45:19,909] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:19.910 | [2025-10-16 00:45:19,910] INFO [Broker id=1] Leader __consumer_offsets-24 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:19.936 | [2025-10-16 00:45:19,935] INFO [LogLoader partition=__consumer_offsets-31, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:19.937 | [2025-10-16 00:45:19,937] INFO Created log for partition __consumer_offsets-31 in /var/lib/kafka/data/__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:19.937 | [2025-10-16 00:45:19,937] INFO [Partition __consumer_offsets-31 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
2025-10-15 19:45:19.937 | [2025-10-16 00:45:19,937] INFO [Partition __consumer_offsets-31 broker=1] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:19.938 | [2025-10-16 00:45:19,937] INFO [Broker id=1] Leader __consumer_offsets-31 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:19.969 | [2025-10-16 00:45:19,968] INFO [LogLoader partition=__consumer_offsets-46, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:19.969 | [2025-10-16 00:45:19,969] INFO Created log for partition __consumer_offsets-46 in /var/lib/kafka/data/__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:19.969 | [2025-10-16 00:45:19,969] INFO [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
2025-10-15 19:45:19.969 | [2025-10-16 00:45:19,969] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:19.970 | [2025-10-16 00:45:19,969] INFO [Broker id=1] Leader __consumer_offsets-46 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:19.999 | [2025-10-16 00:45:19,998] INFO [LogLoader partition=__consumer_offsets-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:20.000 | [2025-10-16 00:45:20,000] INFO Created log for partition __consumer_offsets-1 in /var/lib/kafka/data/__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:20.000 | [2025-10-16 00:45:20,000] INFO [Partition __consumer_offsets-1 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
2025-10-15 19:45:20.001 | [2025-10-16 00:45:20,001] INFO [Partition __consumer_offsets-1 broker=1] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:20.002 | [2025-10-16 00:45:20,002] INFO [Broker id=1] Leader __consumer_offsets-1 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:20.032 | [2025-10-16 00:45:20,031] INFO [LogLoader partition=__consumer_offsets-16, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:20.032 | [2025-10-16 00:45:20,032] INFO Created log for partition __consumer_offsets-16 in /var/lib/kafka/data/__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:20.032 | [2025-10-16 00:45:20,032] INFO [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
2025-10-15 19:45:20.032 | [2025-10-16 00:45:20,032] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:20.032 | [2025-10-16 00:45:20,032] INFO [Broker id=1] Leader __consumer_offsets-16 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:20.059 | [2025-10-16 00:45:20,058] INFO [LogLoader partition=__consumer_offsets-2, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:20.060 | [2025-10-16 00:45:20,059] INFO Created log for partition __consumer_offsets-2 in /var/lib/kafka/data/__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:20.060 | [2025-10-16 00:45:20,059] INFO [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
2025-10-15 19:45:20.060 | [2025-10-16 00:45:20,059] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:20.060 | [2025-10-16 00:45:20,059] INFO [Broker id=1] Leader __consumer_offsets-2 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:20.086 | [2025-10-16 00:45:20,085] INFO [LogLoader partition=__consumer_offsets-25, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:20.088 | [2025-10-16 00:45:20,088] INFO Created log for partition __consumer_offsets-25 in /var/lib/kafka/data/__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:20.090 | [2025-10-16 00:45:20,088] INFO [Partition __consumer_offsets-25 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
2025-10-15 19:45:20.090 | [2025-10-16 00:45:20,088] INFO [Partition __consumer_offsets-25 broker=1] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:20.090 | [2025-10-16 00:45:20,089] INFO [Broker id=1] Leader __consumer_offsets-25 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:20.116 | [2025-10-16 00:45:20,115] INFO [LogLoader partition=__consumer_offsets-40, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:20.117 | [2025-10-16 00:45:20,116] INFO Created log for partition __consumer_offsets-40 in /var/lib/kafka/data/__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:20.117 | [2025-10-16 00:45:20,117] INFO [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
2025-10-15 19:45:20.117 | [2025-10-16 00:45:20,117] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:20.117 | [2025-10-16 00:45:20,117] INFO [Broker id=1] Leader __consumer_offsets-40 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:20.145 | [2025-10-16 00:45:20,144] INFO [LogLoader partition=__consumer_offsets-47, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:20.146 | [2025-10-16 00:45:20,145] INFO Created log for partition __consumer_offsets-47 in /var/lib/kafka/data/__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:20.146 | [2025-10-16 00:45:20,145] INFO [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
2025-10-15 19:45:20.146 | [2025-10-16 00:45:20,145] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:20.146 | [2025-10-16 00:45:20,145] INFO [Broker id=1] Leader __consumer_offsets-47 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:20.162 | [2025-10-16 00:45:20,161] INFO [LogLoader partition=__consumer_offsets-17, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:20.162 | [2025-10-16 00:45:20,162] INFO Created log for partition __consumer_offsets-17 in /var/lib/kafka/data/__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:20.162 | [2025-10-16 00:45:20,162] INFO [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
2025-10-15 19:45:20.162 | [2025-10-16 00:45:20,162] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:20.163 | [2025-10-16 00:45:20,162] INFO [Broker id=1] Leader __consumer_offsets-17 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:20.185 | [2025-10-16 00:45:20,184] INFO [LogLoader partition=__consumer_offsets-32, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:20.186 | [2025-10-16 00:45:20,185] INFO Created log for partition __consumer_offsets-32 in /var/lib/kafka/data/__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:20.186 | [2025-10-16 00:45:20,185] INFO [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
2025-10-15 19:45:20.186 | [2025-10-16 00:45:20,185] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:20.186 | [2025-10-16 00:45:20,186] INFO [Broker id=1] Leader __consumer_offsets-32 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:20.212 | [2025-10-16 00:45:20,211] INFO [LogLoader partition=__consumer_offsets-37, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:20.212 | [2025-10-16 00:45:20,212] INFO Created log for partition __consumer_offsets-37 in /var/lib/kafka/data/__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:20.212 | [2025-10-16 00:45:20,212] INFO [Partition __consumer_offsets-37 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
2025-10-15 19:45:20.212 | [2025-10-16 00:45:20,212] INFO [Partition __consumer_offsets-37 broker=1] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:20.212 | [2025-10-16 00:45:20,212] INFO [Broker id=1] Leader __consumer_offsets-37 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:20.238 | [2025-10-16 00:45:20,238] INFO [LogLoader partition=__consumer_offsets-7, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:20.240 | [2025-10-16 00:45:20,239] INFO Created log for partition __consumer_offsets-7 in /var/lib/kafka/data/__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:20.240 | [2025-10-16 00:45:20,239] INFO [Partition __consumer_offsets-7 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
2025-10-15 19:45:20.240 | [2025-10-16 00:45:20,239] INFO [Partition __consumer_offsets-7 broker=1] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:20.240 | [2025-10-16 00:45:20,239] INFO [Broker id=1] Leader __consumer_offsets-7 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:20.265 | [2025-10-16 00:45:20,265] INFO [LogLoader partition=__consumer_offsets-22, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:20.266 | [2025-10-16 00:45:20,265] INFO Created log for partition __consumer_offsets-22 in /var/lib/kafka/data/__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:20.266 | [2025-10-16 00:45:20,266] INFO [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
2025-10-15 19:45:20.266 | [2025-10-16 00:45:20,266] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:20.266 | [2025-10-16 00:45:20,266] INFO [Broker id=1] Leader __consumer_offsets-22 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:20.295 | [2025-10-16 00:45:20,295] INFO [LogLoader partition=__consumer_offsets-29, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:20.297 | [2025-10-16 00:45:20,296] INFO Created log for partition __consumer_offsets-29 in /var/lib/kafka/data/__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:20.297 | [2025-10-16 00:45:20,296] INFO [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
2025-10-15 19:45:20.297 | [2025-10-16 00:45:20,296] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:20.297 | [2025-10-16 00:45:20,297] INFO [Broker id=1] Leader __consumer_offsets-29 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:20.326 | [2025-10-16 00:45:20,325] INFO [LogLoader partition=__consumer_offsets-44, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:20.327 | [2025-10-16 00:45:20,326] INFO Created log for partition __consumer_offsets-44 in /var/lib/kafka/data/__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:20.327 | [2025-10-16 00:45:20,326] INFO [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
2025-10-15 19:45:20.327 | [2025-10-16 00:45:20,326] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:20.327 | [2025-10-16 00:45:20,326] INFO [Broker id=1] Leader __consumer_offsets-44 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:20.345 | [2025-10-16 00:45:20,345] INFO [LogLoader partition=__consumer_offsets-14, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:20.346 | [2025-10-16 00:45:20,346] INFO Created log for partition __consumer_offsets-14 in /var/lib/kafka/data/__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:20.346 | [2025-10-16 00:45:20,346] INFO [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
2025-10-15 19:45:20.346 | [2025-10-16 00:45:20,346] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:20.347 | [2025-10-16 00:45:20,346] INFO [Broker id=1] Leader __consumer_offsets-14 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:20.374 | [2025-10-16 00:45:20,373] INFO [LogLoader partition=__consumer_offsets-23, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:20.375 | [2025-10-16 00:45:20,374] INFO Created log for partition __consumer_offsets-23 in /var/lib/kafka/data/__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:20.375 | [2025-10-16 00:45:20,374] INFO [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
2025-10-15 19:45:20.375 | [2025-10-16 00:45:20,374] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:20.375 | [2025-10-16 00:45:20,375] INFO [Broker id=1] Leader __consumer_offsets-23 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:20.399 | [2025-10-16 00:45:20,398] INFO [LogLoader partition=__consumer_offsets-38, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:20.399 | [2025-10-16 00:45:20,399] INFO Created log for partition __consumer_offsets-38 in /var/lib/kafka/data/__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:20.399 | [2025-10-16 00:45:20,399] INFO [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
2025-10-15 19:45:20.399 | [2025-10-16 00:45:20,399] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:20.399 | [2025-10-16 00:45:20,399] INFO [Broker id=1] Leader __consumer_offsets-38 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:20.422 | [2025-10-16 00:45:20,421] INFO [LogLoader partition=__consumer_offsets-8, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:20.424 | [2025-10-16 00:45:20,423] INFO Created log for partition __consumer_offsets-8 in /var/lib/kafka/data/__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:20.426 | [2025-10-16 00:45:20,423] INFO [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
2025-10-15 19:45:20.426 | [2025-10-16 00:45:20,423] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:20.426 | [2025-10-16 00:45:20,424] INFO [Broker id=1] Leader __consumer_offsets-8 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:20.451 | [2025-10-16 00:45:20,450] INFO [LogLoader partition=__consumer_offsets-45, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:20.452 | [2025-10-16 00:45:20,451] INFO Created log for partition __consumer_offsets-45 in /var/lib/kafka/data/__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:20.452 | [2025-10-16 00:45:20,451] INFO [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
2025-10-15 19:45:20.452 | [2025-10-16 00:45:20,451] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:20.452 | [2025-10-16 00:45:20,451] INFO [Broker id=1] Leader __consumer_offsets-45 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:20.469 | [2025-10-16 00:45:20,468] INFO [LogLoader partition=__consumer_offsets-15, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:20.469 | [2025-10-16 00:45:20,469] INFO Created log for partition __consumer_offsets-15 in /var/lib/kafka/data/__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:20.469 | [2025-10-16 00:45:20,469] INFO [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
2025-10-15 19:45:20.469 | [2025-10-16 00:45:20,469] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:20.469 | [2025-10-16 00:45:20,469] INFO [Broker id=1] Leader __consumer_offsets-15 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:20.486 | [2025-10-16 00:45:20,486] INFO [LogLoader partition=__consumer_offsets-30, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:20.487 | [2025-10-16 00:45:20,486] INFO Created log for partition __consumer_offsets-30 in /var/lib/kafka/data/__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:20.487 | [2025-10-16 00:45:20,487] INFO [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
2025-10-15 19:45:20.487 | [2025-10-16 00:45:20,487] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:20.487 | [2025-10-16 00:45:20,487] INFO [Broker id=1] Leader __consumer_offsets-30 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:20.515 | [2025-10-16 00:45:20,515] INFO [LogLoader partition=__consumer_offsets-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:20.516 | [2025-10-16 00:45:20,516] INFO Created log for partition __consumer_offsets-0 in /var/lib/kafka/data/__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:20.516 | [2025-10-16 00:45:20,516] INFO [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
2025-10-15 19:45:20.516 | [2025-10-16 00:45:20,516] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:20.516 | [2025-10-16 00:45:20,516] INFO [Broker id=1] Leader __consumer_offsets-0 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:20.532 | [2025-10-16 00:45:20,531] INFO [LogLoader partition=__consumer_offsets-35, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:20.532 | [2025-10-16 00:45:20,532] INFO Created log for partition __consumer_offsets-35 in /var/lib/kafka/data/__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:20.532 | [2025-10-16 00:45:20,532] INFO [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
2025-10-15 19:45:20.532 | [2025-10-16 00:45:20,532] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:20.533 | [2025-10-16 00:45:20,532] INFO [Broker id=1] Leader __consumer_offsets-35 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:20.558 | [2025-10-16 00:45:20,557] INFO [LogLoader partition=__consumer_offsets-5, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:20.558 | [2025-10-16 00:45:20,558] INFO Created log for partition __consumer_offsets-5 in /var/lib/kafka/data/__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:20.558 | [2025-10-16 00:45:20,558] INFO [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
2025-10-15 19:45:20.558 | [2025-10-16 00:45:20,558] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:20.558 | [2025-10-16 00:45:20,558] INFO [Broker id=1] Leader __consumer_offsets-5 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:20.579 | [2025-10-16 00:45:20,578] INFO [LogLoader partition=__consumer_offsets-20, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:20.579 | [2025-10-16 00:45:20,578] INFO Created log for partition __consumer_offsets-20 in /var/lib/kafka/data/__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:20.579 | [2025-10-16 00:45:20,579] INFO [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
2025-10-15 19:45:20.579 | [2025-10-16 00:45:20,579] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:20.579 | [2025-10-16 00:45:20,579] INFO [Broker id=1] Leader __consumer_offsets-20 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:20.603 | [2025-10-16 00:45:20,602] INFO [LogLoader partition=__consumer_offsets-27, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:20.603 | [2025-10-16 00:45:20,603] INFO Created log for partition __consumer_offsets-27 in /var/lib/kafka/data/__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:20.603 | [2025-10-16 00:45:20,603] INFO [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
2025-10-15 19:45:20.603 | [2025-10-16 00:45:20,603] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:20.603 | [2025-10-16 00:45:20,603] INFO [Broker id=1] Leader __consumer_offsets-27 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:20.617 | [2025-10-16 00:45:20,616] INFO [LogLoader partition=__consumer_offsets-42, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:20.617 | [2025-10-16 00:45:20,617] INFO Created log for partition __consumer_offsets-42 in /var/lib/kafka/data/__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:20.617 | [2025-10-16 00:45:20,617] INFO [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
2025-10-15 19:45:20.617 | [2025-10-16 00:45:20,617] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:20.617 | [2025-10-16 00:45:20,617] INFO [Broker id=1] Leader __consumer_offsets-42 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:20.637 | [2025-10-16 00:45:20,637] INFO [LogLoader partition=__consumer_offsets-12, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:20.637 | [2025-10-16 00:45:20,637] INFO Created log for partition __consumer_offsets-12 in /var/lib/kafka/data/__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:20.637 | [2025-10-16 00:45:20,637] INFO [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
2025-10-15 19:45:20.637 | [2025-10-16 00:45:20,637] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:20.638 | [2025-10-16 00:45:20,637] INFO [Broker id=1] Leader __consumer_offsets-12 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:20.662 | [2025-10-16 00:45:20,661] INFO [LogLoader partition=__consumer_offsets-21, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:20.662 | [2025-10-16 00:45:20,662] INFO Created log for partition __consumer_offsets-21 in /var/lib/kafka/data/__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:20.662 | [2025-10-16 00:45:20,662] INFO [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
2025-10-15 19:45:20.662 | [2025-10-16 00:45:20,662] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:20.663 | [2025-10-16 00:45:20,662] INFO [Broker id=1] Leader __consumer_offsets-21 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:20.679 | [2025-10-16 00:45:20,678] INFO [LogLoader partition=__consumer_offsets-36, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:20.679 | [2025-10-16 00:45:20,679] INFO Created log for partition __consumer_offsets-36 in /var/lib/kafka/data/__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:20.679 | [2025-10-16 00:45:20,679] INFO [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
2025-10-15 19:45:20.679 | [2025-10-16 00:45:20,679] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:20.679 | [2025-10-16 00:45:20,679] INFO [Broker id=1] Leader __consumer_offsets-36 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:20.697 | [2025-10-16 00:45:20,697] INFO [LogLoader partition=__consumer_offsets-6, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:20.698 | [2025-10-16 00:45:20,697] INFO Created log for partition __consumer_offsets-6 in /var/lib/kafka/data/__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:20.698 | [2025-10-16 00:45:20,698] INFO [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
2025-10-15 19:45:20.698 | [2025-10-16 00:45:20,698] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:20.698 | [2025-10-16 00:45:20,698] INFO [Broker id=1] Leader __consumer_offsets-6 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:20.729 | [2025-10-16 00:45:20,729] INFO [LogLoader partition=__consumer_offsets-43, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:20.730 | [2025-10-16 00:45:20,729] INFO Created log for partition __consumer_offsets-43 in /var/lib/kafka/data/__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:20.730 | [2025-10-16 00:45:20,730] INFO [Partition __consumer_offsets-43 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
2025-10-15 19:45:20.730 | [2025-10-16 00:45:20,730] INFO [Partition __consumer_offsets-43 broker=1] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:20.730 | [2025-10-16 00:45:20,730] INFO [Broker id=1] Leader __consumer_offsets-43 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:20.760 | [2025-10-16 00:45:20,759] INFO [LogLoader partition=__consumer_offsets-13, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:20.761 | [2025-10-16 00:45:20,760] INFO Created log for partition __consumer_offsets-13 in /var/lib/kafka/data/__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:20.761 | [2025-10-16 00:45:20,760] INFO [Partition __consumer_offsets-13 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
2025-10-15 19:45:20.761 | [2025-10-16 00:45:20,761] INFO [Partition __consumer_offsets-13 broker=1] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:20.761 | [2025-10-16 00:45:20,761] INFO [Broker id=1] Leader __consumer_offsets-13 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:20.790 | [2025-10-16 00:45:20,789] INFO [LogLoader partition=__consumer_offsets-28, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:20.790 | [2025-10-16 00:45:20,790] INFO Created log for partition __consumer_offsets-28 in /var/lib/kafka/data/__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-10-15 19:45:20.790 | [2025-10-16 00:45:20,790] INFO [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
2025-10-15 19:45:20.790 | [2025-10-16 00:45:20,790] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:20.790 | [2025-10-16 00:45:20,790] INFO [Broker id=1] Leader __consumer_offsets-28 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:20.815 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-3 (state.change.logger)
2025-10-15 19:45:20.815 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-18 (state.change.logger)
2025-10-15 19:45:20.815 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-41 (state.change.logger)
2025-10-15 19:45:20.815 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-10 (state.change.logger)
2025-10-15 19:45:20.815 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-33 (state.change.logger)
2025-10-15 19:45:20.815 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-48 (state.change.logger)
2025-10-15 19:45:20.815 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-19 (state.change.logger)
2025-10-15 19:45:20.815 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-34 (state.change.logger)
2025-10-15 19:45:20.815 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-4 (state.change.logger)
2025-10-15 19:45:20.815 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-11 (state.change.logger)
2025-10-15 19:45:20.815 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-26 (state.change.logger)
2025-10-15 19:45:20.815 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-49 (state.change.logger)
2025-10-15 19:45:20.815 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-39 (state.change.logger)
2025-10-15 19:45:20.815 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-9 (state.change.logger)
2025-10-15 19:45:20.815 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-24 (state.change.logger)
2025-10-15 19:45:20.815 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-31 (state.change.logger)
2025-10-15 19:45:20.816 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-46 (state.change.logger)
2025-10-15 19:45:20.816 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-1 (state.change.logger)
2025-10-15 19:45:20.816 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-16 (state.change.logger)
2025-10-15 19:45:20.816 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-2 (state.change.logger)
2025-10-15 19:45:20.816 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-25 (state.change.logger)
2025-10-15 19:45:20.816 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-40 (state.change.logger)
2025-10-15 19:45:20.816 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-47 (state.change.logger)
2025-10-15 19:45:20.816 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-17 (state.change.logger)
2025-10-15 19:45:20.816 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-32 (state.change.logger)
2025-10-15 19:45:20.816 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-37 (state.change.logger)
2025-10-15 19:45:20.816 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-7 (state.change.logger)
2025-10-15 19:45:20.816 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-22 (state.change.logger)
2025-10-15 19:45:20.816 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-29 (state.change.logger)
2025-10-15 19:45:20.816 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-44 (state.change.logger)
2025-10-15 19:45:20.816 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-14 (state.change.logger)
2025-10-15 19:45:20.816 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-23 (state.change.logger)
2025-10-15 19:45:20.816 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-38 (state.change.logger)
2025-10-15 19:45:20.816 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-8 (state.change.logger)
2025-10-15 19:45:20.816 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-45 (state.change.logger)
2025-10-15 19:45:20.816 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-15 (state.change.logger)
2025-10-15 19:45:20.816 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-30 (state.change.logger)
2025-10-15 19:45:20.816 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-0 (state.change.logger)
2025-10-15 19:45:20.816 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-35 (state.change.logger)
2025-10-15 19:45:20.816 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-5 (state.change.logger)
2025-10-15 19:45:20.816 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-20 (state.change.logger)
2025-10-15 19:45:20.816 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-27 (state.change.logger)
2025-10-15 19:45:20.816 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-42 (state.change.logger)
2025-10-15 19:45:20.816 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-12 (state.change.logger)
2025-10-15 19:45:20.816 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-21 (state.change.logger)
2025-10-15 19:45:20.816 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-36 (state.change.logger)
2025-10-15 19:45:20.816 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-6 (state.change.logger)
2025-10-15 19:45:20.816 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-43 (state.change.logger)
2025-10-15 19:45:20.816 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-13 (state.change.logger)
2025-10-15 19:45:20.816 | [2025-10-16 00:45:20,815] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-28 (state.change.logger)
2025-10-15 19:45:20.823 | [2025-10-16 00:45:20,822] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.825 | [2025-10-16 00:45:20,825] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.828 | [2025-10-16 00:45:20,828] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.828 | [2025-10-16 00:45:20,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.828 | [2025-10-16 00:45:20,828] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.828 | [2025-10-16 00:45:20,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.828 | [2025-10-16 00:45:20,828] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.828 | [2025-10-16 00:45:20,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.828 | [2025-10-16 00:45:20,828] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.828 | [2025-10-16 00:45:20,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.828 | [2025-10-16 00:45:20,828] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.828 | [2025-10-16 00:45:20,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.828 | [2025-10-16 00:45:20,828] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.828 | [2025-10-16 00:45:20,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.828 | [2025-10-16 00:45:20,828] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.828 | [2025-10-16 00:45:20,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.828 | [2025-10-16 00:45:20,828] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.828 | [2025-10-16 00:45:20,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.828 | [2025-10-16 00:45:20,828] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.828 | [2025-10-16 00:45:20,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.828 | [2025-10-16 00:45:20,828] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.828 | [2025-10-16 00:45:20,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.829 | [2025-10-16 00:45:20,828] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.829 | [2025-10-16 00:45:20,829] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.829 | [2025-10-16 00:45:20,829] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.829 | [2025-10-16 00:45:20,829] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.829 | [2025-10-16 00:45:20,829] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.829 | [2025-10-16 00:45:20,829] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.829 | [2025-10-16 00:45:20,829] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.829 | [2025-10-16 00:45:20,829] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.829 | [2025-10-16 00:45:20,829] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.829 | [2025-10-16 00:45:20,829] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.829 | [2025-10-16 00:45:20,829] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.829 | [2025-10-16 00:45:20,829] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,829] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,829] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,829] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,829] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,829] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,829] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,829] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,829] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,829] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,829] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,829] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,829] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,829] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,829] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,829] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,829] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,829] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,829] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,829] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,829] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,829] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,829] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,829] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,830] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,830] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,830] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,830] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,830] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,830] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,830] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,830] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,830] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,830] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,830] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,830] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,830] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,830] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,830] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,830] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,830] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,830] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,830] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,830] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,830] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,830] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,830] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,830] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,830] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,830] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,830] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,830] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.830 | [2025-10-16 00:45:20,830] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.831 | [2025-10-16 00:45:20,830] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.833 | [2025-10-16 00:45:20,830] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.833 | [2025-10-16 00:45:20,831] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.833 | [2025-10-16 00:45:20,831] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.833 | [2025-10-16 00:45:20,831] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.833 | [2025-10-16 00:45:20,832] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.833 | [2025-10-16 00:45:20,832] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.833 | [2025-10-16 00:45:20,832] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.833 | [2025-10-16 00:45:20,832] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.833 | [2025-10-16 00:45:20,833] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.833 | [2025-10-16 00:45:20,833] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.833 | [2025-10-16 00:45:20,833] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.833 | [2025-10-16 00:45:20,833] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:20.834 | [2025-10-16 00:45:20,833] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.838 | [2025-10-16 00:45:20,836] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 10 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.838 | [2025-10-16 00:45:20,837] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.838 | [2025-10-16 00:45:20,838] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 10 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.838 | [2025-10-16 00:45:20,838] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.838 | [2025-10-16 00:45:20,838] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.838 | [2025-10-16 00:45:20,838] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.838 | [2025-10-16 00:45:20,838] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.838 | [2025-10-16 00:45:20,838] INFO [Broker id=1] Finished LeaderAndIsr request in 1370ms correlationId 1 from controller 1 for 50 partitions (state.change.logger)
2025-10-15 19:45:20.838 | [2025-10-16 00:45:20,838] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.839 | [2025-10-16 00:45:20,838] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.839 | [2025-10-16 00:45:20,838] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.839 | [2025-10-16 00:45:20,838] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.839 | [2025-10-16 00:45:20,839] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.840 | [2025-10-16 00:45:20,839] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.840 | [2025-10-16 00:45:20,839] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.840 | [2025-10-16 00:45:20,839] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.840 | [2025-10-16 00:45:20,840] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.841 | [2025-10-16 00:45:20,840] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.841 | [2025-10-16 00:45:20,841] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 12 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.842 | [2025-10-16 00:45:20,841] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 12 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.843 | [2025-10-16 00:45:20,842] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.844 | [2025-10-16 00:45:20,843] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 14 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.844 | [2025-10-16 00:45:20,843] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.845 | [2025-10-16 00:45:20,845] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 16 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.846 | [2025-10-16 00:45:20,845] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 16 milliseconds for epoch 0, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.846 | [2025-10-16 00:45:20,846] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 17 milliseconds for epoch 0, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.847 | [2025-10-16 00:45:20,846] TRACE [Controller id=1 epoch=1] Received response LeaderAndIsrResponseData(errorCode=0, partitionErrors=[], topics=[LeaderAndIsrTopicError(topicId=6ep0dUNwQAaqKr79SJ8ITA, partitionErrors=[LeaderAndIsrPartitionError(topicName='', partitionIndex=13, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=46, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=9, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=42, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=21, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=17, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=30, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=26, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=5, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=38, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=1, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=34, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=16, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=45, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=12, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=41, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=24, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=20, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=49, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=0, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=29, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=25, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=8, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=37, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=4, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=33, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=15, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=48, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=11, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=44, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=23, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=19, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=32, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=28, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=7, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=40, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=3, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=36, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=47, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=14, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=43, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=10, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=22, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=18, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=31, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=27, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=39, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=6, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=35, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=2, errorCode=0)])]) for request LEADER_AND_ISR with correlation id 1 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-10-15 19:45:20.847 | [2025-10-16 00:45:20,846] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 17 milliseconds for epoch 0, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.848 | [2025-10-16 00:45:20,847] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 18 milliseconds for epoch 0, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.849 | [2025-10-16 00:45:20,848] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 19 milliseconds for epoch 0, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.849 | [2025-10-16 00:45:20,849] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 19 milliseconds for epoch 0, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.850 | [2025-10-16 00:45:20,849] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 19 milliseconds for epoch 0, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.851 | [2025-10-16 00:45:20,850] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 20 milliseconds for epoch 0, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.852 | [2025-10-16 00:45:20,851] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 21 milliseconds for epoch 0, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.852 | [2025-10-16 00:45:20,851] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 21 milliseconds for epoch 0, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.853 | [2025-10-16 00:45:20,853] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 23 milliseconds for epoch 0, of which 23 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.853 | [2025-10-16 00:45:20,853] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 23 milliseconds for epoch 0, of which 23 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.853 | [2025-10-16 00:45:20,853] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 23 milliseconds for epoch 0, of which 23 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.853 | [2025-10-16 00:45:20,853] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 23 milliseconds for epoch 0, of which 23 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.853 | [2025-10-16 00:45:20,853] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 23 milliseconds for epoch 0, of which 23 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.854 | [2025-10-16 00:45:20,853] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 23 milliseconds for epoch 0, of which 23 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.854 | [2025-10-16 00:45:20,853] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 23 milliseconds for epoch 0, of which 23 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.854 | [2025-10-16 00:45:20,853] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 23 milliseconds for epoch 0, of which 23 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.854 | [2025-10-16 00:45:20,854] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 24 milliseconds for epoch 0, of which 24 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.854 | [2025-10-16 00:45:20,854] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 24 milliseconds for epoch 0, of which 24 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.854 | [2025-10-16 00:45:20,854] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 23 milliseconds for epoch 0, of which 23 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.854 | [2025-10-16 00:45:20,854] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 23 milliseconds for epoch 0, of which 23 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.854 | [2025-10-16 00:45:20,854] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 22 milliseconds for epoch 0, of which 22 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.854 | [2025-10-16 00:45:20,854] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 22 milliseconds for epoch 0, of which 22 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.855 | [2025-10-16 00:45:20,854] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 21 milliseconds for epoch 0, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.856 | [2025-10-16 00:45:20,855] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 22 milliseconds for epoch 0, of which 22 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.856 | [2025-10-16 00:45:20,856] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 23 milliseconds for epoch 0, of which 22 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 19:45:20.858 | [2025-10-16 00:45:20,857] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-13 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.858 | [2025-10-16 00:45:20,857] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-46 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.858 | [2025-10-16 00:45:20,857] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-9 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.858 | [2025-10-16 00:45:20,857] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-42 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.858 | [2025-10-16 00:45:20,857] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-21 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.858 | [2025-10-16 00:45:20,857] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-17 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.858 | [2025-10-16 00:45:20,857] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-30 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.858 | [2025-10-16 00:45:20,858] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-26 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.858 | [2025-10-16 00:45:20,858] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-5 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.858 | [2025-10-16 00:45:20,858] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-38 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.858 | [2025-10-16 00:45:20,858] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-1 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.858 | [2025-10-16 00:45:20,858] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-34 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.858 | [2025-10-16 00:45:20,858] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-16 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.858 | [2025-10-16 00:45:20,858] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-45 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.858 | [2025-10-16 00:45:20,858] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-12 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.858 | [2025-10-16 00:45:20,858] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-41 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.858 | [2025-10-16 00:45:20,858] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-24 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.858 | [2025-10-16 00:45:20,858] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-20 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.858 | [2025-10-16 00:45:20,858] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-49 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.858 | [2025-10-16 00:45:20,858] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.859 | [2025-10-16 00:45:20,858] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-29 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.859 | [2025-10-16 00:45:20,858] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-25 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.859 | [2025-10-16 00:45:20,858] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-8 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.859 | [2025-10-16 00:45:20,858] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-37 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.859 | [2025-10-16 00:45:20,858] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-4 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.859 | [2025-10-16 00:45:20,858] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-33 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.859 | [2025-10-16 00:45:20,859] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-15 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.859 | [2025-10-16 00:45:20,859] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-48 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.859 | [2025-10-16 00:45:20,859] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-11 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.859 | [2025-10-16 00:45:20,859] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-44 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.859 | [2025-10-16 00:45:20,859] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-23 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.859 | [2025-10-16 00:45:20,859] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-19 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.860 | [2025-10-16 00:45:20,859] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-32 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.860 | [2025-10-16 00:45:20,859] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-28 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.860 | [2025-10-16 00:45:20,859] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-7 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.860 | [2025-10-16 00:45:20,859] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-40 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.860 | [2025-10-16 00:45:20,859] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-3 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.860 | [2025-10-16 00:45:20,860] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-36 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.860 | [2025-10-16 00:45:20,860] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-47 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.860 | [2025-10-16 00:45:20,860] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-14 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.860 | [2025-10-16 00:45:20,860] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-43 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.860 | [2025-10-16 00:45:20,860] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-10 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.860 | [2025-10-16 00:45:20,860] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-22 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.860 | [2025-10-16 00:45:20,860] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-18 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.860 | [2025-10-16 00:45:20,860] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-31 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.860 | [2025-10-16 00:45:20,860] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-27 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.860 | [2025-10-16 00:45:20,860] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-39 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.860 | [2025-10-16 00:45:20,860] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-6 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.861 | [2025-10-16 00:45:20,860] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-35 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.861 | [2025-10-16 00:45:20,860] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-2 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.862 | [2025-10-16 00:45:20,862] INFO [Broker id=1] Add 50 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-10-15 19:45:20.863 | [2025-10-16 00:45:20,863] TRACE [Controller id=1 epoch=1] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 2 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-10-15 19:45:21.933 | [2025-10-16 00:45:21,932] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group nestjs-group-client in Empty state. Created a new member id mesa-ya-service-client-9a0094a4-6972-4e79-a5d6-5ed4ed5cfa65 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:21.958 | [2025-10-16 00:45:21,957] INFO [GroupCoordinator 1]: Preparing to rebalance group nestjs-group-client in state PreparingRebalance with old generation 0 (__consumer_offsets-19) (reason: Adding new member mesa-ya-service-client-9a0094a4-6972-4e79-a5d6-5ed4ed5cfa65 with group instance id None; client reason: not provided) (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:24.969 | [2025-10-16 00:45:24,969] INFO [GroupCoordinator 1]: Stabilized group nestjs-group-client generation 1 (__consumer_offsets-19) with 1 members (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:24.989 | [2025-10-16 00:45:24,988] INFO [GroupCoordinator 1]: Assignment received from leader mesa-ya-service-client-9a0094a4-6972-4e79-a5d6-5ed4ed5cfa65 for group nestjs-group-client for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
2025-10-15 19:45:25.055 | [2025-10-16 00:45:25,053] INFO Creating topic mesa-ya.restaurants.created with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
2025-10-15 19:45:25.078 | [2025-10-16 00:45:25,078] INFO [Controller id=1] New topics: [Set(mesa-ya.restaurants.created)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(mesa-ya.restaurants.created,Some(yWm6W48_TyqOOX8W2L0ItA),Map(mesa-ya.restaurants.created-0 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=))))] (kafka.controller.KafkaController)
2025-10-15 19:45:25.079 | [2025-10-16 00:45:25,078] INFO [Controller id=1] New partition creation callback for mesa-ya.restaurants.created-0 (kafka.controller.KafkaController)
2025-10-15 19:45:25.079 | [2025-10-16 00:45:25,078] INFO [Controller id=1 epoch=1] Changed partition mesa-ya.restaurants.created-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-15 19:45:25.079 | [2025-10-16 00:45:25,079] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-10-15 19:45:25.079 | [2025-10-16 00:45:25,079] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition mesa-ya.restaurants.created-0 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-15 19:45:25.079 | [2025-10-16 00:45:25,079] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-10-15 19:45:25.104 | [2025-10-16 00:45:25,104] INFO [Controller id=1 epoch=1] Changed partition mesa-ya.restaurants.created-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-15 19:45:25.104 | [2025-10-16 00:45:25,104] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='mesa-ya.restaurants.created', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition mesa-ya.restaurants.created-0 (state.change.logger)
2025-10-15 19:45:25.104 | [2025-10-16 00:45:25,104] INFO [Controller id=1 epoch=1] Sending LeaderAndIsr request to broker 1 with 1 become-leader and 0 become-follower partitions (state.change.logger)
2025-10-15 19:45:25.105 | [2025-10-16 00:45:25,105] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to brokers HashSet(1) for 1 partitions (state.change.logger)
2025-10-15 19:45:25.106 | [2025-10-16 00:45:25,105] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition mesa-ya.restaurants.created-0 from NewReplica to OnlineReplica (state.change.logger)
2025-10-15 19:45:25.106 | [2025-10-16 00:45:25,105] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-10-15 19:45:25.107 | [2025-10-16 00:45:25,107] INFO [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 for 1 partitions (state.change.logger)
2025-10-15 19:45:25.107 | [2025-10-16 00:45:25,107] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='mesa-ya.restaurants.created', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-10-15 19:45:25.108 | [2025-10-16 00:45:25,107] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition mesa-ya.restaurants.created-0 (state.change.logger)
2025-10-15 19:45:25.109 | [2025-10-16 00:45:25,108] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(mesa-ya.restaurants.created-0) (kafka.server.ReplicaFetcherManager)
2025-10-15 19:45:25.109 | [2025-10-16 00:45:25,108] INFO [Broker id=1] Stopped fetchers as part of LeaderAndIsr request correlationId 3 from controller 1 epoch 1 as part of the become-leader transition for 1 partitions (state.change.logger)
2025-10-15 19:45:25.115 | [2025-10-16 00:45:25,114] INFO [LogLoader partition=mesa-ya.restaurants.created-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 19:45:25.115 | [2025-10-16 00:45:25,115] INFO Created log for partition mesa-ya.restaurants.created-0 in /var/lib/kafka/data/mesa-ya.restaurants.created-0 with properties {} (kafka.log.LogManager)
2025-10-15 19:45:25.117 | [2025-10-16 00:45:25,116] INFO [Partition mesa-ya.restaurants.created-0 broker=1] No checkpointed highwatermark is found for partition mesa-ya.restaurants.created-0 (kafka.cluster.Partition)
2025-10-15 19:45:25.117 | [2025-10-16 00:45:25,117] INFO [Partition mesa-ya.restaurants.created-0 broker=1] Log loaded for partition mesa-ya.restaurants.created-0 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 19:45:25.117 | [2025-10-16 00:45:25,117] INFO [Broker id=1] Leader mesa-ya.restaurants.created-0 with topic id Some(yWm6W48_TyqOOX8W2L0ItA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 19:45:25.136 | [2025-10-16 00:45:25,136] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition mesa-ya.restaurants.created-0 (state.change.logger)
2025-10-15 19:45:25.137 | [2025-10-16 00:45:25,136] INFO [Broker id=1] Finished LeaderAndIsr request in 29ms correlationId 3 from controller 1 for 1 partitions (state.change.logger)
2025-10-15 19:45:25.138 | [2025-10-16 00:45:25,137] TRACE [Controller id=1 epoch=1] Received response LeaderAndIsrResponseData(errorCode=0, partitionErrors=[], topics=[LeaderAndIsrTopicError(topicId=yWm6W48_TyqOOX8W2L0ItA, partitionErrors=[LeaderAndIsrPartitionError(topicName='', partitionIndex=0, errorCode=0)])]) for request LEADER_AND_ISR with correlation id 3 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-10-15 19:45:25.139 | [2025-10-16 00:45:25,138] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='mesa-ya.restaurants.created', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition mesa-ya.restaurants.created-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-10-15 19:45:25.139 | [2025-10-16 00:45:25,139] INFO [Broker id=1] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-10-15 19:45:25.139 | [2025-10-16 00:45:25,139] TRACE [Controller id=1 epoch=1] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 4 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-10-15 19:46:28.186 | [2025-10-16 00:46:28,185] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-15 19:46:28.186 | [2025-10-16 00:46:28,185] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-15 19:46:28.189 | [2025-10-16 00:46:28,188] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-15 19:46:28.190 | [2025-10-16 00:46:28,189] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-15 19:51:26.537 | [2025-10-16 00:51:26,537] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-15 19:51:26.537 | [2025-10-16 00:51:26,537] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-15 19:51:26.539 | [2025-10-16 00:51:26,539] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-15 19:51:26.539 | [2025-10-16 00:51:26,539] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-15 19:56:24.836 | [2025-10-16 00:56:24,835] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-15 19:56:24.836 | [2025-10-16 00:56:24,836] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-15 19:56:24.840 | [2025-10-16 00:56:24,840] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-15 19:56:24.841 | [2025-10-16 00:56:24,840] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-15 20:01:23.076 | [2025-10-16 01:01:23,074] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-15 20:01:23.076 | [2025-10-16 01:01:23,076] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-15 20:01:23.079 | [2025-10-16 01:01:23,079] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-15 20:01:23.079 | [2025-10-16 01:01:23,079] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-15 20:06:20.845 | [2025-10-16 01:06:20,845] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-15 20:06:20.846 | [2025-10-16 01:06:20,845] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-15 20:06:20.847 | [2025-10-16 01:06:20,847] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-15 20:06:20.847 | [2025-10-16 01:06:20,847] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-15 20:10:15.909 | [2025-10-16 01:10:15,907] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
2025-10-15 20:10:15.936 | [2025-10-16 01:10:15,935] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
2025-10-15 20:10:15.953 | [2025-10-16 01:10:15,953] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
2025-10-15 20:10:15.987 | [2025-10-16 01:10:15,987] INFO [Controller id=1] Shutting down broker 1 (kafka.controller.KafkaController)
2025-10-15 20:10:15.989 | [2025-10-16 01:10:15,988] DEBUG [Controller id=1] All shutting down brokers: 1 (kafka.controller.KafkaController)
2025-10-15 20:10:15.990 | [2025-10-16 01:10:15,989] DEBUG [Controller id=1] Live brokers:  (kafka.controller.KafkaController)
2025-10-15 20:10:15.995 | [2025-10-16 01:10:15,994] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-10-15 20:10:16.008 | [2025-10-16 01:10:16,007] TRACE [Controller id=1] All leaders = __consumer_offsets-13 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-46 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-9 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-42 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-21 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-17 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-30 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-26 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-5 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-38 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-1 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-34 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-16 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-45 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-12 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-41 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-24 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-20 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-49 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-0 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-29 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-25 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-8 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-37 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-4 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-33 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-15 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-48 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-11 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-44 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-23 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-19 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-32 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-28 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-7 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-40 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-3 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-36 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-47 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-14 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-43 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-10 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-22 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-18 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-31 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-27 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-39 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-6 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-35 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),mesa-ya.restaurants.created-0 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-2 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1) (kafka.controller.KafkaController)
2025-10-15 20:10:16.017 | [2025-10-16 01:10:16,016] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 43ms (kafka.server.KafkaServer)
2025-10-15 20:10:16.031 | [2025-10-16 01:10:16,030] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-10-15 20:10:16.034 | [2025-10-16 01:10:16,034] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-10-15 20:10:16.036 | [2025-10-16 01:10:16,034] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-10-15 20:10:16.039 | [2025-10-16 01:10:16,039] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
2025-10-15 20:10:16.093 | [2025-10-16 01:10:16,092] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
2025-10-15 20:10:16.094 | [2025-10-16 01:10:16,094] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
2025-10-15 20:10:16.100 | [2025-10-16 01:10:16,099] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
2025-10-15 20:10:16.107 | [2025-10-16 01:10:16,106] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:10:16.110 | [2025-10-16 01:10:16,109] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:10:16.110 | [2025-10-16 01:10:16,109] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:10:16.111 | [2025-10-16 01:10:16,111] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
2025-10-15 20:10:16.113 | [2025-10-16 01:10:16,112] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:10:16.114 | [2025-10-16 01:10:16,114] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:10:16.114 | [2025-10-16 01:10:16,114] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:10:16.118 | [2025-10-16 01:10:16,117] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
2025-10-15 20:10:16.120 | [2025-10-16 01:10:16,120] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
2025-10-15 20:10:16.121 | [2025-10-16 01:10:16,121] INFO [TxnMarkerSenderThread-1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-10-15 20:10:16.122 | [2025-10-16 01:10:16,121] INFO [TxnMarkerSenderThread-1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-10-15 20:10:16.122 | [2025-10-16 01:10:16,122] INFO [TxnMarkerSenderThread-1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-10-15 20:10:16.123 | [2025-10-16 01:10:16,123] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
2025-10-15 20:10:16.124 | [2025-10-16 01:10:16,124] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:10:16.125 | [2025-10-16 01:10:16,125] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:10:16.127 | [2025-10-16 01:10:16,127] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:10:16.127 | [2025-10-16 01:10:16,127] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:10:16.129 | [2025-10-16 01:10:16,128] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:10:16.130 | [2025-10-16 01:10:16,130] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:10:16.130 | [2025-10-16 01:10:16,130] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:10:16.131 | [2025-10-16 01:10:16,131] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:10:16.132 | [2025-10-16 01:10:16,132] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
2025-10-15 20:10:16.132 | [2025-10-16 01:10:16,132] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-10-15 20:10:16.134 | [2025-10-16 01:10:16,133] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-10-15 20:10:16.135 | [2025-10-16 01:10:16,133] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-10-15 20:10:16.136 | [2025-10-16 01:10:16,136] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
2025-10-15 20:10:16.137 | [2025-10-16 01:10:16,137] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
2025-10-15 20:10:16.138 | [2025-10-16 01:10:16,137] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
2025-10-15 20:10:16.138 | [2025-10-16 01:10:16,138] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
2025-10-15 20:10:16.138 | [2025-10-16 01:10:16,138] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:10:16.140 | [2025-10-16 01:10:16,140] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:10:16.167 | [2025-10-16 01:10:16,140] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:10:16.170 | [2025-10-16 01:10:16,170] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:10:16.173 | [2025-10-16 01:10:16,172] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:10:16.173 | [2025-10-16 01:10:16,173] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:10:16.174 | [2025-10-16 01:10:16,174] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:10:16.177 | [2025-10-16 01:10:16,176] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:10:16.177 | [2025-10-16 01:10:16,176] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:10:16.178 | [2025-10-16 01:10:16,177] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:10:16.179 | [2025-10-16 01:10:16,179] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:10:16.179 | [2025-10-16 01:10:16,179] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:10:16.194 | [2025-10-16 01:10:16,193] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
2025-10-15 20:10:16.194 | [2025-10-16 01:10:16,194] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:10:16.195 | [2025-10-16 01:10:16,194] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:10:16.195 | [2025-10-16 01:10:16,194] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:10:16.198 | [2025-10-16 01:10:16,198] INFO Broker to controller channel manager for alter-partition shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
2025-10-15 20:10:16.198 | [2025-10-16 01:10:16,198] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:10:16.198 | [2025-10-16 01:10:16,198] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Stopped (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:10:16.199 | [2025-10-16 01:10:16,198] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:10:16.200 | [2025-10-16 01:10:16,200] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
2025-10-15 20:10:16.201 | [2025-10-16 01:10:16,201] INFO Shutting down. (kafka.log.LogManager)
2025-10-15 20:10:16.203 | [2025-10-16 01:10:16,203] INFO Shutting down the log cleaner. (kafka.log.LogCleaner)
2025-10-15 20:10:16.205 | [2025-10-16 01:10:16,204] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
2025-10-15 20:10:16.205 | [2025-10-16 01:10:16,205] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
2025-10-15 20:10:16.206 | [2025-10-16 01:10:16,205] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
2025-10-15 20:10:16.372 | [2025-10-16 01:10:16,371] INFO [ProducerStateManager partition=__consumer_offsets-19]Wrote producer snapshot at offset 1 with 0 producer ids in 9 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
2025-10-15 20:10:16.709 | [2025-10-16 01:10:16,709] INFO [ProducerStateManager partition=mesa-ya.restaurants.created-0]Wrote producer snapshot at offset 1 with 0 producer ids in 6 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
2025-10-15 20:10:17.007 | [2025-10-16 01:10:17,006] INFO Shutdown complete. (kafka.log.LogManager)
2025-10-15 20:10:17.010 | [2025-10-16 01:10:17,010] INFO [ControllerEventThread controllerId=1] Shutting down (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-10-15 20:10:17.012 | [2025-10-16 01:10:17,012] INFO [ControllerEventThread controllerId=1] Shutdown completed (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-10-15 20:10:17.016 | [2025-10-16 01:10:17,012] INFO [ControllerEventThread controllerId=1] Stopped (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-10-15 20:10:17.017 | [2025-10-16 01:10:17,016] DEBUG [Controller id=1] Resigning (kafka.controller.KafkaController)
2025-10-15 20:10:17.020 | [2025-10-16 01:10:17,019] DEBUG [Controller id=1] Unregister BrokerModifications handler for Set(1) (kafka.controller.KafkaController)
2025-10-15 20:10:17.027 | [2025-10-16 01:10:17,026] INFO [PartitionStateMachine controllerId=1] Stopped partition state machine (kafka.controller.ZkPartitionStateMachine)
2025-10-15 20:10:17.029 | [2025-10-16 01:10:17,029] INFO [ReplicaStateMachine controllerId=1] Stopped replica state machine (kafka.controller.ZkReplicaStateMachine)
2025-10-15 20:10:17.035 | [2025-10-16 01:10:17,034] INFO [RequestSendThread controllerId=1] Shutting down (kafka.controller.RequestSendThread)
2025-10-15 20:10:17.036 | [2025-10-16 01:10:17,036] INFO [RequestSendThread controllerId=1] Shutdown completed (kafka.controller.RequestSendThread)
2025-10-15 20:10:17.037 | [2025-10-16 01:10:17,036] INFO [RequestSendThread controllerId=1] Stopped (kafka.controller.RequestSendThread)
2025-10-15 20:10:17.042 | [2025-10-16 01:10:17,042] INFO [Controller id=1] Resigned (kafka.controller.KafkaController)
2025-10-15 20:10:17.045 | [2025-10-16 01:10:17,044] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-10-15 20:10:17.046 | [2025-10-16 01:10:17,046] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-10-15 20:10:17.048 | [2025-10-16 01:10:17,046] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-10-15 20:10:17.051 | [2025-10-16 01:10:17,050] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
2025-10-15 20:10:17.186 | [2025-10-16 01:10:17,186] INFO Session: 0x1000011a3f20001 closed (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:10:17.187 | [2025-10-16 01:10:17,186] INFO EventThread shut down for session: 0x1000011a3f20001 (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:10:17.190 | [2025-10-16 01:10:17,189] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
2025-10-15 20:10:17.191 | [2025-10-16 01:10:17,190] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:10:17.196 | [2025-10-16 01:10:17,196] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:10:17.197 | [2025-10-16 01:10:17,196] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:10:17.198 | [2025-10-16 01:10:17,197] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:10:17.199 | [2025-10-16 01:10:17,198] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:10:17.199 | [2025-10-16 01:10:17,198] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:10:17.200 | [2025-10-16 01:10:17,199] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:10:17.201 | [2025-10-16 01:10:17,200] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:10:17.201 | [2025-10-16 01:10:17,200] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:10:17.203 | [2025-10-16 01:10:17,202] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:10:17.203 | [2025-10-16 01:10:17,203] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:10:17.203 | [2025-10-16 01:10:17,203] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:10:17.205 | [2025-10-16 01:10:17,205] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
2025-10-15 20:10:17.259 | [2025-10-16 01:10:17,259] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
2025-10-15 20:10:17.260 | [2025-10-16 01:10:17,260] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
2025-10-15 20:10:17.260 | [2025-10-16 01:10:17,260] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
2025-10-15 20:10:17.261 | [2025-10-16 01:10:17,260] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
2025-10-15 20:10:17.264 | [2025-10-16 01:10:17,264] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
2025-10-15 20:10:17.265 | [2025-10-16 01:10:17,265] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
2025-10-15 20:10:17.266 | [2025-10-16 01:10:17,265] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
2025-10-15 20:17:00.695 | ===> User
2025-10-15 20:17:00.698 | uid=1000(appuser) gid=1000(appuser) groups=1000(appuser)
2025-10-15 20:17:00.698 | ===> Configuring ...
2025-10-15 20:17:00.704 | Running in Zookeeper mode...
2025-10-15 20:17:03.368 | ===> Running preflight checks ... 
2025-10-15 20:17:03.371 | ===> Check if /var/lib/kafka/data is writable ...
2025-10-15 20:17:03.732 | ===> Check if Zookeeper is healthy ...
2025-10-15 20:17:04.382 | [2025-10-16 01:17:04,381] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:04.382 | [2025-10-16 01:17:04,382] INFO Client environment:host.name=2ae4b23f74a4 (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:04.382 | [2025-10-16 01:17:04,382] INFO Client environment:java.version=11.0.20 (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:04.382 | [2025-10-16 01:17:04,382] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:04.382 | [2025-10-16 01:17:04,382] INFO Client environment:java.home=/usr/lib/jvm/java-11-zulu-openjdk-ca (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:04.383 | [2025-10-16 01:17:04,382] INFO Client environment:java.class.path=/usr/share/java/cp-base-new/minimal-json-0.9.5.jar:/usr/share/java/cp-base-new/kafka-clients-7.5.0-ccs.jar:/usr/share/java/cp-base-new/slf4j-api-1.7.36.jar:/usr/share/java/cp-base-new/jmx_prometheus_javaagent-0.18.0.jar:/usr/share/java/cp-base-new/jackson-annotations-2.14.2.jar:/usr/share/java/cp-base-new/scala-collection-compat_2.13-2.10.0.jar:/usr/share/java/cp-base-new/gson-2.9.0.jar:/usr/share/java/cp-base-new/kafka-server-common-7.5.0-ccs.jar:/usr/share/java/cp-base-new/jose4j-0.9.3.jar:/usr/share/java/cp-base-new/scala-reflect-2.13.10.jar:/usr/share/java/cp-base-new/zstd-jni-1.5.5-1.jar:/usr/share/java/cp-base-new/jackson-datatype-jdk8-2.14.2.jar:/usr/share/java/cp-base-new/kafka-storage-7.5.0-ccs.jar:/usr/share/java/cp-base-new/reload4j-1.2.19.jar:/usr/share/java/cp-base-new/kafka-raft-7.5.0-ccs.jar:/usr/share/java/cp-base-new/logredactor-1.0.12.jar:/usr/share/java/cp-base-new/jackson-module-scala_2.13-2.14.2.jar:/usr/share/java/cp-base-new/paranamer-2.8.jar:/usr/share/java/cp-base-new/utility-belt-7.5.0.jar:/usr/share/java/cp-base-new/snakeyaml-2.0.jar:/usr/share/java/cp-base-new/metrics-core-2.2.0.jar:/usr/share/java/cp-base-new/metrics-core-4.1.12.1.jar:/usr/share/java/cp-base-new/kafka-tools-api-7.5.0-ccs.jar:/usr/share/java/cp-base-new/logredactor-metrics-1.0.12.jar:/usr/share/java/cp-base-new/scala-logging_2.13-3.9.4.jar:/usr/share/java/cp-base-new/jolokia-core-1.7.1.jar:/usr/share/java/cp-base-new/kafka-metadata-7.5.0-ccs.jar:/usr/share/java/cp-base-new/audience-annotations-0.5.0.jar:/usr/share/java/cp-base-new/argparse4j-0.7.0.jar:/usr/share/java/cp-base-new/kafka-storage-api-7.5.0-ccs.jar:/usr/share/java/cp-base-new/jopt-simple-5.0.4.jar:/usr/share/java/cp-base-new/jackson-dataformat-csv-2.14.2.jar:/usr/share/java/cp-base-new/jackson-core-2.14.2.jar:/usr/share/java/cp-base-new/snappy-java-1.1.10.1.jar:/usr/share/java/cp-base-new/scala-java8-compat_2.13-1.0.2.jar:/usr/share/java/cp-base-new/disk-usage-agent-7.5.0.jar:/usr/share/java/cp-base-new/commons-cli-1.4.jar:/usr/share/java/cp-base-new/common-utils-7.5.0.jar:/usr/share/java/cp-base-new/jolokia-jvm-1.7.1.jar:/usr/share/java/cp-base-new/lz4-java-1.8.0.jar:/usr/share/java/cp-base-new/json-simple-1.1.1.jar:/usr/share/java/cp-base-new/zookeeper-3.6.3.jar:/usr/share/java/cp-base-new/kafka_2.13-7.5.0-ccs.jar:/usr/share/java/cp-base-new/jackson-databind-2.14.2.jar:/usr/share/java/cp-base-new/kafka-group-coordinator-7.5.0-ccs.jar:/usr/share/java/cp-base-new/slf4j-reload4j-1.7.36.jar:/usr/share/java/cp-base-new/zookeeper-jute-3.6.3.jar:/usr/share/java/cp-base-new/scala-library-2.13.10.jar:/usr/share/java/cp-base-new/re2j-1.6.jar:/usr/share/java/cp-base-new/jackson-dataformat-yaml-2.14.2.jar (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:04.383 | [2025-10-16 01:17:04,382] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:04.383 | [2025-10-16 01:17:04,382] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:04.383 | [2025-10-16 01:17:04,382] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:04.383 | [2025-10-16 01:17:04,382] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:04.383 | [2025-10-16 01:17:04,382] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:04.383 | [2025-10-16 01:17:04,382] INFO Client environment:os.version=6.6.87.1-microsoft-standard-WSL2 (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:04.383 | [2025-10-16 01:17:04,382] INFO Client environment:user.name=appuser (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:04.383 | [2025-10-16 01:17:04,382] INFO Client environment:user.home=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:04.383 | [2025-10-16 01:17:04,383] INFO Client environment:user.dir=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:04.383 | [2025-10-16 01:17:04,383] INFO Client environment:os.memory.free=112MB (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:04.383 | [2025-10-16 01:17:04,383] INFO Client environment:os.memory.max=1948MB (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:04.383 | [2025-10-16 01:17:04,383] INFO Client environment:os.memory.total=122MB (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:04.387 | [2025-10-16 01:17:04,386] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=40000 watcher=io.confluent.admin.utils.ZookeeperConnectionWatcher@221af3c0 (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:04.392 | [2025-10-16 01:17:04,391] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
2025-10-15 20:17:04.399 | [2025-10-16 01:17:04,399] INFO jute.maxbuffer value is 1048575 Bytes (org.apache.zookeeper.ClientCnxnSocket)
2025-10-15 20:17:04.405 | [2025-10-16 01:17:04,405] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:17:04.431 | [2025-10-16 01:17:04,429] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:17:04.431 | [2025-10-16 01:17:04,431] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:17:04.438 | [2025-10-16 01:17:04,438] INFO Socket connection established, initiating session, client: /172.18.0.3:39840, server: zookeeper/172.18.0.2:2181 (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:17:04.473 | [2025-10-16 01:17:04,472] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, session id = 0x10000328ad90000, negotiated timeout = 40000 (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:17:04.491 | [2025-10-16 01:17:04,489] WARN An exception was thrown while closing send thread for session 0x10000328ad90000. (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:17:04.491 | EndOfStreamException: Unable to read additional data from server sessionid 0x10000328ad90000, likely server has closed socket
2025-10-15 20:17:04.491 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
2025-10-15 20:17:04.491 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
2025-10-15 20:17:04.491 | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-10-15 20:17:04.594 | [2025-10-16 01:17:04,594] INFO Session: 0x10000328ad90000 closed (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:04.595 | [2025-10-16 01:17:04,594] INFO EventThread shut down for session: 0x10000328ad90000 (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:17:04.602 | Using log4j config /etc/kafka/log4j.properties
2025-10-15 20:17:04.661 | ===> Launching ... 
2025-10-15 20:17:04.670 | ===> Launching kafka ... 
2025-10-15 20:17:05.216 | [2025-10-16 01:17:05,215] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
2025-10-15 20:17:05.554 | [2025-10-16 01:17:05,554] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
2025-10-15 20:17:05.648 | [2025-10-16 01:17:05,647] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
2025-10-15 20:17:05.649 | [2025-10-16 01:17:05,649] INFO starting (kafka.server.KafkaServer)
2025-10-15 20:17:05.650 | [2025-10-16 01:17:05,650] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
2025-10-15 20:17:05.669 | [2025-10-16 01:17:05,668] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
2025-10-15 20:17:05.677 | [2025-10-16 01:17:05,676] INFO Client environment:zookeeper.version=3.6.4--d65253dcf68e9097c6e95a126463fd5fdeb4521c, built on 12/18/2022 18:10 GMT (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:05.677 | [2025-10-16 01:17:05,676] INFO Client environment:host.name=2ae4b23f74a4 (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:05.677 | [2025-10-16 01:17:05,676] INFO Client environment:java.version=11.0.20 (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:05.677 | [2025-10-16 01:17:05,676] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:05.677 | [2025-10-16 01:17:05,676] INFO Client environment:java.home=/usr/lib/jvm/java-11-zulu-openjdk-ca (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:05.677 | [2025-10-16 01:17:05,677] INFO Client environment:java.class.path=/usr/bin/../share/java/kafka/zookeeper-jute-3.6.4.jar:/usr/bin/../share/java/kafka/jackson-datatype-jdk8-2.13.5.jar:/usr/bin/../share/java/kafka/jakarta.inject-2.6.1.jar:/usr/bin/../share/java/kafka/netty-transport-native-epoll-4.1.96.Final.jar:/usr/bin/../share/java/kafka/kafka-clients-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jline-3.22.0.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.36.jar:/usr/bin/../share/java/kafka/reflections-0.9.12.jar:/usr/bin/../share/java/kafka/scala-collection-compat_2.13-2.10.0.jar:/usr/bin/../share/java/kafka/javassist-3.29.2-GA.jar:/usr/bin/../share/java/kafka/connect-runtime-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jakarta.annotation-api-1.3.5.jar:/usr/bin/../share/java/kafka/jackson-databind-2.13.5.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/kafka-streams-scala_2.13-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/javax.activation-api-1.2.0.jar:/usr/bin/../share/java/kafka/rocksdbjni-7.1.2.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/usr/bin/../share/java/kafka/kafka-server-common-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jose4j-0.9.3.jar:/usr/bin/../share/java/kafka/scala-reflect-2.13.10.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.13.5.jar:/usr/bin/../share/java/kafka/zstd-jni-1.5.5-1.jar:/usr/bin/../share/java/kafka/kafka-storage-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jetty-security-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.39.1.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/kafka-raft-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/netty-transport-native-unix-common-4.1.96.Final.jar:/usr/bin/../share/java/kafka/jersey-server-2.39.1.jar:/usr/bin/../share/java/kafka/paranamer-2.8.jar:/usr/bin/../share/java/kafka/jersey-common-2.39.1.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/netty-transport-4.1.96.Final.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/metrics-core-4.1.12.1.jar:/usr/bin/../share/java/kafka/netty-buffer-4.1.96.Final.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.13.5.jar:/usr/bin/../share/java/kafka/netty-resolver-4.1.96.Final.jar:/usr/bin/../share/java/kafka/kafka-tools-api-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jaxb-api-2.3.1.jar:/usr/bin/../share/java/kafka/jetty-util-ajax-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/scala-logging_2.13-3.9.4.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.6.1.jar:/usr/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/usr/bin/../share/java/kafka/jakarta.xml.bind-api-2.3.3.jar:/usr/bin/../share/java/kafka/kafka-metadata-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/plexus-utils-3.3.0.jar:/usr/bin/../share/java/kafka/jakarta.activation-api-1.2.2.jar:/usr/bin/../share/java/kafka/argparse4j-0.7.0.jar:/usr/bin/../share/java/kafka/hk2-utils-2.6.1.jar:/usr/bin/../share/java/kafka/connect-api-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/connect-mirror-client-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.3.jar:/usr/bin/../share/java/kafka/javax.annotation-api-1.3.2.jar:/usr/bin/../share/java/kafka/jersey-hk2-2.39.1.jar:/usr/bin/../share/java/kafka/kafka-storage-api-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jetty-http-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/trogdor-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/maven-artifact-3.8.4.jar:/usr/bin/../share/java/kafka/connect-json-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/scala-java8-compat_2.13-1.0.2.jar:/usr/bin/../share/java/kafka/jetty-server-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/swagger-annotations-2.2.8.jar:/usr/bin/../share/java/kafka/jetty-util-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/commons-cli-1.4.jar:/usr/bin/../share/java/kafka/jetty-io-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/activation-1.1.1.jar:/usr/bin/../share/java/kafka/lz4-java-1.8.0.jar:/usr/bin/../share/java/kafka/kafka-shell-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/netty-common-4.1.96.Final.jar:/usr/bin/../share/java/kafka/jetty-client-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/jackson-module-scala_2.13-2.13.5.jar:/usr/bin/../share/java/kafka/connect-transforms-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jackson-core-2.13.5.jar:/usr/bin/../share/java/kafka/kafka_2.13-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/netty-codec-4.1.96.Final.jar:/usr/bin/../share/java/kafka/zookeeper-3.6.4.jar:/usr/bin/../share/java/kafka/kafka-streams-test-utils-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/hk2-api-2.6.1.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.39.1.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/reload4j-1.2.25.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.10.0.jar:/usr/bin/../share/java/kafka/netty-transport-classes-epoll-4.1.96.Final.jar:/usr/bin/../share/java/kafka/connect-mirror-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/kafka-streams-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/kafka-group-coordinator-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/connect-basic-auth-extension-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jersey-client-2.39.1.jar:/usr/bin/../share/java/kafka/kafka-tools-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/slf4j-reload4j-1.7.36.jar:/usr/bin/../share/java/kafka/jackson-dataformat-csv-2.13.5.jar:/usr/bin/../share/java/kafka/scala-library-2.13.10.jar:/usr/bin/../share/java/kafka/netty-handler-4.1.96.Final.jar:/usr/bin/../share/java/kafka/jakarta.validation-api-2.0.2.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.13.5.jar:/usr/bin/../share/java/kafka/audience-annotations-0.13.0.jar:/usr/bin/../share/java/kafka/hk2-locator-2.6.1.jar:/usr/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.6.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.13.5.jar:/usr/bin/../share/java/confluent-telemetry/* (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:05.677 | [2025-10-16 01:17:05,677] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:05.677 | [2025-10-16 01:17:05,677] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:05.677 | [2025-10-16 01:17:05,677] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:05.677 | [2025-10-16 01:17:05,677] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:05.677 | [2025-10-16 01:17:05,677] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:05.677 | [2025-10-16 01:17:05,677] INFO Client environment:os.version=6.6.87.1-microsoft-standard-WSL2 (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:05.677 | [2025-10-16 01:17:05,677] INFO Client environment:user.name=appuser (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:05.677 | [2025-10-16 01:17:05,677] INFO Client environment:user.home=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:05.677 | [2025-10-16 01:17:05,677] INFO Client environment:user.dir=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:05.677 | [2025-10-16 01:17:05,677] INFO Client environment:os.memory.free=1009MB (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:05.677 | [2025-10-16 01:17:05,677] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:05.677 | [2025-10-16 01:17:05,677] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:05.679 | [2025-10-16 01:17:05,679] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@13d73fa (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:05.686 | [2025-10-16 01:17:05,685] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
2025-10-15 20:17:05.694 | [2025-10-16 01:17:05,693] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:17:05.697 | [2025-10-16 01:17:05,696] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
2025-10-15 20:17:05.702 | [2025-10-16 01:17:05,701] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:17:05.708 | [2025-10-16 01:17:05,708] INFO Socket connection established, initiating session, client: /172.18.0.3:39850, server: zookeeper/172.18.0.2:2181 (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:17:05.721 | [2025-10-16 01:17:05,721] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, session id = 0x10000328ad90001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:17:05.725 | [2025-10-16 01:17:05,725] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
2025-10-15 20:17:06.125 | [2025-10-16 01:17:06,124] INFO Cluster ID = DgiegCMhTNSyWQSymt96xQ (kafka.server.KafkaServer)
2025-10-15 20:17:06.184 | [2025-10-16 01:17:06,183] INFO KafkaConfig values: 
2025-10-15 20:17:06.184 | 	advertised.listeners = PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
2025-10-15 20:17:06.184 | 	alter.config.policy.class.name = null
2025-10-15 20:17:06.184 | 	alter.log.dirs.replication.quota.window.num = 11
2025-10-15 20:17:06.184 | 	alter.log.dirs.replication.quota.window.size.seconds = 1
2025-10-15 20:17:06.184 | 	authorizer.class.name = 
2025-10-15 20:17:06.184 | 	auto.create.topics.enable = true
2025-10-15 20:17:06.184 | 	auto.include.jmx.reporter = true
2025-10-15 20:17:06.184 | 	auto.leader.rebalance.enable = true
2025-10-15 20:17:06.184 | 	background.threads = 10
2025-10-15 20:17:06.184 | 	broker.heartbeat.interval.ms = 2000
2025-10-15 20:17:06.184 | 	broker.id = 1
2025-10-15 20:17:06.184 | 	broker.id.generation.enable = true
2025-10-15 20:17:06.184 | 	broker.rack = null
2025-10-15 20:17:06.184 | 	broker.session.timeout.ms = 9000
2025-10-15 20:17:06.184 | 	client.quota.callback.class = null
2025-10-15 20:17:06.184 | 	compression.type = producer
2025-10-15 20:17:06.184 | 	connection.failed.authentication.delay.ms = 100
2025-10-15 20:17:06.184 | 	connections.max.idle.ms = 600000
2025-10-15 20:17:06.184 | 	connections.max.reauth.ms = 0
2025-10-15 20:17:06.184 | 	control.plane.listener.name = null
2025-10-15 20:17:06.184 | 	controlled.shutdown.enable = true
2025-10-15 20:17:06.184 | 	controlled.shutdown.max.retries = 3
2025-10-15 20:17:06.184 | 	controlled.shutdown.retry.backoff.ms = 5000
2025-10-15 20:17:06.184 | 	controller.listener.names = null
2025-10-15 20:17:06.184 | 	controller.quorum.append.linger.ms = 25
2025-10-15 20:17:06.184 | 	controller.quorum.election.backoff.max.ms = 1000
2025-10-15 20:17:06.184 | 	controller.quorum.election.timeout.ms = 1000
2025-10-15 20:17:06.184 | 	controller.quorum.fetch.timeout.ms = 2000
2025-10-15 20:17:06.184 | 	controller.quorum.request.timeout.ms = 2000
2025-10-15 20:17:06.184 | 	controller.quorum.retry.backoff.ms = 20
2025-10-15 20:17:06.184 | 	controller.quorum.voters = []
2025-10-15 20:17:06.184 | 	controller.quota.window.num = 11
2025-10-15 20:17:06.184 | 	controller.quota.window.size.seconds = 1
2025-10-15 20:17:06.184 | 	controller.socket.timeout.ms = 30000
2025-10-15 20:17:06.184 | 	create.topic.policy.class.name = null
2025-10-15 20:17:06.184 | 	default.replication.factor = 1
2025-10-15 20:17:06.184 | 	delegation.token.expiry.check.interval.ms = 3600000
2025-10-15 20:17:06.184 | 	delegation.token.expiry.time.ms = 86400000
2025-10-15 20:17:06.184 | 	delegation.token.master.key = null
2025-10-15 20:17:06.184 | 	delegation.token.max.lifetime.ms = 604800000
2025-10-15 20:17:06.184 | 	delegation.token.secret.key = null
2025-10-15 20:17:06.184 | 	delete.records.purgatory.purge.interval.requests = 1
2025-10-15 20:17:06.184 | 	delete.topic.enable = true
2025-10-15 20:17:06.184 | 	early.start.listeners = null
2025-10-15 20:17:06.184 | 	fetch.max.bytes = 57671680
2025-10-15 20:17:06.184 | 	fetch.purgatory.purge.interval.requests = 1000
2025-10-15 20:17:06.184 | 	group.consumer.assignors = []
2025-10-15 20:17:06.184 | 	group.consumer.heartbeat.interval.ms = 5000
2025-10-15 20:17:06.184 | 	group.consumer.max.heartbeat.interval.ms = 15000
2025-10-15 20:17:06.184 | 	group.consumer.max.session.timeout.ms = 60000
2025-10-15 20:17:06.184 | 	group.consumer.max.size = 2147483647
2025-10-15 20:17:06.184 | 	group.consumer.min.heartbeat.interval.ms = 5000
2025-10-15 20:17:06.184 | 	group.consumer.min.session.timeout.ms = 45000
2025-10-15 20:17:06.184 | 	group.consumer.session.timeout.ms = 45000
2025-10-15 20:17:06.184 | 	group.coordinator.new.enable = false
2025-10-15 20:17:06.184 | 	group.coordinator.threads = 1
2025-10-15 20:17:06.184 | 	group.initial.rebalance.delay.ms = 3000
2025-10-15 20:17:06.184 | 	group.max.session.timeout.ms = 1800000
2025-10-15 20:17:06.184 | 	group.max.size = 2147483647
2025-10-15 20:17:06.184 | 	group.min.session.timeout.ms = 6000
2025-10-15 20:17:06.184 | 	initial.broker.registration.timeout.ms = 60000
2025-10-15 20:17:06.184 | 	inter.broker.listener.name = PLAINTEXT_INTERNAL
2025-10-15 20:17:06.184 | 	inter.broker.protocol.version = 3.5-IV2
2025-10-15 20:17:06.184 | 	kafka.metrics.polling.interval.secs = 10
2025-10-15 20:17:06.184 | 	kafka.metrics.reporters = []
2025-10-15 20:17:06.184 | 	leader.imbalance.check.interval.seconds = 300
2025-10-15 20:17:06.184 | 	leader.imbalance.per.broker.percentage = 10
2025-10-15 20:17:06.184 | 	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
2025-10-15 20:17:06.184 | 	listeners = PLAINTEXT://0.0.0.0:9092,PLAINTEXT_INTERNAL://0.0.0.0:29092
2025-10-15 20:17:06.184 | 	log.cleaner.backoff.ms = 15000
2025-10-15 20:17:06.184 | 	log.cleaner.dedupe.buffer.size = 134217728
2025-10-15 20:17:06.184 | 	log.cleaner.delete.retention.ms = 86400000
2025-10-15 20:17:06.184 | 	log.cleaner.enable = true
2025-10-15 20:17:06.184 | 	log.cleaner.io.buffer.load.factor = 0.9
2025-10-15 20:17:06.184 | 	log.cleaner.io.buffer.size = 524288
2025-10-15 20:17:06.184 | 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
2025-10-15 20:17:06.184 | 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
2025-10-15 20:17:06.184 | 	log.cleaner.min.cleanable.ratio = 0.5
2025-10-15 20:17:06.184 | 	log.cleaner.min.compaction.lag.ms = 0
2025-10-15 20:17:06.184 | 	log.cleaner.threads = 1
2025-10-15 20:17:06.184 | 	log.cleanup.policy = [delete]
2025-10-15 20:17:06.184 | 	log.dir = /tmp/kafka-logs
2025-10-15 20:17:06.184 | 	log.dirs = /var/lib/kafka/data
2025-10-15 20:17:06.184 | 	log.flush.interval.messages = 9223372036854775807
2025-10-15 20:17:06.184 | 	log.flush.interval.ms = null
2025-10-15 20:17:06.184 | 	log.flush.offset.checkpoint.interval.ms = 60000
2025-10-15 20:17:06.184 | 	log.flush.scheduler.interval.ms = 9223372036854775807
2025-10-15 20:17:06.184 | 	log.flush.start.offset.checkpoint.interval.ms = 60000
2025-10-15 20:17:06.184 | 	log.index.interval.bytes = 4096
2025-10-15 20:17:06.184 | 	log.index.size.max.bytes = 10485760
2025-10-15 20:17:06.184 | 	log.message.downconversion.enable = true
2025-10-15 20:17:06.184 | 	log.message.format.version = 3.0-IV1
2025-10-15 20:17:06.184 | 	log.message.timestamp.difference.max.ms = 9223372036854775807
2025-10-15 20:17:06.184 | 	log.message.timestamp.type = CreateTime
2025-10-15 20:17:06.184 | 	log.preallocate = false
2025-10-15 20:17:06.184 | 	log.retention.bytes = -1
2025-10-15 20:17:06.184 | 	log.retention.check.interval.ms = 300000
2025-10-15 20:17:06.184 | 	log.retention.hours = 168
2025-10-15 20:17:06.184 | 	log.retention.minutes = null
2025-10-15 20:17:06.184 | 	log.retention.ms = null
2025-10-15 20:17:06.184 | 	log.roll.hours = 168
2025-10-15 20:17:06.184 | 	log.roll.jitter.hours = 0
2025-10-15 20:17:06.184 | 	log.roll.jitter.ms = null
2025-10-15 20:17:06.184 | 	log.roll.ms = null
2025-10-15 20:17:06.184 | 	log.segment.bytes = 1073741824
2025-10-15 20:17:06.184 | 	log.segment.delete.delay.ms = 60000
2025-10-15 20:17:06.184 | 	max.connection.creation.rate = 2147483647
2025-10-15 20:17:06.184 | 	max.connections = 2147483647
2025-10-15 20:17:06.184 | 	max.connections.per.ip = 2147483647
2025-10-15 20:17:06.184 | 	max.connections.per.ip.overrides = 
2025-10-15 20:17:06.184 | 	max.incremental.fetch.session.cache.slots = 1000
2025-10-15 20:17:06.184 | 	message.max.bytes = 1048588
2025-10-15 20:17:06.184 | 	metadata.log.dir = null
2025-10-15 20:17:06.184 | 	metadata.log.max.record.bytes.between.snapshots = 20971520
2025-10-15 20:17:06.184 | 	metadata.log.max.snapshot.interval.ms = 3600000
2025-10-15 20:17:06.184 | 	metadata.log.segment.bytes = 1073741824
2025-10-15 20:17:06.184 | 	metadata.log.segment.min.bytes = 8388608
2025-10-15 20:17:06.184 | 	metadata.log.segment.ms = 604800000
2025-10-15 20:17:06.184 | 	metadata.max.idle.interval.ms = 500
2025-10-15 20:17:06.184 | 	metadata.max.retention.bytes = 104857600
2025-10-15 20:17:06.184 | 	metadata.max.retention.ms = 604800000
2025-10-15 20:17:06.184 | 	metric.reporters = []
2025-10-15 20:17:06.184 | 	metrics.num.samples = 2
2025-10-15 20:17:06.184 | 	metrics.recording.level = INFO
2025-10-15 20:17:06.184 | 	metrics.sample.window.ms = 30000
2025-10-15 20:17:06.184 | 	min.insync.replicas = 1
2025-10-15 20:17:06.184 | 	node.id = 1
2025-10-15 20:17:06.184 | 	num.io.threads = 8
2025-10-15 20:17:06.184 | 	num.network.threads = 3
2025-10-15 20:17:06.184 | 	num.partitions = 1
2025-10-15 20:17:06.184 | 	num.recovery.threads.per.data.dir = 1
2025-10-15 20:17:06.184 | 	num.replica.alter.log.dirs.threads = null
2025-10-15 20:17:06.184 | 	num.replica.fetchers = 1
2025-10-15 20:17:06.184 | 	offset.metadata.max.bytes = 4096
2025-10-15 20:17:06.184 | 	offsets.commit.required.acks = -1
2025-10-15 20:17:06.184 | 	offsets.commit.timeout.ms = 5000
2025-10-15 20:17:06.184 | 	offsets.load.buffer.size = 5242880
2025-10-15 20:17:06.184 | 	offsets.retention.check.interval.ms = 600000
2025-10-15 20:17:06.184 | 	offsets.retention.minutes = 10080
2025-10-15 20:17:06.184 | 	offsets.topic.compression.codec = 0
2025-10-15 20:17:06.184 | 	offsets.topic.num.partitions = 50
2025-10-15 20:17:06.184 | 	offsets.topic.replication.factor = 1
2025-10-15 20:17:06.184 | 	offsets.topic.segment.bytes = 104857600
2025-10-15 20:17:06.184 | 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
2025-10-15 20:17:06.184 | 	password.encoder.iterations = 4096
2025-10-15 20:17:06.185 | 	password.encoder.key.length = 128
2025-10-15 20:17:06.185 | 	password.encoder.keyfactory.algorithm = null
2025-10-15 20:17:06.185 | 	password.encoder.old.secret = null
2025-10-15 20:17:06.185 | 	password.encoder.secret = null
2025-10-15 20:17:06.185 | 	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
2025-10-15 20:17:06.185 | 	process.roles = []
2025-10-15 20:17:06.185 | 	producer.id.expiration.check.interval.ms = 600000
2025-10-15 20:17:06.185 | 	producer.id.expiration.ms = 86400000
2025-10-15 20:17:06.185 | 	producer.purgatory.purge.interval.requests = 1000
2025-10-15 20:17:06.185 | 	queued.max.request.bytes = -1
2025-10-15 20:17:06.185 | 	queued.max.requests = 500
2025-10-15 20:17:06.185 | 	quota.window.num = 11
2025-10-15 20:17:06.185 | 	quota.window.size.seconds = 1
2025-10-15 20:17:06.185 | 	remote.log.index.file.cache.total.size.bytes = 1073741824
2025-10-15 20:17:06.185 | 	remote.log.manager.task.interval.ms = 30000
2025-10-15 20:17:06.185 | 	remote.log.manager.task.retry.backoff.max.ms = 30000
2025-10-15 20:17:06.185 | 	remote.log.manager.task.retry.backoff.ms = 500
2025-10-15 20:17:06.185 | 	remote.log.manager.task.retry.jitter = 0.2
2025-10-15 20:17:06.185 | 	remote.log.manager.thread.pool.size = 10
2025-10-15 20:17:06.185 | 	remote.log.metadata.manager.class.name = null
2025-10-15 20:17:06.185 | 	remote.log.metadata.manager.class.path = null
2025-10-15 20:17:06.185 | 	remote.log.metadata.manager.impl.prefix = null
2025-10-15 20:17:06.185 | 	remote.log.metadata.manager.listener.name = null
2025-10-15 20:17:06.185 | 	remote.log.reader.max.pending.tasks = 100
2025-10-15 20:17:06.185 | 	remote.log.reader.threads = 10
2025-10-15 20:17:06.185 | 	remote.log.storage.manager.class.name = null
2025-10-15 20:17:06.185 | 	remote.log.storage.manager.class.path = null
2025-10-15 20:17:06.185 | 	remote.log.storage.manager.impl.prefix = null
2025-10-15 20:17:06.185 | 	remote.log.storage.system.enable = false
2025-10-15 20:17:06.185 | 	replica.fetch.backoff.ms = 1000
2025-10-15 20:17:06.185 | 	replica.fetch.max.bytes = 1048576
2025-10-15 20:17:06.185 | 	replica.fetch.min.bytes = 1
2025-10-15 20:17:06.185 | 	replica.fetch.response.max.bytes = 10485760
2025-10-15 20:17:06.185 | 	replica.fetch.wait.max.ms = 500
2025-10-15 20:17:06.185 | 	replica.high.watermark.checkpoint.interval.ms = 5000
2025-10-15 20:17:06.185 | 	replica.lag.time.max.ms = 30000
2025-10-15 20:17:06.185 | 	replica.selector.class = null
2025-10-15 20:17:06.185 | 	replica.socket.receive.buffer.bytes = 65536
2025-10-15 20:17:06.185 | 	replica.socket.timeout.ms = 30000
2025-10-15 20:17:06.185 | 	replication.quota.window.num = 11
2025-10-15 20:17:06.185 | 	replication.quota.window.size.seconds = 1
2025-10-15 20:17:06.185 | 	request.timeout.ms = 30000
2025-10-15 20:17:06.185 | 	reserved.broker.max.id = 1000
2025-10-15 20:17:06.185 | 	sasl.client.callback.handler.class = null
2025-10-15 20:17:06.185 | 	sasl.enabled.mechanisms = [GSSAPI]
2025-10-15 20:17:06.185 | 	sasl.jaas.config = null
2025-10-15 20:17:06.185 | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
2025-10-15 20:17:06.185 | 	sasl.kerberos.min.time.before.relogin = 60000
2025-10-15 20:17:06.185 | 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
2025-10-15 20:17:06.185 | 	sasl.kerberos.service.name = null
2025-10-15 20:17:06.185 | 	sasl.kerberos.ticket.renew.jitter = 0.05
2025-10-15 20:17:06.185 | 	sasl.kerberos.ticket.renew.window.factor = 0.8
2025-10-15 20:17:06.185 | 	sasl.login.callback.handler.class = null
2025-10-15 20:17:06.185 | 	sasl.login.class = null
2025-10-15 20:17:06.185 | 	sasl.login.connect.timeout.ms = null
2025-10-15 20:17:06.185 | 	sasl.login.read.timeout.ms = null
2025-10-15 20:17:06.185 | 	sasl.login.refresh.buffer.seconds = 300
2025-10-15 20:17:06.185 | 	sasl.login.refresh.min.period.seconds = 60
2025-10-15 20:17:06.185 | 	sasl.login.refresh.window.factor = 0.8
2025-10-15 20:17:06.185 | 	sasl.login.refresh.window.jitter = 0.05
2025-10-15 20:17:06.185 | 	sasl.login.retry.backoff.max.ms = 10000
2025-10-15 20:17:06.185 | 	sasl.login.retry.backoff.ms = 100
2025-10-15 20:17:06.185 | 	sasl.mechanism.controller.protocol = GSSAPI
2025-10-15 20:17:06.185 | 	sasl.mechanism.inter.broker.protocol = GSSAPI
2025-10-15 20:17:06.185 | 	sasl.oauthbearer.clock.skew.seconds = 30
2025-10-15 20:17:06.185 | 	sasl.oauthbearer.expected.audience = null
2025-10-15 20:17:06.185 | 	sasl.oauthbearer.expected.issuer = null
2025-10-15 20:17:06.185 | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
2025-10-15 20:17:06.185 | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
2025-10-15 20:17:06.185 | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
2025-10-15 20:17:06.185 | 	sasl.oauthbearer.jwks.endpoint.url = null
2025-10-15 20:17:06.185 | 	sasl.oauthbearer.scope.claim.name = scope
2025-10-15 20:17:06.185 | 	sasl.oauthbearer.sub.claim.name = sub
2025-10-15 20:17:06.185 | 	sasl.oauthbearer.token.endpoint.url = null
2025-10-15 20:17:06.185 | 	sasl.server.callback.handler.class = null
2025-10-15 20:17:06.185 | 	sasl.server.max.receive.size = 524288
2025-10-15 20:17:06.185 | 	security.inter.broker.protocol = PLAINTEXT
2025-10-15 20:17:06.185 | 	security.providers = null
2025-10-15 20:17:06.185 | 	server.max.startup.time.ms = 9223372036854775807
2025-10-15 20:17:06.185 | 	socket.connection.setup.timeout.max.ms = 30000
2025-10-15 20:17:06.185 | 	socket.connection.setup.timeout.ms = 10000
2025-10-15 20:17:06.185 | 	socket.listen.backlog.size = 50
2025-10-15 20:17:06.185 | 	socket.receive.buffer.bytes = 102400
2025-10-15 20:17:06.185 | 	socket.request.max.bytes = 104857600
2025-10-15 20:17:06.185 | 	socket.send.buffer.bytes = 102400
2025-10-15 20:17:06.185 | 	ssl.cipher.suites = []
2025-10-15 20:17:06.185 | 	ssl.client.auth = none
2025-10-15 20:17:06.185 | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
2025-10-15 20:17:06.185 | 	ssl.endpoint.identification.algorithm = https
2025-10-15 20:17:06.185 | 	ssl.engine.factory.class = null
2025-10-15 20:17:06.185 | 	ssl.key.password = null
2025-10-15 20:17:06.185 | 	ssl.keymanager.algorithm = SunX509
2025-10-15 20:17:06.185 | 	ssl.keystore.certificate.chain = null
2025-10-15 20:17:06.185 | 	ssl.keystore.key = null
2025-10-15 20:17:06.185 | 	ssl.keystore.location = null
2025-10-15 20:17:06.185 | 	ssl.keystore.password = null
2025-10-15 20:17:06.185 | 	ssl.keystore.type = JKS
2025-10-15 20:17:06.185 | 	ssl.principal.mapping.rules = DEFAULT
2025-10-15 20:17:06.185 | 	ssl.protocol = TLSv1.3
2025-10-15 20:17:06.185 | 	ssl.provider = null
2025-10-15 20:17:06.185 | 	ssl.secure.random.implementation = null
2025-10-15 20:17:06.185 | 	ssl.trustmanager.algorithm = PKIX
2025-10-15 20:17:06.185 | 	ssl.truststore.certificates = null
2025-10-15 20:17:06.185 | 	ssl.truststore.location = null
2025-10-15 20:17:06.185 | 	ssl.truststore.password = null
2025-10-15 20:17:06.185 | 	ssl.truststore.type = JKS
2025-10-15 20:17:06.185 | 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
2025-10-15 20:17:06.185 | 	transaction.max.timeout.ms = 900000
2025-10-15 20:17:06.185 | 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
2025-10-15 20:17:06.185 | 	transaction.state.log.load.buffer.size = 5242880
2025-10-15 20:17:06.185 | 	transaction.state.log.min.isr = 1
2025-10-15 20:17:06.185 | 	transaction.state.log.num.partitions = 50
2025-10-15 20:17:06.185 | 	transaction.state.log.replication.factor = 1
2025-10-15 20:17:06.185 | 	transaction.state.log.segment.bytes = 104857600
2025-10-15 20:17:06.185 | 	transactional.id.expiration.ms = 604800000
2025-10-15 20:17:06.185 | 	unclean.leader.election.enable = false
2025-10-15 20:17:06.185 | 	unstable.api.versions.enable = false
2025-10-15 20:17:06.185 | 	zookeeper.clientCnxnSocket = null
2025-10-15 20:17:06.185 | 	zookeeper.connect = zookeeper:2181
2025-10-15 20:17:06.185 | 	zookeeper.connection.timeout.ms = null
2025-10-15 20:17:06.185 | 	zookeeper.max.in.flight.requests = 10
2025-10-15 20:17:06.185 | 	zookeeper.metadata.migration.enable = false
2025-10-15 20:17:06.185 | 	zookeeper.session.timeout.ms = 18000
2025-10-15 20:17:06.185 | 	zookeeper.set.acl = false
2025-10-15 20:17:06.185 | 	zookeeper.ssl.cipher.suites = null
2025-10-15 20:17:06.185 | 	zookeeper.ssl.client.enable = false
2025-10-15 20:17:06.185 | 	zookeeper.ssl.crl.enable = false
2025-10-15 20:17:06.185 | 	zookeeper.ssl.enabled.protocols = null
2025-10-15 20:17:06.185 | 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
2025-10-15 20:17:06.185 | 	zookeeper.ssl.keystore.location = null
2025-10-15 20:17:06.185 | 	zookeeper.ssl.keystore.password = null
2025-10-15 20:17:06.185 | 	zookeeper.ssl.keystore.type = null
2025-10-15 20:17:06.185 | 	zookeeper.ssl.ocsp.enable = false
2025-10-15 20:17:06.185 | 	zookeeper.ssl.protocol = TLSv1.2
2025-10-15 20:17:06.185 | 	zookeeper.ssl.truststore.location = null
2025-10-15 20:17:06.185 | 	zookeeper.ssl.truststore.password = null
2025-10-15 20:17:06.185 | 	zookeeper.ssl.truststore.type = null
2025-10-15 20:17:06.185 |  (kafka.server.KafkaConfig)
2025-10-15 20:17:06.225 | [2025-10-16 01:17:06,224] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:17:06.227 | [2025-10-16 01:17:06,226] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:17:06.228 | [2025-10-16 01:17:06,228] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:17:06.232 | [2025-10-16 01:17:06,231] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:17:06.294 | [2025-10-16 01:17:06,293] INFO Loading logs from log dirs ArraySeq(/var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:06.316 | [2025-10-16 01:17:06,315] INFO Skipping recovery of 51 logs from /var/lib/kafka/data since clean shutdown file was found (kafka.log.LogManager)
2025-10-15 20:17:06.415 | [2025-10-16 01:17:06,414] INFO [LogLoader partition=__consumer_offsets-29, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:06.448 | [2025-10-16 01:17:06,447] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-29, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 125ms (1/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:06.464 | [2025-10-16 01:17:06,463] INFO [LogLoader partition=__consumer_offsets-49, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:06.467 | [2025-10-16 01:17:06,466] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-49, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (2/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:06.482 | [2025-10-16 01:17:06,481] INFO [LogLoader partition=__consumer_offsets-28, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:06.485 | [2025-10-16 01:17:06,485] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-28, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (3/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:06.498 | [2025-10-16 01:17:06,498] INFO [LogLoader partition=__consumer_offsets-5, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:06.502 | [2025-10-16 01:17:06,501] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-5, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (4/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:06.519 | [2025-10-16 01:17:06,519] INFO [LogLoader partition=__consumer_offsets-10, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:06.521 | [2025-10-16 01:17:06,521] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-10, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (5/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:06.534 | [2025-10-16 01:17:06,534] INFO [LogLoader partition=__consumer_offsets-14, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:06.536 | [2025-10-16 01:17:06,536] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-14, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (6/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:06.554 | [2025-10-16 01:17:06,554] INFO [LogLoader partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Loading producer state till offset 1 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:06.555 | [2025-10-16 01:17:06,554] INFO [LogLoader partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 1 (kafka.log.UnifiedLog$)
2025-10-15 20:17:06.555 | [2025-10-16 01:17:06,555] INFO [ProducerStateManager partition=__consumer_offsets-19]Loading producer state from snapshot file 'SnapshotFile(offset=1, file=/var/lib/kafka/data/__consumer_offsets-19/00000000000000000001.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
2025-10-15 20:17:06.561 | [2025-10-16 01:17:06,561] INFO [LogLoader partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 1 (kafka.log.UnifiedLog$)
2025-10-15 20:17:06.563 | [2025-10-16 01:17:06,563] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-19, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=1) with 1 segments in 27ms (7/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:06.577 | [2025-10-16 01:17:06,576] INFO [LogLoader partition=__consumer_offsets-8, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:06.581 | [2025-10-16 01:17:06,580] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-8, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (8/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:06.594 | [2025-10-16 01:17:06,594] INFO [LogLoader partition=__consumer_offsets-17, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:06.597 | [2025-10-16 01:17:06,597] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-17, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (9/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:06.612 | [2025-10-16 01:17:06,612] INFO [LogLoader partition=__consumer_offsets-35, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:06.615 | [2025-10-16 01:17:06,614] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-35, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (10/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:06.627 | [2025-10-16 01:17:06,627] INFO [LogLoader partition=__consumer_offsets-31, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:06.629 | [2025-10-16 01:17:06,629] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-31, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (11/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:06.640 | [2025-10-16 01:17:06,640] INFO [LogLoader partition=__consumer_offsets-6, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:06.642 | [2025-10-16 01:17:06,642] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-6, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (12/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:06.656 | [2025-10-16 01:17:06,656] INFO [LogLoader partition=__consumer_offsets-32, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:06.658 | [2025-10-16 01:17:06,658] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-32, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (13/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:06.676 | [2025-10-16 01:17:06,675] INFO [LogLoader partition=__consumer_offsets-3, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:06.680 | [2025-10-16 01:17:06,679] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-3, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (14/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:06.692 | [2025-10-16 01:17:06,692] INFO [LogLoader partition=__consumer_offsets-30, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:06.695 | [2025-10-16 01:17:06,695] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-30, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (15/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:06.710 | [2025-10-16 01:17:06,709] INFO [LogLoader partition=__consumer_offsets-37, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:06.713 | [2025-10-16 01:17:06,713] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-37, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (16/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:06.728 | [2025-10-16 01:17:06,728] INFO [LogLoader partition=__consumer_offsets-41, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:06.732 | [2025-10-16 01:17:06,731] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-41, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (17/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:06.748 | [2025-10-16 01:17:06,747] INFO [LogLoader partition=__consumer_offsets-26, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:06.761 | [2025-10-16 01:17:06,760] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-26, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 29ms (18/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:06.775 | [2025-10-16 01:17:06,774] INFO [LogLoader partition=__consumer_offsets-4, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:06.776 | [2025-10-16 01:17:06,776] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-4, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (19/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:06.791 | [2025-10-16 01:17:06,790] INFO [LogLoader partition=__consumer_offsets-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:06.793 | [2025-10-16 01:17:06,793] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-1, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (20/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:06.815 | [2025-10-16 01:17:06,814] INFO [LogLoader partition=__consumer_offsets-33, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:06.819 | [2025-10-16 01:17:06,818] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-33, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 26ms (21/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:06.842 | [2025-10-16 01:17:06,841] INFO [LogLoader partition=__consumer_offsets-25, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:06.843 | [2025-10-16 01:17:06,843] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-25, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 24ms (22/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:06.855 | [2025-10-16 01:17:06,855] INFO [LogLoader partition=__consumer_offsets-42, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:06.857 | [2025-10-16 01:17:06,856] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-42, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (23/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:06.872 | [2025-10-16 01:17:06,871] INFO [LogLoader partition=__consumer_offsets-2, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:06.874 | [2025-10-16 01:17:06,873] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-2, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (24/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:06.889 | [2025-10-16 01:17:06,889] INFO [LogLoader partition=__consumer_offsets-34, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:06.891 | [2025-10-16 01:17:06,890] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-34, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (25/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:06.905 | [2025-10-16 01:17:06,905] INFO [LogLoader partition=__consumer_offsets-36, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:06.907 | [2025-10-16 01:17:06,907] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-36, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (26/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:06.925 | [2025-10-16 01:17:06,925] INFO [LogLoader partition=__consumer_offsets-12, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:06.926 | [2025-10-16 01:17:06,926] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-12, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (27/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:06.937 | [2025-10-16 01:17:06,937] INFO [LogLoader partition=__consumer_offsets-20, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:06.939 | [2025-10-16 01:17:06,938] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-20, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (28/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:06.950 | [2025-10-16 01:17:06,949] INFO [LogLoader partition=__consumer_offsets-23, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:06.951 | [2025-10-16 01:17:06,951] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-23, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (29/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:06.964 | [2025-10-16 01:17:06,963] INFO [LogLoader partition=__consumer_offsets-13, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:06.966 | [2025-10-16 01:17:06,965] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-13, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (30/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:06.978 | [2025-10-16 01:17:06,978] INFO [LogLoader partition=__consumer_offsets-40, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:06.980 | [2025-10-16 01:17:06,980] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-40, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (31/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:06.994 | [2025-10-16 01:17:06,994] INFO [LogLoader partition=__consumer_offsets-43, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:06.996 | [2025-10-16 01:17:06,996] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-43, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (32/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:07.015 | [2025-10-16 01:17:07,014] INFO [LogLoader partition=__consumer_offsets-39, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:07.017 | [2025-10-16 01:17:07,017] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-39, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (33/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:07.033 | [2025-10-16 01:17:07,033] INFO [LogLoader partition=__consumer_offsets-46, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:07.035 | [2025-10-16 01:17:07,034] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-46, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (34/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:07.052 | [2025-10-16 01:17:07,052] INFO [LogLoader partition=__consumer_offsets-7, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:07.054 | [2025-10-16 01:17:07,053] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-7, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (35/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:07.068 | [2025-10-16 01:17:07,068] INFO [LogLoader partition=__consumer_offsets-38, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:07.070 | [2025-10-16 01:17:07,070] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-38, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (36/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:07.084 | [2025-10-16 01:17:07,084] INFO [LogLoader partition=__consumer_offsets-47, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:07.086 | [2025-10-16 01:17:07,085] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-47, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (37/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:07.104 | [2025-10-16 01:17:07,103] INFO [LogLoader partition=__consumer_offsets-11, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:07.105 | [2025-10-16 01:17:07,105] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-11, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (38/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:07.120 | [2025-10-16 01:17:07,120] INFO [LogLoader partition=__consumer_offsets-21, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:07.121 | [2025-10-16 01:17:07,121] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-21, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (39/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:07.136 | [2025-10-16 01:17:07,135] INFO [LogLoader partition=__consumer_offsets-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:07.138 | [2025-10-16 01:17:07,137] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-0, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (40/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:07.151 | [2025-10-16 01:17:07,151] INFO [LogLoader partition=__consumer_offsets-16, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:07.152 | [2025-10-16 01:17:07,152] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-16, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (41/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:07.167 | [2025-10-16 01:17:07,167] INFO [LogLoader partition=__consumer_offsets-22, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:07.169 | [2025-10-16 01:17:07,169] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-22, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (42/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:07.188 | [2025-10-16 01:17:07,188] INFO [LogLoader partition=__consumer_offsets-15, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:07.191 | [2025-10-16 01:17:07,190] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-15, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 22ms (43/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:07.214 | [2025-10-16 01:17:07,214] INFO [LogLoader partition=__consumer_offsets-18, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:07.216 | [2025-10-16 01:17:07,216] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-18, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 25ms (44/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:07.228 | [2025-10-16 01:17:07,228] INFO [LogLoader partition=__consumer_offsets-27, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:07.229 | [2025-10-16 01:17:07,229] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-27, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (45/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:07.242 | [2025-10-16 01:17:07,242] INFO [LogLoader partition=__consumer_offsets-24, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:07.243 | [2025-10-16 01:17:07,243] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-24, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (46/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:07.255 | [2025-10-16 01:17:07,255] INFO [LogLoader partition=__consumer_offsets-9, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:07.256 | [2025-10-16 01:17:07,256] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-9, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (47/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:07.267 | [2025-10-16 01:17:07,267] INFO [LogLoader partition=__consumer_offsets-45, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:07.268 | [2025-10-16 01:17:07,268] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-45, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (48/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:07.282 | [2025-10-16 01:17:07,282] INFO [LogLoader partition=__consumer_offsets-44, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:07.284 | [2025-10-16 01:17:07,284] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-44, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (49/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:07.298 | [2025-10-16 01:17:07,298] INFO [LogLoader partition=mesa-ya.restaurants.created-0, dir=/var/lib/kafka/data] Loading producer state till offset 1 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:07.298 | [2025-10-16 01:17:07,298] INFO [LogLoader partition=mesa-ya.restaurants.created-0, dir=/var/lib/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 1 (kafka.log.UnifiedLog$)
2025-10-15 20:17:07.298 | [2025-10-16 01:17:07,298] INFO [ProducerStateManager partition=mesa-ya.restaurants.created-0]Loading producer state from snapshot file 'SnapshotFile(offset=1, file=/var/lib/kafka/data/mesa-ya.restaurants.created-0/00000000000000000001.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
2025-10-15 20:17:07.298 | [2025-10-16 01:17:07,298] INFO [LogLoader partition=mesa-ya.restaurants.created-0, dir=/var/lib/kafka/data] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 1 (kafka.log.UnifiedLog$)
2025-10-15 20:17:07.301 | [2025-10-16 01:17:07,300] INFO Completed load of Log(dir=/var/lib/kafka/data/mesa-ya.restaurants.created-0, topicId=yWm6W48_TyqOOX8W2L0ItA, topic=mesa-ya.restaurants.created, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=1) with 1 segments in 16ms (50/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:07.315 | [2025-10-16 01:17:07,315] INFO [LogLoader partition=__consumer_offsets-48, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:07.318 | [2025-10-16 01:17:07,317] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-48, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (51/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:07.327 | [2025-10-16 01:17:07,326] INFO Loaded 51 logs in 1030ms (kafka.log.LogManager)
2025-10-15 20:17:07.331 | [2025-10-16 01:17:07,330] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
2025-10-15 20:17:07.332 | [2025-10-16 01:17:07,332] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
2025-10-15 20:17:07.347 | [2025-10-16 01:17:07,346] INFO Starting the log cleaner (kafka.log.LogCleaner)
2025-10-15 20:17:07.489 | [2025-10-16 01:17:07,489] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
2025-10-15 20:17:07.522 | [2025-10-16 01:17:07,522] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-10-15 20:17:07.545 | [2025-10-16 01:17:07,545] INFO [MetadataCache brokerId=1] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0). (kafka.server.metadata.ZkMetadataCache)
2025-10-15 20:17:07.571 | [2025-10-16 01:17:07,570] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:17:07.858 | [2025-10-16 01:17:07,858] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
2025-10-15 20:17:07.898 | [2025-10-16 01:17:07,897] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
2025-10-15 20:17:07.898 | [2025-10-16 01:17:07,898] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
2025-10-15 20:17:07.904 | [2025-10-16 01:17:07,904] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT_INTERNAL) (kafka.network.SocketServer)
2025-10-15 20:17:07.916 | [2025-10-16 01:17:07,915] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:17:07.946 | [2025-10-16 01:17:07,945] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:07.948 | [2025-10-16 01:17:07,947] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:07.950 | [2025-10-16 01:17:07,949] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:07.951 | [2025-10-16 01:17:07,951] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:07.969 | [2025-10-16 01:17:07,968] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-10-15 20:17:08.023 | [2025-10-16 01:17:08,023] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
2025-10-15 20:17:08.052 | [2025-10-16 01:17:08,051] INFO Stat of the created znode at /brokers/ids/1 is: 160,160,1760577428040,1760577428040,1,0,0,72057811115769857,270,0,160
2025-10-15 20:17:08.052 |  (kafka.zk.KafkaZkClient)
2025-10-15 20:17:08.052 | [2025-10-16 01:17:08,052] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092, czxid (broker epoch): 160 (kafka.zk.KafkaZkClient)
2025-10-15 20:17:08.152 | [2025-10-16 01:17:08,151] INFO [ControllerEventThread controllerId=1] Starting (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-10-15 20:17:08.163 | [2025-10-16 01:17:08,163] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:08.174 | [2025-10-16 01:17:08,173] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:08.175 | [2025-10-16 01:17:08,174] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:08.192 | [2025-10-16 01:17:08,192] INFO [Controller id=1] 1 successfully elected as the controller. Epoch incremented to 2 and epoch zk version is now 2 (kafka.controller.KafkaController)
2025-10-15 20:17:08.197 | [2025-10-16 01:17:08,196] INFO [Controller id=1] Registering handlers (kafka.controller.KafkaController)
2025-10-15 20:17:08.197 | [2025-10-16 01:17:08,197] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:08.203 | [2025-10-16 01:17:08,203] INFO [Controller id=1] Deleting log dir event notifications (kafka.controller.KafkaController)
2025-10-15 20:17:08.207 | [2025-10-16 01:17:08,207] INFO [Controller id=1] Deleting isr change notifications (kafka.controller.KafkaController)
2025-10-15 20:17:08.212 | [2025-10-16 01:17:08,212] INFO [Controller id=1] Initializing controller context (kafka.controller.KafkaController)
2025-10-15 20:17:08.217 | [2025-10-16 01:17:08,216] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:08.239 | [2025-10-16 01:17:08,238] INFO [Controller id=1] Initialized broker epochs cache: HashMap(1 -> 160) (kafka.controller.KafkaController)
2025-10-15 20:17:08.256 | [2025-10-16 01:17:08,255] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
2025-10-15 20:17:08.259 | [2025-10-16 01:17:08,259] DEBUG [Controller id=1] Register BrokerModifications handler for Set(1) (kafka.controller.KafkaController)
2025-10-15 20:17:08.262 | [2025-10-16 01:17:08,261] INFO [TxnMarkerSenderThread-1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-10-15 20:17:08.262 | [2025-10-16 01:17:08,262] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
2025-10-15 20:17:08.321 | [2025-10-16 01:17:08,320] DEBUG [Channel manager on controller 1]: Controller 1 trying to connect to broker 1 (kafka.controller.ControllerChannelManager)
2025-10-15 20:17:08.331 | [2025-10-16 01:17:08,330] INFO [RequestSendThread controllerId=1] Starting (kafka.controller.RequestSendThread)
2025-10-15 20:17:08.332 | [2025-10-16 01:17:08,332] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:08.333 | [2025-10-16 01:17:08,332] INFO [Controller id=1] Currently active brokers in the cluster: Set(1) (kafka.controller.KafkaController)
2025-10-15 20:17:08.334 | [2025-10-16 01:17:08,333] INFO [Controller id=1] Currently shutting brokers in the cluster: HashSet() (kafka.controller.KafkaController)
2025-10-15 20:17:08.334 | [2025-10-16 01:17:08,334] INFO [Controller id=1] Current list of topics in the cluster: HashSet(__consumer_offsets, mesa-ya.restaurants.created) (kafka.controller.KafkaController)
2025-10-15 20:17:08.335 | [2025-10-16 01:17:08,334] INFO [Controller id=1] Fetching topic deletions in progress (kafka.controller.KafkaController)
2025-10-15 20:17:08.346 | [2025-10-16 01:17:08,346] INFO [Controller id=1] List of topics to be deleted:  (kafka.controller.KafkaController)
2025-10-15 20:17:08.347 | [2025-10-16 01:17:08,347] INFO [Controller id=1] List of topics ineligible for deletion:  (kafka.controller.KafkaController)
2025-10-15 20:17:08.348 | [2025-10-16 01:17:08,347] INFO [Controller id=1] Initializing topic deletion manager (kafka.controller.KafkaController)
2025-10-15 20:17:08.348 | [2025-10-16 01:17:08,348] INFO [Topic Deletion Manager 1] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet() (kafka.controller.TopicDeletionManager)
2025-10-15 20:17:08.350 | [2025-10-16 01:17:08,349] INFO [Controller id=1] Sending update metadata request (kafka.controller.KafkaController)
2025-10-15 20:17:08.353 | [2025-10-16 01:17:08,352] INFO [Controller id=1 epoch=2] Sending UpdateMetadata request to brokers HashSet(1) for 0 partitions (state.change.logger)
2025-10-15 20:17:08.365 | [2025-10-16 01:17:08,365] INFO [ReplicaStateMachine controllerId=1] Initializing replica state (kafka.controller.ZkReplicaStateMachine)
2025-10-15 20:17:08.374 | [2025-10-16 01:17:08,374] INFO [ReplicaStateMachine controllerId=1] Triggering online replica state changes (kafka.controller.ZkReplicaStateMachine)
2025-10-15 20:17:08.376 | [2025-10-16 01:17:08,376] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-10-15 20:17:08.377 | [2025-10-16 01:17:08,377] INFO [Controller id=1, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
2025-10-15 20:17:08.381 | [2025-10-16 01:17:08,380] WARN [Controller id=1, targetBrokerId=1] Connection to node 1 (kafka/172.18.0.3:29092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
2025-10-15 20:17:08.387 | [2025-10-16 01:17:08,383] WARN [RequestSendThread controllerId=1] Controller 1's connection to broker kafka:29092 (id: 1 rack: null) was unsuccessful (kafka.controller.RequestSendThread)
2025-10-15 20:17:08.387 | java.io.IOException: Connection to kafka:29092 (id: 1 rack: null) failed.
2025-10-15 20:17:08.387 | 	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
2025-10-15 20:17:08.387 | 	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:296)
2025-10-15 20:17:08.387 | 	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:249)
2025-10-15 20:17:08.387 | 	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:127)
2025-10-15 20:17:08.387 | [2025-10-16 01:17:08,387] INFO [Controller id=1, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
2025-10-15 20:17:08.403 | [2025-10-16 01:17:08,403] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-46 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.404 | [2025-10-16 01:17:08,403] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-37 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.404 | [2025-10-16 01:17:08,404] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-8 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.404 | [2025-10-16 01:17:08,404] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-49 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.404 | [2025-10-16 01:17:08,404] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-21 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.404 | [2025-10-16 01:17:08,404] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-20 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.404 | [2025-10-16 01:17:08,404] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-17 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.405 | [2025-10-16 01:17:08,404] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-19 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.405 | [2025-10-16 01:17:08,405] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-7 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.406 | [2025-10-16 01:17:08,405] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-43 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.406 | [2025-10-16 01:17:08,406] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-30 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.408 | [2025-10-16 01:17:08,407] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-35 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.408 | [2025-10-16 01:17:08,407] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-27 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.408 | [2025-10-16 01:17:08,408] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition mesa-ya.restaurants.created-0 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.408 | [2025-10-16 01:17:08,408] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-0 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.409 | [2025-10-16 01:17:08,409] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-40 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.409 | [2025-10-16 01:17:08,409] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-47 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.409 | [2025-10-16 01:17:08,409] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-10 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.410 | [2025-10-16 01:17:08,409] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-4 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.410 | [2025-10-16 01:17:08,410] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-31 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.410 | [2025-10-16 01:17:08,410] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-16 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.411 | [2025-10-16 01:17:08,410] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-23 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.411 | [2025-10-16 01:17:08,411] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-26 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.412 | [2025-10-16 01:17:08,412] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-39 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.412 | [2025-10-16 01:17:08,412] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-2 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.413 | [2025-10-16 01:17:08,413] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-34 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.413 | [2025-10-16 01:17:08,413] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-24 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.413 | [2025-10-16 01:17:08,413] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-32 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.414 | [2025-10-16 01:17:08,413] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-41 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.414 | [2025-10-16 01:17:08,414] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-5 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.414 | [2025-10-16 01:17:08,414] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-15 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.415 | [2025-10-16 01:17:08,414] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-1 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.415 | [2025-10-16 01:17:08,415] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-9 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.415 | [2025-10-16 01:17:08,415] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-45 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.415 | [2025-10-16 01:17:08,415] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-36 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.415 | [2025-10-16 01:17:08,415] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-48 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.415 | [2025-10-16 01:17:08,415] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-3 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.416 | [2025-10-16 01:17:08,415] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-18 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.416 | [2025-10-16 01:17:08,416] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-44 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.416 | [2025-10-16 01:17:08,416] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-11 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.416 | [2025-10-16 01:17:08,416] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-25 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.416 | [2025-10-16 01:17:08,416] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-29 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.416 | [2025-10-16 01:17:08,416] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-6 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.416 | [2025-10-16 01:17:08,416] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-42 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.417 | [2025-10-16 01:17:08,416] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-28 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.417 | [2025-10-16 01:17:08,416] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-12 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.417 | [2025-10-16 01:17:08,417] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-38 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.417 | [2025-10-16 01:17:08,417] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-33 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.417 | [2025-10-16 01:17:08,417] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-14 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.417 | [2025-10-16 01:17:08,417] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-13 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.418 | [2025-10-16 01:17:08,417] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-22 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:08.430 | [2025-10-16 01:17:08,429] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
2025-10-15 20:17:08.435 | [2025-10-16 01:17:08,435] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-13 (state.change.logger)
2025-10-15 20:17:08.435 | [2025-10-16 01:17:08,435] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-46 (state.change.logger)
2025-10-15 20:17:08.435 | [2025-10-16 01:17:08,435] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-9 (state.change.logger)
2025-10-15 20:17:08.435 | [2025-10-16 01:17:08,435] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-42 (state.change.logger)
2025-10-15 20:17:08.435 | [2025-10-16 01:17:08,435] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-21 (state.change.logger)
2025-10-15 20:17:08.435 | [2025-10-16 01:17:08,435] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-17 (state.change.logger)
2025-10-15 20:17:08.436 | [2025-10-16 01:17:08,435] INFO Awaiting socket connections on 0.0.0.0:29092. (kafka.network.DataPlaneAcceptor)
2025-10-15 20:17:08.436 | [2025-10-16 01:17:08,435] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-30 (state.change.logger)
2025-10-15 20:17:08.436 | [2025-10-16 01:17:08,436] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-26 (state.change.logger)
2025-10-15 20:17:08.436 | [2025-10-16 01:17:08,436] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-5 (state.change.logger)
2025-10-15 20:17:08.436 | [2025-10-16 01:17:08,436] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-38 (state.change.logger)
2025-10-15 20:17:08.436 | [2025-10-16 01:17:08,436] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-1 (state.change.logger)
2025-10-15 20:17:08.436 | [2025-10-16 01:17:08,436] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-34 (state.change.logger)
2025-10-15 20:17:08.436 | [2025-10-16 01:17:08,436] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-16 (state.change.logger)
2025-10-15 20:17:08.436 | [2025-10-16 01:17:08,436] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-45 (state.change.logger)
2025-10-15 20:17:08.436 | [2025-10-16 01:17:08,436] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-12 (state.change.logger)
2025-10-15 20:17:08.436 | [2025-10-16 01:17:08,436] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-41 (state.change.logger)
2025-10-15 20:17:08.436 | [2025-10-16 01:17:08,436] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-24 (state.change.logger)
2025-10-15 20:17:08.436 | [2025-10-16 01:17:08,436] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-20 (state.change.logger)
2025-10-15 20:17:08.436 | [2025-10-16 01:17:08,436] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-49 (state.change.logger)
2025-10-15 20:17:08.436 | [2025-10-16 01:17:08,436] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-0 (state.change.logger)
2025-10-15 20:17:08.436 | [2025-10-16 01:17:08,436] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-29 (state.change.logger)
2025-10-15 20:17:08.436 | [2025-10-16 01:17:08,436] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-25 (state.change.logger)
2025-10-15 20:17:08.436 | [2025-10-16 01:17:08,436] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-8 (state.change.logger)
2025-10-15 20:17:08.437 | [2025-10-16 01:17:08,436] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-37 (state.change.logger)
2025-10-15 20:17:08.437 | [2025-10-16 01:17:08,436] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-4 (state.change.logger)
2025-10-15 20:17:08.437 | [2025-10-16 01:17:08,436] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-33 (state.change.logger)
2025-10-15 20:17:08.437 | [2025-10-16 01:17:08,436] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-15 (state.change.logger)
2025-10-15 20:17:08.437 | [2025-10-16 01:17:08,436] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-48 (state.change.logger)
2025-10-15 20:17:08.437 | [2025-10-16 01:17:08,436] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-11 (state.change.logger)
2025-10-15 20:17:08.437 | [2025-10-16 01:17:08,437] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-44 (state.change.logger)
2025-10-15 20:17:08.437 | [2025-10-16 01:17:08,437] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-23 (state.change.logger)
2025-10-15 20:17:08.437 | [2025-10-16 01:17:08,437] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-19 (state.change.logger)
2025-10-15 20:17:08.437 | [2025-10-16 01:17:08,437] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-32 (state.change.logger)
2025-10-15 20:17:08.437 | [2025-10-16 01:17:08,437] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-28 (state.change.logger)
2025-10-15 20:17:08.437 | [2025-10-16 01:17:08,437] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-7 (state.change.logger)
2025-10-15 20:17:08.437 | [2025-10-16 01:17:08,437] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-40 (state.change.logger)
2025-10-15 20:17:08.437 | [2025-10-16 01:17:08,437] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-3 (state.change.logger)
2025-10-15 20:17:08.437 | [2025-10-16 01:17:08,437] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-36 (state.change.logger)
2025-10-15 20:17:08.437 | [2025-10-16 01:17:08,437] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-47 (state.change.logger)
2025-10-15 20:17:08.437 | [2025-10-16 01:17:08,437] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-14 (state.change.logger)
2025-10-15 20:17:08.437 | [2025-10-16 01:17:08,437] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-43 (state.change.logger)
2025-10-15 20:17:08.437 | [2025-10-16 01:17:08,437] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-10 (state.change.logger)
2025-10-15 20:17:08.437 | [2025-10-16 01:17:08,437] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-22 (state.change.logger)
2025-10-15 20:17:08.437 | [2025-10-16 01:17:08,437] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-18 (state.change.logger)
2025-10-15 20:17:08.437 | [2025-10-16 01:17:08,437] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-31 (state.change.logger)
2025-10-15 20:17:08.437 | [2025-10-16 01:17:08,437] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-27 (state.change.logger)
2025-10-15 20:17:08.437 | [2025-10-16 01:17:08,437] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-39 (state.change.logger)
2025-10-15 20:17:08.437 | [2025-10-16 01:17:08,437] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-6 (state.change.logger)
2025-10-15 20:17:08.438 | [2025-10-16 01:17:08,437] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-35 (state.change.logger)
2025-10-15 20:17:08.438 | [2025-10-16 01:17:08,437] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='mesa-ya.restaurants.created', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition mesa-ya.restaurants.created-0 (state.change.logger)
2025-10-15 20:17:08.438 | [2025-10-16 01:17:08,437] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-2 (state.change.logger)
2025-10-15 20:17:08.440 | [2025-10-16 01:17:08,439] INFO [Controller id=1 epoch=2] Sending LeaderAndIsr request to broker 1 with 51 become-leader and 0 become-follower partitions (state.change.logger)
2025-10-15 20:17:08.440 | [2025-10-16 01:17:08,440] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
2025-10-15 20:17:08.447 | [2025-10-16 01:17:08,447] INFO [Controller id=1 epoch=2] Sending UpdateMetadata request to brokers HashSet(1) for 51 partitions (state.change.logger)
2025-10-15 20:17:08.448 | [2025-10-16 01:17:08,448] INFO [ReplicaStateMachine controllerId=1] Triggering offline replica state changes (kafka.controller.ZkReplicaStateMachine)
2025-10-15 20:17:08.451 | [2025-10-16 01:17:08,450] DEBUG [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> HashMap([Topic=__consumer_offsets,Partition=46,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=37,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=8,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=49,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=21,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=20,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=17,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=19,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=7,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=43,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=30,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=35,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=27,Replica=1] -> OnlineReplica, [Topic=mesa-ya.restaurants.created,Partition=0,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=0,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=40,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=47,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=10,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=4,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=31,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=16,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=23,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=26,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=39,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=2,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=34,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=24,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=32,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=41,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=5,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=15,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=1,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=9,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=45,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=36,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=48,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=3,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=18,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=44,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=11,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=25,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=29,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=6,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=42,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=28,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=12,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=38,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=33,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=14,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=13,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=22,Replica=1] -> OnlineReplica) (kafka.controller.ZkReplicaStateMachine)
2025-10-15 20:17:08.452 | [2025-10-16 01:17:08,451] INFO [PartitionStateMachine controllerId=1] Initializing partition state (kafka.controller.ZkPartitionStateMachine)
2025-10-15 20:17:08.453 | [2025-10-16 01:17:08,452] INFO Kafka version: 7.5.0-ccs (org.apache.kafka.common.utils.AppInfoParser)
2025-10-15 20:17:08.453 | [2025-10-16 01:17:08,452] INFO Kafka commitId: ff3c201baa948d97889dc26c99d7cdc23d038f2e (org.apache.kafka.common.utils.AppInfoParser)
2025-10-15 20:17:08.453 | [2025-10-16 01:17:08,452] INFO Kafka startTimeMs: 1760577428446 (org.apache.kafka.common.utils.AppInfoParser)
2025-10-15 20:17:08.454 | [2025-10-16 01:17:08,454] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
2025-10-15 20:17:08.457 | [2025-10-16 01:17:08,457] INFO [PartitionStateMachine controllerId=1] Triggering online partition state changes (kafka.controller.ZkPartitionStateMachine)
2025-10-15 20:17:08.460 | [2025-10-16 01:17:08,459] DEBUG [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> HashMap(__consumer_offsets-13 -> OnlinePartition, __consumer_offsets-46 -> OnlinePartition, __consumer_offsets-9 -> OnlinePartition, __consumer_offsets-42 -> OnlinePartition, __consumer_offsets-21 -> OnlinePartition, __consumer_offsets-17 -> OnlinePartition, __consumer_offsets-30 -> OnlinePartition, __consumer_offsets-26 -> OnlinePartition, __consumer_offsets-5 -> OnlinePartition, __consumer_offsets-38 -> OnlinePartition, __consumer_offsets-1 -> OnlinePartition, __consumer_offsets-34 -> OnlinePartition, __consumer_offsets-16 -> OnlinePartition, __consumer_offsets-45 -> OnlinePartition, __consumer_offsets-12 -> OnlinePartition, __consumer_offsets-41 -> OnlinePartition, __consumer_offsets-24 -> OnlinePartition, __consumer_offsets-20 -> OnlinePartition, __consumer_offsets-49 -> OnlinePartition, __consumer_offsets-0 -> OnlinePartition, __consumer_offsets-29 -> OnlinePartition, __consumer_offsets-25 -> OnlinePartition, __consumer_offsets-8 -> OnlinePartition, __consumer_offsets-37 -> OnlinePartition, __consumer_offsets-4 -> OnlinePartition, __consumer_offsets-33 -> OnlinePartition, __consumer_offsets-15 -> OnlinePartition, __consumer_offsets-48 -> OnlinePartition, __consumer_offsets-11 -> OnlinePartition, __consumer_offsets-44 -> OnlinePartition, __consumer_offsets-23 -> OnlinePartition, __consumer_offsets-19 -> OnlinePartition, __consumer_offsets-32 -> OnlinePartition, __consumer_offsets-28 -> OnlinePartition, __consumer_offsets-7 -> OnlinePartition, __consumer_offsets-40 -> OnlinePartition, __consumer_offsets-3 -> OnlinePartition, __consumer_offsets-36 -> OnlinePartition, __consumer_offsets-47 -> OnlinePartition, __consumer_offsets-14 -> OnlinePartition, __consumer_offsets-43 -> OnlinePartition, __consumer_offsets-10 -> OnlinePartition, __consumer_offsets-22 -> OnlinePartition, __consumer_offsets-18 -> OnlinePartition, __consumer_offsets-31 -> OnlinePartition, __consumer_offsets-27 -> OnlinePartition, __consumer_offsets-39 -> OnlinePartition, __consumer_offsets-6 -> OnlinePartition, __consumer_offsets-35 -> OnlinePartition, mesa-ya.restaurants.created-0 -> OnlinePartition, __consumer_offsets-2 -> OnlinePartition) (kafka.controller.ZkPartitionStateMachine)
2025-10-15 20:17:08.460 | [2025-10-16 01:17:08,460] INFO [Controller id=1] Ready to serve as the new controller with epoch 2 (kafka.controller.KafkaController)
2025-10-15 20:17:08.469 | [2025-10-16 01:17:08,469] INFO [Controller id=1] Partitions undergoing preferred replica election:  (kafka.controller.KafkaController)
2025-10-15 20:17:08.470 | [2025-10-16 01:17:08,469] INFO [Controller id=1] Partitions that completed preferred replica election:  (kafka.controller.KafkaController)
2025-10-15 20:17:08.470 | [2025-10-16 01:17:08,470] INFO [Controller id=1] Skipping preferred replica election for partitions due to topic deletion:  (kafka.controller.KafkaController)
2025-10-15 20:17:08.470 | [2025-10-16 01:17:08,470] INFO [Controller id=1] Resuming preferred replica election for partitions:  (kafka.controller.KafkaController)
2025-10-15 20:17:08.472 | [2025-10-16 01:17:08,471] INFO [Controller id=1] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered (kafka.controller.KafkaController)
2025-10-15 20:17:08.488 | [2025-10-16 01:17:08,488] INFO [Controller id=1] Starting the controller scheduler (kafka.controller.KafkaController)
2025-10-15 20:17:08.491 | [2025-10-16 01:17:08,490] INFO [RequestSendThread controllerId=1] Controller 1 connected to kafka:29092 (id: 1 rack: null) for sending state change requests (kafka.controller.RequestSendThread)
2025-10-15 20:17:08.553 | [2025-10-16 01:17:08,553] TRACE [Controller id=1 epoch=2] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 0 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-10-15 20:17:08.560 | [2025-10-16 01:17:08,560] INFO [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 for 51 partitions (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,560] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.561 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.562 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.562 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.562 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.562 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.562 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.562 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.562 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.562 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.562 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.562 | [2025-10-16 01:17:08,561] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.562 | [2025-10-16 01:17:08,562] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.562 | [2025-10-16 01:17:08,562] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='mesa-ya.restaurants.created', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-10-15 20:17:08.587 | [2025-10-16 01:17:08,586] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Recorded new controller, from now on will use node kafka:29092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,588] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-3 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-18 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-41 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-10 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-33 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-48 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-19 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-34 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-4 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-11 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-26 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-49 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-39 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-9 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-24 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-31 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-46 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-1 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-16 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-2 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-25 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-40 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-47 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-17 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-32 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-37 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-7 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-22 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-29 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-44 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-14 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-23 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-38 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-8 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-45 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-15 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-30 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition mesa-ya.restaurants.created-0 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-0 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-35 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-5 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-20 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-27 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-42 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-12 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-21 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-36 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-6 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-43 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-13 (state.change.logger)
2025-10-15 20:17:08.589 | [2025-10-16 01:17:08,589] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-28 (state.change.logger)
2025-10-15 20:17:08.592 | [2025-10-16 01:17:08,591] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-37, __consumer_offsets-38, __consumer_offsets-13, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, mesa-ya.restaurants.created-0, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
2025-10-15 20:17:08.592 | [2025-10-16 01:17:08,592] INFO [Broker id=1] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 1 epoch 2 as part of the become-leader transition for 51 partitions (state.change.logger)
2025-10-15 20:17:08.603 | [2025-10-16 01:17:08,603] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:08.606 | [2025-10-16 01:17:08,605] INFO [Broker id=1] Leader __consumer_offsets-3 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:08.621 | [2025-10-16 01:17:08,621] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:08.622 | [2025-10-16 01:17:08,621] INFO [Broker id=1] Leader __consumer_offsets-18 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:08.631 | [2025-10-16 01:17:08,630] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Recorded new controller, from now on will use node kafka:29092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:17:08.633 | [2025-10-16 01:17:08,632] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:08.633 | [2025-10-16 01:17:08,632] INFO [Broker id=1] Leader __consumer_offsets-41 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:08.645 | [2025-10-16 01:17:08,645] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:08.645 | [2025-10-16 01:17:08,645] INFO [Broker id=1] Leader __consumer_offsets-10 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:08.656 | [2025-10-16 01:17:08,656] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:08.656 | [2025-10-16 01:17:08,656] INFO [Broker id=1] Leader __consumer_offsets-33 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:08.669 | [2025-10-16 01:17:08,668] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:08.669 | [2025-10-16 01:17:08,668] INFO [Broker id=1] Leader __consumer_offsets-48 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:08.683 | [2025-10-16 01:17:08,682] INFO [Partition __consumer_offsets-19 broker=1] Log loaded for partition __consumer_offsets-19 with initial high watermark 1 (kafka.cluster.Partition)
2025-10-15 20:17:08.683 | [2025-10-16 01:17:08,682] INFO [Broker id=1] Leader __consumer_offsets-19 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 1 with partition epoch 0, high watermark 1, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:08.683 | [2025-10-16 01:17:08,683] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:08.683 | [2025-10-16 01:17:08,683] INFO [Broker id=1] Leader __consumer_offsets-34 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:08.698 | [2025-10-16 01:17:08,698] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:08.698 | [2025-10-16 01:17:08,698] INFO [Broker id=1] Leader __consumer_offsets-4 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:08.718 | [2025-10-16 01:17:08,717] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:08.718 | [2025-10-16 01:17:08,717] INFO [Broker id=1] Leader __consumer_offsets-11 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:08.737 | [2025-10-16 01:17:08,736] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:08.738 | [2025-10-16 01:17:08,737] INFO [Broker id=1] Leader __consumer_offsets-26 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:08.755 | [2025-10-16 01:17:08,755] INFO [Partition __consumer_offsets-49 broker=1] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:08.756 | [2025-10-16 01:17:08,755] INFO [Broker id=1] Leader __consumer_offsets-49 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:08.768 | [2025-10-16 01:17:08,767] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:08.768 | [2025-10-16 01:17:08,767] INFO [Broker id=1] Leader __consumer_offsets-39 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:08.781 | [2025-10-16 01:17:08,780] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:08.781 | [2025-10-16 01:17:08,781] INFO [Broker id=1] Leader __consumer_offsets-9 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:08.796 | [2025-10-16 01:17:08,795] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:08.796 | [2025-10-16 01:17:08,796] INFO [Broker id=1] Leader __consumer_offsets-24 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:08.811 | [2025-10-16 01:17:08,811] INFO [Partition __consumer_offsets-31 broker=1] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:08.812 | [2025-10-16 01:17:08,811] INFO [Broker id=1] Leader __consumer_offsets-31 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:08.826 | [2025-10-16 01:17:08,826] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:08.827 | [2025-10-16 01:17:08,826] INFO [Broker id=1] Leader __consumer_offsets-46 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:08.842 | [2025-10-16 01:17:08,841] INFO [Partition __consumer_offsets-1 broker=1] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:08.842 | [2025-10-16 01:17:08,842] INFO [Broker id=1] Leader __consumer_offsets-1 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:08.856 | [2025-10-16 01:17:08,856] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:08.856 | [2025-10-16 01:17:08,856] INFO [Broker id=1] Leader __consumer_offsets-16 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:08.871 | [2025-10-16 01:17:08,871] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:08.871 | [2025-10-16 01:17:08,871] INFO [Broker id=1] Leader __consumer_offsets-2 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:08.886 | [2025-10-16 01:17:08,885] INFO [Partition __consumer_offsets-25 broker=1] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:08.886 | [2025-10-16 01:17:08,885] INFO [Broker id=1] Leader __consumer_offsets-25 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:08.898 | [2025-10-16 01:17:08,898] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:08.898 | [2025-10-16 01:17:08,898] INFO [Broker id=1] Leader __consumer_offsets-40 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:08.914 | [2025-10-16 01:17:08,913] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:08.914 | [2025-10-16 01:17:08,913] INFO [Broker id=1] Leader __consumer_offsets-47 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:08.928 | [2025-10-16 01:17:08,927] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:08.928 | [2025-10-16 01:17:08,928] INFO [Broker id=1] Leader __consumer_offsets-17 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:08.946 | [2025-10-16 01:17:08,946] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:08.946 | [2025-10-16 01:17:08,946] INFO [Broker id=1] Leader __consumer_offsets-32 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:08.961 | [2025-10-16 01:17:08,960] INFO [Partition __consumer_offsets-37 broker=1] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:08.961 | [2025-10-16 01:17:08,960] INFO [Broker id=1] Leader __consumer_offsets-37 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:08.973 | [2025-10-16 01:17:08,973] INFO [Partition __consumer_offsets-7 broker=1] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:08.973 | [2025-10-16 01:17:08,973] INFO [Broker id=1] Leader __consumer_offsets-7 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:08.982 | [2025-10-16 01:17:08,982] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:08.982 | [2025-10-16 01:17:08,982] INFO [Broker id=1] Leader __consumer_offsets-22 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:08.994 | [2025-10-16 01:17:08,994] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:08.994 | [2025-10-16 01:17:08,994] INFO [Broker id=1] Leader __consumer_offsets-29 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:09.006 | [2025-10-16 01:17:09,005] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:09.006 | [2025-10-16 01:17:09,006] INFO [Broker id=1] Leader __consumer_offsets-44 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:09.016 | [2025-10-16 01:17:09,016] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:09.016 | [2025-10-16 01:17:09,016] INFO [Broker id=1] Leader __consumer_offsets-14 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:09.028 | [2025-10-16 01:17:09,027] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:09.028 | [2025-10-16 01:17:09,027] INFO [Broker id=1] Leader __consumer_offsets-23 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:09.039 | [2025-10-16 01:17:09,038] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:09.039 | [2025-10-16 01:17:09,039] INFO [Broker id=1] Leader __consumer_offsets-38 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:09.050 | [2025-10-16 01:17:09,049] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:09.050 | [2025-10-16 01:17:09,050] INFO [Broker id=1] Leader __consumer_offsets-8 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:09.061 | [2025-10-16 01:17:09,061] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:09.061 | [2025-10-16 01:17:09,061] INFO [Broker id=1] Leader __consumer_offsets-45 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:09.073 | [2025-10-16 01:17:09,072] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:09.073 | [2025-10-16 01:17:09,072] INFO [Broker id=1] Leader __consumer_offsets-15 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:09.084 | [2025-10-16 01:17:09,083] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:09.084 | [2025-10-16 01:17:09,084] INFO [Broker id=1] Leader __consumer_offsets-30 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:09.097 | [2025-10-16 01:17:09,096] INFO [Partition mesa-ya.restaurants.created-0 broker=1] Log loaded for partition mesa-ya.restaurants.created-0 with initial high watermark 1 (kafka.cluster.Partition)
2025-10-15 20:17:09.097 | [2025-10-16 01:17:09,096] INFO [Broker id=1] Leader mesa-ya.restaurants.created-0 with topic id Some(yWm6W48_TyqOOX8W2L0ItA) starts at leader epoch 0 from offset 1 with partition epoch 0, high watermark 1, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:09.097 | [2025-10-16 01:17:09,097] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:09.097 | [2025-10-16 01:17:09,097] INFO [Broker id=1] Leader __consumer_offsets-0 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:09.113 | [2025-10-16 01:17:09,112] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:09.113 | [2025-10-16 01:17:09,113] INFO [Broker id=1] Leader __consumer_offsets-35 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:09.126 | [2025-10-16 01:17:09,126] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:09.127 | [2025-10-16 01:17:09,126] INFO [Broker id=1] Leader __consumer_offsets-5 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:09.138 | [2025-10-16 01:17:09,137] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:09.138 | [2025-10-16 01:17:09,137] INFO [Broker id=1] Leader __consumer_offsets-20 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:09.150 | [2025-10-16 01:17:09,150] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:09.151 | [2025-10-16 01:17:09,150] INFO [Broker id=1] Leader __consumer_offsets-27 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:09.164 | [2025-10-16 01:17:09,164] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:09.164 | [2025-10-16 01:17:09,164] INFO [Broker id=1] Leader __consumer_offsets-42 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:09.176 | [2025-10-16 01:17:09,176] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:09.177 | [2025-10-16 01:17:09,176] INFO [Broker id=1] Leader __consumer_offsets-12 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:09.189 | [2025-10-16 01:17:09,188] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:09.189 | [2025-10-16 01:17:09,189] INFO [Broker id=1] Leader __consumer_offsets-21 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:09.200 | [2025-10-16 01:17:09,199] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:09.200 | [2025-10-16 01:17:09,199] INFO [Broker id=1] Leader __consumer_offsets-36 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:09.212 | [2025-10-16 01:17:09,212] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:09.212 | [2025-10-16 01:17:09,212] INFO [Broker id=1] Leader __consumer_offsets-6 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:09.228 | [2025-10-16 01:17:09,227] INFO [Partition __consumer_offsets-43 broker=1] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:09.228 | [2025-10-16 01:17:09,228] INFO [Broker id=1] Leader __consumer_offsets-43 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:09.240 | [2025-10-16 01:17:09,240] INFO [Partition __consumer_offsets-13 broker=1] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:09.240 | [2025-10-16 01:17:09,240] INFO [Broker id=1] Leader __consumer_offsets-13 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:09.251 | [2025-10-16 01:17:09,251] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:09.251 | [2025-10-16 01:17:09,251] INFO [Broker id=1] Leader __consumer_offsets-28 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,265] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-3 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,265] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-18 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,265] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-41 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,265] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-10 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,265] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-33 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,265] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-48 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,265] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-19 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,265] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-34 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,265] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-4 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,265] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-11 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,265] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-26 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,265] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-49 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,265] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-39 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,265] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-9 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,265] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-24 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,265] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-31 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,265] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-46 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,265] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-1 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,265] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-16 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,265] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-2 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,265] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-25 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,265] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-40 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,265] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-47 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,265] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-17 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,265] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-32 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,265] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-37 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,265] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-7 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,265] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-22 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,265] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-29 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,265] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-44 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,265] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-14 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,265] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-23 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,265] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-38 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,266] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-8 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,266] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-45 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,266] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-15 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,266] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-30 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,266] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition mesa-ya.restaurants.created-0 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,266] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-0 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,266] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-35 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,266] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-5 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,266] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-20 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,266] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-27 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,266] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-42 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,266] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-12 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,266] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-21 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,266] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-36 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,266] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-6 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,266] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-43 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,266] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-13 (state.change.logger)
2025-10-15 20:17:09.266 | [2025-10-16 01:17:09,266] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-28 (state.change.logger)
2025-10-15 20:17:09.274 | [2025-10-16 01:17:09,273] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.278 | [2025-10-16 01:17:09,277] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,279] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,279] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,279] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,279] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.280 | [2025-10-16 01:17:09,280] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,280] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,280] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,280] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,280] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,280] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,280] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,280] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,280] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,280] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,280] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,280] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,280] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,280] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,280] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,280] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,281] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,281] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,281] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,281] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,281] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,281] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,281] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,281] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,281] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,281] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,281] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,281] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,281] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,281] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,281] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,281] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,281] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,281] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,281] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,281] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,281] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,281] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,281] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,281] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,281] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,281] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,281] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.281 | [2025-10-16 01:17:09,281] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.282 | [2025-10-16 01:17:09,281] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.282 | [2025-10-16 01:17:09,281] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.282 | [2025-10-16 01:17:09,281] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.290 | [2025-10-16 01:17:09,288] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 10 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.293 | [2025-10-16 01:17:09,292] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 13 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.294 | [2025-10-16 01:17:09,293] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.295 | [2025-10-16 01:17:09,295] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 15 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.297 | [2025-10-16 01:17:09,296] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 16 milliseconds for epoch 0, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.298 | [2025-10-16 01:17:09,297] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 17 milliseconds for epoch 0, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.301 | [2025-10-16 01:17:09,301] INFO [Broker id=1] Finished LeaderAndIsr request in 734ms correlationId 1 from controller 1 for 51 partitions (state.change.logger)
2025-10-15 20:17:09.318 | [2025-10-16 01:17:09,317] TRACE [Controller id=1 epoch=2] Received response LeaderAndIsrResponseData(errorCode=0, partitionErrors=[], topics=[LeaderAndIsrTopicError(topicId=6ep0dUNwQAaqKr79SJ8ITA, partitionErrors=[LeaderAndIsrPartitionError(topicName='', partitionIndex=13, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=46, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=9, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=42, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=21, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=17, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=30, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=26, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=5, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=38, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=1, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=34, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=16, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=45, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=12, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=41, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=24, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=20, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=49, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=0, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=29, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=25, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=8, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=37, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=4, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=33, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=15, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=48, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=11, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=44, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=23, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=19, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=32, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=28, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=7, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=40, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=3, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=36, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=47, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=14, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=43, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=10, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=22, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=18, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=31, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=27, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=39, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=6, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=35, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=2, errorCode=0)]), LeaderAndIsrTopicError(topicId=yWm6W48_TyqOOX8W2L0ItA, partitionErrors=[LeaderAndIsrPartitionError(topicName='', partitionIndex=0, errorCode=0)])]) for request LEADER_AND_ISR with correlation id 1 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-10-15 20:17:09.329 | [2025-10-16 01:17:09,329] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-13 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.329 | [2025-10-16 01:17:09,329] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-46 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.329 | [2025-10-16 01:17:09,329] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-9 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.329 | [2025-10-16 01:17:09,329] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-42 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.329 | [2025-10-16 01:17:09,329] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-21 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.329 | [2025-10-16 01:17:09,329] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-17 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.329 | [2025-10-16 01:17:09,329] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-30 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.329 | [2025-10-16 01:17:09,329] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-26 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.330 | [2025-10-16 01:17:09,329] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-5 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.330 | [2025-10-16 01:17:09,329] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-38 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.330 | [2025-10-16 01:17:09,329] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-1 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.330 | [2025-10-16 01:17:09,330] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-34 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.330 | [2025-10-16 01:17:09,330] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-16 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.330 | [2025-10-16 01:17:09,330] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-45 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.330 | [2025-10-16 01:17:09,330] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-12 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.330 | [2025-10-16 01:17:09,330] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-41 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.330 | [2025-10-16 01:17:09,330] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-24 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.330 | [2025-10-16 01:17:09,330] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-20 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.330 | [2025-10-16 01:17:09,330] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-49 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.330 | [2025-10-16 01:17:09,330] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-0 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.331 | [2025-10-16 01:17:09,330] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-29 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.331 | [2025-10-16 01:17:09,330] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-25 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.331 | [2025-10-16 01:17:09,330] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-8 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.331 | [2025-10-16 01:17:09,330] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-37 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.331 | [2025-10-16 01:17:09,330] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-4 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.331 | [2025-10-16 01:17:09,330] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-33 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.331 | [2025-10-16 01:17:09,330] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-15 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.331 | [2025-10-16 01:17:09,330] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-48 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.331 | [2025-10-16 01:17:09,330] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-11 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.331 | [2025-10-16 01:17:09,331] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-44 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.331 | [2025-10-16 01:17:09,331] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-23 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.331 | [2025-10-16 01:17:09,331] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-19 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.331 | [2025-10-16 01:17:09,331] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-32 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.331 | [2025-10-16 01:17:09,331] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-28 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.331 | [2025-10-16 01:17:09,331] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-7 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.331 | [2025-10-16 01:17:09,331] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-40 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.331 | [2025-10-16 01:17:09,331] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-3 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.331 | [2025-10-16 01:17:09,331] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-36 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.331 | [2025-10-16 01:17:09,331] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-47 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.331 | [2025-10-16 01:17:09,331] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-14 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.331 | [2025-10-16 01:17:09,331] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-43 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.332 | [2025-10-16 01:17:09,331] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-10 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.332 | [2025-10-16 01:17:09,332] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-22 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.332 | [2025-10-16 01:17:09,332] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-18 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.332 | [2025-10-16 01:17:09,332] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-31 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.332 | [2025-10-16 01:17:09,332] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-27 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.332 | [2025-10-16 01:17:09,332] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-39 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.332 | [2025-10-16 01:17:09,332] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-6 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.332 | [2025-10-16 01:17:09,332] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-35 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.332 | [2025-10-16 01:17:09,332] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-2 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.332 | [2025-10-16 01:17:09,332] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='mesa-ya.restaurants.created', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition mesa-ya.restaurants.created-0 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.334 | [2025-10-16 01:17:09,333] INFO [Broker id=1] Add 51 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-10-15 20:17:09.336 | [2025-10-16 01:17:09,335] TRACE [Controller id=1 epoch=2] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 2 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-10-15 20:17:09.355 | [2025-10-16 01:17:09,355] INFO Loaded member MemberMetadata(memberId=mesa-ya-service-client-9a0094a4-6972-4e79-a5d6-5ed4ed5cfa65, groupInstanceId=None, clientId=mesa-ya-service-client, clientHost=/172.18.0.4, sessionTimeoutMs=30000, rebalanceTimeoutMs=60000, supportedProtocols=List(NestReplyPartitionAssigner)) in group nestjs-group-client with generation 1. (kafka.coordinator.group.GroupMetadata$)
2025-10-15 20:17:09.361 | [2025-10-16 01:17:09,360] INFO [GroupCoordinator 1]: Loading group metadata for nestjs-group-client with generation 1 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:09.365 | [2025-10-16 01:17:09,365] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 85 milliseconds for epoch 0, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.365 | [2025-10-16 01:17:09,365] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 85 milliseconds for epoch 0, of which 85 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.365 | [2025-10-16 01:17:09,365] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 85 milliseconds for epoch 0, of which 85 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.365 | [2025-10-16 01:17:09,365] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 85 milliseconds for epoch 0, of which 85 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.365 | [2025-10-16 01:17:09,365] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 85 milliseconds for epoch 0, of which 85 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.366 | [2025-10-16 01:17:09,365] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 85 milliseconds for epoch 0, of which 85 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.366 | [2025-10-16 01:17:09,366] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 86 milliseconds for epoch 0, of which 85 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.366 | [2025-10-16 01:17:09,366] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 86 milliseconds for epoch 0, of which 86 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.366 | [2025-10-16 01:17:09,366] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 86 milliseconds for epoch 0, of which 86 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.366 | [2025-10-16 01:17:09,366] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 86 milliseconds for epoch 0, of which 86 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.366 | [2025-10-16 01:17:09,366] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 86 milliseconds for epoch 0, of which 86 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.366 | [2025-10-16 01:17:09,366] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 86 milliseconds for epoch 0, of which 86 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.366 | [2025-10-16 01:17:09,366] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 86 milliseconds for epoch 0, of which 86 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.366 | [2025-10-16 01:17:09,366] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 86 milliseconds for epoch 0, of which 86 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.366 | [2025-10-16 01:17:09,366] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 86 milliseconds for epoch 0, of which 86 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.366 | [2025-10-16 01:17:09,366] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 86 milliseconds for epoch 0, of which 86 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.367 | [2025-10-16 01:17:09,367] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 87 milliseconds for epoch 0, of which 86 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.367 | [2025-10-16 01:17:09,367] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 87 milliseconds for epoch 0, of which 87 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.367 | [2025-10-16 01:17:09,367] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 87 milliseconds for epoch 0, of which 87 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.367 | [2025-10-16 01:17:09,367] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 87 milliseconds for epoch 0, of which 87 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.367 | [2025-10-16 01:17:09,367] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 87 milliseconds for epoch 0, of which 87 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.368 | [2025-10-16 01:17:09,367] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 87 milliseconds for epoch 0, of which 87 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.368 | [2025-10-16 01:17:09,368] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 88 milliseconds for epoch 0, of which 87 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.368 | [2025-10-16 01:17:09,368] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 88 milliseconds for epoch 0, of which 88 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.368 | [2025-10-16 01:17:09,368] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 88 milliseconds for epoch 0, of which 88 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.368 | [2025-10-16 01:17:09,368] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 88 milliseconds for epoch 0, of which 88 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.368 | [2025-10-16 01:17:09,368] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 88 milliseconds for epoch 0, of which 88 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.368 | [2025-10-16 01:17:09,368] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 88 milliseconds for epoch 0, of which 88 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.368 | [2025-10-16 01:17:09,368] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 87 milliseconds for epoch 0, of which 87 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.368 | [2025-10-16 01:17:09,368] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 87 milliseconds for epoch 0, of which 87 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.369 | [2025-10-16 01:17:09,368] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 87 milliseconds for epoch 0, of which 87 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.369 | [2025-10-16 01:17:09,368] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 87 milliseconds for epoch 0, of which 87 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.369 | [2025-10-16 01:17:09,368] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 87 milliseconds for epoch 0, of which 87 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.369 | [2025-10-16 01:17:09,369] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 88 milliseconds for epoch 0, of which 88 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.369 | [2025-10-16 01:17:09,369] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 88 milliseconds for epoch 0, of which 88 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.369 | [2025-10-16 01:17:09,369] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 88 milliseconds for epoch 0, of which 88 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.369 | [2025-10-16 01:17:09,369] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 88 milliseconds for epoch 0, of which 88 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.369 | [2025-10-16 01:17:09,369] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 88 milliseconds for epoch 0, of which 88 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.369 | [2025-10-16 01:17:09,369] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 88 milliseconds for epoch 0, of which 88 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.369 | [2025-10-16 01:17:09,369] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 88 milliseconds for epoch 0, of which 88 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.369 | [2025-10-16 01:17:09,369] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 88 milliseconds for epoch 0, of which 88 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.369 | [2025-10-16 01:17:09,369] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 88 milliseconds for epoch 0, of which 88 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.370 | [2025-10-16 01:17:09,369] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 88 milliseconds for epoch 0, of which 88 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:09.370 | [2025-10-16 01:17:09,370] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 89 milliseconds for epoch 0, of which 89 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:13.489 | [2025-10-16 01:17:13,489] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-15 20:17:13.490 | [2025-10-16 01:17:13,489] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-15 20:17:13.493 | [2025-10-16 01:17:13,492] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-15 20:17:13.493 | [2025-10-16 01:17:13,493] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-15 20:17:38.342 | [2025-10-16 01:17:38,337] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:43006-2); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 20:17:38.342 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 20:17:38.342 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 20:17:38.342 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 20:17:38.342 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 20:17:38.342 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 20:17:38.342 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 20:17:38.342 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 20:17:38.342 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 20:17:38.342 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 20:17:38.342 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 20:17:38.351 | [2025-10-16 01:17:38,350] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:43022-2); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 20:17:38.351 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 20:17:38.351 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 20:17:38.351 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 20:17:38.351 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 20:17:38.351 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 20:17:38.351 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 20:17:38.351 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 20:17:38.351 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 20:17:38.351 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 20:17:38.351 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 20:17:38.357 | [2025-10-16 01:17:38,356] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:43024-2); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 20:17:38.357 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 20:17:38.357 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 20:17:38.357 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 20:17:38.357 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 20:17:38.357 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 20:17:38.357 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 20:17:38.357 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 20:17:38.357 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 20:17:38.357 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 20:17:38.357 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 20:17:38.361 | [2025-10-16 01:17:38,361] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:43036-3); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 20:17:38.361 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 20:17:38.361 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 20:17:38.361 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 20:17:38.361 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 20:17:38.361 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 20:17:38.361 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 20:17:38.361 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 20:17:38.361 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 20:17:38.361 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 20:17:38.362 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 20:17:38.366 | [2025-10-16 01:17:38,365] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:43046-3); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 20:17:38.366 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 20:17:38.366 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 20:17:38.366 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 20:17:38.366 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 20:17:38.366 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 20:17:38.366 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 20:17:38.366 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 20:17:38.366 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 20:17:38.366 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 20:17:38.366 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 20:17:38.369 | [2025-10-16 01:17:38,368] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:43052-3); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 20:17:38.369 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 20:17:38.369 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 20:17:38.369 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 20:17:38.369 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 20:17:38.369 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 20:17:38.369 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 20:17:38.369 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 20:17:38.369 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 20:17:38.369 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 20:17:38.369 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 20:17:38.375 | [2025-10-16 01:17:38,373] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:43054-4); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 20:17:38.375 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 20:17:38.375 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 20:17:38.375 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 20:17:38.375 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 20:17:38.375 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 20:17:38.375 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 20:17:38.375 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 20:17:38.375 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 20:17:38.375 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 20:17:38.375 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 20:17:38.379 | [2025-10-16 01:17:38,378] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:43064-4); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 20:17:38.379 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 20:17:38.379 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 20:17:38.379 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 20:17:38.379 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 20:17:38.379 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 20:17:38.379 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 20:17:38.379 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 20:17:38.379 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 20:17:38.379 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 20:17:38.379 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 20:17:38.382 | [2025-10-16 01:17:38,381] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:43068-4); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 20:17:38.382 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 20:17:38.382 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 20:17:38.382 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 20:17:38.382 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 20:17:38.382 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 20:17:38.382 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 20:17:38.382 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 20:17:38.382 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 20:17:38.382 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 20:17:38.382 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 20:17:38.386 | [2025-10-16 01:17:38,385] WARN [SocketServer listenerType=ZK_BROKER, nodeId=1] Unexpected error from /172.18.0.1 (channelId=172.18.0.3:9092-172.18.0.1:43072-5); closing connection (org.apache.kafka.common.network.Selector)
2025-10-15 20:17:38.386 | org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
2025-10-15 20:17:38.386 | 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
2025-10-15 20:17:38.386 | 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:452)
2025-10-15 20:17:38.386 | 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:402)
2025-10-15 20:17:38.386 | 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
2025-10-15 20:17:38.386 | 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
2025-10-15 20:17:38.386 | 	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
2025-10-15 20:17:38.386 | 	at kafka.network.Processor.poll(SocketServer.scala:1107)
2025-10-15 20:17:38.386 | 	at kafka.network.Processor.run(SocketServer.scala:1011)
2025-10-15 20:17:38.386 | 	at java.base/java.lang.Thread.run(Thread.java:829)
2025-10-15 20:17:39.177 | [2025-10-16 01:17:39,177] INFO [GroupCoordinator 1]: Member mesa-ya-service-client-9a0094a4-6972-4e79-a5d6-5ed4ed5cfa65 in group nestjs-group-client has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:39.184 | [2025-10-16 01:17:39,184] INFO [GroupCoordinator 1]: Preparing to rebalance group nestjs-group-client in state PreparingRebalance with old generation 1 (__consumer_offsets-19) (reason: removing member mesa-ya-service-client-9a0094a4-6972-4e79-a5d6-5ed4ed5cfa65 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:39.187 | [2025-10-16 01:17:39,187] INFO [GroupCoordinator 1]: Group nestjs-group-client with generation 2 is now empty (__consumer_offsets-19) (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:44.611 | [2025-10-16 01:17:44,609] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
2025-10-15 20:17:44.618 | [2025-10-16 01:17:44,616] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
2025-10-15 20:17:44.624 | [2025-10-16 01:17:44,623] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
2025-10-15 20:17:44.651 | [2025-10-16 01:17:44,651] INFO [Controller id=1] Shutting down broker 1 (kafka.controller.KafkaController)
2025-10-15 20:17:44.652 | [2025-10-16 01:17:44,651] DEBUG [Controller id=1] All shutting down brokers: 1 (kafka.controller.KafkaController)
2025-10-15 20:17:44.652 | [2025-10-16 01:17:44,652] DEBUG [Controller id=1] Live brokers:  (kafka.controller.KafkaController)
2025-10-15 20:17:44.656 | [2025-10-16 01:17:44,656] INFO [Controller id=1 epoch=2] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-10-15 20:17:44.659 | [2025-10-16 01:17:44,658] TRACE [Controller id=1] All leaders = __consumer_offsets-13 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-46 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-9 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-42 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-21 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-17 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-30 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-26 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-5 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-38 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-1 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-34 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-16 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-45 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-12 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-41 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-24 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-20 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-49 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-0 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-29 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-25 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-8 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-37 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-4 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-33 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-15 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-48 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-11 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-44 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-23 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-19 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-32 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-28 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-7 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-40 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-3 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-36 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-47 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-14 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-43 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-10 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-22 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-18 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-31 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-27 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-39 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-6 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-35 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),mesa-ya.restaurants.created-0 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-2 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1) (kafka.controller.KafkaController)
2025-10-15 20:17:44.663 | [2025-10-16 01:17:44,662] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 14ms (kafka.server.KafkaServer)
2025-10-15 20:17:44.668 | [2025-10-16 01:17:44,667] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-10-15 20:17:44.669 | [2025-10-16 01:17:44,668] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-10-15 20:17:44.669 | [2025-10-16 01:17:44,668] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-10-15 20:17:44.672 | [2025-10-16 01:17:44,671] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
2025-10-15 20:17:44.697 | [2025-10-16 01:17:44,696] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
2025-10-15 20:17:44.699 | [2025-10-16 01:17:44,698] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
2025-10-15 20:17:44.704 | [2025-10-16 01:17:44,704] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
2025-10-15 20:17:44.711 | [2025-10-16 01:17:44,710] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:44.714 | [2025-10-16 01:17:44,714] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:44.714 | [2025-10-16 01:17:44,714] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:44.716 | [2025-10-16 01:17:44,715] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
2025-10-15 20:17:44.717 | [2025-10-16 01:17:44,717] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:44.719 | [2025-10-16 01:17:44,719] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:44.719 | [2025-10-16 01:17:44,719] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:44.725 | [2025-10-16 01:17:44,724] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
2025-10-15 20:17:44.727 | [2025-10-16 01:17:44,727] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
2025-10-15 20:17:44.729 | [2025-10-16 01:17:44,728] INFO [TxnMarkerSenderThread-1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-10-15 20:17:44.730 | [2025-10-16 01:17:44,730] INFO [TxnMarkerSenderThread-1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-10-15 20:17:44.730 | [2025-10-16 01:17:44,730] INFO [TxnMarkerSenderThread-1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-10-15 20:17:44.732 | [2025-10-16 01:17:44,732] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
2025-10-15 20:17:44.734 | [2025-10-16 01:17:44,733] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:44.735 | [2025-10-16 01:17:44,735] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:44.737 | [2025-10-16 01:17:44,737] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:44.737 | [2025-10-16 01:17:44,737] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:44.738 | [2025-10-16 01:17:44,738] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:44.741 | [2025-10-16 01:17:44,740] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:44.741 | [2025-10-16 01:17:44,741] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:44.742 | [2025-10-16 01:17:44,742] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:44.744 | [2025-10-16 01:17:44,744] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
2025-10-15 20:17:44.745 | [2025-10-16 01:17:44,744] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-10-15 20:17:44.746 | [2025-10-16 01:17:44,745] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-10-15 20:17:44.746 | [2025-10-16 01:17:44,745] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-10-15 20:17:44.747 | [2025-10-16 01:17:44,746] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
2025-10-15 20:17:44.750 | [2025-10-16 01:17:44,749] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
2025-10-15 20:17:44.750 | [2025-10-16 01:17:44,750] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
2025-10-15 20:17:44.751 | [2025-10-16 01:17:44,750] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
2025-10-15 20:17:44.752 | [2025-10-16 01:17:44,751] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:44.755 | [2025-10-16 01:17:44,754] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:44.755 | [2025-10-16 01:17:44,754] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:44.756 | [2025-10-16 01:17:44,756] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:44.759 | [2025-10-16 01:17:44,758] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:44.759 | [2025-10-16 01:17:44,758] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:44.760 | [2025-10-16 01:17:44,759] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:44.762 | [2025-10-16 01:17:44,761] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:44.762 | [2025-10-16 01:17:44,762] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:44.763 | [2025-10-16 01:17:44,763] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:44.766 | [2025-10-16 01:17:44,765] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:44.766 | [2025-10-16 01:17:44,765] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:44.786 | [2025-10-16 01:17:44,785] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
2025-10-15 20:17:44.786 | [2025-10-16 01:17:44,786] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:17:44.787 | [2025-10-16 01:17:44,786] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:17:44.787 | [2025-10-16 01:17:44,787] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:17:44.791 | [2025-10-16 01:17:44,790] INFO Broker to controller channel manager for alter-partition shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
2025-10-15 20:17:44.791 | [2025-10-16 01:17:44,791] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:17:44.791 | [2025-10-16 01:17:44,791] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Stopped (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:17:44.791 | [2025-10-16 01:17:44,791] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:17:44.793 | [2025-10-16 01:17:44,792] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
2025-10-15 20:17:44.793 | [2025-10-16 01:17:44,793] INFO Shutting down. (kafka.log.LogManager)
2025-10-15 20:17:44.796 | [2025-10-16 01:17:44,795] INFO Shutting down the log cleaner. (kafka.log.LogCleaner)
2025-10-15 20:17:44.797 | [2025-10-16 01:17:44,797] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
2025-10-15 20:17:44.798 | [2025-10-16 01:17:44,797] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
2025-10-15 20:17:44.798 | [2025-10-16 01:17:44,798] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
2025-10-15 20:17:44.944 | [2025-10-16 01:17:44,944] INFO [ProducerStateManager partition=__consumer_offsets-19]Wrote producer snapshot at offset 2 with 0 producer ids in 6 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
2025-10-15 20:17:45.396 | [2025-10-16 01:17:45,396] INFO Shutdown complete. (kafka.log.LogManager)
2025-10-15 20:17:45.397 | [2025-10-16 01:17:45,397] INFO [ControllerEventThread controllerId=1] Shutting down (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-10-15 20:17:45.398 | [2025-10-16 01:17:45,398] INFO [ControllerEventThread controllerId=1] Shutdown completed (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-10-15 20:17:45.399 | [2025-10-16 01:17:45,398] INFO [ControllerEventThread controllerId=1] Stopped (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-10-15 20:17:45.400 | [2025-10-16 01:17:45,400] DEBUG [Controller id=1] Resigning (kafka.controller.KafkaController)
2025-10-15 20:17:45.401 | [2025-10-16 01:17:45,401] DEBUG [Controller id=1] Unregister BrokerModifications handler for Set(1) (kafka.controller.KafkaController)
2025-10-15 20:17:45.405 | [2025-10-16 01:17:45,404] INFO [PartitionStateMachine controllerId=1] Stopped partition state machine (kafka.controller.ZkPartitionStateMachine)
2025-10-15 20:17:45.405 | [2025-10-16 01:17:45,405] INFO [ReplicaStateMachine controllerId=1] Stopped replica state machine (kafka.controller.ZkReplicaStateMachine)
2025-10-15 20:17:45.406 | [2025-10-16 01:17:45,406] INFO [RequestSendThread controllerId=1] Shutting down (kafka.controller.RequestSendThread)
2025-10-15 20:17:45.406 | [2025-10-16 01:17:45,406] INFO [RequestSendThread controllerId=1] Shutdown completed (kafka.controller.RequestSendThread)
2025-10-15 20:17:45.408 | [2025-10-16 01:17:45,406] INFO [RequestSendThread controllerId=1] Stopped (kafka.controller.RequestSendThread)
2025-10-15 20:17:45.413 | [2025-10-16 01:17:45,413] INFO [Controller id=1] Resigned (kafka.controller.KafkaController)
2025-10-15 20:17:45.417 | [2025-10-16 01:17:45,416] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-10-15 20:17:45.417 | [2025-10-16 01:17:45,417] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-10-15 20:17:45.418 | [2025-10-16 01:17:45,417] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-10-15 20:17:45.419 | [2025-10-16 01:17:45,418] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
2025-10-15 20:17:45.534 | [2025-10-16 01:17:45,533] INFO Session: 0x10000328ad90001 closed (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:45.534 | [2025-10-16 01:17:45,534] INFO EventThread shut down for session: 0x10000328ad90001 (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:17:45.535 | [2025-10-16 01:17:45,535] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
2025-10-15 20:17:45.536 | [2025-10-16 01:17:45,536] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:17:45.538 | [2025-10-16 01:17:45,538] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:17:45.538 | [2025-10-16 01:17:45,538] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:17:45.538 | [2025-10-16 01:17:45,538] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:17:45.538 | [2025-10-16 01:17:45,538] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:17:45.538 | [2025-10-16 01:17:45,538] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:17:45.539 | [2025-10-16 01:17:45,539] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:17:45.539 | [2025-10-16 01:17:45,539] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:17:45.539 | [2025-10-16 01:17:45,539] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:17:45.540 | [2025-10-16 01:17:45,539] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:17:45.540 | [2025-10-16 01:17:45,540] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:17:45.540 | [2025-10-16 01:17:45,540] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:17:45.542 | [2025-10-16 01:17:45,541] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
2025-10-15 20:17:45.560 | [2025-10-16 01:17:45,559] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
2025-10-15 20:17:45.560 | [2025-10-16 01:17:45,560] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
2025-10-15 20:17:45.560 | [2025-10-16 01:17:45,560] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
2025-10-15 20:17:45.561 | [2025-10-16 01:17:45,560] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
2025-10-15 20:17:45.563 | [2025-10-16 01:17:45,562] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
2025-10-15 20:17:45.563 | [2025-10-16 01:17:45,563] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
2025-10-15 20:17:45.564 | [2025-10-16 01:17:45,563] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
2025-10-15 20:17:46.578 | ===> User
2025-10-15 20:17:46.583 | uid=1000(appuser) gid=1000(appuser) groups=1000(appuser)
2025-10-15 20:17:46.584 | ===> Configuring ...
2025-10-15 20:17:46.588 | Running in Zookeeper mode...
2025-10-15 20:17:48.935 | ===> Running preflight checks ... 
2025-10-15 20:17:48.940 | ===> Check if /var/lib/kafka/data is writable ...
2025-10-15 20:17:49.334 | ===> Check if Zookeeper is healthy ...
2025-10-15 20:17:49.968 | [2025-10-16 01:17:49,967] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:49.968 | [2025-10-16 01:17:49,968] INFO Client environment:host.name=2ae4b23f74a4 (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:49.968 | [2025-10-16 01:17:49,968] INFO Client environment:java.version=11.0.20 (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:49.968 | [2025-10-16 01:17:49,968] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:49.968 | [2025-10-16 01:17:49,968] INFO Client environment:java.home=/usr/lib/jvm/java-11-zulu-openjdk-ca (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:49.968 | [2025-10-16 01:17:49,968] INFO Client environment:java.class.path=/usr/share/java/cp-base-new/minimal-json-0.9.5.jar:/usr/share/java/cp-base-new/kafka-clients-7.5.0-ccs.jar:/usr/share/java/cp-base-new/slf4j-api-1.7.36.jar:/usr/share/java/cp-base-new/jmx_prometheus_javaagent-0.18.0.jar:/usr/share/java/cp-base-new/jackson-annotations-2.14.2.jar:/usr/share/java/cp-base-new/scala-collection-compat_2.13-2.10.0.jar:/usr/share/java/cp-base-new/gson-2.9.0.jar:/usr/share/java/cp-base-new/kafka-server-common-7.5.0-ccs.jar:/usr/share/java/cp-base-new/jose4j-0.9.3.jar:/usr/share/java/cp-base-new/scala-reflect-2.13.10.jar:/usr/share/java/cp-base-new/zstd-jni-1.5.5-1.jar:/usr/share/java/cp-base-new/jackson-datatype-jdk8-2.14.2.jar:/usr/share/java/cp-base-new/kafka-storage-7.5.0-ccs.jar:/usr/share/java/cp-base-new/reload4j-1.2.19.jar:/usr/share/java/cp-base-new/kafka-raft-7.5.0-ccs.jar:/usr/share/java/cp-base-new/logredactor-1.0.12.jar:/usr/share/java/cp-base-new/jackson-module-scala_2.13-2.14.2.jar:/usr/share/java/cp-base-new/paranamer-2.8.jar:/usr/share/java/cp-base-new/utility-belt-7.5.0.jar:/usr/share/java/cp-base-new/snakeyaml-2.0.jar:/usr/share/java/cp-base-new/metrics-core-2.2.0.jar:/usr/share/java/cp-base-new/metrics-core-4.1.12.1.jar:/usr/share/java/cp-base-new/kafka-tools-api-7.5.0-ccs.jar:/usr/share/java/cp-base-new/logredactor-metrics-1.0.12.jar:/usr/share/java/cp-base-new/scala-logging_2.13-3.9.4.jar:/usr/share/java/cp-base-new/jolokia-core-1.7.1.jar:/usr/share/java/cp-base-new/kafka-metadata-7.5.0-ccs.jar:/usr/share/java/cp-base-new/audience-annotations-0.5.0.jar:/usr/share/java/cp-base-new/argparse4j-0.7.0.jar:/usr/share/java/cp-base-new/kafka-storage-api-7.5.0-ccs.jar:/usr/share/java/cp-base-new/jopt-simple-5.0.4.jar:/usr/share/java/cp-base-new/jackson-dataformat-csv-2.14.2.jar:/usr/share/java/cp-base-new/jackson-core-2.14.2.jar:/usr/share/java/cp-base-new/snappy-java-1.1.10.1.jar:/usr/share/java/cp-base-new/scala-java8-compat_2.13-1.0.2.jar:/usr/share/java/cp-base-new/disk-usage-agent-7.5.0.jar:/usr/share/java/cp-base-new/commons-cli-1.4.jar:/usr/share/java/cp-base-new/common-utils-7.5.0.jar:/usr/share/java/cp-base-new/jolokia-jvm-1.7.1.jar:/usr/share/java/cp-base-new/lz4-java-1.8.0.jar:/usr/share/java/cp-base-new/json-simple-1.1.1.jar:/usr/share/java/cp-base-new/zookeeper-3.6.3.jar:/usr/share/java/cp-base-new/kafka_2.13-7.5.0-ccs.jar:/usr/share/java/cp-base-new/jackson-databind-2.14.2.jar:/usr/share/java/cp-base-new/kafka-group-coordinator-7.5.0-ccs.jar:/usr/share/java/cp-base-new/slf4j-reload4j-1.7.36.jar:/usr/share/java/cp-base-new/zookeeper-jute-3.6.3.jar:/usr/share/java/cp-base-new/scala-library-2.13.10.jar:/usr/share/java/cp-base-new/re2j-1.6.jar:/usr/share/java/cp-base-new/jackson-dataformat-yaml-2.14.2.jar (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:49.968 | [2025-10-16 01:17:49,968] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:49.968 | [2025-10-16 01:17:49,968] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:49.968 | [2025-10-16 01:17:49,968] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:49.968 | [2025-10-16 01:17:49,968] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:49.968 | [2025-10-16 01:17:49,968] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:49.968 | [2025-10-16 01:17:49,968] INFO Client environment:os.version=6.6.87.1-microsoft-standard-WSL2 (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:49.968 | [2025-10-16 01:17:49,968] INFO Client environment:user.name=appuser (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:49.968 | [2025-10-16 01:17:49,968] INFO Client environment:user.home=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:49.968 | [2025-10-16 01:17:49,968] INFO Client environment:user.dir=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:49.968 | [2025-10-16 01:17:49,968] INFO Client environment:os.memory.free=112MB (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:49.968 | [2025-10-16 01:17:49,968] INFO Client environment:os.memory.max=1948MB (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:49.969 | [2025-10-16 01:17:49,968] INFO Client environment:os.memory.total=122MB (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:49.975 | [2025-10-16 01:17:49,975] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=40000 watcher=io.confluent.admin.utils.ZookeeperConnectionWatcher@221af3c0 (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:49.979 | [2025-10-16 01:17:49,979] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
2025-10-15 20:17:49.986 | [2025-10-16 01:17:49,986] INFO jute.maxbuffer value is 1048575 Bytes (org.apache.zookeeper.ClientCnxnSocket)
2025-10-15 20:17:49.995 | [2025-10-16 01:17:49,994] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:17:50.034 | [2025-10-16 01:17:50,031] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:17:50.034 | [2025-10-16 01:17:50,033] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:17:50.045 | [2025-10-16 01:17:50,045] INFO Socket connection established, initiating session, client: /172.18.0.3:47016, server: zookeeper/172.18.0.2:2181 (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:17:50.061 | [2025-10-16 01:17:50,060] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, session id = 0x10000328ad90002, negotiated timeout = 40000 (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:17:50.088 | [2025-10-16 01:17:50,086] WARN An exception was thrown while closing send thread for session 0x10000328ad90002. (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:17:50.088 | EndOfStreamException: Unable to read additional data from server sessionid 0x10000328ad90002, likely server has closed socket
2025-10-15 20:17:50.088 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
2025-10-15 20:17:50.088 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
2025-10-15 20:17:50.088 | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-10-15 20:17:50.194 | [2025-10-16 01:17:50,193] INFO Session: 0x10000328ad90002 closed (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:50.194 | [2025-10-16 01:17:50,193] INFO EventThread shut down for session: 0x10000328ad90002 (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:17:50.201 | Using log4j config /etc/kafka/log4j.properties
2025-10-15 20:17:50.284 | ===> Launching ... 
2025-10-15 20:17:50.292 | ===> Launching kafka ... 
2025-10-15 20:17:50.911 | [2025-10-16 01:17:50,910] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
2025-10-15 20:17:51.228 | [2025-10-16 01:17:51,227] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
2025-10-15 20:17:51.337 | [2025-10-16 01:17:51,337] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
2025-10-15 20:17:51.339 | [2025-10-16 01:17:51,339] INFO starting (kafka.server.KafkaServer)
2025-10-15 20:17:51.340 | [2025-10-16 01:17:51,339] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
2025-10-15 20:17:51.358 | [2025-10-16 01:17:51,358] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
2025-10-15 20:17:51.365 | [2025-10-16 01:17:51,364] INFO Client environment:zookeeper.version=3.6.4--d65253dcf68e9097c6e95a126463fd5fdeb4521c, built on 12/18/2022 18:10 GMT (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:51.365 | [2025-10-16 01:17:51,365] INFO Client environment:host.name=2ae4b23f74a4 (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:51.365 | [2025-10-16 01:17:51,365] INFO Client environment:java.version=11.0.20 (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:51.365 | [2025-10-16 01:17:51,365] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:51.365 | [2025-10-16 01:17:51,365] INFO Client environment:java.home=/usr/lib/jvm/java-11-zulu-openjdk-ca (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:51.365 | [2025-10-16 01:17:51,365] INFO Client environment:java.class.path=/usr/bin/../share/java/kafka/zookeeper-jute-3.6.4.jar:/usr/bin/../share/java/kafka/jackson-datatype-jdk8-2.13.5.jar:/usr/bin/../share/java/kafka/jakarta.inject-2.6.1.jar:/usr/bin/../share/java/kafka/netty-transport-native-epoll-4.1.96.Final.jar:/usr/bin/../share/java/kafka/kafka-clients-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jline-3.22.0.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.36.jar:/usr/bin/../share/java/kafka/reflections-0.9.12.jar:/usr/bin/../share/java/kafka/scala-collection-compat_2.13-2.10.0.jar:/usr/bin/../share/java/kafka/javassist-3.29.2-GA.jar:/usr/bin/../share/java/kafka/connect-runtime-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jakarta.annotation-api-1.3.5.jar:/usr/bin/../share/java/kafka/jackson-databind-2.13.5.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/kafka-streams-scala_2.13-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/javax.activation-api-1.2.0.jar:/usr/bin/../share/java/kafka/rocksdbjni-7.1.2.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/usr/bin/../share/java/kafka/kafka-server-common-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jose4j-0.9.3.jar:/usr/bin/../share/java/kafka/scala-reflect-2.13.10.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.13.5.jar:/usr/bin/../share/java/kafka/zstd-jni-1.5.5-1.jar:/usr/bin/../share/java/kafka/kafka-storage-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jetty-security-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.39.1.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/kafka-raft-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/netty-transport-native-unix-common-4.1.96.Final.jar:/usr/bin/../share/java/kafka/jersey-server-2.39.1.jar:/usr/bin/../share/java/kafka/paranamer-2.8.jar:/usr/bin/../share/java/kafka/jersey-common-2.39.1.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/netty-transport-4.1.96.Final.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/metrics-core-4.1.12.1.jar:/usr/bin/../share/java/kafka/netty-buffer-4.1.96.Final.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.13.5.jar:/usr/bin/../share/java/kafka/netty-resolver-4.1.96.Final.jar:/usr/bin/../share/java/kafka/kafka-tools-api-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jaxb-api-2.3.1.jar:/usr/bin/../share/java/kafka/jetty-util-ajax-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/scala-logging_2.13-3.9.4.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.6.1.jar:/usr/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/usr/bin/../share/java/kafka/jakarta.xml.bind-api-2.3.3.jar:/usr/bin/../share/java/kafka/kafka-metadata-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/plexus-utils-3.3.0.jar:/usr/bin/../share/java/kafka/jakarta.activation-api-1.2.2.jar:/usr/bin/../share/java/kafka/argparse4j-0.7.0.jar:/usr/bin/../share/java/kafka/hk2-utils-2.6.1.jar:/usr/bin/../share/java/kafka/connect-api-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/connect-mirror-client-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.3.jar:/usr/bin/../share/java/kafka/javax.annotation-api-1.3.2.jar:/usr/bin/../share/java/kafka/jersey-hk2-2.39.1.jar:/usr/bin/../share/java/kafka/kafka-storage-api-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jetty-http-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/trogdor-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/maven-artifact-3.8.4.jar:/usr/bin/../share/java/kafka/connect-json-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/scala-java8-compat_2.13-1.0.2.jar:/usr/bin/../share/java/kafka/jetty-server-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/swagger-annotations-2.2.8.jar:/usr/bin/../share/java/kafka/jetty-util-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/commons-cli-1.4.jar:/usr/bin/../share/java/kafka/jetty-io-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/activation-1.1.1.jar:/usr/bin/../share/java/kafka/lz4-java-1.8.0.jar:/usr/bin/../share/java/kafka/kafka-shell-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/netty-common-4.1.96.Final.jar:/usr/bin/../share/java/kafka/jetty-client-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/jackson-module-scala_2.13-2.13.5.jar:/usr/bin/../share/java/kafka/connect-transforms-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jackson-core-2.13.5.jar:/usr/bin/../share/java/kafka/kafka_2.13-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/netty-codec-4.1.96.Final.jar:/usr/bin/../share/java/kafka/zookeeper-3.6.4.jar:/usr/bin/../share/java/kafka/kafka-streams-test-utils-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/hk2-api-2.6.1.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.39.1.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/reload4j-1.2.25.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.10.0.jar:/usr/bin/../share/java/kafka/netty-transport-classes-epoll-4.1.96.Final.jar:/usr/bin/../share/java/kafka/connect-mirror-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/kafka-streams-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/kafka-group-coordinator-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/connect-basic-auth-extension-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jersey-client-2.39.1.jar:/usr/bin/../share/java/kafka/kafka-tools-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/slf4j-reload4j-1.7.36.jar:/usr/bin/../share/java/kafka/jackson-dataformat-csv-2.13.5.jar:/usr/bin/../share/java/kafka/scala-library-2.13.10.jar:/usr/bin/../share/java/kafka/netty-handler-4.1.96.Final.jar:/usr/bin/../share/java/kafka/jakarta.validation-api-2.0.2.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.13.5.jar:/usr/bin/../share/java/kafka/audience-annotations-0.13.0.jar:/usr/bin/../share/java/kafka/hk2-locator-2.6.1.jar:/usr/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.6.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.13.5.jar:/usr/bin/../share/java/confluent-telemetry/* (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:51.365 | [2025-10-16 01:17:51,365] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:51.365 | [2025-10-16 01:17:51,365] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:51.365 | [2025-10-16 01:17:51,365] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:51.365 | [2025-10-16 01:17:51,365] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:51.366 | [2025-10-16 01:17:51,365] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:51.366 | [2025-10-16 01:17:51,365] INFO Client environment:os.version=6.6.87.1-microsoft-standard-WSL2 (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:51.367 | [2025-10-16 01:17:51,366] INFO Client environment:user.name=appuser (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:51.367 | [2025-10-16 01:17:51,366] INFO Client environment:user.home=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:51.367 | [2025-10-16 01:17:51,366] INFO Client environment:user.dir=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:51.367 | [2025-10-16 01:17:51,366] INFO Client environment:os.memory.free=1010MB (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:51.367 | [2025-10-16 01:17:51,366] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:51.367 | [2025-10-16 01:17:51,366] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:51.371 | [2025-10-16 01:17:51,371] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@13d73fa (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:17:51.379 | [2025-10-16 01:17:51,379] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
2025-10-15 20:17:51.388 | [2025-10-16 01:17:51,388] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:17:51.392 | [2025-10-16 01:17:51,391] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
2025-10-15 20:17:51.400 | [2025-10-16 01:17:51,398] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:17:51.406 | [2025-10-16 01:17:51,405] INFO Socket connection established, initiating session, client: /172.18.0.3:47032, server: zookeeper/172.18.0.2:2181 (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:17:51.419 | [2025-10-16 01:17:51,419] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, session id = 0x10000328ad90003, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:17:51.424 | [2025-10-16 01:17:51,423] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
2025-10-15 20:17:51.692 | [2025-10-16 01:17:51,691] INFO Cluster ID = DgiegCMhTNSyWQSymt96xQ (kafka.server.KafkaServer)
2025-10-15 20:17:51.752 | [2025-10-16 01:17:51,752] INFO KafkaConfig values: 
2025-10-15 20:17:51.752 | 	advertised.listeners = PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
2025-10-15 20:17:51.752 | 	alter.config.policy.class.name = null
2025-10-15 20:17:51.752 | 	alter.log.dirs.replication.quota.window.num = 11
2025-10-15 20:17:51.752 | 	alter.log.dirs.replication.quota.window.size.seconds = 1
2025-10-15 20:17:51.752 | 	authorizer.class.name = 
2025-10-15 20:17:51.752 | 	auto.create.topics.enable = true
2025-10-15 20:17:51.752 | 	auto.include.jmx.reporter = true
2025-10-15 20:17:51.752 | 	auto.leader.rebalance.enable = true
2025-10-15 20:17:51.752 | 	background.threads = 10
2025-10-15 20:17:51.752 | 	broker.heartbeat.interval.ms = 2000
2025-10-15 20:17:51.752 | 	broker.id = 1
2025-10-15 20:17:51.752 | 	broker.id.generation.enable = true
2025-10-15 20:17:51.752 | 	broker.rack = null
2025-10-15 20:17:51.752 | 	broker.session.timeout.ms = 9000
2025-10-15 20:17:51.752 | 	client.quota.callback.class = null
2025-10-15 20:17:51.752 | 	compression.type = producer
2025-10-15 20:17:51.752 | 	connection.failed.authentication.delay.ms = 100
2025-10-15 20:17:51.752 | 	connections.max.idle.ms = 600000
2025-10-15 20:17:51.752 | 	connections.max.reauth.ms = 0
2025-10-15 20:17:51.752 | 	control.plane.listener.name = null
2025-10-15 20:17:51.752 | 	controlled.shutdown.enable = true
2025-10-15 20:17:51.752 | 	controlled.shutdown.max.retries = 3
2025-10-15 20:17:51.752 | 	controlled.shutdown.retry.backoff.ms = 5000
2025-10-15 20:17:51.752 | 	controller.listener.names = null
2025-10-15 20:17:51.752 | 	controller.quorum.append.linger.ms = 25
2025-10-15 20:17:51.752 | 	controller.quorum.election.backoff.max.ms = 1000
2025-10-15 20:17:51.752 | 	controller.quorum.election.timeout.ms = 1000
2025-10-15 20:17:51.752 | 	controller.quorum.fetch.timeout.ms = 2000
2025-10-15 20:17:51.752 | 	controller.quorum.request.timeout.ms = 2000
2025-10-15 20:17:51.752 | 	controller.quorum.retry.backoff.ms = 20
2025-10-15 20:17:51.752 | 	controller.quorum.voters = []
2025-10-15 20:17:51.752 | 	controller.quota.window.num = 11
2025-10-15 20:17:51.752 | 	controller.quota.window.size.seconds = 1
2025-10-15 20:17:51.752 | 	controller.socket.timeout.ms = 30000
2025-10-15 20:17:51.752 | 	create.topic.policy.class.name = null
2025-10-15 20:17:51.752 | 	default.replication.factor = 1
2025-10-15 20:17:51.752 | 	delegation.token.expiry.check.interval.ms = 3600000
2025-10-15 20:17:51.752 | 	delegation.token.expiry.time.ms = 86400000
2025-10-15 20:17:51.752 | 	delegation.token.master.key = null
2025-10-15 20:17:51.752 | 	delegation.token.max.lifetime.ms = 604800000
2025-10-15 20:17:51.752 | 	delegation.token.secret.key = null
2025-10-15 20:17:51.752 | 	delete.records.purgatory.purge.interval.requests = 1
2025-10-15 20:17:51.752 | 	delete.topic.enable = true
2025-10-15 20:17:51.752 | 	early.start.listeners = null
2025-10-15 20:17:51.752 | 	fetch.max.bytes = 57671680
2025-10-15 20:17:51.752 | 	fetch.purgatory.purge.interval.requests = 1000
2025-10-15 20:17:51.753 | 	group.consumer.assignors = []
2025-10-15 20:17:51.753 | 	group.consumer.heartbeat.interval.ms = 5000
2025-10-15 20:17:51.753 | 	group.consumer.max.heartbeat.interval.ms = 15000
2025-10-15 20:17:51.753 | 	group.consumer.max.session.timeout.ms = 60000
2025-10-15 20:17:51.753 | 	group.consumer.max.size = 2147483647
2025-10-15 20:17:51.753 | 	group.consumer.min.heartbeat.interval.ms = 5000
2025-10-15 20:17:51.753 | 	group.consumer.min.session.timeout.ms = 45000
2025-10-15 20:17:51.753 | 	group.consumer.session.timeout.ms = 45000
2025-10-15 20:17:51.753 | 	group.coordinator.new.enable = false
2025-10-15 20:17:51.753 | 	group.coordinator.threads = 1
2025-10-15 20:17:51.753 | 	group.initial.rebalance.delay.ms = 3000
2025-10-15 20:17:51.753 | 	group.max.session.timeout.ms = 1800000
2025-10-15 20:17:51.753 | 	group.max.size = 2147483647
2025-10-15 20:17:51.753 | 	group.min.session.timeout.ms = 6000
2025-10-15 20:17:51.753 | 	initial.broker.registration.timeout.ms = 60000
2025-10-15 20:17:51.753 | 	inter.broker.listener.name = PLAINTEXT_INTERNAL
2025-10-15 20:17:51.753 | 	inter.broker.protocol.version = 3.5-IV2
2025-10-15 20:17:51.753 | 	kafka.metrics.polling.interval.secs = 10
2025-10-15 20:17:51.753 | 	kafka.metrics.reporters = []
2025-10-15 20:17:51.753 | 	leader.imbalance.check.interval.seconds = 300
2025-10-15 20:17:51.753 | 	leader.imbalance.per.broker.percentage = 10
2025-10-15 20:17:51.753 | 	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
2025-10-15 20:17:51.753 | 	listeners = PLAINTEXT://0.0.0.0:9092,PLAINTEXT_INTERNAL://0.0.0.0:29092
2025-10-15 20:17:51.753 | 	log.cleaner.backoff.ms = 15000
2025-10-15 20:17:51.753 | 	log.cleaner.dedupe.buffer.size = 134217728
2025-10-15 20:17:51.753 | 	log.cleaner.delete.retention.ms = 86400000
2025-10-15 20:17:51.753 | 	log.cleaner.enable = true
2025-10-15 20:17:51.753 | 	log.cleaner.io.buffer.load.factor = 0.9
2025-10-15 20:17:51.753 | 	log.cleaner.io.buffer.size = 524288
2025-10-15 20:17:51.753 | 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
2025-10-15 20:17:51.753 | 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
2025-10-15 20:17:51.753 | 	log.cleaner.min.cleanable.ratio = 0.5
2025-10-15 20:17:51.753 | 	log.cleaner.min.compaction.lag.ms = 0
2025-10-15 20:17:51.753 | 	log.cleaner.threads = 1
2025-10-15 20:17:51.753 | 	log.cleanup.policy = [delete]
2025-10-15 20:17:51.753 | 	log.dir = /tmp/kafka-logs
2025-10-15 20:17:51.753 | 	log.dirs = /var/lib/kafka/data
2025-10-15 20:17:51.753 | 	log.flush.interval.messages = 9223372036854775807
2025-10-15 20:17:51.753 | 	log.flush.interval.ms = null
2025-10-15 20:17:51.753 | 	log.flush.offset.checkpoint.interval.ms = 60000
2025-10-15 20:17:51.753 | 	log.flush.scheduler.interval.ms = 9223372036854775807
2025-10-15 20:17:51.753 | 	log.flush.start.offset.checkpoint.interval.ms = 60000
2025-10-15 20:17:51.753 | 	log.index.interval.bytes = 4096
2025-10-15 20:17:51.753 | 	log.index.size.max.bytes = 10485760
2025-10-15 20:17:51.753 | 	log.message.downconversion.enable = true
2025-10-15 20:17:51.753 | 	log.message.format.version = 3.0-IV1
2025-10-15 20:17:51.753 | 	log.message.timestamp.difference.max.ms = 9223372036854775807
2025-10-15 20:17:51.753 | 	log.message.timestamp.type = CreateTime
2025-10-15 20:17:51.753 | 	log.preallocate = false
2025-10-15 20:17:51.753 | 	log.retention.bytes = -1
2025-10-15 20:17:51.753 | 	log.retention.check.interval.ms = 300000
2025-10-15 20:17:51.753 | 	log.retention.hours = 168
2025-10-15 20:17:51.753 | 	log.retention.minutes = null
2025-10-15 20:17:51.753 | 	log.retention.ms = null
2025-10-15 20:17:51.753 | 	log.roll.hours = 168
2025-10-15 20:17:51.753 | 	log.roll.jitter.hours = 0
2025-10-15 20:17:51.753 | 	log.roll.jitter.ms = null
2025-10-15 20:17:51.753 | 	log.roll.ms = null
2025-10-15 20:17:51.753 | 	log.segment.bytes = 1073741824
2025-10-15 20:17:51.753 | 	log.segment.delete.delay.ms = 60000
2025-10-15 20:17:51.753 | 	max.connection.creation.rate = 2147483647
2025-10-15 20:17:51.753 | 	max.connections = 2147483647
2025-10-15 20:17:51.753 | 	max.connections.per.ip = 2147483647
2025-10-15 20:17:51.753 | 	max.connections.per.ip.overrides = 
2025-10-15 20:17:51.753 | 	max.incremental.fetch.session.cache.slots = 1000
2025-10-15 20:17:51.753 | 	message.max.bytes = 1048588
2025-10-15 20:17:51.753 | 	metadata.log.dir = null
2025-10-15 20:17:51.753 | 	metadata.log.max.record.bytes.between.snapshots = 20971520
2025-10-15 20:17:51.753 | 	metadata.log.max.snapshot.interval.ms = 3600000
2025-10-15 20:17:51.753 | 	metadata.log.segment.bytes = 1073741824
2025-10-15 20:17:51.753 | 	metadata.log.segment.min.bytes = 8388608
2025-10-15 20:17:51.753 | 	metadata.log.segment.ms = 604800000
2025-10-15 20:17:51.753 | 	metadata.max.idle.interval.ms = 500
2025-10-15 20:17:51.753 | 	metadata.max.retention.bytes = 104857600
2025-10-15 20:17:51.753 | 	metadata.max.retention.ms = 604800000
2025-10-15 20:17:51.753 | 	metric.reporters = []
2025-10-15 20:17:51.753 | 	metrics.num.samples = 2
2025-10-15 20:17:51.753 | 	metrics.recording.level = INFO
2025-10-15 20:17:51.753 | 	metrics.sample.window.ms = 30000
2025-10-15 20:17:51.753 | 	min.insync.replicas = 1
2025-10-15 20:17:51.753 | 	node.id = 1
2025-10-15 20:17:51.753 | 	num.io.threads = 8
2025-10-15 20:17:51.753 | 	num.network.threads = 3
2025-10-15 20:17:51.753 | 	num.partitions = 1
2025-10-15 20:17:51.753 | 	num.recovery.threads.per.data.dir = 1
2025-10-15 20:17:51.753 | 	num.replica.alter.log.dirs.threads = null
2025-10-15 20:17:51.753 | 	num.replica.fetchers = 1
2025-10-15 20:17:51.753 | 	offset.metadata.max.bytes = 4096
2025-10-15 20:17:51.753 | 	offsets.commit.required.acks = -1
2025-10-15 20:17:51.753 | 	offsets.commit.timeout.ms = 5000
2025-10-15 20:17:51.753 | 	offsets.load.buffer.size = 5242880
2025-10-15 20:17:51.753 | 	offsets.retention.check.interval.ms = 600000
2025-10-15 20:17:51.753 | 	offsets.retention.minutes = 10080
2025-10-15 20:17:51.753 | 	offsets.topic.compression.codec = 0
2025-10-15 20:17:51.753 | 	offsets.topic.num.partitions = 50
2025-10-15 20:17:51.753 | 	offsets.topic.replication.factor = 1
2025-10-15 20:17:51.753 | 	offsets.topic.segment.bytes = 104857600
2025-10-15 20:17:51.753 | 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
2025-10-15 20:17:51.753 | 	password.encoder.iterations = 4096
2025-10-15 20:17:51.753 | 	password.encoder.key.length = 128
2025-10-15 20:17:51.753 | 	password.encoder.keyfactory.algorithm = null
2025-10-15 20:17:51.753 | 	password.encoder.old.secret = null
2025-10-15 20:17:51.753 | 	password.encoder.secret = null
2025-10-15 20:17:51.753 | 	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
2025-10-15 20:17:51.753 | 	process.roles = []
2025-10-15 20:17:51.753 | 	producer.id.expiration.check.interval.ms = 600000
2025-10-15 20:17:51.753 | 	producer.id.expiration.ms = 86400000
2025-10-15 20:17:51.753 | 	producer.purgatory.purge.interval.requests = 1000
2025-10-15 20:17:51.753 | 	queued.max.request.bytes = -1
2025-10-15 20:17:51.753 | 	queued.max.requests = 500
2025-10-15 20:17:51.753 | 	quota.window.num = 11
2025-10-15 20:17:51.753 | 	quota.window.size.seconds = 1
2025-10-15 20:17:51.753 | 	remote.log.index.file.cache.total.size.bytes = 1073741824
2025-10-15 20:17:51.753 | 	remote.log.manager.task.interval.ms = 30000
2025-10-15 20:17:51.753 | 	remote.log.manager.task.retry.backoff.max.ms = 30000
2025-10-15 20:17:51.753 | 	remote.log.manager.task.retry.backoff.ms = 500
2025-10-15 20:17:51.753 | 	remote.log.manager.task.retry.jitter = 0.2
2025-10-15 20:17:51.753 | 	remote.log.manager.thread.pool.size = 10
2025-10-15 20:17:51.753 | 	remote.log.metadata.manager.class.name = null
2025-10-15 20:17:51.753 | 	remote.log.metadata.manager.class.path = null
2025-10-15 20:17:51.753 | 	remote.log.metadata.manager.impl.prefix = null
2025-10-15 20:17:51.753 | 	remote.log.metadata.manager.listener.name = null
2025-10-15 20:17:51.753 | 	remote.log.reader.max.pending.tasks = 100
2025-10-15 20:17:51.753 | 	remote.log.reader.threads = 10
2025-10-15 20:17:51.753 | 	remote.log.storage.manager.class.name = null
2025-10-15 20:17:51.753 | 	remote.log.storage.manager.class.path = null
2025-10-15 20:17:51.753 | 	remote.log.storage.manager.impl.prefix = null
2025-10-15 20:17:51.753 | 	remote.log.storage.system.enable = false
2025-10-15 20:17:51.753 | 	replica.fetch.backoff.ms = 1000
2025-10-15 20:17:51.753 | 	replica.fetch.max.bytes = 1048576
2025-10-15 20:17:51.753 | 	replica.fetch.min.bytes = 1
2025-10-15 20:17:51.753 | 	replica.fetch.response.max.bytes = 10485760
2025-10-15 20:17:51.753 | 	replica.fetch.wait.max.ms = 500
2025-10-15 20:17:51.753 | 	replica.high.watermark.checkpoint.interval.ms = 5000
2025-10-15 20:17:51.753 | 	replica.lag.time.max.ms = 30000
2025-10-15 20:17:51.753 | 	replica.selector.class = null
2025-10-15 20:17:51.753 | 	replica.socket.receive.buffer.bytes = 65536
2025-10-15 20:17:51.753 | 	replica.socket.timeout.ms = 30000
2025-10-15 20:17:51.753 | 	replication.quota.window.num = 11
2025-10-15 20:17:51.753 | 	replication.quota.window.size.seconds = 1
2025-10-15 20:17:51.753 | 	request.timeout.ms = 30000
2025-10-15 20:17:51.753 | 	reserved.broker.max.id = 1000
2025-10-15 20:17:51.753 | 	sasl.client.callback.handler.class = null
2025-10-15 20:17:51.753 | 	sasl.enabled.mechanisms = [GSSAPI]
2025-10-15 20:17:51.753 | 	sasl.jaas.config = null
2025-10-15 20:17:51.753 | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
2025-10-15 20:17:51.753 | 	sasl.kerberos.min.time.before.relogin = 60000
2025-10-15 20:17:51.753 | 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
2025-10-15 20:17:51.753 | 	sasl.kerberos.service.name = null
2025-10-15 20:17:51.753 | 	sasl.kerberos.ticket.renew.jitter = 0.05
2025-10-15 20:17:51.753 | 	sasl.kerberos.ticket.renew.window.factor = 0.8
2025-10-15 20:17:51.753 | 	sasl.login.callback.handler.class = null
2025-10-15 20:17:51.753 | 	sasl.login.class = null
2025-10-15 20:17:51.753 | 	sasl.login.connect.timeout.ms = null
2025-10-15 20:17:51.753 | 	sasl.login.read.timeout.ms = null
2025-10-15 20:17:51.753 | 	sasl.login.refresh.buffer.seconds = 300
2025-10-15 20:17:51.753 | 	sasl.login.refresh.min.period.seconds = 60
2025-10-15 20:17:51.753 | 	sasl.login.refresh.window.factor = 0.8
2025-10-15 20:17:51.753 | 	sasl.login.refresh.window.jitter = 0.05
2025-10-15 20:17:51.753 | 	sasl.login.retry.backoff.max.ms = 10000
2025-10-15 20:17:51.753 | 	sasl.login.retry.backoff.ms = 100
2025-10-15 20:17:51.753 | 	sasl.mechanism.controller.protocol = GSSAPI
2025-10-15 20:17:51.753 | 	sasl.mechanism.inter.broker.protocol = GSSAPI
2025-10-15 20:17:51.753 | 	sasl.oauthbearer.clock.skew.seconds = 30
2025-10-15 20:17:51.753 | 	sasl.oauthbearer.expected.audience = null
2025-10-15 20:17:51.753 | 	sasl.oauthbearer.expected.issuer = null
2025-10-15 20:17:51.753 | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
2025-10-15 20:17:51.753 | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
2025-10-15 20:17:51.753 | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
2025-10-15 20:17:51.753 | 	sasl.oauthbearer.jwks.endpoint.url = null
2025-10-15 20:17:51.753 | 	sasl.oauthbearer.scope.claim.name = scope
2025-10-15 20:17:51.753 | 	sasl.oauthbearer.sub.claim.name = sub
2025-10-15 20:17:51.753 | 	sasl.oauthbearer.token.endpoint.url = null
2025-10-15 20:17:51.753 | 	sasl.server.callback.handler.class = null
2025-10-15 20:17:51.753 | 	sasl.server.max.receive.size = 524288
2025-10-15 20:17:51.753 | 	security.inter.broker.protocol = PLAINTEXT
2025-10-15 20:17:51.753 | 	security.providers = null
2025-10-15 20:17:51.753 | 	server.max.startup.time.ms = 9223372036854775807
2025-10-15 20:17:51.753 | 	socket.connection.setup.timeout.max.ms = 30000
2025-10-15 20:17:51.753 | 	socket.connection.setup.timeout.ms = 10000
2025-10-15 20:17:51.753 | 	socket.listen.backlog.size = 50
2025-10-15 20:17:51.753 | 	socket.receive.buffer.bytes = 102400
2025-10-15 20:17:51.753 | 	socket.request.max.bytes = 104857600
2025-10-15 20:17:51.753 | 	socket.send.buffer.bytes = 102400
2025-10-15 20:17:51.753 | 	ssl.cipher.suites = []
2025-10-15 20:17:51.753 | 	ssl.client.auth = none
2025-10-15 20:17:51.753 | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
2025-10-15 20:17:51.753 | 	ssl.endpoint.identification.algorithm = https
2025-10-15 20:17:51.753 | 	ssl.engine.factory.class = null
2025-10-15 20:17:51.753 | 	ssl.key.password = null
2025-10-15 20:17:51.753 | 	ssl.keymanager.algorithm = SunX509
2025-10-15 20:17:51.753 | 	ssl.keystore.certificate.chain = null
2025-10-15 20:17:51.753 | 	ssl.keystore.key = null
2025-10-15 20:17:51.753 | 	ssl.keystore.location = null
2025-10-15 20:17:51.753 | 	ssl.keystore.password = null
2025-10-15 20:17:51.753 | 	ssl.keystore.type = JKS
2025-10-15 20:17:51.753 | 	ssl.principal.mapping.rules = DEFAULT
2025-10-15 20:17:51.753 | 	ssl.protocol = TLSv1.3
2025-10-15 20:17:51.753 | 	ssl.provider = null
2025-10-15 20:17:51.753 | 	ssl.secure.random.implementation = null
2025-10-15 20:17:51.753 | 	ssl.trustmanager.algorithm = PKIX
2025-10-15 20:17:51.753 | 	ssl.truststore.certificates = null
2025-10-15 20:17:51.753 | 	ssl.truststore.location = null
2025-10-15 20:17:51.753 | 	ssl.truststore.password = null
2025-10-15 20:17:51.753 | 	ssl.truststore.type = JKS
2025-10-15 20:17:51.753 | 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
2025-10-15 20:17:51.753 | 	transaction.max.timeout.ms = 900000
2025-10-15 20:17:51.753 | 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
2025-10-15 20:17:51.753 | 	transaction.state.log.load.buffer.size = 5242880
2025-10-15 20:17:51.753 | 	transaction.state.log.min.isr = 1
2025-10-15 20:17:51.753 | 	transaction.state.log.num.partitions = 50
2025-10-15 20:17:51.753 | 	transaction.state.log.replication.factor = 1
2025-10-15 20:17:51.753 | 	transaction.state.log.segment.bytes = 104857600
2025-10-15 20:17:51.753 | 	transactional.id.expiration.ms = 604800000
2025-10-15 20:17:51.753 | 	unclean.leader.election.enable = false
2025-10-15 20:17:51.753 | 	unstable.api.versions.enable = false
2025-10-15 20:17:51.753 | 	zookeeper.clientCnxnSocket = null
2025-10-15 20:17:51.753 | 	zookeeper.connect = zookeeper:2181
2025-10-15 20:17:51.753 | 	zookeeper.connection.timeout.ms = null
2025-10-15 20:17:51.753 | 	zookeeper.max.in.flight.requests = 10
2025-10-15 20:17:51.753 | 	zookeeper.metadata.migration.enable = false
2025-10-15 20:17:51.753 | 	zookeeper.session.timeout.ms = 18000
2025-10-15 20:17:51.753 | 	zookeeper.set.acl = false
2025-10-15 20:17:51.753 | 	zookeeper.ssl.cipher.suites = null
2025-10-15 20:17:51.753 | 	zookeeper.ssl.client.enable = false
2025-10-15 20:17:51.753 | 	zookeeper.ssl.crl.enable = false
2025-10-15 20:17:51.753 | 	zookeeper.ssl.enabled.protocols = null
2025-10-15 20:17:51.753 | 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
2025-10-15 20:17:51.753 | 	zookeeper.ssl.keystore.location = null
2025-10-15 20:17:51.753 | 	zookeeper.ssl.keystore.password = null
2025-10-15 20:17:51.753 | 	zookeeper.ssl.keystore.type = null
2025-10-15 20:17:51.753 | 	zookeeper.ssl.ocsp.enable = false
2025-10-15 20:17:51.753 | 	zookeeper.ssl.protocol = TLSv1.2
2025-10-15 20:17:51.753 | 	zookeeper.ssl.truststore.location = null
2025-10-15 20:17:51.753 | 	zookeeper.ssl.truststore.password = null
2025-10-15 20:17:51.753 | 	zookeeper.ssl.truststore.type = null
2025-10-15 20:17:51.753 |  (kafka.server.KafkaConfig)
2025-10-15 20:17:51.795 | [2025-10-16 01:17:51,793] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:17:51.797 | [2025-10-16 01:17:51,795] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:17:51.799 | [2025-10-16 01:17:51,798] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:17:51.802 | [2025-10-16 01:17:51,802] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:17:51.853 | [2025-10-16 01:17:51,853] INFO Loading logs from log dirs ArraySeq(/var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:51.868 | [2025-10-16 01:17:51,867] INFO Skipping recovery of 51 logs from /var/lib/kafka/data since clean shutdown file was found (kafka.log.LogManager)
2025-10-15 20:17:51.975 | [2025-10-16 01:17:51,974] INFO [LogLoader partition=__consumer_offsets-29, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.003 | [2025-10-16 01:17:52,001] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-29, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 123ms (1/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.020 | [2025-10-16 01:17:52,020] INFO [LogLoader partition=__consumer_offsets-49, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.023 | [2025-10-16 01:17:52,023] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-49, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (2/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.038 | [2025-10-16 01:17:52,038] INFO [LogLoader partition=__consumer_offsets-28, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.041 | [2025-10-16 01:17:52,041] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-28, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (3/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.057 | [2025-10-16 01:17:52,056] INFO [LogLoader partition=__consumer_offsets-5, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.061 | [2025-10-16 01:17:52,061] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-5, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (4/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.077 | [2025-10-16 01:17:52,076] INFO [LogLoader partition=__consumer_offsets-10, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.080 | [2025-10-16 01:17:52,079] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-10, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (5/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.094 | [2025-10-16 01:17:52,094] INFO [LogLoader partition=__consumer_offsets-14, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.097 | [2025-10-16 01:17:52,096] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-14, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (6/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.118 | [2025-10-16 01:17:52,117] INFO Deleted producer state snapshot /var/lib/kafka/data/__consumer_offsets-19/00000000000000000001.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
2025-10-15 20:17:52.118 | [2025-10-16 01:17:52,117] INFO [LogLoader partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Loading producer state till offset 2 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.118 | [2025-10-16 01:17:52,118] INFO [LogLoader partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.118 | [2025-10-16 01:17:52,118] INFO [ProducerStateManager partition=__consumer_offsets-19]Loading producer state from snapshot file 'SnapshotFile(offset=2, file=/var/lib/kafka/data/__consumer_offsets-19/00000000000000000002.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
2025-10-15 20:17:52.126 | [2025-10-16 01:17:52,125] INFO [LogLoader partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.130 | [2025-10-16 01:17:52,129] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-19, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=2) with 1 segments in 33ms (7/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.150 | [2025-10-16 01:17:52,149] INFO [LogLoader partition=__consumer_offsets-8, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.152 | [2025-10-16 01:17:52,152] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-8, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 22ms (8/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.167 | [2025-10-16 01:17:52,167] INFO [LogLoader partition=__consumer_offsets-17, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.170 | [2025-10-16 01:17:52,169] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-17, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (9/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.184 | [2025-10-16 01:17:52,184] INFO [LogLoader partition=__consumer_offsets-35, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.186 | [2025-10-16 01:17:52,186] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-35, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (10/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.200 | [2025-10-16 01:17:52,199] INFO [LogLoader partition=__consumer_offsets-31, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.201 | [2025-10-16 01:17:52,201] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-31, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (11/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.215 | [2025-10-16 01:17:52,215] INFO [LogLoader partition=__consumer_offsets-6, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.217 | [2025-10-16 01:17:52,216] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-6, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (12/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.234 | [2025-10-16 01:17:52,233] INFO [LogLoader partition=__consumer_offsets-32, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.236 | [2025-10-16 01:17:52,235] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-32, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (13/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.251 | [2025-10-16 01:17:52,251] INFO [LogLoader partition=__consumer_offsets-3, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.253 | [2025-10-16 01:17:52,252] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-3, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (14/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.267 | [2025-10-16 01:17:52,266] INFO [LogLoader partition=__consumer_offsets-30, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.269 | [2025-10-16 01:17:52,268] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-30, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (15/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.284 | [2025-10-16 01:17:52,284] INFO [LogLoader partition=__consumer_offsets-37, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.286 | [2025-10-16 01:17:52,285] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-37, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (16/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.300 | [2025-10-16 01:17:52,300] INFO [LogLoader partition=__consumer_offsets-41, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.302 | [2025-10-16 01:17:52,301] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-41, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (17/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.316 | [2025-10-16 01:17:52,316] INFO [LogLoader partition=__consumer_offsets-26, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.318 | [2025-10-16 01:17:52,318] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-26, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (18/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.333 | [2025-10-16 01:17:52,332] INFO [LogLoader partition=__consumer_offsets-4, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.334 | [2025-10-16 01:17:52,334] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-4, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (19/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.348 | [2025-10-16 01:17:52,348] INFO [LogLoader partition=__consumer_offsets-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.350 | [2025-10-16 01:17:52,349] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-1, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (20/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.362 | [2025-10-16 01:17:52,361] INFO [LogLoader partition=__consumer_offsets-33, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.364 | [2025-10-16 01:17:52,364] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-33, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (21/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.382 | [2025-10-16 01:17:52,382] INFO [LogLoader partition=__consumer_offsets-25, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.384 | [2025-10-16 01:17:52,384] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-25, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (22/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.399 | [2025-10-16 01:17:52,399] INFO [LogLoader partition=__consumer_offsets-42, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.401 | [2025-10-16 01:17:52,401] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-42, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (23/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.418 | [2025-10-16 01:17:52,417] INFO [LogLoader partition=__consumer_offsets-2, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.431 | [2025-10-16 01:17:52,430] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-2, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 29ms (24/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.445 | [2025-10-16 01:17:52,445] INFO [LogLoader partition=__consumer_offsets-34, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.447 | [2025-10-16 01:17:52,446] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-34, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (25/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.462 | [2025-10-16 01:17:52,462] INFO [LogLoader partition=__consumer_offsets-36, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.464 | [2025-10-16 01:17:52,464] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-36, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (26/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.478 | [2025-10-16 01:17:52,478] INFO [LogLoader partition=__consumer_offsets-12, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.481 | [2025-10-16 01:17:52,480] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-12, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (27/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.495 | [2025-10-16 01:17:52,495] INFO [LogLoader partition=__consumer_offsets-20, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.497 | [2025-10-16 01:17:52,496] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-20, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (28/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.511 | [2025-10-16 01:17:52,511] INFO [LogLoader partition=__consumer_offsets-23, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.512 | [2025-10-16 01:17:52,512] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-23, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (29/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.526 | [2025-10-16 01:17:52,526] INFO [LogLoader partition=__consumer_offsets-13, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.527 | [2025-10-16 01:17:52,527] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-13, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (30/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.542 | [2025-10-16 01:17:52,541] INFO [LogLoader partition=__consumer_offsets-40, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.543 | [2025-10-16 01:17:52,543] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-40, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (31/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.556 | [2025-10-16 01:17:52,556] INFO [LogLoader partition=__consumer_offsets-43, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.557 | [2025-10-16 01:17:52,557] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-43, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (32/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.571 | [2025-10-16 01:17:52,570] INFO [LogLoader partition=__consumer_offsets-39, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.572 | [2025-10-16 01:17:52,572] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-39, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (33/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.585 | [2025-10-16 01:17:52,585] INFO [LogLoader partition=__consumer_offsets-46, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.587 | [2025-10-16 01:17:52,586] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-46, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (34/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.601 | [2025-10-16 01:17:52,600] INFO [LogLoader partition=__consumer_offsets-7, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.602 | [2025-10-16 01:17:52,602] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-7, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (35/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.615 | [2025-10-16 01:17:52,614] INFO [LogLoader partition=__consumer_offsets-38, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.617 | [2025-10-16 01:17:52,616] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-38, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (36/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.634 | [2025-10-16 01:17:52,633] INFO [LogLoader partition=__consumer_offsets-47, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.636 | [2025-10-16 01:17:52,635] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-47, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (37/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.653 | [2025-10-16 01:17:52,652] INFO [LogLoader partition=__consumer_offsets-11, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.655 | [2025-10-16 01:17:52,655] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-11, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (38/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.670 | [2025-10-16 01:17:52,670] INFO [LogLoader partition=__consumer_offsets-21, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.672 | [2025-10-16 01:17:52,672] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-21, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (39/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.685 | [2025-10-16 01:17:52,685] INFO [LogLoader partition=__consumer_offsets-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.687 | [2025-10-16 01:17:52,686] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-0, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (40/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.700 | [2025-10-16 01:17:52,700] INFO [LogLoader partition=__consumer_offsets-16, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.702 | [2025-10-16 01:17:52,701] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-16, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (41/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.717 | [2025-10-16 01:17:52,716] INFO [LogLoader partition=__consumer_offsets-22, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.719 | [2025-10-16 01:17:52,718] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-22, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (42/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.738 | [2025-10-16 01:17:52,738] INFO [LogLoader partition=__consumer_offsets-15, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.739 | [2025-10-16 01:17:52,739] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-15, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 21ms (43/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.753 | [2025-10-16 01:17:52,753] INFO [LogLoader partition=__consumer_offsets-18, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.755 | [2025-10-16 01:17:52,755] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-18, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (44/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.774 | [2025-10-16 01:17:52,774] INFO [LogLoader partition=__consumer_offsets-27, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.775 | [2025-10-16 01:17:52,775] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-27, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (45/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.791 | [2025-10-16 01:17:52,790] INFO [LogLoader partition=__consumer_offsets-24, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.792 | [2025-10-16 01:17:52,792] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-24, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (46/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.806 | [2025-10-16 01:17:52,805] INFO [LogLoader partition=__consumer_offsets-9, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.808 | [2025-10-16 01:17:52,807] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-9, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (47/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.820 | [2025-10-16 01:17:52,819] INFO [LogLoader partition=__consumer_offsets-45, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.822 | [2025-10-16 01:17:52,821] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-45, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (48/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.835 | [2025-10-16 01:17:52,834] INFO [LogLoader partition=__consumer_offsets-44, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.836 | [2025-10-16 01:17:52,836] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-44, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (49/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.855 | [2025-10-16 01:17:52,855] INFO [LogLoader partition=mesa-ya.restaurants.created-0, dir=/var/lib/kafka/data] Loading producer state till offset 1 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.855 | [2025-10-16 01:17:52,855] INFO [LogLoader partition=mesa-ya.restaurants.created-0, dir=/var/lib/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 1 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.855 | [2025-10-16 01:17:52,855] INFO [ProducerStateManager partition=mesa-ya.restaurants.created-0]Loading producer state from snapshot file 'SnapshotFile(offset=1, file=/var/lib/kafka/data/mesa-ya.restaurants.created-0/00000000000000000001.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
2025-10-15 20:17:52.856 | [2025-10-16 01:17:52,856] INFO [LogLoader partition=mesa-ya.restaurants.created-0, dir=/var/lib/kafka/data] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 1 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.858 | [2025-10-16 01:17:52,857] INFO Completed load of Log(dir=/var/lib/kafka/data/mesa-ya.restaurants.created-0, topicId=yWm6W48_TyqOOX8W2L0ItA, topic=mesa-ya.restaurants.created, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=1) with 1 segments in 21ms (50/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.869 | [2025-10-16 01:17:52,869] INFO [LogLoader partition=__consumer_offsets-48, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:17:52.870 | [2025-10-16 01:17:52,870] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-48, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (51/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:17:52.878 | [2025-10-16 01:17:52,877] INFO Loaded 51 logs in 1023ms (kafka.log.LogManager)
2025-10-15 20:17:52.880 | [2025-10-16 01:17:52,880] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
2025-10-15 20:17:52.881 | [2025-10-16 01:17:52,881] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
2025-10-15 20:17:52.891 | [2025-10-16 01:17:52,890] INFO Starting the log cleaner (kafka.log.LogCleaner)
2025-10-15 20:17:53.005 | [2025-10-16 01:17:53,004] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
2025-10-15 20:17:53.033 | [2025-10-16 01:17:53,032] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-10-15 20:17:53.071 | [2025-10-16 01:17:53,070] INFO [MetadataCache brokerId=1] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0). (kafka.server.metadata.ZkMetadataCache)
2025-10-15 20:17:53.099 | [2025-10-16 01:17:53,099] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:17:53.388 | [2025-10-16 01:17:53,388] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
2025-10-15 20:17:53.415 | [2025-10-16 01:17:53,415] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
2025-10-15 20:17:53.416 | [2025-10-16 01:17:53,416] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
2025-10-15 20:17:53.425 | [2025-10-16 01:17:53,425] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT_INTERNAL) (kafka.network.SocketServer)
2025-10-15 20:17:53.432 | [2025-10-16 01:17:53,430] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:17:53.445 | [2025-10-16 01:17:53,444] INFO [ControllerEventThread controllerId=1] Starting (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-10-15 20:17:53.452 | [2025-10-16 01:17:53,452] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:53.455 | [2025-10-16 01:17:53,454] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:53.458 | [2025-10-16 01:17:53,456] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:53.459 | [2025-10-16 01:17:53,459] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:53.461 | [2025-10-16 01:17:53,461] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:53.461 | [2025-10-16 01:17:53,460] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:53.463 | [2025-10-16 01:17:53,462] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:53.476 | [2025-10-16 01:17:53,475] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-10-15 20:17:53.477 | [2025-10-16 01:17:53,476] INFO [Controller id=1] 1 successfully elected as the controller. Epoch incremented to 3 and epoch zk version is now 3 (kafka.controller.KafkaController)
2025-10-15 20:17:53.481 | [2025-10-16 01:17:53,480] INFO [Controller id=1] Registering handlers (kafka.controller.KafkaController)
2025-10-15 20:17:53.485 | [2025-10-16 01:17:53,485] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:53.488 | [2025-10-16 01:17:53,488] INFO [Controller id=1] Deleting log dir event notifications (kafka.controller.KafkaController)
2025-10-15 20:17:53.494 | [2025-10-16 01:17:53,493] INFO [Controller id=1] Deleting isr change notifications (kafka.controller.KafkaController)
2025-10-15 20:17:53.499 | [2025-10-16 01:17:53,498] INFO [Controller id=1] Initializing controller context (kafka.controller.KafkaController)
2025-10-15 20:17:53.504 | [2025-10-16 01:17:53,503] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:53.522 | [2025-10-16 01:17:53,522] INFO [Controller id=1] Initialized broker epochs cache: HashMap(1 -> 181) (kafka.controller.KafkaController)
2025-10-15 20:17:53.533 | [2025-10-16 01:17:53,533] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
2025-10-15 20:17:53.537 | [2025-10-16 01:17:53,537] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
2025-10-15 20:17:53.540 | [2025-10-16 01:17:53,539] INFO [TxnMarkerSenderThread-1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-10-15 20:17:53.540 | [2025-10-16 01:17:53,539] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
2025-10-15 20:17:53.547 | [2025-10-16 01:17:53,546] DEBUG [Controller id=1] Register BrokerModifications handler for Set(1) (kafka.controller.KafkaController)
2025-10-15 20:17:53.563 | [2025-10-16 01:17:53,563] INFO Stat of the created znode at /brokers/ids/1 is: 181,181,1760577473554,1760577473554,1,0,0,72057811115769859,270,0,181
2025-10-15 20:17:53.563 |  (kafka.zk.KafkaZkClient)
2025-10-15 20:17:53.564 | [2025-10-16 01:17:53,564] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092, czxid (broker epoch): 181 (kafka.zk.KafkaZkClient)
2025-10-15 20:17:53.600 | [2025-10-16 01:17:53,599] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:17:53.603 | [2025-10-16 01:17:53,603] DEBUG [Channel manager on controller 1]: Controller 1 trying to connect to broker 1 (kafka.controller.ControllerChannelManager)
2025-10-15 20:17:53.613 | [2025-10-16 01:17:53,613] INFO [RequestSendThread controllerId=1] Starting (kafka.controller.RequestSendThread)
2025-10-15 20:17:53.616 | [2025-10-16 01:17:53,615] INFO [Controller id=1] Currently active brokers in the cluster: Set(1) (kafka.controller.KafkaController)
2025-10-15 20:17:53.616 | [2025-10-16 01:17:53,616] INFO [Controller id=1] Currently shutting brokers in the cluster: HashSet() (kafka.controller.KafkaController)
2025-10-15 20:17:53.617 | [2025-10-16 01:17:53,617] INFO [Controller id=1] Current list of topics in the cluster: HashSet(__consumer_offsets, mesa-ya.restaurants.created) (kafka.controller.KafkaController)
2025-10-15 20:17:53.619 | [2025-10-16 01:17:53,618] INFO [Controller id=1] Fetching topic deletions in progress (kafka.controller.KafkaController)
2025-10-15 20:17:53.630 | [2025-10-16 01:17:53,629] INFO [Controller id=1] List of topics to be deleted:  (kafka.controller.KafkaController)
2025-10-15 20:17:53.630 | [2025-10-16 01:17:53,630] INFO [Controller id=1] List of topics ineligible for deletion:  (kafka.controller.KafkaController)
2025-10-15 20:17:53.631 | [2025-10-16 01:17:53,630] INFO [Controller id=1] Initializing topic deletion manager (kafka.controller.KafkaController)
2025-10-15 20:17:53.632 | [2025-10-16 01:17:53,631] INFO [Topic Deletion Manager 1] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet() (kafka.controller.TopicDeletionManager)
2025-10-15 20:17:53.634 | [2025-10-16 01:17:53,633] INFO [Controller id=1] Sending update metadata request (kafka.controller.KafkaController)
2025-10-15 20:17:53.641 | [2025-10-16 01:17:53,639] INFO [Controller id=1 epoch=3] Sending UpdateMetadata request to brokers HashSet(1) for 0 partitions (state.change.logger)
2025-10-15 20:17:53.641 | [2025-10-16 01:17:53,640] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-10-15 20:17:53.651 | [2025-10-16 01:17:53,650] INFO [ReplicaStateMachine controllerId=1] Initializing replica state (kafka.controller.ZkReplicaStateMachine)
2025-10-15 20:17:53.660 | [2025-10-16 01:17:53,659] INFO [Controller id=1, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
2025-10-15 20:17:53.661 | [2025-10-16 01:17:53,660] INFO [ReplicaStateMachine controllerId=1] Triggering online replica state changes (kafka.controller.ZkReplicaStateMachine)
2025-10-15 20:17:53.663 | [2025-10-16 01:17:53,663] WARN [Controller id=1, targetBrokerId=1] Connection to node 1 (kafka/172.18.0.3:29092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
2025-10-15 20:17:53.670 | [2025-10-16 01:17:53,667] WARN [RequestSendThread controllerId=1] Controller 1's connection to broker kafka:29092 (id: 1 rack: null) was unsuccessful (kafka.controller.RequestSendThread)
2025-10-15 20:17:53.670 | java.io.IOException: Connection to kafka:29092 (id: 1 rack: null) failed.
2025-10-15 20:17:53.670 | 	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
2025-10-15 20:17:53.670 | 	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:296)
2025-10-15 20:17:53.670 | 	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:249)
2025-10-15 20:17:53.670 | 	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:127)
2025-10-15 20:17:53.670 | [2025-10-16 01:17:53,670] INFO [Controller id=1, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
2025-10-15 20:17:53.688 | [2025-10-16 01:17:53,688] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-46 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.689 | [2025-10-16 01:17:53,688] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-37 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.689 | [2025-10-16 01:17:53,689] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-8 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.690 | [2025-10-16 01:17:53,689] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-49 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.690 | [2025-10-16 01:17:53,690] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-21 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.690 | [2025-10-16 01:17:53,690] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-20 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.691 | [2025-10-16 01:17:53,690] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-17 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.691 | [2025-10-16 01:17:53,691] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-19 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.691 | [2025-10-16 01:17:53,691] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-7 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.692 | [2025-10-16 01:17:53,691] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-43 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.692 | [2025-10-16 01:17:53,691] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-30 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.692 | [2025-10-16 01:17:53,692] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-35 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.692 | [2025-10-16 01:17:53,692] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-27 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.693 | [2025-10-16 01:17:53,692] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition mesa-ya.restaurants.created-0 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.693 | [2025-10-16 01:17:53,692] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-0 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.693 | [2025-10-16 01:17:53,693] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-40 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.693 | [2025-10-16 01:17:53,693] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-47 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.693 | [2025-10-16 01:17:53,693] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-10 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.694 | [2025-10-16 01:17:53,693] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-4 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.694 | [2025-10-16 01:17:53,694] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-31 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.694 | [2025-10-16 01:17:53,694] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-16 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.695 | [2025-10-16 01:17:53,694] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-23 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.695 | [2025-10-16 01:17:53,695] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-26 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.695 | [2025-10-16 01:17:53,695] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-39 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.696 | [2025-10-16 01:17:53,695] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-2 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.696 | [2025-10-16 01:17:53,696] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
2025-10-15 20:17:53.698 | [2025-10-16 01:17:53,696] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-34 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.698 | [2025-10-16 01:17:53,697] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-24 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.698 | [2025-10-16 01:17:53,697] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-32 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.698 | [2025-10-16 01:17:53,697] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-41 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.698 | [2025-10-16 01:17:53,698] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-5 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.698 | [2025-10-16 01:17:53,698] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-15 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.698 | [2025-10-16 01:17:53,698] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-1 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.698 | [2025-10-16 01:17:53,698] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-9 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.699 | [2025-10-16 01:17:53,699] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-45 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.699 | [2025-10-16 01:17:53,699] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-36 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.701 | [2025-10-16 01:17:53,700] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-48 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.701 | [2025-10-16 01:17:53,701] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-3 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.702 | [2025-10-16 01:17:53,702] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-18 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.702 | [2025-10-16 01:17:53,702] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-44 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.704 | [2025-10-16 01:17:53,703] INFO Awaiting socket connections on 0.0.0.0:29092. (kafka.network.DataPlaneAcceptor)
2025-10-15 20:17:53.704 | [2025-10-16 01:17:53,703] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-11 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.704 | [2025-10-16 01:17:53,704] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-25 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.704 | [2025-10-16 01:17:53,704] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-29 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.704 | [2025-10-16 01:17:53,704] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-6 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.704 | [2025-10-16 01:17:53,704] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-42 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.705 | [2025-10-16 01:17:53,704] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-28 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.705 | [2025-10-16 01:17:53,705] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-12 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.705 | [2025-10-16 01:17:53,705] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-38 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.705 | [2025-10-16 01:17:53,705] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-33 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.706 | [2025-10-16 01:17:53,705] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-14 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.707 | [2025-10-16 01:17:53,706] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-13 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.707 | [2025-10-16 01:17:53,707] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-22 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:17:53.710 | [2025-10-16 01:17:53,709] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
2025-10-15 20:17:53.715 | [2025-10-16 01:17:53,715] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-13 (state.change.logger)
2025-10-15 20:17:53.715 | [2025-10-16 01:17:53,715] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-46 (state.change.logger)
2025-10-15 20:17:53.715 | [2025-10-16 01:17:53,715] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-9 (state.change.logger)
2025-10-15 20:17:53.715 | [2025-10-16 01:17:53,715] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-42 (state.change.logger)
2025-10-15 20:17:53.716 | [2025-10-16 01:17:53,715] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-21 (state.change.logger)
2025-10-15 20:17:53.716 | [2025-10-16 01:17:53,715] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-17 (state.change.logger)
2025-10-15 20:17:53.716 | [2025-10-16 01:17:53,715] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-30 (state.change.logger)
2025-10-15 20:17:53.716 | [2025-10-16 01:17:53,716] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-26 (state.change.logger)
2025-10-15 20:17:53.716 | [2025-10-16 01:17:53,716] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-5 (state.change.logger)
2025-10-15 20:17:53.716 | [2025-10-16 01:17:53,716] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-38 (state.change.logger)
2025-10-15 20:17:53.716 | [2025-10-16 01:17:53,716] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-1 (state.change.logger)
2025-10-15 20:17:53.716 | [2025-10-16 01:17:53,716] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-34 (state.change.logger)
2025-10-15 20:17:53.716 | [2025-10-16 01:17:53,716] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-16 (state.change.logger)
2025-10-15 20:17:53.716 | [2025-10-16 01:17:53,716] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-45 (state.change.logger)
2025-10-15 20:17:53.716 | [2025-10-16 01:17:53,716] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-12 (state.change.logger)
2025-10-15 20:17:53.716 | [2025-10-16 01:17:53,716] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-41 (state.change.logger)
2025-10-15 20:17:53.716 | [2025-10-16 01:17:53,716] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-24 (state.change.logger)
2025-10-15 20:17:53.729 | [2025-10-16 01:17:53,716] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-20 (state.change.logger)
2025-10-15 20:17:53.729 | [2025-10-16 01:17:53,729] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-49 (state.change.logger)
2025-10-15 20:17:53.729 | [2025-10-16 01:17:53,729] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-0 (state.change.logger)
2025-10-15 20:17:53.729 | [2025-10-16 01:17:53,729] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-29 (state.change.logger)
2025-10-15 20:17:53.729 | [2025-10-16 01:17:53,729] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-25 (state.change.logger)
2025-10-15 20:17:53.730 | [2025-10-16 01:17:53,729] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-8 (state.change.logger)
2025-10-15 20:17:53.730 | [2025-10-16 01:17:53,729] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-37 (state.change.logger)
2025-10-15 20:17:53.730 | [2025-10-16 01:17:53,729] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-4 (state.change.logger)
2025-10-15 20:17:53.730 | [2025-10-16 01:17:53,730] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-33 (state.change.logger)
2025-10-15 20:17:53.730 | [2025-10-16 01:17:53,730] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-15 (state.change.logger)
2025-10-15 20:17:53.730 | [2025-10-16 01:17:53,730] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-48 (state.change.logger)
2025-10-15 20:17:53.731 | [2025-10-16 01:17:53,731] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-11 (state.change.logger)
2025-10-15 20:17:53.731 | [2025-10-16 01:17:53,731] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-44 (state.change.logger)
2025-10-15 20:17:53.731 | [2025-10-16 01:17:53,731] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-23 (state.change.logger)
2025-10-15 20:17:53.731 | [2025-10-16 01:17:53,731] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-19 (state.change.logger)
2025-10-15 20:17:53.732 | [2025-10-16 01:17:53,731] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-32 (state.change.logger)
2025-10-15 20:17:53.732 | [2025-10-16 01:17:53,731] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-28 (state.change.logger)
2025-10-15 20:17:53.732 | [2025-10-16 01:17:53,731] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-7 (state.change.logger)
2025-10-15 20:17:53.732 | [2025-10-16 01:17:53,732] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-40 (state.change.logger)
2025-10-15 20:17:53.732 | [2025-10-16 01:17:53,732] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-3 (state.change.logger)
2025-10-15 20:17:53.732 | [2025-10-16 01:17:53,732] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-36 (state.change.logger)
2025-10-15 20:17:53.732 | [2025-10-16 01:17:53,732] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-47 (state.change.logger)
2025-10-15 20:17:53.732 | [2025-10-16 01:17:53,732] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-14 (state.change.logger)
2025-10-15 20:17:53.732 | [2025-10-16 01:17:53,732] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-43 (state.change.logger)
2025-10-15 20:17:53.732 | [2025-10-16 01:17:53,732] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-10 (state.change.logger)
2025-10-15 20:17:53.732 | [2025-10-16 01:17:53,732] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-22 (state.change.logger)
2025-10-15 20:17:53.732 | [2025-10-16 01:17:53,732] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-18 (state.change.logger)
2025-10-15 20:17:53.732 | [2025-10-16 01:17:53,732] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-31 (state.change.logger)
2025-10-15 20:17:53.733 | [2025-10-16 01:17:53,732] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-27 (state.change.logger)
2025-10-15 20:17:53.733 | [2025-10-16 01:17:53,732] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-39 (state.change.logger)
2025-10-15 20:17:53.733 | [2025-10-16 01:17:53,733] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-6 (state.change.logger)
2025-10-15 20:17:53.733 | [2025-10-16 01:17:53,733] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-35 (state.change.logger)
2025-10-15 20:17:53.733 | [2025-10-16 01:17:53,733] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='mesa-ya.restaurants.created', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition mesa-ya.restaurants.created-0 (state.change.logger)
2025-10-15 20:17:53.733 | [2025-10-16 01:17:53,733] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-2 (state.change.logger)
2025-10-15 20:17:53.734 | [2025-10-16 01:17:53,734] INFO Kafka version: 7.5.0-ccs (org.apache.kafka.common.utils.AppInfoParser)
2025-10-15 20:17:53.734 | [2025-10-16 01:17:53,734] INFO Kafka commitId: ff3c201baa948d97889dc26c99d7cdc23d038f2e (org.apache.kafka.common.utils.AppInfoParser)
2025-10-15 20:17:53.734 | [2025-10-16 01:17:53,734] INFO Kafka startTimeMs: 1760577473714 (org.apache.kafka.common.utils.AppInfoParser)
2025-10-15 20:17:53.736 | [2025-10-16 01:17:53,736] INFO [Controller id=1 epoch=3] Sending LeaderAndIsr request to broker 1 with 51 become-leader and 0 become-follower partitions (state.change.logger)
2025-10-15 20:17:53.738 | [2025-10-16 01:17:53,737] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
2025-10-15 20:17:53.741 | [2025-10-16 01:17:53,741] INFO [Controller id=1 epoch=3] Sending UpdateMetadata request to brokers HashSet(1) for 51 partitions (state.change.logger)
2025-10-15 20:17:53.742 | [2025-10-16 01:17:53,742] INFO [ReplicaStateMachine controllerId=1] Triggering offline replica state changes (kafka.controller.ZkReplicaStateMachine)
2025-10-15 20:17:53.743 | [2025-10-16 01:17:53,743] DEBUG [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> HashMap([Topic=__consumer_offsets,Partition=46,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=37,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=8,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=49,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=21,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=20,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=17,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=19,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=7,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=43,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=30,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=35,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=27,Replica=1] -> OnlineReplica, [Topic=mesa-ya.restaurants.created,Partition=0,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=0,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=40,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=47,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=10,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=4,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=31,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=16,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=23,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=26,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=39,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=2,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=34,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=24,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=32,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=41,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=5,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=15,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=1,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=9,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=45,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=36,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=48,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=3,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=18,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=44,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=11,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=25,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=29,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=6,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=42,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=28,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=12,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=38,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=33,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=14,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=13,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=22,Replica=1] -> OnlineReplica) (kafka.controller.ZkReplicaStateMachine)
2025-10-15 20:17:53.744 | [2025-10-16 01:17:53,744] INFO [PartitionStateMachine controllerId=1] Initializing partition state (kafka.controller.ZkPartitionStateMachine)
2025-10-15 20:17:53.751 | [2025-10-16 01:17:53,750] INFO [PartitionStateMachine controllerId=1] Triggering online partition state changes (kafka.controller.ZkPartitionStateMachine)
2025-10-15 20:17:53.753 | [2025-10-16 01:17:53,753] DEBUG [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> HashMap(__consumer_offsets-13 -> OnlinePartition, __consumer_offsets-46 -> OnlinePartition, __consumer_offsets-9 -> OnlinePartition, __consumer_offsets-42 -> OnlinePartition, __consumer_offsets-21 -> OnlinePartition, __consumer_offsets-17 -> OnlinePartition, __consumer_offsets-30 -> OnlinePartition, __consumer_offsets-26 -> OnlinePartition, __consumer_offsets-5 -> OnlinePartition, __consumer_offsets-38 -> OnlinePartition, __consumer_offsets-1 -> OnlinePartition, __consumer_offsets-34 -> OnlinePartition, __consumer_offsets-16 -> OnlinePartition, __consumer_offsets-45 -> OnlinePartition, __consumer_offsets-12 -> OnlinePartition, __consumer_offsets-41 -> OnlinePartition, __consumer_offsets-24 -> OnlinePartition, __consumer_offsets-20 -> OnlinePartition, __consumer_offsets-49 -> OnlinePartition, __consumer_offsets-0 -> OnlinePartition, __consumer_offsets-29 -> OnlinePartition, __consumer_offsets-25 -> OnlinePartition, __consumer_offsets-8 -> OnlinePartition, __consumer_offsets-37 -> OnlinePartition, __consumer_offsets-4 -> OnlinePartition, __consumer_offsets-33 -> OnlinePartition, __consumer_offsets-15 -> OnlinePartition, __consumer_offsets-48 -> OnlinePartition, __consumer_offsets-11 -> OnlinePartition, __consumer_offsets-44 -> OnlinePartition, __consumer_offsets-23 -> OnlinePartition, __consumer_offsets-19 -> OnlinePartition, __consumer_offsets-32 -> OnlinePartition, __consumer_offsets-28 -> OnlinePartition, __consumer_offsets-7 -> OnlinePartition, __consumer_offsets-40 -> OnlinePartition, __consumer_offsets-3 -> OnlinePartition, __consumer_offsets-36 -> OnlinePartition, __consumer_offsets-47 -> OnlinePartition, __consumer_offsets-14 -> OnlinePartition, __consumer_offsets-43 -> OnlinePartition, __consumer_offsets-10 -> OnlinePartition, __consumer_offsets-22 -> OnlinePartition, __consumer_offsets-18 -> OnlinePartition, __consumer_offsets-31 -> OnlinePartition, __consumer_offsets-27 -> OnlinePartition, __consumer_offsets-39 -> OnlinePartition, __consumer_offsets-6 -> OnlinePartition, __consumer_offsets-35 -> OnlinePartition, mesa-ya.restaurants.created-0 -> OnlinePartition, __consumer_offsets-2 -> OnlinePartition) (kafka.controller.ZkPartitionStateMachine)
2025-10-15 20:17:53.753 | [2025-10-16 01:17:53,753] INFO [Controller id=1] Ready to serve as the new controller with epoch 3 (kafka.controller.KafkaController)
2025-10-15 20:17:53.762 | [2025-10-16 01:17:53,761] INFO [Controller id=1] Partitions undergoing preferred replica election:  (kafka.controller.KafkaController)
2025-10-15 20:17:53.762 | [2025-10-16 01:17:53,762] INFO [Controller id=1] Partitions that completed preferred replica election:  (kafka.controller.KafkaController)
2025-10-15 20:17:53.762 | [2025-10-16 01:17:53,762] INFO [Controller id=1] Skipping preferred replica election for partitions due to topic deletion:  (kafka.controller.KafkaController)
2025-10-15 20:17:53.763 | [2025-10-16 01:17:53,762] INFO [Controller id=1] Resuming preferred replica election for partitions:  (kafka.controller.KafkaController)
2025-10-15 20:17:53.765 | [2025-10-16 01:17:53,764] INFO [Controller id=1] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered (kafka.controller.KafkaController)
2025-10-15 20:17:53.777 | [2025-10-16 01:17:53,776] INFO [RequestSendThread controllerId=1] Controller 1 connected to kafka:29092 (id: 1 rack: null) for sending state change requests (kafka.controller.RequestSendThread)
2025-10-15 20:17:53.786 | [2025-10-16 01:17:53,786] INFO [Controller id=1] Starting the controller scheduler (kafka.controller.KafkaController)
2025-10-15 20:17:53.847 | [2025-10-16 01:17:53,847] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Recorded new controller, from now on will use node kafka:29092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:17:53.850 | [2025-10-16 01:17:53,849] TRACE [Controller id=1 epoch=3] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 0 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-10-15 20:17:53.859 | [2025-10-16 01:17:53,859] INFO [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 for 51 partitions (state.change.logger)
2025-10-15 20:17:53.860 | [2025-10-16 01:17:53,859] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.860 | [2025-10-16 01:17:53,859] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.860 | [2025-10-16 01:17:53,859] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.860 | [2025-10-16 01:17:53,859] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.860 | [2025-10-16 01:17:53,859] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.860 | [2025-10-16 01:17:53,859] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.860 | [2025-10-16 01:17:53,860] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.860 | [2025-10-16 01:17:53,860] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.860 | [2025-10-16 01:17:53,860] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.860 | [2025-10-16 01:17:53,860] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.860 | [2025-10-16 01:17:53,860] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.860 | [2025-10-16 01:17:53,860] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.860 | [2025-10-16 01:17:53,860] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.860 | [2025-10-16 01:17:53,860] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.860 | [2025-10-16 01:17:53,860] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.860 | [2025-10-16 01:17:53,860] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.860 | [2025-10-16 01:17:53,860] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.860 | [2025-10-16 01:17:53,860] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.860 | [2025-10-16 01:17:53,860] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.860 | [2025-10-16 01:17:53,860] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.860 | [2025-10-16 01:17:53,860] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.860 | [2025-10-16 01:17:53,860] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.860 | [2025-10-16 01:17:53,860] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.860 | [2025-10-16 01:17:53,860] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.860 | [2025-10-16 01:17:53,860] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.860 | [2025-10-16 01:17:53,860] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.860 | [2025-10-16 01:17:53,860] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.860 | [2025-10-16 01:17:53,860] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.860 | [2025-10-16 01:17:53,860] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.860 | [2025-10-16 01:17:53,860] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.861 | [2025-10-16 01:17:53,860] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.861 | [2025-10-16 01:17:53,861] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.861 | [2025-10-16 01:17:53,861] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.861 | [2025-10-16 01:17:53,861] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.861 | [2025-10-16 01:17:53,861] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.861 | [2025-10-16 01:17:53,861] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.861 | [2025-10-16 01:17:53,861] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.861 | [2025-10-16 01:17:53,861] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.861 | [2025-10-16 01:17:53,861] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.861 | [2025-10-16 01:17:53,861] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.861 | [2025-10-16 01:17:53,861] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.861 | [2025-10-16 01:17:53,861] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.861 | [2025-10-16 01:17:53,861] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.861 | [2025-10-16 01:17:53,861] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.861 | [2025-10-16 01:17:53,861] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.861 | [2025-10-16 01:17:53,861] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.861 | [2025-10-16 01:17:53,861] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.862 | [2025-10-16 01:17:53,861] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.862 | [2025-10-16 01:17:53,861] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.862 | [2025-10-16 01:17:53,861] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.862 | [2025-10-16 01:17:53,861] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='mesa-ya.restaurants.created', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-10-15 20:17:53.890 | [2025-10-16 01:17:53,890] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-3 (state.change.logger)
2025-10-15 20:17:53.890 | [2025-10-16 01:17:53,890] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-18 (state.change.logger)
2025-10-15 20:17:53.890 | [2025-10-16 01:17:53,890] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-41 (state.change.logger)
2025-10-15 20:17:53.890 | [2025-10-16 01:17:53,890] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-10 (state.change.logger)
2025-10-15 20:17:53.890 | [2025-10-16 01:17:53,890] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-33 (state.change.logger)
2025-10-15 20:17:53.890 | [2025-10-16 01:17:53,890] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-48 (state.change.logger)
2025-10-15 20:17:53.890 | [2025-10-16 01:17:53,890] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-19 (state.change.logger)
2025-10-15 20:17:53.890 | [2025-10-16 01:17:53,890] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-34 (state.change.logger)
2025-10-15 20:17:53.890 | [2025-10-16 01:17:53,890] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-4 (state.change.logger)
2025-10-15 20:17:53.890 | [2025-10-16 01:17:53,890] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-11 (state.change.logger)
2025-10-15 20:17:53.891 | [2025-10-16 01:17:53,890] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-26 (state.change.logger)
2025-10-15 20:17:53.891 | [2025-10-16 01:17:53,890] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-49 (state.change.logger)
2025-10-15 20:17:53.891 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-39 (state.change.logger)
2025-10-15 20:17:53.891 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-9 (state.change.logger)
2025-10-15 20:17:53.891 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-24 (state.change.logger)
2025-10-15 20:17:53.891 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-31 (state.change.logger)
2025-10-15 20:17:53.891 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-46 (state.change.logger)
2025-10-15 20:17:53.891 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-1 (state.change.logger)
2025-10-15 20:17:53.891 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-16 (state.change.logger)
2025-10-15 20:17:53.891 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-2 (state.change.logger)
2025-10-15 20:17:53.891 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-25 (state.change.logger)
2025-10-15 20:17:53.891 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-40 (state.change.logger)
2025-10-15 20:17:53.891 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-47 (state.change.logger)
2025-10-15 20:17:53.891 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-17 (state.change.logger)
2025-10-15 20:17:53.891 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-32 (state.change.logger)
2025-10-15 20:17:53.891 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-37 (state.change.logger)
2025-10-15 20:17:53.891 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-7 (state.change.logger)
2025-10-15 20:17:53.891 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-22 (state.change.logger)
2025-10-15 20:17:53.891 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-29 (state.change.logger)
2025-10-15 20:17:53.891 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-44 (state.change.logger)
2025-10-15 20:17:53.891 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-14 (state.change.logger)
2025-10-15 20:17:53.891 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-23 (state.change.logger)
2025-10-15 20:17:53.891 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-38 (state.change.logger)
2025-10-15 20:17:53.891 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-8 (state.change.logger)
2025-10-15 20:17:53.891 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-45 (state.change.logger)
2025-10-15 20:17:53.891 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-15 (state.change.logger)
2025-10-15 20:17:53.891 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-30 (state.change.logger)
2025-10-15 20:17:53.891 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition mesa-ya.restaurants.created-0 (state.change.logger)
2025-10-15 20:17:53.891 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-0 (state.change.logger)
2025-10-15 20:17:53.891 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-35 (state.change.logger)
2025-10-15 20:17:53.891 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-5 (state.change.logger)
2025-10-15 20:17:53.891 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-20 (state.change.logger)
2025-10-15 20:17:53.891 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-27 (state.change.logger)
2025-10-15 20:17:53.892 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-42 (state.change.logger)
2025-10-15 20:17:53.892 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-12 (state.change.logger)
2025-10-15 20:17:53.892 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-21 (state.change.logger)
2025-10-15 20:17:53.892 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-36 (state.change.logger)
2025-10-15 20:17:53.892 | [2025-10-16 01:17:53,891] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-6 (state.change.logger)
2025-10-15 20:17:53.892 | [2025-10-16 01:17:53,892] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-43 (state.change.logger)
2025-10-15 20:17:53.892 | [2025-10-16 01:17:53,892] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-13 (state.change.logger)
2025-10-15 20:17:53.892 | [2025-10-16 01:17:53,892] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-28 (state.change.logger)
2025-10-15 20:17:53.895 | [2025-10-16 01:17:53,894] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-37, __consumer_offsets-38, __consumer_offsets-13, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, mesa-ya.restaurants.created-0, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
2025-10-15 20:17:53.895 | [2025-10-16 01:17:53,895] INFO [Broker id=1] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 1 epoch 3 as part of the become-leader transition for 51 partitions (state.change.logger)
2025-10-15 20:17:53.909 | [2025-10-16 01:17:53,909] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:53.914 | [2025-10-16 01:17:53,914] INFO [Broker id=1] Leader __consumer_offsets-3 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:53.932 | [2025-10-16 01:17:53,931] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Recorded new controller, from now on will use node kafka:29092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:17:53.939 | [2025-10-16 01:17:53,938] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:53.939 | [2025-10-16 01:17:53,939] INFO [Broker id=1] Leader __consumer_offsets-18 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:53.955 | [2025-10-16 01:17:53,954] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:53.955 | [2025-10-16 01:17:53,955] INFO [Broker id=1] Leader __consumer_offsets-41 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:53.970 | [2025-10-16 01:17:53,969] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:53.970 | [2025-10-16 01:17:53,969] INFO [Broker id=1] Leader __consumer_offsets-10 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:53.985 | [2025-10-16 01:17:53,985] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:53.985 | [2025-10-16 01:17:53,985] INFO [Broker id=1] Leader __consumer_offsets-33 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.000 | [2025-10-16 01:17:54,000] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.000 | [2025-10-16 01:17:54,000] INFO [Broker id=1] Leader __consumer_offsets-48 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.014 | [2025-10-16 01:17:54,014] INFO [Partition __consumer_offsets-19 broker=1] Log loaded for partition __consumer_offsets-19 with initial high watermark 2 (kafka.cluster.Partition)
2025-10-15 20:17:54.014 | [2025-10-16 01:17:54,014] INFO [Broker id=1] Leader __consumer_offsets-19 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 2 with partition epoch 0, high watermark 2, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.014 | [2025-10-16 01:17:54,014] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.015 | [2025-10-16 01:17:54,014] INFO [Broker id=1] Leader __consumer_offsets-34 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.028 | [2025-10-16 01:17:54,027] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.028 | [2025-10-16 01:17:54,028] INFO [Broker id=1] Leader __consumer_offsets-4 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.042 | [2025-10-16 01:17:54,041] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.042 | [2025-10-16 01:17:54,042] INFO [Broker id=1] Leader __consumer_offsets-11 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.053 | [2025-10-16 01:17:54,053] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.053 | [2025-10-16 01:17:54,053] INFO [Broker id=1] Leader __consumer_offsets-26 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.066 | [2025-10-16 01:17:54,065] INFO [Partition __consumer_offsets-49 broker=1] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.066 | [2025-10-16 01:17:54,066] INFO [Broker id=1] Leader __consumer_offsets-49 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.078 | [2025-10-16 01:17:54,078] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.078 | [2025-10-16 01:17:54,078] INFO [Broker id=1] Leader __consumer_offsets-39 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.091 | [2025-10-16 01:17:54,091] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.091 | [2025-10-16 01:17:54,091] INFO [Broker id=1] Leader __consumer_offsets-9 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.103 | [2025-10-16 01:17:54,103] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.103 | [2025-10-16 01:17:54,103] INFO [Broker id=1] Leader __consumer_offsets-24 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.114 | [2025-10-16 01:17:54,113] INFO [Partition __consumer_offsets-31 broker=1] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.114 | [2025-10-16 01:17:54,114] INFO [Broker id=1] Leader __consumer_offsets-31 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.125 | [2025-10-16 01:17:54,125] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.126 | [2025-10-16 01:17:54,125] INFO [Broker id=1] Leader __consumer_offsets-46 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.136 | [2025-10-16 01:17:54,136] INFO [Partition __consumer_offsets-1 broker=1] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.137 | [2025-10-16 01:17:54,136] INFO [Broker id=1] Leader __consumer_offsets-1 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.150 | [2025-10-16 01:17:54,150] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.150 | [2025-10-16 01:17:54,150] INFO [Broker id=1] Leader __consumer_offsets-16 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.161 | [2025-10-16 01:17:54,160] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.161 | [2025-10-16 01:17:54,161] INFO [Broker id=1] Leader __consumer_offsets-2 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.174 | [2025-10-16 01:17:54,174] INFO [Partition __consumer_offsets-25 broker=1] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.174 | [2025-10-16 01:17:54,174] INFO [Broker id=1] Leader __consumer_offsets-25 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.192 | [2025-10-16 01:17:54,191] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.192 | [2025-10-16 01:17:54,191] INFO [Broker id=1] Leader __consumer_offsets-40 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.204 | [2025-10-16 01:17:54,204] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.204 | [2025-10-16 01:17:54,204] INFO [Broker id=1] Leader __consumer_offsets-47 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.218 | [2025-10-16 01:17:54,217] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.218 | [2025-10-16 01:17:54,217] INFO [Broker id=1] Leader __consumer_offsets-17 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.229 | [2025-10-16 01:17:54,228] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.229 | [2025-10-16 01:17:54,229] INFO [Broker id=1] Leader __consumer_offsets-32 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.241 | [2025-10-16 01:17:54,240] INFO [Partition __consumer_offsets-37 broker=1] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.241 | [2025-10-16 01:17:54,241] INFO [Broker id=1] Leader __consumer_offsets-37 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.252 | [2025-10-16 01:17:54,251] INFO [Partition __consumer_offsets-7 broker=1] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.252 | [2025-10-16 01:17:54,252] INFO [Broker id=1] Leader __consumer_offsets-7 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.263 | [2025-10-16 01:17:54,263] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.263 | [2025-10-16 01:17:54,263] INFO [Broker id=1] Leader __consumer_offsets-22 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.275 | [2025-10-16 01:17:54,274] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.275 | [2025-10-16 01:17:54,274] INFO [Broker id=1] Leader __consumer_offsets-29 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.287 | [2025-10-16 01:17:54,287] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.287 | [2025-10-16 01:17:54,287] INFO [Broker id=1] Leader __consumer_offsets-44 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.299 | [2025-10-16 01:17:54,298] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.299 | [2025-10-16 01:17:54,298] INFO [Broker id=1] Leader __consumer_offsets-14 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.310 | [2025-10-16 01:17:54,310] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.311 | [2025-10-16 01:17:54,310] INFO [Broker id=1] Leader __consumer_offsets-23 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.322 | [2025-10-16 01:17:54,322] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.322 | [2025-10-16 01:17:54,322] INFO [Broker id=1] Leader __consumer_offsets-38 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.334 | [2025-10-16 01:17:54,333] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.334 | [2025-10-16 01:17:54,333] INFO [Broker id=1] Leader __consumer_offsets-8 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.344 | [2025-10-16 01:17:54,344] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.345 | [2025-10-16 01:17:54,344] INFO [Broker id=1] Leader __consumer_offsets-45 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.356 | [2025-10-16 01:17:54,356] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.356 | [2025-10-16 01:17:54,356] INFO [Broker id=1] Leader __consumer_offsets-15 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.369 | [2025-10-16 01:17:54,369] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.369 | [2025-10-16 01:17:54,369] INFO [Broker id=1] Leader __consumer_offsets-30 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.381 | [2025-10-16 01:17:54,381] INFO [Partition mesa-ya.restaurants.created-0 broker=1] Log loaded for partition mesa-ya.restaurants.created-0 with initial high watermark 1 (kafka.cluster.Partition)
2025-10-15 20:17:54.381 | [2025-10-16 01:17:54,381] INFO [Broker id=1] Leader mesa-ya.restaurants.created-0 with topic id Some(yWm6W48_TyqOOX8W2L0ItA) starts at leader epoch 0 from offset 1 with partition epoch 0, high watermark 1, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.382 | [2025-10-16 01:17:54,381] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.382 | [2025-10-16 01:17:54,381] INFO [Broker id=1] Leader __consumer_offsets-0 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.395 | [2025-10-16 01:17:54,395] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.395 | [2025-10-16 01:17:54,395] INFO [Broker id=1] Leader __consumer_offsets-35 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.410 | [2025-10-16 01:17:54,410] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.410 | [2025-10-16 01:17:54,410] INFO [Broker id=1] Leader __consumer_offsets-5 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.422 | [2025-10-16 01:17:54,422] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.422 | [2025-10-16 01:17:54,422] INFO [Broker id=1] Leader __consumer_offsets-20 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.435 | [2025-10-16 01:17:54,434] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.435 | [2025-10-16 01:17:54,434] INFO [Broker id=1] Leader __consumer_offsets-27 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.447 | [2025-10-16 01:17:54,447] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.447 | [2025-10-16 01:17:54,447] INFO [Broker id=1] Leader __consumer_offsets-42 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.460 | [2025-10-16 01:17:54,460] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.460 | [2025-10-16 01:17:54,460] INFO [Broker id=1] Leader __consumer_offsets-12 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.471 | [2025-10-16 01:17:54,470] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.471 | [2025-10-16 01:17:54,471] INFO [Broker id=1] Leader __consumer_offsets-21 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.487 | [2025-10-16 01:17:54,487] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.487 | [2025-10-16 01:17:54,487] INFO [Broker id=1] Leader __consumer_offsets-36 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.500 | [2025-10-16 01:17:54,499] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.500 | [2025-10-16 01:17:54,499] INFO [Broker id=1] Leader __consumer_offsets-6 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.511 | [2025-10-16 01:17:54,510] INFO [Partition __consumer_offsets-43 broker=1] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.511 | [2025-10-16 01:17:54,511] INFO [Broker id=1] Leader __consumer_offsets-43 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.523 | [2025-10-16 01:17:54,523] INFO [Partition __consumer_offsets-13 broker=1] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.524 | [2025-10-16 01:17:54,523] INFO [Broker id=1] Leader __consumer_offsets-13 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.535 | [2025-10-16 01:17:54,535] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:17:54.535 | [2025-10-16 01:17:54,535] INFO [Broker id=1] Leader __consumer_offsets-28 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,549] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-3 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,549] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-18 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,549] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-41 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,549] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-10 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,549] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-33 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,549] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-48 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,549] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-19 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,549] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-34 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,549] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-4 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,549] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-11 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,549] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-26 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,549] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-49 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-39 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-9 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-24 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-31 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-46 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-1 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-16 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-2 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-25 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-40 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-47 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-17 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-32 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-37 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-7 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-22 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-29 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-44 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-14 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-23 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-38 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-8 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-45 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-15 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-30 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition mesa-ya.restaurants.created-0 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-0 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-35 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-5 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-20 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-27 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-42 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-12 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-21 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-36 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-6 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-43 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-13 (state.change.logger)
2025-10-15 20:17:54.550 | [2025-10-16 01:17:54,550] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-28 (state.change.logger)
2025-10-15 20:17:54.561 | [2025-10-16 01:17:54,560] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.564 | [2025-10-16 01:17:54,563] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,566] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,566] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,566] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,566] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,566] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,566] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,566] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,566] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,566] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,566] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,566] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,566] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,566] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,566] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.567 | [2025-10-16 01:17:54,567] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.568 | [2025-10-16 01:17:54,567] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.568 | [2025-10-16 01:17:54,567] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.568 | [2025-10-16 01:17:54,567] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.568 | [2025-10-16 01:17:54,567] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.568 | [2025-10-16 01:17:54,567] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.568 | [2025-10-16 01:17:54,567] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.568 | [2025-10-16 01:17:54,567] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.568 | [2025-10-16 01:17:54,567] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.568 | [2025-10-16 01:17:54,567] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.568 | [2025-10-16 01:17:54,568] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.568 | [2025-10-16 01:17:54,568] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.568 | [2025-10-16 01:17:54,568] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.568 | [2025-10-16 01:17:54,568] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.568 | [2025-10-16 01:17:54,568] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.568 | [2025-10-16 01:17:54,568] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.568 | [2025-10-16 01:17:54,568] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.568 | [2025-10-16 01:17:54,568] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.568 | [2025-10-16 01:17:54,568] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.568 | [2025-10-16 01:17:54,568] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.568 | [2025-10-16 01:17:54,568] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.568 | [2025-10-16 01:17:54,568] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.568 | [2025-10-16 01:17:54,568] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.568 | [2025-10-16 01:17:54,568] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.568 | [2025-10-16 01:17:54,568] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.568 | [2025-10-16 01:17:54,568] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.568 | [2025-10-16 01:17:54,568] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.568 | [2025-10-16 01:17:54,568] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.568 | [2025-10-16 01:17:54,568] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.568 | [2025-10-16 01:17:54,568] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.568 | [2025-10-16 01:17:54,568] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.568 | [2025-10-16 01:17:54,568] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.568 | [2025-10-16 01:17:54,568] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.569 | [2025-10-16 01:17:54,568] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.569 | [2025-10-16 01:17:54,568] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.569 | [2025-10-16 01:17:54,568] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.569 | [2025-10-16 01:17:54,568] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.569 | [2025-10-16 01:17:54,568] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.569 | [2025-10-16 01:17:54,569] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.569 | [2025-10-16 01:17:54,569] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.569 | [2025-10-16 01:17:54,569] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.569 | [2025-10-16 01:17:54,569] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.569 | [2025-10-16 01:17:54,569] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.569 | [2025-10-16 01:17:54,569] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.569 | [2025-10-16 01:17:54,569] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.579 | [2025-10-16 01:17:54,577] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 13 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.579 | [2025-10-16 01:17:54,579] INFO [Broker id=1] Finished LeaderAndIsr request in 719ms correlationId 1 from controller 1 for 51 partitions (state.change.logger)
2025-10-15 20:17:54.579 | [2025-10-16 01:17:54,579] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.579 | [2025-10-16 01:17:54,579] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.581 | [2025-10-16 01:17:54,580] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.581 | [2025-10-16 01:17:54,581] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.582 | [2025-10-16 01:17:54,581] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.589 | [2025-10-16 01:17:54,589] TRACE [Controller id=1 epoch=3] Received response LeaderAndIsrResponseData(errorCode=0, partitionErrors=[], topics=[LeaderAndIsrTopicError(topicId=6ep0dUNwQAaqKr79SJ8ITA, partitionErrors=[LeaderAndIsrPartitionError(topicName='', partitionIndex=13, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=46, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=9, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=42, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=21, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=17, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=30, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=26, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=5, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=38, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=1, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=34, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=16, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=45, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=12, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=41, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=24, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=20, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=49, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=0, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=29, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=25, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=8, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=37, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=4, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=33, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=15, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=48, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=11, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=44, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=23, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=19, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=32, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=28, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=7, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=40, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=3, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=36, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=47, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=14, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=43, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=10, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=22, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=18, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=31, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=27, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=39, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=6, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=35, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=2, errorCode=0)]), LeaderAndIsrTopicError(topicId=yWm6W48_TyqOOX8W2L0ItA, partitionErrors=[LeaderAndIsrPartitionError(topicName='', partitionIndex=0, errorCode=0)])]) for request LEADER_AND_ISR with correlation id 1 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-10-15 20:17:54.598 | [2025-10-16 01:17:54,597] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-13 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.598 | [2025-10-16 01:17:54,597] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-46 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.598 | [2025-10-16 01:17:54,597] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-9 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.598 | [2025-10-16 01:17:54,597] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-42 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.598 | [2025-10-16 01:17:54,597] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-21 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.598 | [2025-10-16 01:17:54,597] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-17 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.598 | [2025-10-16 01:17:54,598] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-30 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.598 | [2025-10-16 01:17:54,598] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-26 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.598 | [2025-10-16 01:17:54,598] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-5 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.598 | [2025-10-16 01:17:54,598] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-38 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.598 | [2025-10-16 01:17:54,598] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-1 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.598 | [2025-10-16 01:17:54,598] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-34 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.598 | [2025-10-16 01:17:54,598] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-16 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.599 | [2025-10-16 01:17:54,598] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-45 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.599 | [2025-10-16 01:17:54,598] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-12 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.599 | [2025-10-16 01:17:54,598] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-41 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.599 | [2025-10-16 01:17:54,598] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-24 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.599 | [2025-10-16 01:17:54,599] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-20 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.599 | [2025-10-16 01:17:54,599] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-49 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.599 | [2025-10-16 01:17:54,599] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-0 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.599 | [2025-10-16 01:17:54,599] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-29 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.599 | [2025-10-16 01:17:54,599] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-25 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.599 | [2025-10-16 01:17:54,599] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-8 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.599 | [2025-10-16 01:17:54,599] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-37 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.599 | [2025-10-16 01:17:54,599] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-4 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.599 | [2025-10-16 01:17:54,599] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-33 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.599 | [2025-10-16 01:17:54,599] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-15 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.599 | [2025-10-16 01:17:54,599] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-48 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.599 | [2025-10-16 01:17:54,599] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-11 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.599 | [2025-10-16 01:17:54,599] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-44 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.599 | [2025-10-16 01:17:54,599] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-23 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.599 | [2025-10-16 01:17:54,599] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-19 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.599 | [2025-10-16 01:17:54,599] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-32 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.599 | [2025-10-16 01:17:54,599] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-28 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.599 | [2025-10-16 01:17:54,599] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-7 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.599 | [2025-10-16 01:17:54,599] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-40 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.599 | [2025-10-16 01:17:54,599] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-3 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.599 | [2025-10-16 01:17:54,599] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-36 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.599 | [2025-10-16 01:17:54,599] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-47 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.600 | [2025-10-16 01:17:54,599] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-14 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.600 | [2025-10-16 01:17:54,600] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-43 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.600 | [2025-10-16 01:17:54,600] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-10 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.601 | [2025-10-16 01:17:54,601] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-22 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.601 | [2025-10-16 01:17:54,601] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-18 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.602 | [2025-10-16 01:17:54,601] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-31 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.602 | [2025-10-16 01:17:54,602] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-27 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.603 | [2025-10-16 01:17:54,602] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-39 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.603 | [2025-10-16 01:17:54,602] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-6 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.603 | [2025-10-16 01:17:54,603] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-35 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.603 | [2025-10-16 01:17:54,603] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-2 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.603 | [2025-10-16 01:17:54,603] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='mesa-ya.restaurants.created', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition mesa-ya.restaurants.created-0 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.606 | [2025-10-16 01:17:54,606] INFO [Broker id=1] Add 51 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-10-15 20:17:54.608 | [2025-10-16 01:17:54,607] TRACE [Controller id=1 epoch=3] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 2 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-10-15 20:17:54.623 | [2025-10-16 01:17:54,623] INFO Loaded member MemberMetadata(memberId=mesa-ya-service-client-9a0094a4-6972-4e79-a5d6-5ed4ed5cfa65, groupInstanceId=None, clientId=mesa-ya-service-client, clientHost=/172.18.0.4, sessionTimeoutMs=30000, rebalanceTimeoutMs=60000, supportedProtocols=List(NestReplyPartitionAssigner)) in group nestjs-group-client with generation 1. (kafka.coordinator.group.GroupMetadata$)
2025-10-15 20:17:54.628 | [2025-10-16 01:17:54,627] INFO [GroupCoordinator 1]: Loading group metadata for nestjs-group-client with generation 2 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:17:54.628 | [2025-10-16 01:17:54,628] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 62 milliseconds for epoch 0, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.628 | [2025-10-16 01:17:54,628] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 62 milliseconds for epoch 0, of which 62 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.629 | [2025-10-16 01:17:54,628] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 61 milliseconds for epoch 0, of which 61 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.629 | [2025-10-16 01:17:54,629] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 62 milliseconds for epoch 0, of which 62 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.629 | [2025-10-16 01:17:54,629] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 62 milliseconds for epoch 0, of which 62 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.629 | [2025-10-16 01:17:54,629] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 62 milliseconds for epoch 0, of which 62 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.629 | [2025-10-16 01:17:54,629] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 62 milliseconds for epoch 0, of which 62 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.630 | [2025-10-16 01:17:54,629] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 62 milliseconds for epoch 0, of which 62 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.630 | [2025-10-16 01:17:54,630] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 63 milliseconds for epoch 0, of which 63 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.630 | [2025-10-16 01:17:54,630] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 63 milliseconds for epoch 0, of which 63 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.630 | [2025-10-16 01:17:54,630] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 63 milliseconds for epoch 0, of which 63 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.630 | [2025-10-16 01:17:54,630] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 63 milliseconds for epoch 0, of which 63 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.631 | [2025-10-16 01:17:54,630] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 63 milliseconds for epoch 0, of which 63 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.631 | [2025-10-16 01:17:54,631] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 64 milliseconds for epoch 0, of which 64 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.631 | [2025-10-16 01:17:54,631] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 64 milliseconds for epoch 0, of which 64 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.631 | [2025-10-16 01:17:54,631] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 64 milliseconds for epoch 0, of which 64 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.631 | [2025-10-16 01:17:54,631] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 64 milliseconds for epoch 0, of which 64 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.631 | [2025-10-16 01:17:54,631] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 64 milliseconds for epoch 0, of which 64 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.632 | [2025-10-16 01:17:54,632] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 65 milliseconds for epoch 0, of which 64 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.632 | [2025-10-16 01:17:54,632] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 65 milliseconds for epoch 0, of which 65 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.632 | [2025-10-16 01:17:54,632] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 65 milliseconds for epoch 0, of which 65 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.634 | [2025-10-16 01:17:54,633] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 66 milliseconds for epoch 0, of which 65 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.634 | [2025-10-16 01:17:54,634] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 67 milliseconds for epoch 0, of which 67 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.635 | [2025-10-16 01:17:54,635] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 68 milliseconds for epoch 0, of which 67 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.635 | [2025-10-16 01:17:54,635] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 68 milliseconds for epoch 0, of which 68 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.635 | [2025-10-16 01:17:54,635] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 68 milliseconds for epoch 0, of which 68 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.635 | [2025-10-16 01:17:54,635] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 67 milliseconds for epoch 0, of which 67 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.636 | [2025-10-16 01:17:54,636] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 68 milliseconds for epoch 0, of which 67 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.636 | [2025-10-16 01:17:54,636] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 68 milliseconds for epoch 0, of which 68 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.636 | [2025-10-16 01:17:54,636] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 68 milliseconds for epoch 0, of which 68 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.637 | [2025-10-16 01:17:54,637] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 69 milliseconds for epoch 0, of which 68 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.637 | [2025-10-16 01:17:54,637] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 69 milliseconds for epoch 0, of which 69 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.638 | [2025-10-16 01:17:54,638] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 70 milliseconds for epoch 0, of which 69 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.639 | [2025-10-16 01:17:54,638] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 70 milliseconds for epoch 0, of which 70 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.639 | [2025-10-16 01:17:54,639] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 71 milliseconds for epoch 0, of which 71 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.639 | [2025-10-16 01:17:54,639] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 71 milliseconds for epoch 0, of which 71 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.640 | [2025-10-16 01:17:54,639] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 71 milliseconds for epoch 0, of which 71 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.640 | [2025-10-16 01:17:54,640] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 72 milliseconds for epoch 0, of which 72 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.641 | [2025-10-16 01:17:54,640] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 72 milliseconds for epoch 0, of which 72 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.641 | [2025-10-16 01:17:54,641] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 72 milliseconds for epoch 0, of which 72 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.641 | [2025-10-16 01:17:54,641] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 72 milliseconds for epoch 0, of which 72 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.641 | [2025-10-16 01:17:54,641] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 72 milliseconds for epoch 0, of which 72 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.641 | [2025-10-16 01:17:54,641] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 72 milliseconds for epoch 0, of which 72 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:54.642 | [2025-10-16 01:17:54,641] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 72 milliseconds for epoch 0, of which 72 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:17:58.791 | [2025-10-16 01:17:58,790] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-15 20:17:58.791 | [2025-10-16 01:17:58,791] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-15 20:17:58.803 | [2025-10-16 01:17:58,803] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-15 20:17:58.808 | [2025-10-16 01:17:58,807] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-15 20:18:09.292 | [2025-10-16 01:18:09,291] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group nestjs-group-client in Empty state. Created a new member id mesa-ya-service-client-72bf5d0c-5531-4f4b-bc39-f00715991c39 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:18:09.309 | [2025-10-16 01:18:09,309] INFO [GroupCoordinator 1]: Preparing to rebalance group nestjs-group-client in state PreparingRebalance with old generation 2 (__consumer_offsets-19) (reason: Adding new member mesa-ya-service-client-72bf5d0c-5531-4f4b-bc39-f00715991c39 with group instance id None; client reason: not provided) (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:18:12.319 | [2025-10-16 01:18:12,319] INFO [GroupCoordinator 1]: Stabilized group nestjs-group-client generation 3 (__consumer_offsets-19) with 1 members (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:18:12.372 | [2025-10-16 01:18:12,372] INFO [GroupCoordinator 1]: Assignment received from leader mesa-ya-service-client-72bf5d0c-5531-4f4b-bc39-f00715991c39 for group nestjs-group-client for generation 3. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:19:48.200 | [2025-10-16 01:19:48,199] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
2025-10-15 20:19:48.205 | [2025-10-16 01:19:48,203] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
2025-10-15 20:19:48.208 | [2025-10-16 01:19:48,207] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
2025-10-15 20:19:48.222 | [2025-10-16 01:19:48,222] INFO [Controller id=1] Shutting down broker 1 (kafka.controller.KafkaController)
2025-10-15 20:19:48.223 | [2025-10-16 01:19:48,223] DEBUG [Controller id=1] All shutting down brokers: 1 (kafka.controller.KafkaController)
2025-10-15 20:19:48.223 | [2025-10-16 01:19:48,223] DEBUG [Controller id=1] Live brokers:  (kafka.controller.KafkaController)
2025-10-15 20:19:48.226 | [2025-10-16 01:19:48,226] INFO [Controller id=1 epoch=3] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-10-15 20:19:48.227 | [2025-10-16 01:19:48,227] TRACE [Controller id=1] All leaders = __consumer_offsets-13 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-46 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-9 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-42 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-21 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-17 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-30 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-26 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-5 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-38 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-1 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-34 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-16 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-45 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-12 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-41 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-24 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-20 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-49 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-0 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-29 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-25 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-8 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-37 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-4 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-33 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-15 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-48 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-11 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-44 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-23 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-19 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-32 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-28 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-7 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-40 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-3 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-36 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-47 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-14 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-43 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-10 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-22 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-18 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-31 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-27 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-39 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-6 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-35 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),mesa-ya.restaurants.created-0 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-2 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1) (kafka.controller.KafkaController)
2025-10-15 20:19:48.231 | [2025-10-16 01:19:48,231] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 12ms (kafka.server.KafkaServer)
2025-10-15 20:19:48.239 | [2025-10-16 01:19:48,238] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-10-15 20:19:48.239 | [2025-10-16 01:19:48,239] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-10-15 20:19:48.240 | [2025-10-16 01:19:48,239] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-10-15 20:19:48.242 | [2025-10-16 01:19:48,241] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
2025-10-15 20:19:48.267 | [2025-10-16 01:19:48,266] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
2025-10-15 20:19:48.268 | [2025-10-16 01:19:48,268] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
2025-10-15 20:19:48.273 | [2025-10-16 01:19:48,273] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
2025-10-15 20:19:48.280 | [2025-10-16 01:19:48,279] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:19:48.282 | [2025-10-16 01:19:48,282] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:19:48.282 | [2025-10-16 01:19:48,282] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:19:48.284 | [2025-10-16 01:19:48,283] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
2025-10-15 20:19:48.285 | [2025-10-16 01:19:48,285] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:19:48.287 | [2025-10-16 01:19:48,287] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:19:48.287 | [2025-10-16 01:19:48,287] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:19:48.291 | [2025-10-16 01:19:48,290] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
2025-10-15 20:19:48.292 | [2025-10-16 01:19:48,292] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
2025-10-15 20:19:48.293 | [2025-10-16 01:19:48,292] INFO [TxnMarkerSenderThread-1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-10-15 20:19:48.293 | [2025-10-16 01:19:48,293] INFO [TxnMarkerSenderThread-1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-10-15 20:19:48.293 | [2025-10-16 01:19:48,293] INFO [TxnMarkerSenderThread-1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-10-15 20:19:48.295 | [2025-10-16 01:19:48,294] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
2025-10-15 20:19:48.295 | [2025-10-16 01:19:48,295] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:19:48.296 | [2025-10-16 01:19:48,296] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:19:48.297 | [2025-10-16 01:19:48,297] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:19:48.297 | [2025-10-16 01:19:48,297] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:19:48.298 | [2025-10-16 01:19:48,298] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:19:48.300 | [2025-10-16 01:19:48,299] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:19:48.300 | [2025-10-16 01:19:48,299] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:19:48.301 | [2025-10-16 01:19:48,300] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:19:48.302 | [2025-10-16 01:19:48,302] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
2025-10-15 20:19:48.304 | [2025-10-16 01:19:48,303] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-10-15 20:19:48.304 | [2025-10-16 01:19:48,304] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-10-15 20:19:48.304 | [2025-10-16 01:19:48,304] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-10-15 20:19:48.305 | [2025-10-16 01:19:48,304] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
2025-10-15 20:19:48.306 | [2025-10-16 01:19:48,306] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
2025-10-15 20:19:48.307 | [2025-10-16 01:19:48,307] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
2025-10-15 20:19:48.307 | [2025-10-16 01:19:48,307] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
2025-10-15 20:19:48.308 | [2025-10-16 01:19:48,308] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:19:48.310 | [2025-10-16 01:19:48,310] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:19:48.310 | [2025-10-16 01:19:48,310] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:19:48.311 | [2025-10-16 01:19:48,311] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:19:48.314 | [2025-10-16 01:19:48,313] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:19:48.314 | [2025-10-16 01:19:48,313] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:19:48.314 | [2025-10-16 01:19:48,314] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:19:48.316 | [2025-10-16 01:19:48,316] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:19:48.316 | [2025-10-16 01:19:48,316] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:19:48.317 | [2025-10-16 01:19:48,317] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:19:48.320 | [2025-10-16 01:19:48,319] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:19:48.320 | [2025-10-16 01:19:48,319] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:19:48.336 | [2025-10-16 01:19:48,336] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
2025-10-15 20:19:48.336 | [2025-10-16 01:19:48,336] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:19:48.337 | [2025-10-16 01:19:48,337] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:19:48.337 | [2025-10-16 01:19:48,337] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:19:48.339 | [2025-10-16 01:19:48,339] INFO Broker to controller channel manager for alter-partition shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
2025-10-15 20:19:48.340 | [2025-10-16 01:19:48,339] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:19:48.340 | [2025-10-16 01:19:48,340] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Stopped (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:19:48.340 | [2025-10-16 01:19:48,340] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:19:48.341 | [2025-10-16 01:19:48,341] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
2025-10-15 20:19:48.342 | [2025-10-16 01:19:48,342] INFO Shutting down. (kafka.log.LogManager)
2025-10-15 20:19:48.343 | [2025-10-16 01:19:48,343] INFO Shutting down the log cleaner. (kafka.log.LogCleaner)
2025-10-15 20:19:48.344 | [2025-10-16 01:19:48,344] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
2025-10-15 20:19:48.345 | [2025-10-16 01:19:48,345] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
2025-10-15 20:19:48.345 | [2025-10-16 01:19:48,345] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
2025-10-15 20:19:48.490 | [2025-10-16 01:19:48,490] INFO [ProducerStateManager partition=__consumer_offsets-19]Wrote producer snapshot at offset 3 with 0 producer ids in 6 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
2025-10-15 20:19:48.762 | [2025-10-16 01:19:48,761] INFO [ProducerStateManager partition=mesa-ya.restaurants.created-0]Wrote producer snapshot at offset 2 with 0 producer ids in 6 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
2025-10-15 20:19:49.025 | [2025-10-16 01:19:49,024] INFO Shutdown complete. (kafka.log.LogManager)
2025-10-15 20:19:49.026 | [2025-10-16 01:19:49,026] INFO [ControllerEventThread controllerId=1] Shutting down (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-10-15 20:19:49.027 | [2025-10-16 01:19:49,027] INFO [ControllerEventThread controllerId=1] Shutdown completed (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-10-15 20:19:49.028 | [2025-10-16 01:19:49,027] INFO [ControllerEventThread controllerId=1] Stopped (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-10-15 20:19:49.028 | [2025-10-16 01:19:49,028] DEBUG [Controller id=1] Resigning (kafka.controller.KafkaController)
2025-10-15 20:19:49.029 | [2025-10-16 01:19:49,029] DEBUG [Controller id=1] Unregister BrokerModifications handler for Set(1) (kafka.controller.KafkaController)
2025-10-15 20:19:49.032 | [2025-10-16 01:19:49,031] INFO [PartitionStateMachine controllerId=1] Stopped partition state machine (kafka.controller.ZkPartitionStateMachine)
2025-10-15 20:19:49.033 | [2025-10-16 01:19:49,032] INFO [ReplicaStateMachine controllerId=1] Stopped replica state machine (kafka.controller.ZkReplicaStateMachine)
2025-10-15 20:19:49.033 | [2025-10-16 01:19:49,033] INFO [RequestSendThread controllerId=1] Shutting down (kafka.controller.RequestSendThread)
2025-10-15 20:19:49.033 | [2025-10-16 01:19:49,033] INFO [RequestSendThread controllerId=1] Shutdown completed (kafka.controller.RequestSendThread)
2025-10-15 20:19:49.034 | [2025-10-16 01:19:49,033] INFO [RequestSendThread controllerId=1] Stopped (kafka.controller.RequestSendThread)
2025-10-15 20:19:49.038 | [2025-10-16 01:19:49,037] INFO [Controller id=1] Resigned (kafka.controller.KafkaController)
2025-10-15 20:19:49.039 | [2025-10-16 01:19:49,039] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-10-15 20:19:49.040 | [2025-10-16 01:19:49,039] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-10-15 20:19:49.040 | [2025-10-16 01:19:49,039] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-10-15 20:19:49.042 | [2025-10-16 01:19:49,042] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
2025-10-15 20:19:49.154 | [2025-10-16 01:19:49,154] INFO Session: 0x10000328ad90003 closed (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:19:49.154 | [2025-10-16 01:19:49,154] INFO EventThread shut down for session: 0x10000328ad90003 (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:19:49.157 | [2025-10-16 01:19:49,156] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
2025-10-15 20:19:49.158 | [2025-10-16 01:19:49,157] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:19:49.162 | [2025-10-16 01:19:49,161] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:19:49.162 | [2025-10-16 01:19:49,161] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:19:49.163 | [2025-10-16 01:19:49,162] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:19:49.164 | [2025-10-16 01:19:49,163] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:19:49.164 | [2025-10-16 01:19:49,163] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:19:49.165 | [2025-10-16 01:19:49,164] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:19:49.165 | [2025-10-16 01:19:49,164] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:19:49.165 | [2025-10-16 01:19:49,164] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:19:49.166 | [2025-10-16 01:19:49,166] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:19:49.167 | [2025-10-16 01:19:49,166] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:19:49.167 | [2025-10-16 01:19:49,166] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:19:49.168 | [2025-10-16 01:19:49,167] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
2025-10-15 20:19:49.211 | [2025-10-16 01:19:49,210] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
2025-10-15 20:19:49.212 | [2025-10-16 01:19:49,211] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
2025-10-15 20:19:49.212 | [2025-10-16 01:19:49,212] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
2025-10-15 20:19:49.213 | [2025-10-16 01:19:49,212] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
2025-10-15 20:19:49.215 | [2025-10-16 01:19:49,214] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
2025-10-15 20:19:49.216 | [2025-10-16 01:19:49,215] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
2025-10-15 20:19:49.216 | [2025-10-16 01:19:49,215] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
2025-10-15 20:37:32.955 | ===> User
2025-10-15 20:37:32.965 | uid=1000(appuser) gid=1000(appuser) groups=1000(appuser)
2025-10-15 20:37:32.966 | ===> Configuring ...
2025-10-15 20:37:32.977 | Running in Zookeeper mode...
2025-10-15 20:37:35.532 | ===> Running preflight checks ... 
2025-10-15 20:37:35.540 | ===> Check if /var/lib/kafka/data is writable ...
2025-10-15 20:37:35.984 | ===> Check if Zookeeper is healthy ...
2025-10-15 20:37:36.752 | [2025-10-16 01:37:36,751] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:36.752 | [2025-10-16 01:37:36,751] INFO Client environment:host.name=2ae4b23f74a4 (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:36.752 | [2025-10-16 01:37:36,751] INFO Client environment:java.version=11.0.20 (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:36.752 | [2025-10-16 01:37:36,751] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:36.752 | [2025-10-16 01:37:36,751] INFO Client environment:java.home=/usr/lib/jvm/java-11-zulu-openjdk-ca (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:36.752 | [2025-10-16 01:37:36,751] INFO Client environment:java.class.path=/usr/share/java/cp-base-new/minimal-json-0.9.5.jar:/usr/share/java/cp-base-new/kafka-clients-7.5.0-ccs.jar:/usr/share/java/cp-base-new/slf4j-api-1.7.36.jar:/usr/share/java/cp-base-new/jmx_prometheus_javaagent-0.18.0.jar:/usr/share/java/cp-base-new/jackson-annotations-2.14.2.jar:/usr/share/java/cp-base-new/scala-collection-compat_2.13-2.10.0.jar:/usr/share/java/cp-base-new/gson-2.9.0.jar:/usr/share/java/cp-base-new/kafka-server-common-7.5.0-ccs.jar:/usr/share/java/cp-base-new/jose4j-0.9.3.jar:/usr/share/java/cp-base-new/scala-reflect-2.13.10.jar:/usr/share/java/cp-base-new/zstd-jni-1.5.5-1.jar:/usr/share/java/cp-base-new/jackson-datatype-jdk8-2.14.2.jar:/usr/share/java/cp-base-new/kafka-storage-7.5.0-ccs.jar:/usr/share/java/cp-base-new/reload4j-1.2.19.jar:/usr/share/java/cp-base-new/kafka-raft-7.5.0-ccs.jar:/usr/share/java/cp-base-new/logredactor-1.0.12.jar:/usr/share/java/cp-base-new/jackson-module-scala_2.13-2.14.2.jar:/usr/share/java/cp-base-new/paranamer-2.8.jar:/usr/share/java/cp-base-new/utility-belt-7.5.0.jar:/usr/share/java/cp-base-new/snakeyaml-2.0.jar:/usr/share/java/cp-base-new/metrics-core-2.2.0.jar:/usr/share/java/cp-base-new/metrics-core-4.1.12.1.jar:/usr/share/java/cp-base-new/kafka-tools-api-7.5.0-ccs.jar:/usr/share/java/cp-base-new/logredactor-metrics-1.0.12.jar:/usr/share/java/cp-base-new/scala-logging_2.13-3.9.4.jar:/usr/share/java/cp-base-new/jolokia-core-1.7.1.jar:/usr/share/java/cp-base-new/kafka-metadata-7.5.0-ccs.jar:/usr/share/java/cp-base-new/audience-annotations-0.5.0.jar:/usr/share/java/cp-base-new/argparse4j-0.7.0.jar:/usr/share/java/cp-base-new/kafka-storage-api-7.5.0-ccs.jar:/usr/share/java/cp-base-new/jopt-simple-5.0.4.jar:/usr/share/java/cp-base-new/jackson-dataformat-csv-2.14.2.jar:/usr/share/java/cp-base-new/jackson-core-2.14.2.jar:/usr/share/java/cp-base-new/snappy-java-1.1.10.1.jar:/usr/share/java/cp-base-new/scala-java8-compat_2.13-1.0.2.jar:/usr/share/java/cp-base-new/disk-usage-agent-7.5.0.jar:/usr/share/java/cp-base-new/commons-cli-1.4.jar:/usr/share/java/cp-base-new/common-utils-7.5.0.jar:/usr/share/java/cp-base-new/jolokia-jvm-1.7.1.jar:/usr/share/java/cp-base-new/lz4-java-1.8.0.jar:/usr/share/java/cp-base-new/json-simple-1.1.1.jar:/usr/share/java/cp-base-new/zookeeper-3.6.3.jar:/usr/share/java/cp-base-new/kafka_2.13-7.5.0-ccs.jar:/usr/share/java/cp-base-new/jackson-databind-2.14.2.jar:/usr/share/java/cp-base-new/kafka-group-coordinator-7.5.0-ccs.jar:/usr/share/java/cp-base-new/slf4j-reload4j-1.7.36.jar:/usr/share/java/cp-base-new/zookeeper-jute-3.6.3.jar:/usr/share/java/cp-base-new/scala-library-2.13.10.jar:/usr/share/java/cp-base-new/re2j-1.6.jar:/usr/share/java/cp-base-new/jackson-dataformat-yaml-2.14.2.jar (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:36.752 | [2025-10-16 01:37:36,751] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:36.752 | [2025-10-16 01:37:36,751] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:36.752 | [2025-10-16 01:37:36,752] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:36.752 | [2025-10-16 01:37:36,752] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:36.752 | [2025-10-16 01:37:36,752] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:36.752 | [2025-10-16 01:37:36,752] INFO Client environment:os.version=6.6.87.1-microsoft-standard-WSL2 (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:36.752 | [2025-10-16 01:37:36,752] INFO Client environment:user.name=appuser (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:36.752 | [2025-10-16 01:37:36,752] INFO Client environment:user.home=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:36.752 | [2025-10-16 01:37:36,752] INFO Client environment:user.dir=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:36.752 | [2025-10-16 01:37:36,752] INFO Client environment:os.memory.free=112MB (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:36.752 | [2025-10-16 01:37:36,752] INFO Client environment:os.memory.max=1948MB (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:36.752 | [2025-10-16 01:37:36,752] INFO Client environment:os.memory.total=122MB (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:36.761 | [2025-10-16 01:37:36,760] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=40000 watcher=io.confluent.admin.utils.ZookeeperConnectionWatcher@221af3c0 (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:36.771 | [2025-10-16 01:37:36,771] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
2025-10-15 20:37:36.780 | [2025-10-16 01:37:36,779] INFO jute.maxbuffer value is 1048575 Bytes (org.apache.zookeeper.ClientCnxnSocket)
2025-10-15 20:37:36.789 | [2025-10-16 01:37:36,789] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:37:36.816 | [2025-10-16 01:37:36,815] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:37:36.816 | [2025-10-16 01:37:36,816] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:37:36.832 | [2025-10-16 01:37:36,832] INFO Socket connection established, initiating session, client: /172.18.0.3:50550, server: zookeeper/172.18.0.2:2181 (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:37:36.874 | [2025-10-16 01:37:36,874] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, session id = 0x10000457b300000, negotiated timeout = 40000 (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:37:36.896 | [2025-10-16 01:37:36,894] WARN An exception was thrown while closing send thread for session 0x10000457b300000. (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:37:36.896 | EndOfStreamException: Unable to read additional data from server sessionid 0x10000457b300000, likely server has closed socket
2025-10-15 20:37:36.896 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
2025-10-15 20:37:36.896 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
2025-10-15 20:37:36.896 | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-10-15 20:37:37.006 | [2025-10-16 01:37:37,005] INFO Session: 0x10000457b300000 closed (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:37.006 | [2025-10-16 01:37:37,005] INFO EventThread shut down for session: 0x10000457b300000 (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:37:37.019 | Using log4j config /etc/kafka/log4j.properties
2025-10-15 20:37:37.095 | ===> Launching ... 
2025-10-15 20:37:37.103 | ===> Launching kafka ... 
2025-10-15 20:37:37.909 | [2025-10-16 01:37:37,908] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
2025-10-15 20:37:38.373 | [2025-10-16 01:37:38,373] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
2025-10-15 20:37:38.473 | [2025-10-16 01:37:38,472] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
2025-10-15 20:37:38.475 | [2025-10-16 01:37:38,474] INFO starting (kafka.server.KafkaServer)
2025-10-15 20:37:38.475 | [2025-10-16 01:37:38,475] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
2025-10-15 20:37:38.503 | [2025-10-16 01:37:38,503] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
2025-10-15 20:37:38.513 | [2025-10-16 01:37:38,513] INFO Client environment:zookeeper.version=3.6.4--d65253dcf68e9097c6e95a126463fd5fdeb4521c, built on 12/18/2022 18:10 GMT (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:38.513 | [2025-10-16 01:37:38,513] INFO Client environment:host.name=2ae4b23f74a4 (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:38.513 | [2025-10-16 01:37:38,513] INFO Client environment:java.version=11.0.20 (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:38.513 | [2025-10-16 01:37:38,513] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:38.513 | [2025-10-16 01:37:38,513] INFO Client environment:java.home=/usr/lib/jvm/java-11-zulu-openjdk-ca (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:38.513 | [2025-10-16 01:37:38,513] INFO Client environment:java.class.path=/usr/bin/../share/java/kafka/zookeeper-jute-3.6.4.jar:/usr/bin/../share/java/kafka/jackson-datatype-jdk8-2.13.5.jar:/usr/bin/../share/java/kafka/jakarta.inject-2.6.1.jar:/usr/bin/../share/java/kafka/netty-transport-native-epoll-4.1.96.Final.jar:/usr/bin/../share/java/kafka/kafka-clients-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jline-3.22.0.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.36.jar:/usr/bin/../share/java/kafka/reflections-0.9.12.jar:/usr/bin/../share/java/kafka/scala-collection-compat_2.13-2.10.0.jar:/usr/bin/../share/java/kafka/javassist-3.29.2-GA.jar:/usr/bin/../share/java/kafka/connect-runtime-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jakarta.annotation-api-1.3.5.jar:/usr/bin/../share/java/kafka/jackson-databind-2.13.5.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/kafka-streams-scala_2.13-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/javax.activation-api-1.2.0.jar:/usr/bin/../share/java/kafka/rocksdbjni-7.1.2.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/usr/bin/../share/java/kafka/kafka-server-common-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jose4j-0.9.3.jar:/usr/bin/../share/java/kafka/scala-reflect-2.13.10.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.13.5.jar:/usr/bin/../share/java/kafka/zstd-jni-1.5.5-1.jar:/usr/bin/../share/java/kafka/kafka-storage-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jetty-security-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.39.1.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/kafka-raft-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/netty-transport-native-unix-common-4.1.96.Final.jar:/usr/bin/../share/java/kafka/jersey-server-2.39.1.jar:/usr/bin/../share/java/kafka/paranamer-2.8.jar:/usr/bin/../share/java/kafka/jersey-common-2.39.1.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/netty-transport-4.1.96.Final.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/metrics-core-4.1.12.1.jar:/usr/bin/../share/java/kafka/netty-buffer-4.1.96.Final.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.13.5.jar:/usr/bin/../share/java/kafka/netty-resolver-4.1.96.Final.jar:/usr/bin/../share/java/kafka/kafka-tools-api-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jaxb-api-2.3.1.jar:/usr/bin/../share/java/kafka/jetty-util-ajax-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/scala-logging_2.13-3.9.4.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.6.1.jar:/usr/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/usr/bin/../share/java/kafka/jakarta.xml.bind-api-2.3.3.jar:/usr/bin/../share/java/kafka/kafka-metadata-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/plexus-utils-3.3.0.jar:/usr/bin/../share/java/kafka/jakarta.activation-api-1.2.2.jar:/usr/bin/../share/java/kafka/argparse4j-0.7.0.jar:/usr/bin/../share/java/kafka/hk2-utils-2.6.1.jar:/usr/bin/../share/java/kafka/connect-api-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/connect-mirror-client-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.3.jar:/usr/bin/../share/java/kafka/javax.annotation-api-1.3.2.jar:/usr/bin/../share/java/kafka/jersey-hk2-2.39.1.jar:/usr/bin/../share/java/kafka/kafka-storage-api-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jetty-http-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/trogdor-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/maven-artifact-3.8.4.jar:/usr/bin/../share/java/kafka/connect-json-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/scala-java8-compat_2.13-1.0.2.jar:/usr/bin/../share/java/kafka/jetty-server-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/swagger-annotations-2.2.8.jar:/usr/bin/../share/java/kafka/jetty-util-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/commons-cli-1.4.jar:/usr/bin/../share/java/kafka/jetty-io-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/activation-1.1.1.jar:/usr/bin/../share/java/kafka/lz4-java-1.8.0.jar:/usr/bin/../share/java/kafka/kafka-shell-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/netty-common-4.1.96.Final.jar:/usr/bin/../share/java/kafka/jetty-client-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/jackson-module-scala_2.13-2.13.5.jar:/usr/bin/../share/java/kafka/connect-transforms-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jackson-core-2.13.5.jar:/usr/bin/../share/java/kafka/kafka_2.13-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/netty-codec-4.1.96.Final.jar:/usr/bin/../share/java/kafka/zookeeper-3.6.4.jar:/usr/bin/../share/java/kafka/kafka-streams-test-utils-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/hk2-api-2.6.1.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.39.1.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/reload4j-1.2.25.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.10.0.jar:/usr/bin/../share/java/kafka/netty-transport-classes-epoll-4.1.96.Final.jar:/usr/bin/../share/java/kafka/connect-mirror-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/kafka-streams-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/kafka-group-coordinator-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/connect-basic-auth-extension-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jersey-client-2.39.1.jar:/usr/bin/../share/java/kafka/kafka-tools-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/slf4j-reload4j-1.7.36.jar:/usr/bin/../share/java/kafka/jackson-dataformat-csv-2.13.5.jar:/usr/bin/../share/java/kafka/scala-library-2.13.10.jar:/usr/bin/../share/java/kafka/netty-handler-4.1.96.Final.jar:/usr/bin/../share/java/kafka/jakarta.validation-api-2.0.2.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.13.5.jar:/usr/bin/../share/java/kafka/audience-annotations-0.13.0.jar:/usr/bin/../share/java/kafka/hk2-locator-2.6.1.jar:/usr/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.6.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.13.5.jar:/usr/bin/../share/java/confluent-telemetry/* (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:38.513 | [2025-10-16 01:37:38,513] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:38.513 | [2025-10-16 01:37:38,513] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:38.513 | [2025-10-16 01:37:38,513] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:38.513 | [2025-10-16 01:37:38,513] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:38.513 | [2025-10-16 01:37:38,513] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:38.513 | [2025-10-16 01:37:38,513] INFO Client environment:os.version=6.6.87.1-microsoft-standard-WSL2 (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:38.513 | [2025-10-16 01:37:38,513] INFO Client environment:user.name=appuser (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:38.513 | [2025-10-16 01:37:38,513] INFO Client environment:user.home=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:38.513 | [2025-10-16 01:37:38,513] INFO Client environment:user.dir=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:38.513 | [2025-10-16 01:37:38,513] INFO Client environment:os.memory.free=1009MB (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:38.513 | [2025-10-16 01:37:38,513] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:38.513 | [2025-10-16 01:37:38,513] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:38.517 | [2025-10-16 01:37:38,516] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@13d73fa (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:37:38.523 | [2025-10-16 01:37:38,523] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
2025-10-15 20:37:38.532 | [2025-10-16 01:37:38,531] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:37:38.534 | [2025-10-16 01:37:38,534] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
2025-10-15 20:37:38.539 | [2025-10-16 01:37:38,537] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:37:38.543 | [2025-10-16 01:37:38,542] INFO Socket connection established, initiating session, client: /172.18.0.3:50566, server: zookeeper/172.18.0.2:2181 (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:37:38.562 | [2025-10-16 01:37:38,562] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, session id = 0x10000457b300001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:37:38.567 | [2025-10-16 01:37:38,567] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
2025-10-15 20:37:38.910 | [2025-10-16 01:37:38,910] INFO Cluster ID = DgiegCMhTNSyWQSymt96xQ (kafka.server.KafkaServer)
2025-10-15 20:37:38.966 | [2025-10-16 01:37:38,966] INFO KafkaConfig values: 
2025-10-15 20:37:38.966 | 	advertised.listeners = PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
2025-10-15 20:37:38.967 | 	alter.config.policy.class.name = null
2025-10-15 20:37:38.967 | 	alter.log.dirs.replication.quota.window.num = 11
2025-10-15 20:37:38.967 | 	alter.log.dirs.replication.quota.window.size.seconds = 1
2025-10-15 20:37:38.967 | 	authorizer.class.name = 
2025-10-15 20:37:38.967 | 	auto.create.topics.enable = true
2025-10-15 20:37:38.967 | 	auto.include.jmx.reporter = true
2025-10-15 20:37:38.967 | 	auto.leader.rebalance.enable = true
2025-10-15 20:37:38.967 | 	background.threads = 10
2025-10-15 20:37:38.967 | 	broker.heartbeat.interval.ms = 2000
2025-10-15 20:37:38.967 | 	broker.id = 1
2025-10-15 20:37:38.967 | 	broker.id.generation.enable = true
2025-10-15 20:37:38.967 | 	broker.rack = null
2025-10-15 20:37:38.967 | 	broker.session.timeout.ms = 9000
2025-10-15 20:37:38.967 | 	client.quota.callback.class = null
2025-10-15 20:37:38.967 | 	compression.type = producer
2025-10-15 20:37:38.967 | 	connection.failed.authentication.delay.ms = 100
2025-10-15 20:37:38.967 | 	connections.max.idle.ms = 600000
2025-10-15 20:37:38.967 | 	connections.max.reauth.ms = 0
2025-10-15 20:37:38.967 | 	control.plane.listener.name = null
2025-10-15 20:37:38.967 | 	controlled.shutdown.enable = true
2025-10-15 20:37:38.967 | 	controlled.shutdown.max.retries = 3
2025-10-15 20:37:38.967 | 	controlled.shutdown.retry.backoff.ms = 5000
2025-10-15 20:37:38.967 | 	controller.listener.names = null
2025-10-15 20:37:38.967 | 	controller.quorum.append.linger.ms = 25
2025-10-15 20:37:38.967 | 	controller.quorum.election.backoff.max.ms = 1000
2025-10-15 20:37:38.967 | 	controller.quorum.election.timeout.ms = 1000
2025-10-15 20:37:38.967 | 	controller.quorum.fetch.timeout.ms = 2000
2025-10-15 20:37:38.967 | 	controller.quorum.request.timeout.ms = 2000
2025-10-15 20:37:38.967 | 	controller.quorum.retry.backoff.ms = 20
2025-10-15 20:37:38.967 | 	controller.quorum.voters = []
2025-10-15 20:37:38.967 | 	controller.quota.window.num = 11
2025-10-15 20:37:38.967 | 	controller.quota.window.size.seconds = 1
2025-10-15 20:37:38.967 | 	controller.socket.timeout.ms = 30000
2025-10-15 20:37:38.967 | 	create.topic.policy.class.name = null
2025-10-15 20:37:38.967 | 	default.replication.factor = 1
2025-10-15 20:37:38.967 | 	delegation.token.expiry.check.interval.ms = 3600000
2025-10-15 20:37:38.967 | 	delegation.token.expiry.time.ms = 86400000
2025-10-15 20:37:38.967 | 	delegation.token.master.key = null
2025-10-15 20:37:38.967 | 	delegation.token.max.lifetime.ms = 604800000
2025-10-15 20:37:38.967 | 	delegation.token.secret.key = null
2025-10-15 20:37:38.967 | 	delete.records.purgatory.purge.interval.requests = 1
2025-10-15 20:37:38.967 | 	delete.topic.enable = true
2025-10-15 20:37:38.967 | 	early.start.listeners = null
2025-10-15 20:37:38.967 | 	fetch.max.bytes = 57671680
2025-10-15 20:37:38.967 | 	fetch.purgatory.purge.interval.requests = 1000
2025-10-15 20:37:38.967 | 	group.consumer.assignors = []
2025-10-15 20:37:38.967 | 	group.consumer.heartbeat.interval.ms = 5000
2025-10-15 20:37:38.967 | 	group.consumer.max.heartbeat.interval.ms = 15000
2025-10-15 20:37:38.967 | 	group.consumer.max.session.timeout.ms = 60000
2025-10-15 20:37:38.967 | 	group.consumer.max.size = 2147483647
2025-10-15 20:37:38.967 | 	group.consumer.min.heartbeat.interval.ms = 5000
2025-10-15 20:37:38.967 | 	group.consumer.min.session.timeout.ms = 45000
2025-10-15 20:37:38.967 | 	group.consumer.session.timeout.ms = 45000
2025-10-15 20:37:38.967 | 	group.coordinator.new.enable = false
2025-10-15 20:37:38.967 | 	group.coordinator.threads = 1
2025-10-15 20:37:38.967 | 	group.initial.rebalance.delay.ms = 3000
2025-10-15 20:37:38.967 | 	group.max.session.timeout.ms = 1800000
2025-10-15 20:37:38.967 | 	group.max.size = 2147483647
2025-10-15 20:37:38.967 | 	group.min.session.timeout.ms = 6000
2025-10-15 20:37:38.967 | 	initial.broker.registration.timeout.ms = 60000
2025-10-15 20:37:38.967 | 	inter.broker.listener.name = PLAINTEXT_INTERNAL
2025-10-15 20:37:38.967 | 	inter.broker.protocol.version = 3.5-IV2
2025-10-15 20:37:38.967 | 	kafka.metrics.polling.interval.secs = 10
2025-10-15 20:37:38.967 | 	kafka.metrics.reporters = []
2025-10-15 20:37:38.967 | 	leader.imbalance.check.interval.seconds = 300
2025-10-15 20:37:38.967 | 	leader.imbalance.per.broker.percentage = 10
2025-10-15 20:37:38.967 | 	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
2025-10-15 20:37:38.967 | 	listeners = PLAINTEXT://0.0.0.0:9092,PLAINTEXT_INTERNAL://0.0.0.0:29092
2025-10-15 20:37:38.967 | 	log.cleaner.backoff.ms = 15000
2025-10-15 20:37:38.967 | 	log.cleaner.dedupe.buffer.size = 134217728
2025-10-15 20:37:38.967 | 	log.cleaner.delete.retention.ms = 86400000
2025-10-15 20:37:38.967 | 	log.cleaner.enable = true
2025-10-15 20:37:38.967 | 	log.cleaner.io.buffer.load.factor = 0.9
2025-10-15 20:37:38.967 | 	log.cleaner.io.buffer.size = 524288
2025-10-15 20:37:38.967 | 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
2025-10-15 20:37:38.967 | 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
2025-10-15 20:37:38.967 | 	log.cleaner.min.cleanable.ratio = 0.5
2025-10-15 20:37:38.967 | 	log.cleaner.min.compaction.lag.ms = 0
2025-10-15 20:37:38.967 | 	log.cleaner.threads = 1
2025-10-15 20:37:38.967 | 	log.cleanup.policy = [delete]
2025-10-15 20:37:38.967 | 	log.dir = /tmp/kafka-logs
2025-10-15 20:37:38.967 | 	log.dirs = /var/lib/kafka/data
2025-10-15 20:37:38.967 | 	log.flush.interval.messages = 9223372036854775807
2025-10-15 20:37:38.967 | 	log.flush.interval.ms = null
2025-10-15 20:37:38.967 | 	log.flush.offset.checkpoint.interval.ms = 60000
2025-10-15 20:37:38.967 | 	log.flush.scheduler.interval.ms = 9223372036854775807
2025-10-15 20:37:38.967 | 	log.flush.start.offset.checkpoint.interval.ms = 60000
2025-10-15 20:37:38.967 | 	log.index.interval.bytes = 4096
2025-10-15 20:37:38.967 | 	log.index.size.max.bytes = 10485760
2025-10-15 20:37:38.967 | 	log.message.downconversion.enable = true
2025-10-15 20:37:38.967 | 	log.message.format.version = 3.0-IV1
2025-10-15 20:37:38.967 | 	log.message.timestamp.difference.max.ms = 9223372036854775807
2025-10-15 20:37:38.967 | 	log.message.timestamp.type = CreateTime
2025-10-15 20:37:38.967 | 	log.preallocate = false
2025-10-15 20:37:38.967 | 	log.retention.bytes = -1
2025-10-15 20:37:38.967 | 	log.retention.check.interval.ms = 300000
2025-10-15 20:37:38.967 | 	log.retention.hours = 168
2025-10-15 20:37:38.967 | 	log.retention.minutes = null
2025-10-15 20:37:38.967 | 	log.retention.ms = null
2025-10-15 20:37:38.967 | 	log.roll.hours = 168
2025-10-15 20:37:38.967 | 	log.roll.jitter.hours = 0
2025-10-15 20:37:38.967 | 	log.roll.jitter.ms = null
2025-10-15 20:37:38.967 | 	log.roll.ms = null
2025-10-15 20:37:38.967 | 	log.segment.bytes = 1073741824
2025-10-15 20:37:38.967 | 	log.segment.delete.delay.ms = 60000
2025-10-15 20:37:38.967 | 	max.connection.creation.rate = 2147483647
2025-10-15 20:37:38.967 | 	max.connections = 2147483647
2025-10-15 20:37:38.967 | 	max.connections.per.ip = 2147483647
2025-10-15 20:37:38.967 | 	max.connections.per.ip.overrides = 
2025-10-15 20:37:38.967 | 	max.incremental.fetch.session.cache.slots = 1000
2025-10-15 20:37:38.967 | 	message.max.bytes = 1048588
2025-10-15 20:37:38.967 | 	metadata.log.dir = null
2025-10-15 20:37:38.967 | 	metadata.log.max.record.bytes.between.snapshots = 20971520
2025-10-15 20:37:38.967 | 	metadata.log.max.snapshot.interval.ms = 3600000
2025-10-15 20:37:38.967 | 	metadata.log.segment.bytes = 1073741824
2025-10-15 20:37:38.967 | 	metadata.log.segment.min.bytes = 8388608
2025-10-15 20:37:38.967 | 	metadata.log.segment.ms = 604800000
2025-10-15 20:37:38.967 | 	metadata.max.idle.interval.ms = 500
2025-10-15 20:37:38.967 | 	metadata.max.retention.bytes = 104857600
2025-10-15 20:37:38.967 | 	metadata.max.retention.ms = 604800000
2025-10-15 20:37:38.967 | 	metric.reporters = []
2025-10-15 20:37:38.967 | 	metrics.num.samples = 2
2025-10-15 20:37:38.967 | 	metrics.recording.level = INFO
2025-10-15 20:37:38.967 | 	metrics.sample.window.ms = 30000
2025-10-15 20:37:38.967 | 	min.insync.replicas = 1
2025-10-15 20:37:38.967 | 	node.id = 1
2025-10-15 20:37:38.967 | 	num.io.threads = 8
2025-10-15 20:37:38.967 | 	num.network.threads = 3
2025-10-15 20:37:38.967 | 	num.partitions = 1
2025-10-15 20:37:38.967 | 	num.recovery.threads.per.data.dir = 1
2025-10-15 20:37:38.967 | 	num.replica.alter.log.dirs.threads = null
2025-10-15 20:37:38.967 | 	num.replica.fetchers = 1
2025-10-15 20:37:38.967 | 	offset.metadata.max.bytes = 4096
2025-10-15 20:37:38.967 | 	offsets.commit.required.acks = -1
2025-10-15 20:37:38.967 | 	offsets.commit.timeout.ms = 5000
2025-10-15 20:37:38.967 | 	offsets.load.buffer.size = 5242880
2025-10-15 20:37:38.967 | 	offsets.retention.check.interval.ms = 600000
2025-10-15 20:37:38.967 | 	offsets.retention.minutes = 10080
2025-10-15 20:37:38.967 | 	offsets.topic.compression.codec = 0
2025-10-15 20:37:38.967 | 	offsets.topic.num.partitions = 50
2025-10-15 20:37:38.967 | 	offsets.topic.replication.factor = 1
2025-10-15 20:37:38.967 | 	offsets.topic.segment.bytes = 104857600
2025-10-15 20:37:38.967 | 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
2025-10-15 20:37:38.967 | 	password.encoder.iterations = 4096
2025-10-15 20:37:38.967 | 	password.encoder.key.length = 128
2025-10-15 20:37:38.967 | 	password.encoder.keyfactory.algorithm = null
2025-10-15 20:37:38.967 | 	password.encoder.old.secret = null
2025-10-15 20:37:38.967 | 	password.encoder.secret = null
2025-10-15 20:37:38.967 | 	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
2025-10-15 20:37:38.967 | 	process.roles = []
2025-10-15 20:37:38.967 | 	producer.id.expiration.check.interval.ms = 600000
2025-10-15 20:37:38.967 | 	producer.id.expiration.ms = 86400000
2025-10-15 20:37:38.967 | 	producer.purgatory.purge.interval.requests = 1000
2025-10-15 20:37:38.967 | 	queued.max.request.bytes = -1
2025-10-15 20:37:38.967 | 	queued.max.requests = 500
2025-10-15 20:37:38.967 | 	quota.window.num = 11
2025-10-15 20:37:38.967 | 	quota.window.size.seconds = 1
2025-10-15 20:37:38.967 | 	remote.log.index.file.cache.total.size.bytes = 1073741824
2025-10-15 20:37:38.967 | 	remote.log.manager.task.interval.ms = 30000
2025-10-15 20:37:38.967 | 	remote.log.manager.task.retry.backoff.max.ms = 30000
2025-10-15 20:37:38.967 | 	remote.log.manager.task.retry.backoff.ms = 500
2025-10-15 20:37:38.967 | 	remote.log.manager.task.retry.jitter = 0.2
2025-10-15 20:37:38.967 | 	remote.log.manager.thread.pool.size = 10
2025-10-15 20:37:38.967 | 	remote.log.metadata.manager.class.name = null
2025-10-15 20:37:38.967 | 	remote.log.metadata.manager.class.path = null
2025-10-15 20:37:38.967 | 	remote.log.metadata.manager.impl.prefix = null
2025-10-15 20:37:38.967 | 	remote.log.metadata.manager.listener.name = null
2025-10-15 20:37:38.967 | 	remote.log.reader.max.pending.tasks = 100
2025-10-15 20:37:38.967 | 	remote.log.reader.threads = 10
2025-10-15 20:37:38.967 | 	remote.log.storage.manager.class.name = null
2025-10-15 20:37:38.967 | 	remote.log.storage.manager.class.path = null
2025-10-15 20:37:38.967 | 	remote.log.storage.manager.impl.prefix = null
2025-10-15 20:37:38.967 | 	remote.log.storage.system.enable = false
2025-10-15 20:37:38.967 | 	replica.fetch.backoff.ms = 1000
2025-10-15 20:37:38.967 | 	replica.fetch.max.bytes = 1048576
2025-10-15 20:37:38.967 | 	replica.fetch.min.bytes = 1
2025-10-15 20:37:38.967 | 	replica.fetch.response.max.bytes = 10485760
2025-10-15 20:37:38.967 | 	replica.fetch.wait.max.ms = 500
2025-10-15 20:37:38.967 | 	replica.high.watermark.checkpoint.interval.ms = 5000
2025-10-15 20:37:38.967 | 	replica.lag.time.max.ms = 30000
2025-10-15 20:37:38.967 | 	replica.selector.class = null
2025-10-15 20:37:38.967 | 	replica.socket.receive.buffer.bytes = 65536
2025-10-15 20:37:38.967 | 	replica.socket.timeout.ms = 30000
2025-10-15 20:37:38.967 | 	replication.quota.window.num = 11
2025-10-15 20:37:38.967 | 	replication.quota.window.size.seconds = 1
2025-10-15 20:37:38.967 | 	request.timeout.ms = 30000
2025-10-15 20:37:38.967 | 	reserved.broker.max.id = 1000
2025-10-15 20:37:38.967 | 	sasl.client.callback.handler.class = null
2025-10-15 20:37:38.967 | 	sasl.enabled.mechanisms = [GSSAPI]
2025-10-15 20:37:38.967 | 	sasl.jaas.config = null
2025-10-15 20:37:38.967 | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
2025-10-15 20:37:38.967 | 	sasl.kerberos.min.time.before.relogin = 60000
2025-10-15 20:37:38.967 | 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
2025-10-15 20:37:38.967 | 	sasl.kerberos.service.name = null
2025-10-15 20:37:38.967 | 	sasl.kerberos.ticket.renew.jitter = 0.05
2025-10-15 20:37:38.967 | 	sasl.kerberos.ticket.renew.window.factor = 0.8
2025-10-15 20:37:38.967 | 	sasl.login.callback.handler.class = null
2025-10-15 20:37:38.967 | 	sasl.login.class = null
2025-10-15 20:37:38.967 | 	sasl.login.connect.timeout.ms = null
2025-10-15 20:37:38.967 | 	sasl.login.read.timeout.ms = null
2025-10-15 20:37:38.967 | 	sasl.login.refresh.buffer.seconds = 300
2025-10-15 20:37:38.967 | 	sasl.login.refresh.min.period.seconds = 60
2025-10-15 20:37:38.967 | 	sasl.login.refresh.window.factor = 0.8
2025-10-15 20:37:38.967 | 	sasl.login.refresh.window.jitter = 0.05
2025-10-15 20:37:38.967 | 	sasl.login.retry.backoff.max.ms = 10000
2025-10-15 20:37:38.967 | 	sasl.login.retry.backoff.ms = 100
2025-10-15 20:37:38.967 | 	sasl.mechanism.controller.protocol = GSSAPI
2025-10-15 20:37:38.967 | 	sasl.mechanism.inter.broker.protocol = GSSAPI
2025-10-15 20:37:38.967 | 	sasl.oauthbearer.clock.skew.seconds = 30
2025-10-15 20:37:38.967 | 	sasl.oauthbearer.expected.audience = null
2025-10-15 20:37:38.967 | 	sasl.oauthbearer.expected.issuer = null
2025-10-15 20:37:38.967 | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
2025-10-15 20:37:38.967 | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
2025-10-15 20:37:38.967 | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
2025-10-15 20:37:38.967 | 	sasl.oauthbearer.jwks.endpoint.url = null
2025-10-15 20:37:38.967 | 	sasl.oauthbearer.scope.claim.name = scope
2025-10-15 20:37:38.967 | 	sasl.oauthbearer.sub.claim.name = sub
2025-10-15 20:37:38.967 | 	sasl.oauthbearer.token.endpoint.url = null
2025-10-15 20:37:38.967 | 	sasl.server.callback.handler.class = null
2025-10-15 20:37:38.967 | 	sasl.server.max.receive.size = 524288
2025-10-15 20:37:38.967 | 	security.inter.broker.protocol = PLAINTEXT
2025-10-15 20:37:38.967 | 	security.providers = null
2025-10-15 20:37:38.967 | 	server.max.startup.time.ms = 9223372036854775807
2025-10-15 20:37:38.967 | 	socket.connection.setup.timeout.max.ms = 30000
2025-10-15 20:37:38.967 | 	socket.connection.setup.timeout.ms = 10000
2025-10-15 20:37:38.967 | 	socket.listen.backlog.size = 50
2025-10-15 20:37:38.967 | 	socket.receive.buffer.bytes = 102400
2025-10-15 20:37:38.967 | 	socket.request.max.bytes = 104857600
2025-10-15 20:37:38.967 | 	socket.send.buffer.bytes = 102400
2025-10-15 20:37:38.967 | 	ssl.cipher.suites = []
2025-10-15 20:37:38.967 | 	ssl.client.auth = none
2025-10-15 20:37:38.967 | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
2025-10-15 20:37:38.967 | 	ssl.endpoint.identification.algorithm = https
2025-10-15 20:37:38.967 | 	ssl.engine.factory.class = null
2025-10-15 20:37:38.967 | 	ssl.key.password = null
2025-10-15 20:37:38.967 | 	ssl.keymanager.algorithm = SunX509
2025-10-15 20:37:38.967 | 	ssl.keystore.certificate.chain = null
2025-10-15 20:37:38.967 | 	ssl.keystore.key = null
2025-10-15 20:37:38.967 | 	ssl.keystore.location = null
2025-10-15 20:37:38.967 | 	ssl.keystore.password = null
2025-10-15 20:37:38.967 | 	ssl.keystore.type = JKS
2025-10-15 20:37:38.967 | 	ssl.principal.mapping.rules = DEFAULT
2025-10-15 20:37:38.967 | 	ssl.protocol = TLSv1.3
2025-10-15 20:37:38.967 | 	ssl.provider = null
2025-10-15 20:37:38.967 | 	ssl.secure.random.implementation = null
2025-10-15 20:37:38.967 | 	ssl.trustmanager.algorithm = PKIX
2025-10-15 20:37:38.967 | 	ssl.truststore.certificates = null
2025-10-15 20:37:38.967 | 	ssl.truststore.location = null
2025-10-15 20:37:38.967 | 	ssl.truststore.password = null
2025-10-15 20:37:38.967 | 	ssl.truststore.type = JKS
2025-10-15 20:37:38.967 | 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
2025-10-15 20:37:38.967 | 	transaction.max.timeout.ms = 900000
2025-10-15 20:37:38.967 | 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
2025-10-15 20:37:38.967 | 	transaction.state.log.load.buffer.size = 5242880
2025-10-15 20:37:38.967 | 	transaction.state.log.min.isr = 1
2025-10-15 20:37:38.967 | 	transaction.state.log.num.partitions = 50
2025-10-15 20:37:38.967 | 	transaction.state.log.replication.factor = 1
2025-10-15 20:37:38.967 | 	transaction.state.log.segment.bytes = 104857600
2025-10-15 20:37:38.967 | 	transactional.id.expiration.ms = 604800000
2025-10-15 20:37:38.967 | 	unclean.leader.election.enable = false
2025-10-15 20:37:38.967 | 	unstable.api.versions.enable = false
2025-10-15 20:37:38.967 | 	zookeeper.clientCnxnSocket = null
2025-10-15 20:37:38.967 | 	zookeeper.connect = zookeeper:2181
2025-10-15 20:37:38.967 | 	zookeeper.connection.timeout.ms = null
2025-10-15 20:37:38.967 | 	zookeeper.max.in.flight.requests = 10
2025-10-15 20:37:38.967 | 	zookeeper.metadata.migration.enable = false
2025-10-15 20:37:38.967 | 	zookeeper.session.timeout.ms = 18000
2025-10-15 20:37:38.967 | 	zookeeper.set.acl = false
2025-10-15 20:37:38.967 | 	zookeeper.ssl.cipher.suites = null
2025-10-15 20:37:38.967 | 	zookeeper.ssl.client.enable = false
2025-10-15 20:37:38.967 | 	zookeeper.ssl.crl.enable = false
2025-10-15 20:37:38.967 | 	zookeeper.ssl.enabled.protocols = null
2025-10-15 20:37:38.967 | 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
2025-10-15 20:37:38.967 | 	zookeeper.ssl.keystore.location = null
2025-10-15 20:37:38.967 | 	zookeeper.ssl.keystore.password = null
2025-10-15 20:37:38.967 | 	zookeeper.ssl.keystore.type = null
2025-10-15 20:37:38.967 | 	zookeeper.ssl.ocsp.enable = false
2025-10-15 20:37:38.967 | 	zookeeper.ssl.protocol = TLSv1.2
2025-10-15 20:37:38.967 | 	zookeeper.ssl.truststore.location = null
2025-10-15 20:37:38.967 | 	zookeeper.ssl.truststore.password = null
2025-10-15 20:37:38.967 | 	zookeeper.ssl.truststore.type = null
2025-10-15 20:37:38.967 |  (kafka.server.KafkaConfig)
2025-10-15 20:37:39.009 | [2025-10-16 01:37:39,008] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:37:39.010 | [2025-10-16 01:37:39,009] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:37:39.012 | [2025-10-16 01:37:39,011] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:37:39.015 | [2025-10-16 01:37:39,015] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:37:39.066 | [2025-10-16 01:37:39,065] INFO Loading logs from log dirs ArraySeq(/var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.084 | [2025-10-16 01:37:39,084] INFO Skipping recovery of 51 logs from /var/lib/kafka/data since clean shutdown file was found (kafka.log.LogManager)
2025-10-15 20:37:39.165 | [2025-10-16 01:37:39,164] INFO [LogLoader partition=__consumer_offsets-29, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.197 | [2025-10-16 01:37:39,196] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-29, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 102ms (1/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.211 | [2025-10-16 01:37:39,211] INFO [LogLoader partition=__consumer_offsets-49, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.214 | [2025-10-16 01:37:39,213] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-49, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (2/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.226 | [2025-10-16 01:37:39,225] INFO [LogLoader partition=__consumer_offsets-28, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.228 | [2025-10-16 01:37:39,228] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-28, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (3/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.241 | [2025-10-16 01:37:39,240] INFO [LogLoader partition=__consumer_offsets-5, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.245 | [2025-10-16 01:37:39,244] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-5, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (4/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.256 | [2025-10-16 01:37:39,256] INFO [LogLoader partition=__consumer_offsets-10, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.260 | [2025-10-16 01:37:39,259] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-10, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (5/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.278 | [2025-10-16 01:37:39,277] INFO [LogLoader partition=__consumer_offsets-14, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.280 | [2025-10-16 01:37:39,280] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-14, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (6/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.299 | [2025-10-16 01:37:39,298] INFO Deleted producer state snapshot /var/lib/kafka/data/__consumer_offsets-19/00000000000000000002.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
2025-10-15 20:37:39.299 | [2025-10-16 01:37:39,299] INFO [LogLoader partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.299 | [2025-10-16 01:37:39,299] INFO [LogLoader partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.299 | [2025-10-16 01:37:39,299] INFO [ProducerStateManager partition=__consumer_offsets-19]Loading producer state from snapshot file 'SnapshotFile(offset=3, file=/var/lib/kafka/data/__consumer_offsets-19/00000000000000000003.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
2025-10-15 20:37:39.305 | [2025-10-16 01:37:39,304] INFO [LogLoader partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Producer state recovery took 5ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.309 | [2025-10-16 01:37:39,308] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-19, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments in 28ms (7/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.322 | [2025-10-16 01:37:39,322] INFO [LogLoader partition=__consumer_offsets-8, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.325 | [2025-10-16 01:37:39,325] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-8, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (8/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.337 | [2025-10-16 01:37:39,337] INFO [LogLoader partition=__consumer_offsets-17, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.341 | [2025-10-16 01:37:39,340] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-17, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (9/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.355 | [2025-10-16 01:37:39,354] INFO [LogLoader partition=__consumer_offsets-35, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.359 | [2025-10-16 01:37:39,358] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-35, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (10/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.374 | [2025-10-16 01:37:39,373] INFO [LogLoader partition=__consumer_offsets-31, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.378 | [2025-10-16 01:37:39,377] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-31, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (11/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.389 | [2025-10-16 01:37:39,389] INFO [LogLoader partition=__consumer_offsets-6, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.394 | [2025-10-16 01:37:39,394] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-6, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (12/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.410 | [2025-10-16 01:37:39,410] INFO [LogLoader partition=__consumer_offsets-32, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.412 | [2025-10-16 01:37:39,412] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-32, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (13/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.424 | [2025-10-16 01:37:39,424] INFO [LogLoader partition=__consumer_offsets-3, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.427 | [2025-10-16 01:37:39,426] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-3, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (14/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.440 | [2025-10-16 01:37:39,440] INFO [LogLoader partition=__consumer_offsets-30, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.444 | [2025-10-16 01:37:39,443] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-30, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (15/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.456 | [2025-10-16 01:37:39,456] INFO [LogLoader partition=__consumer_offsets-37, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.459 | [2025-10-16 01:37:39,458] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-37, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (16/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.474 | [2025-10-16 01:37:39,474] INFO [LogLoader partition=__consumer_offsets-41, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.478 | [2025-10-16 01:37:39,478] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-41, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (17/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.493 | [2025-10-16 01:37:39,492] INFO [LogLoader partition=__consumer_offsets-26, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.506 | [2025-10-16 01:37:39,506] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-26, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 27ms (18/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.521 | [2025-10-16 01:37:39,521] INFO [LogLoader partition=__consumer_offsets-4, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.523 | [2025-10-16 01:37:39,522] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-4, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (19/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.534 | [2025-10-16 01:37:39,534] INFO [LogLoader partition=__consumer_offsets-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.536 | [2025-10-16 01:37:39,536] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-1, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (20/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.549 | [2025-10-16 01:37:39,548] INFO [LogLoader partition=__consumer_offsets-33, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.550 | [2025-10-16 01:37:39,550] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-33, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (21/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.568 | [2025-10-16 01:37:39,568] INFO [LogLoader partition=__consumer_offsets-25, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.571 | [2025-10-16 01:37:39,570] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-25, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (22/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.585 | [2025-10-16 01:37:39,584] INFO [LogLoader partition=__consumer_offsets-42, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.586 | [2025-10-16 01:37:39,586] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-42, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (23/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.601 | [2025-10-16 01:37:39,600] INFO [LogLoader partition=__consumer_offsets-2, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.602 | [2025-10-16 01:37:39,602] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-2, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (24/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.616 | [2025-10-16 01:37:39,616] INFO [LogLoader partition=__consumer_offsets-34, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.618 | [2025-10-16 01:37:39,617] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-34, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (25/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.632 | [2025-10-16 01:37:39,632] INFO [LogLoader partition=__consumer_offsets-36, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.634 | [2025-10-16 01:37:39,633] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-36, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (26/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.648 | [2025-10-16 01:37:39,647] INFO [LogLoader partition=__consumer_offsets-12, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.650 | [2025-10-16 01:37:39,649] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-12, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (27/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.664 | [2025-10-16 01:37:39,664] INFO [LogLoader partition=__consumer_offsets-20, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.666 | [2025-10-16 01:37:39,666] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-20, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (28/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.681 | [2025-10-16 01:37:39,680] INFO [LogLoader partition=__consumer_offsets-23, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.684 | [2025-10-16 01:37:39,683] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-23, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (29/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.698 | [2025-10-16 01:37:39,697] INFO [LogLoader partition=__consumer_offsets-13, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.700 | [2025-10-16 01:37:39,700] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-13, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (30/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.723 | [2025-10-16 01:37:39,722] INFO [LogLoader partition=__consumer_offsets-40, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.726 | [2025-10-16 01:37:39,725] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-40, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 25ms (31/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.745 | [2025-10-16 01:37:39,744] INFO [LogLoader partition=__consumer_offsets-43, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.748 | [2025-10-16 01:37:39,748] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-43, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 22ms (32/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.766 | [2025-10-16 01:37:39,766] INFO [LogLoader partition=__consumer_offsets-39, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.770 | [2025-10-16 01:37:39,769] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-39, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 21ms (33/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.788 | [2025-10-16 01:37:39,787] INFO [LogLoader partition=__consumer_offsets-46, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.791 | [2025-10-16 01:37:39,791] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-46, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (34/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.811 | [2025-10-16 01:37:39,810] INFO [LogLoader partition=__consumer_offsets-7, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.814 | [2025-10-16 01:37:39,813] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-7, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 22ms (35/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.836 | [2025-10-16 01:37:39,835] INFO [LogLoader partition=__consumer_offsets-38, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.837 | [2025-10-16 01:37:39,837] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-38, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 24ms (36/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.849 | [2025-10-16 01:37:39,848] INFO [LogLoader partition=__consumer_offsets-47, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.850 | [2025-10-16 01:37:39,850] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-47, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (37/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.862 | [2025-10-16 01:37:39,862] INFO [LogLoader partition=__consumer_offsets-11, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.864 | [2025-10-16 01:37:39,864] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-11, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (38/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.877 | [2025-10-16 01:37:39,877] INFO [LogLoader partition=__consumer_offsets-21, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.879 | [2025-10-16 01:37:39,879] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-21, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (39/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.893 | [2025-10-16 01:37:39,892] INFO [LogLoader partition=__consumer_offsets-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.894 | [2025-10-16 01:37:39,894] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-0, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (40/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.910 | [2025-10-16 01:37:39,910] INFO [LogLoader partition=__consumer_offsets-16, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.913 | [2025-10-16 01:37:39,912] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-16, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (41/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.926 | [2025-10-16 01:37:39,926] INFO [LogLoader partition=__consumer_offsets-22, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.928 | [2025-10-16 01:37:39,928] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-22, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (42/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.941 | [2025-10-16 01:37:39,941] INFO [LogLoader partition=__consumer_offsets-15, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.943 | [2025-10-16 01:37:39,943] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-15, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (43/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.955 | [2025-10-16 01:37:39,955] INFO [LogLoader partition=__consumer_offsets-18, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.957 | [2025-10-16 01:37:39,956] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-18, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (44/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.970 | [2025-10-16 01:37:39,969] INFO [LogLoader partition=__consumer_offsets-27, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.973 | [2025-10-16 01:37:39,972] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-27, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (45/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:39.995 | [2025-10-16 01:37:39,994] INFO [LogLoader partition=__consumer_offsets-24, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:39.999 | [2025-10-16 01:37:39,998] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-24, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 26ms (46/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:40.015 | [2025-10-16 01:37:40,015] INFO [LogLoader partition=__consumer_offsets-9, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:40.017 | [2025-10-16 01:37:40,017] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-9, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (47/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:40.030 | [2025-10-16 01:37:40,030] INFO [LogLoader partition=__consumer_offsets-45, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:40.032 | [2025-10-16 01:37:40,032] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-45, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (48/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:40.046 | [2025-10-16 01:37:40,045] INFO [LogLoader partition=__consumer_offsets-44, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:40.047 | [2025-10-16 01:37:40,047] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-44, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (49/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:40.061 | [2025-10-16 01:37:40,060] INFO Deleted producer state snapshot /var/lib/kafka/data/mesa-ya.restaurants.created-0/00000000000000000001.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
2025-10-15 20:37:40.061 | [2025-10-16 01:37:40,060] INFO [LogLoader partition=mesa-ya.restaurants.created-0, dir=/var/lib/kafka/data] Loading producer state till offset 2 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:40.061 | [2025-10-16 01:37:40,061] INFO [LogLoader partition=mesa-ya.restaurants.created-0, dir=/var/lib/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:40.061 | [2025-10-16 01:37:40,061] INFO [ProducerStateManager partition=mesa-ya.restaurants.created-0]Loading producer state from snapshot file 'SnapshotFile(offset=2, file=/var/lib/kafka/data/mesa-ya.restaurants.created-0/00000000000000000002.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
2025-10-15 20:37:40.062 | [2025-10-16 01:37:40,062] INFO [LogLoader partition=mesa-ya.restaurants.created-0, dir=/var/lib/kafka/data] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:40.064 | [2025-10-16 01:37:40,064] INFO Completed load of Log(dir=/var/lib/kafka/data/mesa-ya.restaurants.created-0, topicId=yWm6W48_TyqOOX8W2L0ItA, topic=mesa-ya.restaurants.created, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=2) with 1 segments in 17ms (50/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:40.082 | [2025-10-16 01:37:40,082] INFO [LogLoader partition=__consumer_offsets-48, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-15 20:37:40.084 | [2025-10-16 01:37:40,083] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-48, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (51/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-15 20:37:40.091 | [2025-10-16 01:37:40,090] INFO Loaded 51 logs in 1025ms (kafka.log.LogManager)
2025-10-15 20:37:40.093 | [2025-10-16 01:37:40,093] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
2025-10-15 20:37:40.094 | [2025-10-16 01:37:40,093] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
2025-10-15 20:37:40.108 | [2025-10-16 01:37:40,108] INFO Starting the log cleaner (kafka.log.LogCleaner)
2025-10-15 20:37:40.242 | [2025-10-16 01:37:40,241] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
2025-10-15 20:37:40.262 | [2025-10-16 01:37:40,261] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-10-15 20:37:40.296 | [2025-10-16 01:37:40,296] INFO [MetadataCache brokerId=1] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0). (kafka.server.metadata.ZkMetadataCache)
2025-10-15 20:37:40.333 | [2025-10-16 01:37:40,332] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:37:40.673 | [2025-10-16 01:37:40,673] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
2025-10-15 20:37:40.699 | [2025-10-16 01:37:40,698] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
2025-10-15 20:37:40.699 | [2025-10-16 01:37:40,699] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
2025-10-15 20:37:40.703 | [2025-10-16 01:37:40,703] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT_INTERNAL) (kafka.network.SocketServer)
2025-10-15 20:37:40.709 | [2025-10-16 01:37:40,708] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:37:40.729 | [2025-10-16 01:37:40,729] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:37:40.732 | [2025-10-16 01:37:40,731] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:37:40.732 | [2025-10-16 01:37:40,732] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:37:40.734 | [2025-10-16 01:37:40,733] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:37:40.746 | [2025-10-16 01:37:40,745] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-10-15 20:37:40.793 | [2025-10-16 01:37:40,793] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
2025-10-15 20:37:40.820 | [2025-10-16 01:37:40,820] INFO Stat of the created znode at /brokers/ids/1 is: 202,202,1760578660808,1760578660808,1,0,0,72057892457414657,270,0,202
2025-10-15 20:37:40.820 |  (kafka.zk.KafkaZkClient)
2025-10-15 20:37:40.821 | [2025-10-16 01:37:40,821] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092, czxid (broker epoch): 202 (kafka.zk.KafkaZkClient)
2025-10-15 20:37:40.892 | [2025-10-16 01:37:40,891] INFO [ControllerEventThread controllerId=1] Starting (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-10-15 20:37:40.904 | [2025-10-16 01:37:40,904] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:37:40.911 | [2025-10-16 01:37:40,910] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:37:40.911 | [2025-10-16 01:37:40,911] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:37:40.926 | [2025-10-16 01:37:40,925] INFO [Controller id=1] 1 successfully elected as the controller. Epoch incremented to 4 and epoch zk version is now 4 (kafka.controller.KafkaController)
2025-10-15 20:37:40.929 | [2025-10-16 01:37:40,929] INFO [Controller id=1] Registering handlers (kafka.controller.KafkaController)
2025-10-15 20:37:40.931 | [2025-10-16 01:37:40,931] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:40.936 | [2025-10-16 01:37:40,936] INFO [Controller id=1] Deleting log dir event notifications (kafka.controller.KafkaController)
2025-10-15 20:37:40.939 | [2025-10-16 01:37:40,939] INFO [Controller id=1] Deleting isr change notifications (kafka.controller.KafkaController)
2025-10-15 20:37:40.943 | [2025-10-16 01:37:40,943] INFO [Controller id=1] Initializing controller context (kafka.controller.KafkaController)
2025-10-15 20:37:40.944 | [2025-10-16 01:37:40,944] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:40.961 | [2025-10-16 01:37:40,961] INFO [Controller id=1] Initialized broker epochs cache: HashMap(1 -> 202) (kafka.controller.KafkaController)
2025-10-15 20:37:40.961 | [2025-10-16 01:37:40,961] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
2025-10-15 20:37:40.969 | [2025-10-16 01:37:40,969] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
2025-10-15 20:37:40.969 | [2025-10-16 01:37:40,969] INFO [TxnMarkerSenderThread-1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-10-15 20:37:40.980 | [2025-10-16 01:37:40,979] DEBUG [Controller id=1] Register BrokerModifications handler for Set(1) (kafka.controller.KafkaController)
2025-10-15 20:37:41.028 | [2025-10-16 01:37:41,027] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:37:41.039 | [2025-10-16 01:37:41,038] DEBUG [Channel manager on controller 1]: Controller 1 trying to connect to broker 1 (kafka.controller.ControllerChannelManager)
2025-10-15 20:37:41.049 | [2025-10-16 01:37:41,048] INFO [RequestSendThread controllerId=1] Starting (kafka.controller.RequestSendThread)
2025-10-15 20:37:41.051 | [2025-10-16 01:37:41,050] INFO [Controller id=1] Currently active brokers in the cluster: Set(1) (kafka.controller.KafkaController)
2025-10-15 20:37:41.052 | [2025-10-16 01:37:41,051] INFO [Controller id=1] Currently shutting brokers in the cluster: HashSet() (kafka.controller.KafkaController)
2025-10-15 20:37:41.053 | [2025-10-16 01:37:41,052] INFO [Controller id=1] Current list of topics in the cluster: HashSet(__consumer_offsets, mesa-ya.restaurants.created) (kafka.controller.KafkaController)
2025-10-15 20:37:41.053 | [2025-10-16 01:37:41,053] INFO [Controller id=1] Fetching topic deletions in progress (kafka.controller.KafkaController)
2025-10-15 20:37:41.061 | [2025-10-16 01:37:41,061] INFO [Controller id=1] List of topics to be deleted:  (kafka.controller.KafkaController)
2025-10-15 20:37:41.061 | [2025-10-16 01:37:41,061] INFO [Controller id=1] List of topics ineligible for deletion:  (kafka.controller.KafkaController)
2025-10-15 20:37:41.062 | [2025-10-16 01:37:41,061] INFO [Controller id=1] Initializing topic deletion manager (kafka.controller.KafkaController)
2025-10-15 20:37:41.062 | [2025-10-16 01:37:41,062] INFO [Topic Deletion Manager 1] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet() (kafka.controller.TopicDeletionManager)
2025-10-15 20:37:41.063 | [2025-10-16 01:37:41,063] INFO [Controller id=1] Sending update metadata request (kafka.controller.KafkaController)
2025-10-15 20:37:41.067 | [2025-10-16 01:37:41,066] INFO [Controller id=1 epoch=4] Sending UpdateMetadata request to brokers HashSet(1) for 0 partitions (state.change.logger)
2025-10-15 20:37:41.071 | [2025-10-16 01:37:41,071] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-10-15 20:37:41.076 | [2025-10-16 01:37:41,076] INFO [ReplicaStateMachine controllerId=1] Initializing replica state (kafka.controller.ZkReplicaStateMachine)
2025-10-15 20:37:41.085 | [2025-10-16 01:37:41,085] INFO [ReplicaStateMachine controllerId=1] Triggering online replica state changes (kafka.controller.ZkReplicaStateMachine)
2025-10-15 20:37:41.094 | [2025-10-16 01:37:41,093] INFO [Controller id=1, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
2025-10-15 20:37:41.096 | [2025-10-16 01:37:41,096] WARN [Controller id=1, targetBrokerId=1] Connection to node 1 (kafka/172.18.0.3:29092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
2025-10-15 20:37:41.104 | [2025-10-16 01:37:41,100] WARN [RequestSendThread controllerId=1] Controller 1's connection to broker kafka:29092 (id: 1 rack: null) was unsuccessful (kafka.controller.RequestSendThread)
2025-10-15 20:37:41.104 | java.io.IOException: Connection to kafka:29092 (id: 1 rack: null) failed.
2025-10-15 20:37:41.104 | 	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
2025-10-15 20:37:41.104 | 	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:296)
2025-10-15 20:37:41.104 | 	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:249)
2025-10-15 20:37:41.104 | 	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:127)
2025-10-15 20:37:41.104 | [2025-10-16 01:37:41,104] INFO [Controller id=1, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
2025-10-15 20:37:41.113 | [2025-10-16 01:37:41,113] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
2025-10-15 20:37:41.114 | [2025-10-16 01:37:41,114] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-46 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.115 | [2025-10-16 01:37:41,114] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-37 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.115 | [2025-10-16 01:37:41,115] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-8 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.116 | [2025-10-16 01:37:41,115] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-49 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.116 | [2025-10-16 01:37:41,116] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-21 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.116 | [2025-10-16 01:37:41,116] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-20 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.116 | [2025-10-16 01:37:41,116] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-17 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.116 | [2025-10-16 01:37:41,116] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-19 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.117 | [2025-10-16 01:37:41,116] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-7 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.117 | [2025-10-16 01:37:41,117] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-43 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.117 | [2025-10-16 01:37:41,117] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-30 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.120 | [2025-10-16 01:37:41,119] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-35 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.121 | [2025-10-16 01:37:41,119] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-27 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.121 | [2025-10-16 01:37:41,119] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition mesa-ya.restaurants.created-0 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.121 | [2025-10-16 01:37:41,120] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-0 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.121 | [2025-10-16 01:37:41,120] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-40 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.121 | [2025-10-16 01:37:41,120] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-47 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.121 | [2025-10-16 01:37:41,121] INFO Awaiting socket connections on 0.0.0.0:29092. (kafka.network.DataPlaneAcceptor)
2025-10-15 20:37:41.121 | [2025-10-16 01:37:41,121] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-10 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.122 | [2025-10-16 01:37:41,121] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-4 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.122 | [2025-10-16 01:37:41,121] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-31 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.132 | [2025-10-16 01:37:41,132] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-16 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.133 | [2025-10-16 01:37:41,132] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-23 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.133 | [2025-10-16 01:37:41,133] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-26 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.133 | [2025-10-16 01:37:41,133] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-39 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.134 | [2025-10-16 01:37:41,133] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-2 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.134 | [2025-10-16 01:37:41,134] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-34 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.134 | [2025-10-16 01:37:41,134] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-24 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.135 | [2025-10-16 01:37:41,134] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-32 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.136 | [2025-10-16 01:37:41,135] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-41 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.136 | [2025-10-16 01:37:41,136] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-5 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.137 | [2025-10-16 01:37:41,136] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-15 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.138 | [2025-10-16 01:37:41,138] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
2025-10-15 20:37:41.138 | [2025-10-16 01:37:41,138] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-1 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.139 | [2025-10-16 01:37:41,139] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-9 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.139 | [2025-10-16 01:37:41,139] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-45 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.140 | [2025-10-16 01:37:41,139] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-36 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.140 | [2025-10-16 01:37:41,140] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-48 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.140 | [2025-10-16 01:37:41,140] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-3 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.141 | [2025-10-16 01:37:41,140] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-18 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.141 | [2025-10-16 01:37:41,140] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-44 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.141 | [2025-10-16 01:37:41,141] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-11 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.141 | [2025-10-16 01:37:41,141] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-25 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.142 | [2025-10-16 01:37:41,141] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-29 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.142 | [2025-10-16 01:37:41,142] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-6 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.142 | [2025-10-16 01:37:41,142] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-42 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.143 | [2025-10-16 01:37:41,143] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-28 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.144 | [2025-10-16 01:37:41,143] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-12 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.144 | [2025-10-16 01:37:41,144] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-38 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.144 | [2025-10-16 01:37:41,144] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-33 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.144 | [2025-10-16 01:37:41,144] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-14 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.145 | [2025-10-16 01:37:41,144] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-13 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.145 | [2025-10-16 01:37:41,145] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-22 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-15 20:37:41.153 | [2025-10-16 01:37:41,152] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-13 (state.change.logger)
2025-10-15 20:37:41.153 | [2025-10-16 01:37:41,152] INFO Kafka version: 7.5.0-ccs (org.apache.kafka.common.utils.AppInfoParser)
2025-10-15 20:37:41.153 | [2025-10-16 01:37:41,152] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-46 (state.change.logger)
2025-10-15 20:37:41.153 | [2025-10-16 01:37:41,152] INFO Kafka commitId: ff3c201baa948d97889dc26c99d7cdc23d038f2e (org.apache.kafka.common.utils.AppInfoParser)
2025-10-15 20:37:41.153 | [2025-10-16 01:37:41,153] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-9 (state.change.logger)
2025-10-15 20:37:41.153 | [2025-10-16 01:37:41,153] INFO Kafka startTimeMs: 1760578661144 (org.apache.kafka.common.utils.AppInfoParser)
2025-10-15 20:37:41.153 | [2025-10-16 01:37:41,153] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-42 (state.change.logger)
2025-10-15 20:37:41.153 | [2025-10-16 01:37:41,153] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-21 (state.change.logger)
2025-10-15 20:37:41.153 | [2025-10-16 01:37:41,153] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-17 (state.change.logger)
2025-10-15 20:37:41.153 | [2025-10-16 01:37:41,153] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-30 (state.change.logger)
2025-10-15 20:37:41.153 | [2025-10-16 01:37:41,153] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-26 (state.change.logger)
2025-10-15 20:37:41.153 | [2025-10-16 01:37:41,153] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-5 (state.change.logger)
2025-10-15 20:37:41.154 | [2025-10-16 01:37:41,153] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-38 (state.change.logger)
2025-10-15 20:37:41.154 | [2025-10-16 01:37:41,154] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-1 (state.change.logger)
2025-10-15 20:37:41.154 | [2025-10-16 01:37:41,154] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-34 (state.change.logger)
2025-10-15 20:37:41.154 | [2025-10-16 01:37:41,154] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-16 (state.change.logger)
2025-10-15 20:37:41.154 | [2025-10-16 01:37:41,154] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-45 (state.change.logger)
2025-10-15 20:37:41.154 | [2025-10-16 01:37:41,154] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-12 (state.change.logger)
2025-10-15 20:37:41.154 | [2025-10-16 01:37:41,154] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-41 (state.change.logger)
2025-10-15 20:37:41.154 | [2025-10-16 01:37:41,154] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-24 (state.change.logger)
2025-10-15 20:37:41.154 | [2025-10-16 01:37:41,154] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-20 (state.change.logger)
2025-10-15 20:37:41.154 | [2025-10-16 01:37:41,154] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-49 (state.change.logger)
2025-10-15 20:37:41.154 | [2025-10-16 01:37:41,154] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-0 (state.change.logger)
2025-10-15 20:37:41.154 | [2025-10-16 01:37:41,154] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-29 (state.change.logger)
2025-10-15 20:37:41.154 | [2025-10-16 01:37:41,154] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-25 (state.change.logger)
2025-10-15 20:37:41.154 | [2025-10-16 01:37:41,154] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-8 (state.change.logger)
2025-10-15 20:37:41.155 | [2025-10-16 01:37:41,154] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-37 (state.change.logger)
2025-10-15 20:37:41.155 | [2025-10-16 01:37:41,154] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-4 (state.change.logger)
2025-10-15 20:37:41.155 | [2025-10-16 01:37:41,154] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-33 (state.change.logger)
2025-10-15 20:37:41.155 | [2025-10-16 01:37:41,155] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-15 (state.change.logger)
2025-10-15 20:37:41.155 | [2025-10-16 01:37:41,155] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-48 (state.change.logger)
2025-10-15 20:37:41.155 | [2025-10-16 01:37:41,155] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-11 (state.change.logger)
2025-10-15 20:37:41.155 | [2025-10-16 01:37:41,155] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-44 (state.change.logger)
2025-10-15 20:37:41.155 | [2025-10-16 01:37:41,155] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-23 (state.change.logger)
2025-10-15 20:37:41.155 | [2025-10-16 01:37:41,155] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
2025-10-15 20:37:41.155 | [2025-10-16 01:37:41,155] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-19 (state.change.logger)
2025-10-15 20:37:41.155 | [2025-10-16 01:37:41,155] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-32 (state.change.logger)
2025-10-15 20:37:41.155 | [2025-10-16 01:37:41,155] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-28 (state.change.logger)
2025-10-15 20:37:41.155 | [2025-10-16 01:37:41,155] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-7 (state.change.logger)
2025-10-15 20:37:41.155 | [2025-10-16 01:37:41,155] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-40 (state.change.logger)
2025-10-15 20:37:41.155 | [2025-10-16 01:37:41,155] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-3 (state.change.logger)
2025-10-15 20:37:41.155 | [2025-10-16 01:37:41,155] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-36 (state.change.logger)
2025-10-15 20:37:41.156 | [2025-10-16 01:37:41,155] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-47 (state.change.logger)
2025-10-15 20:37:41.156 | [2025-10-16 01:37:41,155] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-14 (state.change.logger)
2025-10-15 20:37:41.156 | [2025-10-16 01:37:41,155] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-43 (state.change.logger)
2025-10-15 20:37:41.156 | [2025-10-16 01:37:41,155] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-10 (state.change.logger)
2025-10-15 20:37:41.156 | [2025-10-16 01:37:41,155] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-22 (state.change.logger)
2025-10-15 20:37:41.156 | [2025-10-16 01:37:41,156] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-18 (state.change.logger)
2025-10-15 20:37:41.156 | [2025-10-16 01:37:41,156] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-31 (state.change.logger)
2025-10-15 20:37:41.156 | [2025-10-16 01:37:41,156] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-27 (state.change.logger)
2025-10-15 20:37:41.156 | [2025-10-16 01:37:41,156] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-39 (state.change.logger)
2025-10-15 20:37:41.156 | [2025-10-16 01:37:41,156] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-6 (state.change.logger)
2025-10-15 20:37:41.156 | [2025-10-16 01:37:41,156] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-35 (state.change.logger)
2025-10-15 20:37:41.156 | [2025-10-16 01:37:41,156] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='mesa-ya.restaurants.created', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition mesa-ya.restaurants.created-0 (state.change.logger)
2025-10-15 20:37:41.156 | [2025-10-16 01:37:41,156] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-2 (state.change.logger)
2025-10-15 20:37:41.158 | [2025-10-16 01:37:41,158] INFO [Controller id=1 epoch=4] Sending LeaderAndIsr request to broker 1 with 51 become-leader and 0 become-follower partitions (state.change.logger)
2025-10-15 20:37:41.162 | [2025-10-16 01:37:41,162] INFO [Controller id=1 epoch=4] Sending UpdateMetadata request to brokers HashSet(1) for 51 partitions (state.change.logger)
2025-10-15 20:37:41.163 | [2025-10-16 01:37:41,163] INFO [ReplicaStateMachine controllerId=1] Triggering offline replica state changes (kafka.controller.ZkReplicaStateMachine)
2025-10-15 20:37:41.164 | [2025-10-16 01:37:41,163] DEBUG [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> HashMap([Topic=__consumer_offsets,Partition=46,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=37,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=8,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=49,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=21,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=20,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=17,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=19,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=7,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=43,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=30,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=35,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=27,Replica=1] -> OnlineReplica, [Topic=mesa-ya.restaurants.created,Partition=0,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=0,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=40,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=47,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=10,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=4,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=31,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=16,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=23,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=26,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=39,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=2,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=34,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=24,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=32,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=41,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=5,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=15,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=1,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=9,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=45,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=36,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=48,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=3,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=18,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=44,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=11,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=25,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=29,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=6,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=42,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=28,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=12,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=38,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=33,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=14,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=13,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=22,Replica=1] -> OnlineReplica) (kafka.controller.ZkReplicaStateMachine)
2025-10-15 20:37:41.164 | [2025-10-16 01:37:41,164] INFO [PartitionStateMachine controllerId=1] Initializing partition state (kafka.controller.ZkPartitionStateMachine)
2025-10-15 20:37:41.168 | [2025-10-16 01:37:41,168] INFO [PartitionStateMachine controllerId=1] Triggering online partition state changes (kafka.controller.ZkPartitionStateMachine)
2025-10-15 20:37:41.171 | [2025-10-16 01:37:41,171] DEBUG [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> HashMap(__consumer_offsets-13 -> OnlinePartition, __consumer_offsets-46 -> OnlinePartition, __consumer_offsets-9 -> OnlinePartition, __consumer_offsets-42 -> OnlinePartition, __consumer_offsets-21 -> OnlinePartition, __consumer_offsets-17 -> OnlinePartition, __consumer_offsets-30 -> OnlinePartition, __consumer_offsets-26 -> OnlinePartition, __consumer_offsets-5 -> OnlinePartition, __consumer_offsets-38 -> OnlinePartition, __consumer_offsets-1 -> OnlinePartition, __consumer_offsets-34 -> OnlinePartition, __consumer_offsets-16 -> OnlinePartition, __consumer_offsets-45 -> OnlinePartition, __consumer_offsets-12 -> OnlinePartition, __consumer_offsets-41 -> OnlinePartition, __consumer_offsets-24 -> OnlinePartition, __consumer_offsets-20 -> OnlinePartition, __consumer_offsets-49 -> OnlinePartition, __consumer_offsets-0 -> OnlinePartition, __consumer_offsets-29 -> OnlinePartition, __consumer_offsets-25 -> OnlinePartition, __consumer_offsets-8 -> OnlinePartition, __consumer_offsets-37 -> OnlinePartition, __consumer_offsets-4 -> OnlinePartition, __consumer_offsets-33 -> OnlinePartition, __consumer_offsets-15 -> OnlinePartition, __consumer_offsets-48 -> OnlinePartition, __consumer_offsets-11 -> OnlinePartition, __consumer_offsets-44 -> OnlinePartition, __consumer_offsets-23 -> OnlinePartition, __consumer_offsets-19 -> OnlinePartition, __consumer_offsets-32 -> OnlinePartition, __consumer_offsets-28 -> OnlinePartition, __consumer_offsets-7 -> OnlinePartition, __consumer_offsets-40 -> OnlinePartition, __consumer_offsets-3 -> OnlinePartition, __consumer_offsets-36 -> OnlinePartition, __consumer_offsets-47 -> OnlinePartition, __consumer_offsets-14 -> OnlinePartition, __consumer_offsets-43 -> OnlinePartition, __consumer_offsets-10 -> OnlinePartition, __consumer_offsets-22 -> OnlinePartition, __consumer_offsets-18 -> OnlinePartition, __consumer_offsets-31 -> OnlinePartition, __consumer_offsets-27 -> OnlinePartition, __consumer_offsets-39 -> OnlinePartition, __consumer_offsets-6 -> OnlinePartition, __consumer_offsets-35 -> OnlinePartition, mesa-ya.restaurants.created-0 -> OnlinePartition, __consumer_offsets-2 -> OnlinePartition) (kafka.controller.ZkPartitionStateMachine)
2025-10-15 20:37:41.171 | [2025-10-16 01:37:41,171] INFO [Controller id=1] Ready to serve as the new controller with epoch 4 (kafka.controller.KafkaController)
2025-10-15 20:37:41.180 | [2025-10-16 01:37:41,179] INFO [Controller id=1] Partitions undergoing preferred replica election:  (kafka.controller.KafkaController)
2025-10-15 20:37:41.180 | [2025-10-16 01:37:41,180] INFO [Controller id=1] Partitions that completed preferred replica election:  (kafka.controller.KafkaController)
2025-10-15 20:37:41.180 | [2025-10-16 01:37:41,180] INFO [Controller id=1] Skipping preferred replica election for partitions due to topic deletion:  (kafka.controller.KafkaController)
2025-10-15 20:37:41.181 | [2025-10-16 01:37:41,181] INFO [Controller id=1] Resuming preferred replica election for partitions:  (kafka.controller.KafkaController)
2025-10-15 20:37:41.182 | [2025-10-16 01:37:41,182] INFO [Controller id=1] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered (kafka.controller.KafkaController)
2025-10-15 20:37:41.207 | [2025-10-16 01:37:41,206] INFO [Controller id=1] Starting the controller scheduler (kafka.controller.KafkaController)
2025-10-15 20:37:41.209 | [2025-10-16 01:37:41,208] INFO [RequestSendThread controllerId=1] Controller 1 connected to kafka:29092 (id: 1 rack: null) for sending state change requests (kafka.controller.RequestSendThread)
2025-10-15 20:37:41.279 | [2025-10-16 01:37:41,279] TRACE [Controller id=1 epoch=4] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 0 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-10-15 20:37:41.289 | [2025-10-16 01:37:41,289] INFO [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 for 51 partitions (state.change.logger)
2025-10-15 20:37:41.291 | [2025-10-16 01:37:41,290] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.291 | [2025-10-16 01:37:41,290] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.291 | [2025-10-16 01:37:41,290] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.291 | [2025-10-16 01:37:41,290] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.291 | [2025-10-16 01:37:41,291] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.291 | [2025-10-16 01:37:41,291] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.291 | [2025-10-16 01:37:41,291] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.291 | [2025-10-16 01:37:41,291] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.291 | [2025-10-16 01:37:41,291] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.291 | [2025-10-16 01:37:41,291] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.291 | [2025-10-16 01:37:41,291] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.291 | [2025-10-16 01:37:41,291] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.291 | [2025-10-16 01:37:41,291] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.291 | [2025-10-16 01:37:41,291] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.291 | [2025-10-16 01:37:41,291] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.291 | [2025-10-16 01:37:41,291] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.292 | [2025-10-16 01:37:41,291] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.292 | [2025-10-16 01:37:41,291] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.292 | [2025-10-16 01:37:41,291] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.292 | [2025-10-16 01:37:41,291] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.292 | [2025-10-16 01:37:41,291] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.292 | [2025-10-16 01:37:41,292] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.292 | [2025-10-16 01:37:41,292] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.292 | [2025-10-16 01:37:41,292] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.292 | [2025-10-16 01:37:41,292] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.292 | [2025-10-16 01:37:41,292] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.292 | [2025-10-16 01:37:41,292] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.292 | [2025-10-16 01:37:41,292] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.292 | [2025-10-16 01:37:41,292] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.292 | [2025-10-16 01:37:41,292] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.292 | [2025-10-16 01:37:41,292] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.292 | [2025-10-16 01:37:41,292] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.292 | [2025-10-16 01:37:41,292] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.292 | [2025-10-16 01:37:41,292] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.293 | [2025-10-16 01:37:41,292] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.293 | [2025-10-16 01:37:41,292] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.293 | [2025-10-16 01:37:41,292] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.293 | [2025-10-16 01:37:41,293] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.293 | [2025-10-16 01:37:41,293] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.293 | [2025-10-16 01:37:41,293] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.293 | [2025-10-16 01:37:41,293] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.293 | [2025-10-16 01:37:41,293] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.293 | [2025-10-16 01:37:41,293] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.293 | [2025-10-16 01:37:41,293] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.293 | [2025-10-16 01:37:41,293] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.293 | [2025-10-16 01:37:41,293] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.293 | [2025-10-16 01:37:41,293] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.293 | [2025-10-16 01:37:41,293] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.293 | [2025-10-16 01:37:41,293] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.293 | [2025-10-16 01:37:41,293] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.294 | [2025-10-16 01:37:41,293] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='mesa-ya.restaurants.created', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-10-15 20:37:41.316 | [2025-10-16 01:37:41,315] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Recorded new controller, from now on will use node kafka:29092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:37:41.336 | [2025-10-16 01:37:41,336] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-3 (state.change.logger)
2025-10-15 20:37:41.336 | [2025-10-16 01:37:41,336] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-18 (state.change.logger)
2025-10-15 20:37:41.336 | [2025-10-16 01:37:41,336] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-41 (state.change.logger)
2025-10-15 20:37:41.336 | [2025-10-16 01:37:41,336] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-10 (state.change.logger)
2025-10-15 20:37:41.336 | [2025-10-16 01:37:41,336] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-33 (state.change.logger)
2025-10-15 20:37:41.336 | [2025-10-16 01:37:41,336] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-48 (state.change.logger)
2025-10-15 20:37:41.336 | [2025-10-16 01:37:41,336] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-19 (state.change.logger)
2025-10-15 20:37:41.336 | [2025-10-16 01:37:41,336] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-34 (state.change.logger)
2025-10-15 20:37:41.336 | [2025-10-16 01:37:41,336] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-4 (state.change.logger)
2025-10-15 20:37:41.336 | [2025-10-16 01:37:41,336] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-11 (state.change.logger)
2025-10-15 20:37:41.336 | [2025-10-16 01:37:41,336] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-26 (state.change.logger)
2025-10-15 20:37:41.336 | [2025-10-16 01:37:41,336] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-49 (state.change.logger)
2025-10-15 20:37:41.336 | [2025-10-16 01:37:41,336] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-39 (state.change.logger)
2025-10-15 20:37:41.337 | [2025-10-16 01:37:41,336] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-9 (state.change.logger)
2025-10-15 20:37:41.337 | [2025-10-16 01:37:41,336] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-24 (state.change.logger)
2025-10-15 20:37:41.337 | [2025-10-16 01:37:41,336] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-31 (state.change.logger)
2025-10-15 20:37:41.337 | [2025-10-16 01:37:41,336] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-46 (state.change.logger)
2025-10-15 20:37:41.337 | [2025-10-16 01:37:41,336] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-1 (state.change.logger)
2025-10-15 20:37:41.337 | [2025-10-16 01:37:41,336] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-16 (state.change.logger)
2025-10-15 20:37:41.337 | [2025-10-16 01:37:41,336] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-2 (state.change.logger)
2025-10-15 20:37:41.337 | [2025-10-16 01:37:41,337] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-25 (state.change.logger)
2025-10-15 20:37:41.337 | [2025-10-16 01:37:41,337] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-40 (state.change.logger)
2025-10-15 20:37:41.337 | [2025-10-16 01:37:41,337] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-47 (state.change.logger)
2025-10-15 20:37:41.337 | [2025-10-16 01:37:41,337] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-17 (state.change.logger)
2025-10-15 20:37:41.337 | [2025-10-16 01:37:41,337] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-32 (state.change.logger)
2025-10-15 20:37:41.337 | [2025-10-16 01:37:41,337] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-37 (state.change.logger)
2025-10-15 20:37:41.337 | [2025-10-16 01:37:41,337] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-7 (state.change.logger)
2025-10-15 20:37:41.337 | [2025-10-16 01:37:41,337] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-22 (state.change.logger)
2025-10-15 20:37:41.337 | [2025-10-16 01:37:41,337] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-29 (state.change.logger)
2025-10-15 20:37:41.337 | [2025-10-16 01:37:41,337] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-44 (state.change.logger)
2025-10-15 20:37:41.337 | [2025-10-16 01:37:41,337] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-14 (state.change.logger)
2025-10-15 20:37:41.337 | [2025-10-16 01:37:41,337] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-23 (state.change.logger)
2025-10-15 20:37:41.337 | [2025-10-16 01:37:41,337] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-38 (state.change.logger)
2025-10-15 20:37:41.337 | [2025-10-16 01:37:41,337] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-8 (state.change.logger)
2025-10-15 20:37:41.337 | [2025-10-16 01:37:41,337] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-45 (state.change.logger)
2025-10-15 20:37:41.337 | [2025-10-16 01:37:41,337] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-15 (state.change.logger)
2025-10-15 20:37:41.337 | [2025-10-16 01:37:41,337] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-30 (state.change.logger)
2025-10-15 20:37:41.337 | [2025-10-16 01:37:41,337] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition mesa-ya.restaurants.created-0 (state.change.logger)
2025-10-15 20:37:41.338 | [2025-10-16 01:37:41,337] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-0 (state.change.logger)
2025-10-15 20:37:41.338 | [2025-10-16 01:37:41,337] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-35 (state.change.logger)
2025-10-15 20:37:41.338 | [2025-10-16 01:37:41,337] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-5 (state.change.logger)
2025-10-15 20:37:41.338 | [2025-10-16 01:37:41,337] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-20 (state.change.logger)
2025-10-15 20:37:41.338 | [2025-10-16 01:37:41,337] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-27 (state.change.logger)
2025-10-15 20:37:41.338 | [2025-10-16 01:37:41,338] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-42 (state.change.logger)
2025-10-15 20:37:41.338 | [2025-10-16 01:37:41,338] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-12 (state.change.logger)
2025-10-15 20:37:41.338 | [2025-10-16 01:37:41,338] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-21 (state.change.logger)
2025-10-15 20:37:41.338 | [2025-10-16 01:37:41,338] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-36 (state.change.logger)
2025-10-15 20:37:41.338 | [2025-10-16 01:37:41,338] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-6 (state.change.logger)
2025-10-15 20:37:41.338 | [2025-10-16 01:37:41,338] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-43 (state.change.logger)
2025-10-15 20:37:41.338 | [2025-10-16 01:37:41,338] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-13 (state.change.logger)
2025-10-15 20:37:41.338 | [2025-10-16 01:37:41,338] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-28 (state.change.logger)
2025-10-15 20:37:41.340 | [2025-10-16 01:37:41,339] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-37, __consumer_offsets-38, __consumer_offsets-13, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, mesa-ya.restaurants.created-0, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
2025-10-15 20:37:41.341 | [2025-10-16 01:37:41,341] INFO [Broker id=1] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 1 epoch 4 as part of the become-leader transition for 51 partitions (state.change.logger)
2025-10-15 20:37:41.345 | [2025-10-16 01:37:41,344] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Recorded new controller, from now on will use node kafka:29092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:37:41.353 | [2025-10-16 01:37:41,352] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.357 | [2025-10-16 01:37:41,357] INFO [Broker id=1] Leader __consumer_offsets-3 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.373 | [2025-10-16 01:37:41,373] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.374 | [2025-10-16 01:37:41,373] INFO [Broker id=1] Leader __consumer_offsets-18 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.385 | [2025-10-16 01:37:41,385] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.385 | [2025-10-16 01:37:41,385] INFO [Broker id=1] Leader __consumer_offsets-41 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.397 | [2025-10-16 01:37:41,397] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.398 | [2025-10-16 01:37:41,397] INFO [Broker id=1] Leader __consumer_offsets-10 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.408 | [2025-10-16 01:37:41,407] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.408 | [2025-10-16 01:37:41,407] INFO [Broker id=1] Leader __consumer_offsets-33 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.419 | [2025-10-16 01:37:41,419] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.419 | [2025-10-16 01:37:41,419] INFO [Broker id=1] Leader __consumer_offsets-48 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.431 | [2025-10-16 01:37:41,430] INFO [Partition __consumer_offsets-19 broker=1] Log loaded for partition __consumer_offsets-19 with initial high watermark 3 (kafka.cluster.Partition)
2025-10-15 20:37:41.431 | [2025-10-16 01:37:41,430] INFO [Broker id=1] Leader __consumer_offsets-19 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 3 with partition epoch 0, high watermark 3, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.431 | [2025-10-16 01:37:41,431] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.431 | [2025-10-16 01:37:41,431] INFO [Broker id=1] Leader __consumer_offsets-34 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.440 | [2025-10-16 01:37:41,440] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.440 | [2025-10-16 01:37:41,440] INFO [Broker id=1] Leader __consumer_offsets-4 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.450 | [2025-10-16 01:37:41,450] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.450 | [2025-10-16 01:37:41,450] INFO [Broker id=1] Leader __consumer_offsets-11 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.461 | [2025-10-16 01:37:41,461] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.461 | [2025-10-16 01:37:41,461] INFO [Broker id=1] Leader __consumer_offsets-26 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.473 | [2025-10-16 01:37:41,472] INFO [Partition __consumer_offsets-49 broker=1] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.473 | [2025-10-16 01:37:41,472] INFO [Broker id=1] Leader __consumer_offsets-49 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.486 | [2025-10-16 01:37:41,485] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.486 | [2025-10-16 01:37:41,486] INFO [Broker id=1] Leader __consumer_offsets-39 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.502 | [2025-10-16 01:37:41,502] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.502 | [2025-10-16 01:37:41,502] INFO [Broker id=1] Leader __consumer_offsets-9 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.516 | [2025-10-16 01:37:41,515] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.516 | [2025-10-16 01:37:41,516] INFO [Broker id=1] Leader __consumer_offsets-24 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.529 | [2025-10-16 01:37:41,529] INFO [Partition __consumer_offsets-31 broker=1] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.529 | [2025-10-16 01:37:41,529] INFO [Broker id=1] Leader __consumer_offsets-31 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.543 | [2025-10-16 01:37:41,542] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.544 | [2025-10-16 01:37:41,543] INFO [Broker id=1] Leader __consumer_offsets-46 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.557 | [2025-10-16 01:37:41,556] INFO [Partition __consumer_offsets-1 broker=1] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.557 | [2025-10-16 01:37:41,556] INFO [Broker id=1] Leader __consumer_offsets-1 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.568 | [2025-10-16 01:37:41,568] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.568 | [2025-10-16 01:37:41,568] INFO [Broker id=1] Leader __consumer_offsets-16 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.581 | [2025-10-16 01:37:41,581] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.581 | [2025-10-16 01:37:41,581] INFO [Broker id=1] Leader __consumer_offsets-2 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.596 | [2025-10-16 01:37:41,595] INFO [Partition __consumer_offsets-25 broker=1] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.596 | [2025-10-16 01:37:41,596] INFO [Broker id=1] Leader __consumer_offsets-25 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.609 | [2025-10-16 01:37:41,608] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.609 | [2025-10-16 01:37:41,609] INFO [Broker id=1] Leader __consumer_offsets-40 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.628 | [2025-10-16 01:37:41,627] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.629 | [2025-10-16 01:37:41,628] INFO [Broker id=1] Leader __consumer_offsets-47 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.653 | [2025-10-16 01:37:41,652] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.653 | [2025-10-16 01:37:41,653] INFO [Broker id=1] Leader __consumer_offsets-17 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.668 | [2025-10-16 01:37:41,668] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.668 | [2025-10-16 01:37:41,668] INFO [Broker id=1] Leader __consumer_offsets-32 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.679 | [2025-10-16 01:37:41,678] INFO [Partition __consumer_offsets-37 broker=1] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.679 | [2025-10-16 01:37:41,679] INFO [Broker id=1] Leader __consumer_offsets-37 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.694 | [2025-10-16 01:37:41,693] INFO [Partition __consumer_offsets-7 broker=1] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.694 | [2025-10-16 01:37:41,693] INFO [Broker id=1] Leader __consumer_offsets-7 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.710 | [2025-10-16 01:37:41,710] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.710 | [2025-10-16 01:37:41,710] INFO [Broker id=1] Leader __consumer_offsets-22 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.727 | [2025-10-16 01:37:41,727] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.727 | [2025-10-16 01:37:41,727] INFO [Broker id=1] Leader __consumer_offsets-29 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.742 | [2025-10-16 01:37:41,741] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.742 | [2025-10-16 01:37:41,741] INFO [Broker id=1] Leader __consumer_offsets-44 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.752 | [2025-10-16 01:37:41,752] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.752 | [2025-10-16 01:37:41,752] INFO [Broker id=1] Leader __consumer_offsets-14 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.763 | [2025-10-16 01:37:41,762] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.763 | [2025-10-16 01:37:41,762] INFO [Broker id=1] Leader __consumer_offsets-23 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.777 | [2025-10-16 01:37:41,776] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.777 | [2025-10-16 01:37:41,777] INFO [Broker id=1] Leader __consumer_offsets-38 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.791 | [2025-10-16 01:37:41,790] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.791 | [2025-10-16 01:37:41,791] INFO [Broker id=1] Leader __consumer_offsets-8 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.807 | [2025-10-16 01:37:41,806] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.807 | [2025-10-16 01:37:41,807] INFO [Broker id=1] Leader __consumer_offsets-45 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.823 | [2025-10-16 01:37:41,822] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.823 | [2025-10-16 01:37:41,822] INFO [Broker id=1] Leader __consumer_offsets-15 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.839 | [2025-10-16 01:37:41,838] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.839 | [2025-10-16 01:37:41,839] INFO [Broker id=1] Leader __consumer_offsets-30 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.852 | [2025-10-16 01:37:41,851] INFO [Partition mesa-ya.restaurants.created-0 broker=1] Log loaded for partition mesa-ya.restaurants.created-0 with initial high watermark 2 (kafka.cluster.Partition)
2025-10-15 20:37:41.852 | [2025-10-16 01:37:41,851] INFO [Broker id=1] Leader mesa-ya.restaurants.created-0 with topic id Some(yWm6W48_TyqOOX8W2L0ItA) starts at leader epoch 0 from offset 2 with partition epoch 0, high watermark 2, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.852 | [2025-10-16 01:37:41,852] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.852 | [2025-10-16 01:37:41,852] INFO [Broker id=1] Leader __consumer_offsets-0 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.862 | [2025-10-16 01:37:41,861] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.862 | [2025-10-16 01:37:41,861] INFO [Broker id=1] Leader __consumer_offsets-35 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.874 | [2025-10-16 01:37:41,874] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.874 | [2025-10-16 01:37:41,874] INFO [Broker id=1] Leader __consumer_offsets-5 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.888 | [2025-10-16 01:37:41,887] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.888 | [2025-10-16 01:37:41,887] INFO [Broker id=1] Leader __consumer_offsets-20 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.901 | [2025-10-16 01:37:41,901] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.902 | [2025-10-16 01:37:41,901] INFO [Broker id=1] Leader __consumer_offsets-27 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.915 | [2025-10-16 01:37:41,914] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.915 | [2025-10-16 01:37:41,914] INFO [Broker id=1] Leader __consumer_offsets-42 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.927 | [2025-10-16 01:37:41,927] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.927 | [2025-10-16 01:37:41,927] INFO [Broker id=1] Leader __consumer_offsets-12 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.939 | [2025-10-16 01:37:41,938] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.939 | [2025-10-16 01:37:41,938] INFO [Broker id=1] Leader __consumer_offsets-21 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.950 | [2025-10-16 01:37:41,949] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.950 | [2025-10-16 01:37:41,950] INFO [Broker id=1] Leader __consumer_offsets-36 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.961 | [2025-10-16 01:37:41,961] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.962 | [2025-10-16 01:37:41,961] INFO [Broker id=1] Leader __consumer_offsets-6 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.973 | [2025-10-16 01:37:41,972] INFO [Partition __consumer_offsets-43 broker=1] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.973 | [2025-10-16 01:37:41,973] INFO [Broker id=1] Leader __consumer_offsets-43 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.985 | [2025-10-16 01:37:41,985] INFO [Partition __consumer_offsets-13 broker=1] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.985 | [2025-10-16 01:37:41,985] INFO [Broker id=1] Leader __consumer_offsets-13 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:41.999 | [2025-10-16 01:37:41,998] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-15 20:37:41.999 | [2025-10-16 01:37:41,998] INFO [Broker id=1] Leader __consumer_offsets-28 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-15 20:37:42.018 | [2025-10-16 01:37:42,017] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-3 (state.change.logger)
2025-10-15 20:37:42.018 | [2025-10-16 01:37:42,017] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-18 (state.change.logger)
2025-10-15 20:37:42.018 | [2025-10-16 01:37:42,017] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-41 (state.change.logger)
2025-10-15 20:37:42.018 | [2025-10-16 01:37:42,017] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-10 (state.change.logger)
2025-10-15 20:37:42.018 | [2025-10-16 01:37:42,017] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-33 (state.change.logger)
2025-10-15 20:37:42.018 | [2025-10-16 01:37:42,017] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-48 (state.change.logger)
2025-10-15 20:37:42.018 | [2025-10-16 01:37:42,017] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-19 (state.change.logger)
2025-10-15 20:37:42.018 | [2025-10-16 01:37:42,017] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-34 (state.change.logger)
2025-10-15 20:37:42.018 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-4 (state.change.logger)
2025-10-15 20:37:42.018 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-11 (state.change.logger)
2025-10-15 20:37:42.018 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-26 (state.change.logger)
2025-10-15 20:37:42.018 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-49 (state.change.logger)
2025-10-15 20:37:42.018 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-39 (state.change.logger)
2025-10-15 20:37:42.019 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-9 (state.change.logger)
2025-10-15 20:37:42.019 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-24 (state.change.logger)
2025-10-15 20:37:42.019 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-31 (state.change.logger)
2025-10-15 20:37:42.019 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-46 (state.change.logger)
2025-10-15 20:37:42.019 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-1 (state.change.logger)
2025-10-15 20:37:42.019 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-16 (state.change.logger)
2025-10-15 20:37:42.019 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-2 (state.change.logger)
2025-10-15 20:37:42.020 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-25 (state.change.logger)
2025-10-15 20:37:42.020 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-40 (state.change.logger)
2025-10-15 20:37:42.020 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-47 (state.change.logger)
2025-10-15 20:37:42.020 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-17 (state.change.logger)
2025-10-15 20:37:42.020 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-32 (state.change.logger)
2025-10-15 20:37:42.020 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-37 (state.change.logger)
2025-10-15 20:37:42.020 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-7 (state.change.logger)
2025-10-15 20:37:42.020 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-22 (state.change.logger)
2025-10-15 20:37:42.020 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-29 (state.change.logger)
2025-10-15 20:37:42.020 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-44 (state.change.logger)
2025-10-15 20:37:42.020 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-14 (state.change.logger)
2025-10-15 20:37:42.020 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-23 (state.change.logger)
2025-10-15 20:37:42.020 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-38 (state.change.logger)
2025-10-15 20:37:42.020 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-8 (state.change.logger)
2025-10-15 20:37:42.020 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-45 (state.change.logger)
2025-10-15 20:37:42.020 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-15 (state.change.logger)
2025-10-15 20:37:42.020 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-30 (state.change.logger)
2025-10-15 20:37:42.020 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition mesa-ya.restaurants.created-0 (state.change.logger)
2025-10-15 20:37:42.020 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-0 (state.change.logger)
2025-10-15 20:37:42.020 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-35 (state.change.logger)
2025-10-15 20:37:42.020 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-5 (state.change.logger)
2025-10-15 20:37:42.021 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-20 (state.change.logger)
2025-10-15 20:37:42.021 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-27 (state.change.logger)
2025-10-15 20:37:42.021 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-42 (state.change.logger)
2025-10-15 20:37:42.021 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-12 (state.change.logger)
2025-10-15 20:37:42.021 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-21 (state.change.logger)
2025-10-15 20:37:42.021 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-36 (state.change.logger)
2025-10-15 20:37:42.021 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-6 (state.change.logger)
2025-10-15 20:37:42.021 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-43 (state.change.logger)
2025-10-15 20:37:42.021 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-13 (state.change.logger)
2025-10-15 20:37:42.021 | [2025-10-16 01:37:42,018] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-28 (state.change.logger)
2025-10-15 20:37:42.027 | [2025-10-16 01:37:42,027] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.030 | [2025-10-16 01:37:42,030] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.031 | [2025-10-16 01:37:42,031] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.031 | [2025-10-16 01:37:42,031] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.031 | [2025-10-16 01:37:42,031] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.032 | [2025-10-16 01:37:42,031] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.032 | [2025-10-16 01:37:42,031] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.032 | [2025-10-16 01:37:42,031] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.032 | [2025-10-16 01:37:42,031] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.032 | [2025-10-16 01:37:42,032] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.032 | [2025-10-16 01:37:42,032] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.032 | [2025-10-16 01:37:42,032] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.032 | [2025-10-16 01:37:42,032] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.032 | [2025-10-16 01:37:42,032] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.032 | [2025-10-16 01:37:42,032] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.032 | [2025-10-16 01:37:42,032] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.032 | [2025-10-16 01:37:42,032] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.032 | [2025-10-16 01:37:42,032] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.032 | [2025-10-16 01:37:42,032] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.032 | [2025-10-16 01:37:42,032] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.032 | [2025-10-16 01:37:42,032] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.032 | [2025-10-16 01:37:42,032] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.032 | [2025-10-16 01:37:42,032] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.032 | [2025-10-16 01:37:42,032] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.032 | [2025-10-16 01:37:42,032] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.032 | [2025-10-16 01:37:42,032] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.032 | [2025-10-16 01:37:42,032] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.032 | [2025-10-16 01:37:42,032] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.032 | [2025-10-16 01:37:42,032] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.032 | [2025-10-16 01:37:42,032] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.032 | [2025-10-16 01:37:42,032] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.032 | [2025-10-16 01:37:42,032] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.032 | [2025-10-16 01:37:42,032] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.032 | [2025-10-16 01:37:42,032] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.032 | [2025-10-16 01:37:42,032] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.033 | [2025-10-16 01:37:42,032] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,032] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,033] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,033] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,033] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,033] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,033] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,033] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,033] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,033] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,033] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,033] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,033] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,033] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,033] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,033] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,033] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,033] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,033] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,033] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,033] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,033] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,033] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,033] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,033] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,033] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,033] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.034 | [2025-10-16 01:37:42,033] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.043 | [2025-10-16 01:37:42,042] INFO [Broker id=1] Finished LeaderAndIsr request in 754ms correlationId 1 from controller 1 for 51 partitions (state.change.logger)
2025-10-15 20:37:42.052 | [2025-10-16 01:37:42,049] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 17 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.053 | [2025-10-16 01:37:42,053] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 22 milliseconds for epoch 0, of which 22 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.054 | [2025-10-16 01:37:42,053] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 22 milliseconds for epoch 0, of which 22 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.054 | [2025-10-16 01:37:42,054] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 23 milliseconds for epoch 0, of which 23 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.054 | [2025-10-16 01:37:42,054] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 22 milliseconds for epoch 0, of which 22 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.055 | [2025-10-16 01:37:42,055] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 22 milliseconds for epoch 0, of which 22 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.056 | [2025-10-16 01:37:42,055] TRACE [Controller id=1 epoch=4] Received response LeaderAndIsrResponseData(errorCode=0, partitionErrors=[], topics=[LeaderAndIsrTopicError(topicId=6ep0dUNwQAaqKr79SJ8ITA, partitionErrors=[LeaderAndIsrPartitionError(topicName='', partitionIndex=13, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=46, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=9, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=42, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=21, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=17, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=30, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=26, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=5, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=38, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=1, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=34, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=16, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=45, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=12, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=41, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=24, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=20, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=49, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=0, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=29, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=25, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=8, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=37, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=4, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=33, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=15, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=48, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=11, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=44, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=23, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=19, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=32, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=28, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=7, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=40, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=3, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=36, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=47, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=14, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=43, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=10, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=22, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=18, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=31, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=27, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=39, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=6, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=35, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=2, errorCode=0)]), LeaderAndIsrTopicError(topicId=yWm6W48_TyqOOX8W2L0ItA, partitionErrors=[LeaderAndIsrPartitionError(topicName='', partitionIndex=0, errorCode=0)])]) for request LEADER_AND_ISR with correlation id 1 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-13 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-46 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-9 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-42 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-21 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-17 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-30 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-26 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-5 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-38 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-1 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-34 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-16 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-45 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-12 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-41 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-24 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-20 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-49 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-0 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-29 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-25 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-8 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-37 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-4 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-33 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-15 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-48 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-11 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-44 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-23 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-19 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-32 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-28 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-7 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-40 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-3 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-36 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-47 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-14 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-43 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-10 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-22 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-18 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-31 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-27 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-39 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-6 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-35 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.062 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-2 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.063 | [2025-10-16 01:37:42,062] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='mesa-ya.restaurants.created', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition mesa-ya.restaurants.created-0 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.064 | [2025-10-16 01:37:42,063] INFO [Broker id=1] Add 51 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-10-15 20:37:42.069 | [2025-10-16 01:37:42,065] TRACE [Controller id=1 epoch=4] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 2 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-10-15 20:37:42.092 | [2025-10-16 01:37:42,092] INFO Loaded member MemberMetadata(memberId=mesa-ya-service-client-9a0094a4-6972-4e79-a5d6-5ed4ed5cfa65, groupInstanceId=None, clientId=mesa-ya-service-client, clientHost=/172.18.0.4, sessionTimeoutMs=30000, rebalanceTimeoutMs=60000, supportedProtocols=List(NestReplyPartitionAssigner)) in group nestjs-group-client with generation 1. (kafka.coordinator.group.GroupMetadata$)
2025-10-15 20:37:42.101 | [2025-10-16 01:37:42,100] INFO Loaded member MemberMetadata(memberId=mesa-ya-service-client-72bf5d0c-5531-4f4b-bc39-f00715991c39, groupInstanceId=None, clientId=mesa-ya-service-client, clientHost=/172.18.0.4, sessionTimeoutMs=30000, rebalanceTimeoutMs=60000, supportedProtocols=List(NestReplyPartitionAssigner)) in group nestjs-group-client with generation 3. (kafka.coordinator.group.GroupMetadata$)
2025-10-15 20:37:42.102 | [2025-10-16 01:37:42,102] INFO [GroupCoordinator 1]: Loading group metadata for nestjs-group-client with generation 3 (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:37:42.108 | [2025-10-16 01:37:42,108] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 76 milliseconds for epoch 0, of which 23 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.108 | [2025-10-16 01:37:42,108] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 76 milliseconds for epoch 0, of which 76 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.109 | [2025-10-16 01:37:42,108] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 76 milliseconds for epoch 0, of which 76 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.109 | [2025-10-16 01:37:42,109] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 77 milliseconds for epoch 0, of which 77 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.109 | [2025-10-16 01:37:42,109] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 77 milliseconds for epoch 0, of which 77 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.109 | [2025-10-16 01:37:42,109] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 77 milliseconds for epoch 0, of which 77 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.109 | [2025-10-16 01:37:42,109] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 77 milliseconds for epoch 0, of which 77 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.110 | [2025-10-16 01:37:42,109] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 77 milliseconds for epoch 0, of which 77 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.110 | [2025-10-16 01:37:42,110] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 78 milliseconds for epoch 0, of which 77 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.110 | [2025-10-16 01:37:42,110] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 78 milliseconds for epoch 0, of which 78 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.110 | [2025-10-16 01:37:42,110] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 78 milliseconds for epoch 0, of which 78 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.110 | [2025-10-16 01:37:42,110] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 78 milliseconds for epoch 0, of which 78 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.110 | [2025-10-16 01:37:42,110] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 78 milliseconds for epoch 0, of which 78 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.110 | [2025-10-16 01:37:42,110] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 78 milliseconds for epoch 0, of which 78 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.110 | [2025-10-16 01:37:42,110] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 78 milliseconds for epoch 0, of which 78 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.111 | [2025-10-16 01:37:42,110] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 78 milliseconds for epoch 0, of which 78 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.111 | [2025-10-16 01:37:42,111] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 79 milliseconds for epoch 0, of which 79 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.111 | [2025-10-16 01:37:42,111] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 79 milliseconds for epoch 0, of which 79 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.111 | [2025-10-16 01:37:42,111] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 79 milliseconds for epoch 0, of which 79 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.111 | [2025-10-16 01:37:42,111] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 79 milliseconds for epoch 0, of which 79 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.111 | [2025-10-16 01:37:42,111] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 79 milliseconds for epoch 0, of which 79 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.112 | [2025-10-16 01:37:42,111] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 79 milliseconds for epoch 0, of which 79 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.112 | [2025-10-16 01:37:42,111] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 79 milliseconds for epoch 0, of which 79 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.112 | [2025-10-16 01:37:42,112] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 80 milliseconds for epoch 0, of which 79 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.112 | [2025-10-16 01:37:42,112] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 80 milliseconds for epoch 0, of which 80 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.112 | [2025-10-16 01:37:42,112] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 80 milliseconds for epoch 0, of which 80 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.112 | [2025-10-16 01:37:42,112] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 80 milliseconds for epoch 0, of which 80 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.112 | [2025-10-16 01:37:42,112] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 80 milliseconds for epoch 0, of which 80 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.112 | [2025-10-16 01:37:42,112] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 80 milliseconds for epoch 0, of which 80 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.112 | [2025-10-16 01:37:42,112] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 80 milliseconds for epoch 0, of which 80 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.113 | [2025-10-16 01:37:42,112] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 79 milliseconds for epoch 0, of which 79 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.113 | [2025-10-16 01:37:42,113] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 80 milliseconds for epoch 0, of which 80 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.113 | [2025-10-16 01:37:42,113] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 80 milliseconds for epoch 0, of which 80 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.113 | [2025-10-16 01:37:42,113] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 80 milliseconds for epoch 0, of which 80 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.113 | [2025-10-16 01:37:42,113] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 80 milliseconds for epoch 0, of which 80 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.113 | [2025-10-16 01:37:42,113] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 80 milliseconds for epoch 0, of which 80 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.114 | [2025-10-16 01:37:42,113] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 80 milliseconds for epoch 0, of which 80 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.114 | [2025-10-16 01:37:42,113] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 80 milliseconds for epoch 0, of which 80 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.114 | [2025-10-16 01:37:42,114] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 81 milliseconds for epoch 0, of which 80 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.114 | [2025-10-16 01:37:42,114] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 81 milliseconds for epoch 0, of which 81 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.114 | [2025-10-16 01:37:42,114] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 81 milliseconds for epoch 0, of which 81 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.114 | [2025-10-16 01:37:42,114] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 81 milliseconds for epoch 0, of which 81 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.114 | [2025-10-16 01:37:42,114] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 81 milliseconds for epoch 0, of which 81 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:42.114 | [2025-10-16 01:37:42,114] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 81 milliseconds for epoch 0, of which 81 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-15 20:37:46.016 | [2025-10-16 01:37:46,015] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-15 20:37:46.017 | [2025-10-16 01:37:46,017] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-15 20:37:46.025 | [2025-10-16 01:37:46,024] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-15 20:37:46.028 | [2025-10-16 01:37:46,027] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-15 20:38:11.924 | [2025-10-16 01:38:11,923] INFO [GroupCoordinator 1]: Member mesa-ya-service-client-72bf5d0c-5531-4f4b-bc39-f00715991c39 in group nestjs-group-client has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:38:11.931 | [2025-10-16 01:38:11,930] INFO [GroupCoordinator 1]: Preparing to rebalance group nestjs-group-client in state PreparingRebalance with old generation 3 (__consumer_offsets-19) (reason: removing member mesa-ya-service-client-72bf5d0c-5531-4f4b-bc39-f00715991c39 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:38:11.934 | [2025-10-16 01:38:11,933] INFO [GroupCoordinator 1]: Group nestjs-group-client with generation 4 is now empty (__consumer_offsets-19) (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:42:30.743 | [2025-10-16 01:42:30,741] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
2025-10-15 20:42:30.746 | [2025-10-16 01:42:30,745] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
2025-10-15 20:42:30.748 | [2025-10-16 01:42:30,748] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
2025-10-15 20:42:30.766 | [2025-10-16 01:42:30,766] INFO [Controller id=1] Shutting down broker 1 (kafka.controller.KafkaController)
2025-10-15 20:42:30.766 | [2025-10-16 01:42:30,766] DEBUG [Controller id=1] All shutting down brokers: 1 (kafka.controller.KafkaController)
2025-10-15 20:42:30.767 | [2025-10-16 01:42:30,767] DEBUG [Controller id=1] Live brokers:  (kafka.controller.KafkaController)
2025-10-15 20:42:30.770 | [2025-10-16 01:42:30,770] INFO [Controller id=1 epoch=4] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-10-15 20:42:30.772 | [2025-10-16 01:42:30,771] TRACE [Controller id=1] All leaders = __consumer_offsets-13 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-46 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-9 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-42 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-21 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-17 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-30 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-26 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-5 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-38 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-1 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-34 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-16 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-45 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-12 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-41 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-24 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-20 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-49 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-0 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-29 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-25 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-8 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-37 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-4 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-33 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-15 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-48 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-11 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-44 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-23 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-19 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-32 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-28 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-7 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-40 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-3 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-36 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-47 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-14 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-43 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-10 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-22 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-18 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-31 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-27 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-39 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-6 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-35 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),mesa-ya.restaurants.created-0 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-2 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1) (kafka.controller.KafkaController)
2025-10-15 20:42:30.775 | [2025-10-16 01:42:30,774] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 13ms (kafka.server.KafkaServer)
2025-10-15 20:42:30.780 | [2025-10-16 01:42:30,779] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-10-15 20:42:30.782 | [2025-10-16 01:42:30,781] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-10-15 20:42:30.782 | [2025-10-16 01:42:30,781] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-10-15 20:42:30.784 | [2025-10-16 01:42:30,783] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
2025-10-15 20:42:30.805 | [2025-10-16 01:42:30,805] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
2025-10-15 20:42:30.807 | [2025-10-16 01:42:30,806] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
2025-10-15 20:42:30.812 | [2025-10-16 01:42:30,811] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
2025-10-15 20:42:30.818 | [2025-10-16 01:42:30,818] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:42:30.821 | [2025-10-16 01:42:30,821] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:42:30.821 | [2025-10-16 01:42:30,821] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:42:30.823 | [2025-10-16 01:42:30,822] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
2025-10-15 20:42:30.825 | [2025-10-16 01:42:30,825] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:42:30.827 | [2025-10-16 01:42:30,827] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:42:30.828 | [2025-10-16 01:42:30,827] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:42:30.830 | [2025-10-16 01:42:30,829] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
2025-10-15 20:42:30.832 | [2025-10-16 01:42:30,831] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
2025-10-15 20:42:30.833 | [2025-10-16 01:42:30,832] INFO [TxnMarkerSenderThread-1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-10-15 20:42:30.833 | [2025-10-16 01:42:30,833] INFO [TxnMarkerSenderThread-1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-10-15 20:42:30.833 | [2025-10-16 01:42:30,833] INFO [TxnMarkerSenderThread-1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-10-15 20:42:30.835 | [2025-10-16 01:42:30,835] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
2025-10-15 20:42:30.836 | [2025-10-16 01:42:30,836] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:42:30.838 | [2025-10-16 01:42:30,837] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:42:30.840 | [2025-10-16 01:42:30,839] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:42:30.840 | [2025-10-16 01:42:30,839] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:42:30.841 | [2025-10-16 01:42:30,840] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:42:30.843 | [2025-10-16 01:42:30,843] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:42:30.843 | [2025-10-16 01:42:30,843] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:42:30.845 | [2025-10-16 01:42:30,845] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
2025-10-15 20:42:30.847 | [2025-10-16 01:42:30,847] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
2025-10-15 20:42:30.849 | [2025-10-16 01:42:30,848] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-10-15 20:42:30.850 | [2025-10-16 01:42:30,849] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-10-15 20:42:30.850 | [2025-10-16 01:42:30,849] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-10-15 20:42:30.851 | [2025-10-16 01:42:30,850] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
2025-10-15 20:42:30.853 | [2025-10-16 01:42:30,852] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
2025-10-15 20:42:30.853 | [2025-10-16 01:42:30,853] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
2025-10-15 20:42:30.854 | [2025-10-16 01:42:30,853] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
2025-10-15 20:42:30.854 | [2025-10-16 01:42:30,854] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:42:30.857 | [2025-10-16 01:42:30,856] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:42:30.857 | [2025-10-16 01:42:30,856] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:42:30.858 | [2025-10-16 01:42:30,857] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:42:30.860 | [2025-10-16 01:42:30,860] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:42:30.860 | [2025-10-16 01:42:30,860] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:42:30.862 | [2025-10-16 01:42:30,861] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:42:30.864 | [2025-10-16 01:42:30,864] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:42:30.864 | [2025-10-16 01:42:30,864] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:42:30.865 | [2025-10-16 01:42:30,865] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:42:30.867 | [2025-10-16 01:42:30,867] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:42:30.867 | [2025-10-16 01:42:30,867] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-15 20:42:30.883 | [2025-10-16 01:42:30,882] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
2025-10-15 20:42:30.883 | [2025-10-16 01:42:30,883] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:42:30.883 | [2025-10-16 01:42:30,883] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:42:30.883 | [2025-10-16 01:42:30,883] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:42:30.886 | [2025-10-16 01:42:30,886] INFO Broker to controller channel manager for alter-partition shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
2025-10-15 20:42:30.886 | [2025-10-16 01:42:30,886] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:42:30.887 | [2025-10-16 01:42:30,886] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Stopped (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:42:30.887 | [2025-10-16 01:42:30,886] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
2025-10-15 20:42:30.888 | [2025-10-16 01:42:30,888] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
2025-10-15 20:42:30.889 | [2025-10-16 01:42:30,888] INFO Shutting down. (kafka.log.LogManager)
2025-10-15 20:42:30.890 | [2025-10-16 01:42:30,889] INFO Shutting down the log cleaner. (kafka.log.LogCleaner)
2025-10-15 20:42:30.890 | [2025-10-16 01:42:30,890] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
2025-10-15 20:42:30.891 | [2025-10-16 01:42:30,890] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
2025-10-15 20:42:30.891 | [2025-10-16 01:42:30,890] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
2025-10-15 20:42:31.026 | [2025-10-16 01:42:31,026] INFO [ProducerStateManager partition=__consumer_offsets-19]Wrote producer snapshot at offset 4 with 0 producer ids in 7 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
2025-10-15 20:42:31.610 | [2025-10-16 01:42:31,610] INFO Shutdown complete. (kafka.log.LogManager)
2025-10-15 20:42:31.611 | [2025-10-16 01:42:31,610] INFO [ControllerEventThread controllerId=1] Shutting down (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-10-15 20:42:31.612 | [2025-10-16 01:42:31,611] INFO [ControllerEventThread controllerId=1] Shutdown completed (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-10-15 20:42:31.612 | [2025-10-16 01:42:31,611] INFO [ControllerEventThread controllerId=1] Stopped (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-10-15 20:42:31.613 | [2025-10-16 01:42:31,613] DEBUG [Controller id=1] Resigning (kafka.controller.KafkaController)
2025-10-15 20:42:31.614 | [2025-10-16 01:42:31,614] DEBUG [Controller id=1] Unregister BrokerModifications handler for Set(1) (kafka.controller.KafkaController)
2025-10-15 20:42:31.617 | [2025-10-16 01:42:31,616] INFO [PartitionStateMachine controllerId=1] Stopped partition state machine (kafka.controller.ZkPartitionStateMachine)
2025-10-15 20:42:31.618 | [2025-10-16 01:42:31,618] INFO [ReplicaStateMachine controllerId=1] Stopped replica state machine (kafka.controller.ZkReplicaStateMachine)
2025-10-15 20:42:31.619 | [2025-10-16 01:42:31,619] INFO [RequestSendThread controllerId=1] Shutting down (kafka.controller.RequestSendThread)
2025-10-15 20:42:31.620 | [2025-10-16 01:42:31,619] INFO [RequestSendThread controllerId=1] Shutdown completed (kafka.controller.RequestSendThread)
2025-10-15 20:42:31.620 | [2025-10-16 01:42:31,619] INFO [RequestSendThread controllerId=1] Stopped (kafka.controller.RequestSendThread)
2025-10-15 20:42:31.623 | [2025-10-16 01:42:31,623] INFO [Controller id=1] Resigned (kafka.controller.KafkaController)
2025-10-15 20:42:31.624 | [2025-10-16 01:42:31,624] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-10-15 20:42:31.625 | [2025-10-16 01:42:31,624] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-10-15 20:42:31.625 | [2025-10-16 01:42:31,624] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-10-15 20:42:31.626 | [2025-10-16 01:42:31,625] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
2025-10-15 20:42:31.738 | [2025-10-16 01:42:31,737] INFO Session: 0x10000457b300001 closed (org.apache.zookeeper.ZooKeeper)
2025-10-15 20:42:31.738 | [2025-10-16 01:42:31,737] INFO EventThread shut down for session: 0x10000457b300001 (org.apache.zookeeper.ClientCnxn)
2025-10-15 20:42:31.741 | [2025-10-16 01:42:31,740] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
2025-10-15 20:42:31.742 | [2025-10-16 01:42:31,742] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:42:31.745 | [2025-10-16 01:42:31,745] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:42:31.745 | [2025-10-16 01:42:31,745] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:42:31.746 | [2025-10-16 01:42:31,746] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:42:31.746 | [2025-10-16 01:42:31,746] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:42:31.746 | [2025-10-16 01:42:31,746] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:42:31.747 | [2025-10-16 01:42:31,747] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:42:31.748 | [2025-10-16 01:42:31,747] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:42:31.748 | [2025-10-16 01:42:31,747] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:42:31.749 | [2025-10-16 01:42:31,748] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:42:31.749 | [2025-10-16 01:42:31,748] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:42:31.749 | [2025-10-16 01:42:31,749] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-15 20:42:31.751 | [2025-10-16 01:42:31,750] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
2025-10-15 20:42:31.775 | [2025-10-16 01:42:31,775] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
2025-10-15 20:42:31.776 | [2025-10-16 01:42:31,776] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
2025-10-15 20:42:31.776 | [2025-10-16 01:42:31,776] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
2025-10-15 20:42:31.776 | [2025-10-16 01:42:31,776] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
2025-10-15 20:42:31.777 | [2025-10-16 01:42:31,777] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
2025-10-15 20:42:31.778 | [2025-10-16 01:42:31,778] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
2025-10-15 20:42:31.779 | [2025-10-16 01:42:31,778] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
2025-10-19 12:06:59.862 | ===> User
2025-10-19 12:06:59.870 | uid=1000(appuser) gid=1000(appuser) groups=1000(appuser)
2025-10-19 12:06:59.871 | ===> Configuring ...
2025-10-19 12:06:59.880 | Running in Zookeeper mode...
2025-10-19 12:07:04.018 | ===> Running preflight checks ... 
2025-10-19 12:07:04.024 | ===> Check if /var/lib/kafka/data is writable ...
2025-10-19 12:07:04.050 | ===> Check if Zookeeper is healthy ...
2025-10-19 12:07:05.173 | [2025-10-19 17:07:05,171] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:05.173 | [2025-10-19 17:07:05,172] INFO Client environment:host.name=2ae4b23f74a4 (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:05.173 | [2025-10-19 17:07:05,172] INFO Client environment:java.version=11.0.20 (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:05.173 | [2025-10-19 17:07:05,172] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:05.173 | [2025-10-19 17:07:05,172] INFO Client environment:java.home=/usr/lib/jvm/java-11-zulu-openjdk-ca (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:05.173 | [2025-10-19 17:07:05,172] INFO Client environment:java.class.path=/usr/share/java/cp-base-new/minimal-json-0.9.5.jar:/usr/share/java/cp-base-new/kafka-clients-7.5.0-ccs.jar:/usr/share/java/cp-base-new/slf4j-api-1.7.36.jar:/usr/share/java/cp-base-new/jmx_prometheus_javaagent-0.18.0.jar:/usr/share/java/cp-base-new/jackson-annotations-2.14.2.jar:/usr/share/java/cp-base-new/scala-collection-compat_2.13-2.10.0.jar:/usr/share/java/cp-base-new/gson-2.9.0.jar:/usr/share/java/cp-base-new/kafka-server-common-7.5.0-ccs.jar:/usr/share/java/cp-base-new/jose4j-0.9.3.jar:/usr/share/java/cp-base-new/scala-reflect-2.13.10.jar:/usr/share/java/cp-base-new/zstd-jni-1.5.5-1.jar:/usr/share/java/cp-base-new/jackson-datatype-jdk8-2.14.2.jar:/usr/share/java/cp-base-new/kafka-storage-7.5.0-ccs.jar:/usr/share/java/cp-base-new/reload4j-1.2.19.jar:/usr/share/java/cp-base-new/kafka-raft-7.5.0-ccs.jar:/usr/share/java/cp-base-new/logredactor-1.0.12.jar:/usr/share/java/cp-base-new/jackson-module-scala_2.13-2.14.2.jar:/usr/share/java/cp-base-new/paranamer-2.8.jar:/usr/share/java/cp-base-new/utility-belt-7.5.0.jar:/usr/share/java/cp-base-new/snakeyaml-2.0.jar:/usr/share/java/cp-base-new/metrics-core-2.2.0.jar:/usr/share/java/cp-base-new/metrics-core-4.1.12.1.jar:/usr/share/java/cp-base-new/kafka-tools-api-7.5.0-ccs.jar:/usr/share/java/cp-base-new/logredactor-metrics-1.0.12.jar:/usr/share/java/cp-base-new/scala-logging_2.13-3.9.4.jar:/usr/share/java/cp-base-new/jolokia-core-1.7.1.jar:/usr/share/java/cp-base-new/kafka-metadata-7.5.0-ccs.jar:/usr/share/java/cp-base-new/audience-annotations-0.5.0.jar:/usr/share/java/cp-base-new/argparse4j-0.7.0.jar:/usr/share/java/cp-base-new/kafka-storage-api-7.5.0-ccs.jar:/usr/share/java/cp-base-new/jopt-simple-5.0.4.jar:/usr/share/java/cp-base-new/jackson-dataformat-csv-2.14.2.jar:/usr/share/java/cp-base-new/jackson-core-2.14.2.jar:/usr/share/java/cp-base-new/snappy-java-1.1.10.1.jar:/usr/share/java/cp-base-new/scala-java8-compat_2.13-1.0.2.jar:/usr/share/java/cp-base-new/disk-usage-agent-7.5.0.jar:/usr/share/java/cp-base-new/commons-cli-1.4.jar:/usr/share/java/cp-base-new/common-utils-7.5.0.jar:/usr/share/java/cp-base-new/jolokia-jvm-1.7.1.jar:/usr/share/java/cp-base-new/lz4-java-1.8.0.jar:/usr/share/java/cp-base-new/json-simple-1.1.1.jar:/usr/share/java/cp-base-new/zookeeper-3.6.3.jar:/usr/share/java/cp-base-new/kafka_2.13-7.5.0-ccs.jar:/usr/share/java/cp-base-new/jackson-databind-2.14.2.jar:/usr/share/java/cp-base-new/kafka-group-coordinator-7.5.0-ccs.jar:/usr/share/java/cp-base-new/slf4j-reload4j-1.7.36.jar:/usr/share/java/cp-base-new/zookeeper-jute-3.6.3.jar:/usr/share/java/cp-base-new/scala-library-2.13.10.jar:/usr/share/java/cp-base-new/re2j-1.6.jar:/usr/share/java/cp-base-new/jackson-dataformat-yaml-2.14.2.jar (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:05.173 | [2025-10-19 17:07:05,172] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:05.173 | [2025-10-19 17:07:05,173] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:05.173 | [2025-10-19 17:07:05,173] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:05.173 | [2025-10-19 17:07:05,173] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:05.173 | [2025-10-19 17:07:05,173] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:05.173 | [2025-10-19 17:07:05,173] INFO Client environment:os.version=6.6.87.1-microsoft-standard-WSL2 (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:05.173 | [2025-10-19 17:07:05,173] INFO Client environment:user.name=appuser (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:05.173 | [2025-10-19 17:07:05,173] INFO Client environment:user.home=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:05.173 | [2025-10-19 17:07:05,173] INFO Client environment:user.dir=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:05.173 | [2025-10-19 17:07:05,173] INFO Client environment:os.memory.free=112MB (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:05.173 | [2025-10-19 17:07:05,173] INFO Client environment:os.memory.max=1948MB (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:05.173 | [2025-10-19 17:07:05,173] INFO Client environment:os.memory.total=122MB (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:05.182 | [2025-10-19 17:07:05,182] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=40000 watcher=io.confluent.admin.utils.ZookeeperConnectionWatcher@221af3c0 (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:05.194 | [2025-10-19 17:07:05,193] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
2025-10-19 12:07:05.204 | [2025-10-19 17:07:05,203] INFO jute.maxbuffer value is 1048575 Bytes (org.apache.zookeeper.ClientCnxnSocket)
2025-10-19 12:07:05.217 | [2025-10-19 17:07:05,216] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
2025-10-19 12:07:05.258 | [2025-10-19 17:07:05,254] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. (org.apache.zookeeper.ClientCnxn)
2025-10-19 12:07:05.258 | [2025-10-19 17:07:05,258] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-10-19 12:07:05.273 | [2025-10-19 17:07:05,273] INFO Socket connection established, initiating session, client: /172.18.0.3:44140, server: zookeeper/172.18.0.2:2181 (org.apache.zookeeper.ClientCnxn)
2025-10-19 12:07:05.319 | [2025-10-19 17:07:05,319] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, session id = 0x10000049fb70000, negotiated timeout = 40000 (org.apache.zookeeper.ClientCnxn)
2025-10-19 12:07:05.352 | [2025-10-19 17:07:05,346] WARN An exception was thrown while closing send thread for session 0x10000049fb70000. (org.apache.zookeeper.ClientCnxn)
2025-10-19 12:07:05.352 | EndOfStreamException: Unable to read additional data from server sessionid 0x10000049fb70000, likely server has closed socket
2025-10-19 12:07:05.352 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
2025-10-19 12:07:05.352 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
2025-10-19 12:07:05.352 | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-10-19 12:07:05.457 | [2025-10-19 17:07:05,457] INFO Session: 0x10000049fb70000 closed (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:05.458 | [2025-10-19 17:07:05,457] INFO EventThread shut down for session: 0x10000049fb70000 (org.apache.zookeeper.ClientCnxn)
2025-10-19 12:07:05.469 | Using log4j config /etc/kafka/log4j.properties
2025-10-19 12:07:05.580 | ===> Launching ... 
2025-10-19 12:07:05.593 | ===> Launching kafka ... 
2025-10-19 12:07:06.663 | [2025-10-19 17:07:06,662] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
2025-10-19 12:07:07.292 | [2025-10-19 17:07:07,291] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
2025-10-19 12:07:07.421 | [2025-10-19 17:07:07,421] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
2025-10-19 12:07:07.424 | [2025-10-19 17:07:07,424] INFO starting (kafka.server.KafkaServer)
2025-10-19 12:07:07.425 | [2025-10-19 17:07:07,424] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
2025-10-19 12:07:07.454 | [2025-10-19 17:07:07,454] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
2025-10-19 12:07:07.466 | [2025-10-19 17:07:07,466] INFO Client environment:zookeeper.version=3.6.4--d65253dcf68e9097c6e95a126463fd5fdeb4521c, built on 12/18/2022 18:10 GMT (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:07.466 | [2025-10-19 17:07:07,466] INFO Client environment:host.name=2ae4b23f74a4 (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:07.466 | [2025-10-19 17:07:07,466] INFO Client environment:java.version=11.0.20 (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:07.466 | [2025-10-19 17:07:07,466] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:07.466 | [2025-10-19 17:07:07,466] INFO Client environment:java.home=/usr/lib/jvm/java-11-zulu-openjdk-ca (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:07.466 | [2025-10-19 17:07:07,466] INFO Client environment:java.class.path=/usr/bin/../share/java/kafka/zookeeper-jute-3.6.4.jar:/usr/bin/../share/java/kafka/jackson-datatype-jdk8-2.13.5.jar:/usr/bin/../share/java/kafka/jakarta.inject-2.6.1.jar:/usr/bin/../share/java/kafka/netty-transport-native-epoll-4.1.96.Final.jar:/usr/bin/../share/java/kafka/kafka-clients-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jline-3.22.0.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.36.jar:/usr/bin/../share/java/kafka/reflections-0.9.12.jar:/usr/bin/../share/java/kafka/scala-collection-compat_2.13-2.10.0.jar:/usr/bin/../share/java/kafka/javassist-3.29.2-GA.jar:/usr/bin/../share/java/kafka/connect-runtime-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jakarta.annotation-api-1.3.5.jar:/usr/bin/../share/java/kafka/jackson-databind-2.13.5.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/kafka-streams-scala_2.13-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/javax.activation-api-1.2.0.jar:/usr/bin/../share/java/kafka/rocksdbjni-7.1.2.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/usr/bin/../share/java/kafka/kafka-server-common-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jose4j-0.9.3.jar:/usr/bin/../share/java/kafka/scala-reflect-2.13.10.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.13.5.jar:/usr/bin/../share/java/kafka/zstd-jni-1.5.5-1.jar:/usr/bin/../share/java/kafka/kafka-storage-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jetty-security-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.39.1.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/kafka-raft-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/netty-transport-native-unix-common-4.1.96.Final.jar:/usr/bin/../share/java/kafka/jersey-server-2.39.1.jar:/usr/bin/../share/java/kafka/paranamer-2.8.jar:/usr/bin/../share/java/kafka/jersey-common-2.39.1.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/netty-transport-4.1.96.Final.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/metrics-core-4.1.12.1.jar:/usr/bin/../share/java/kafka/netty-buffer-4.1.96.Final.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.13.5.jar:/usr/bin/../share/java/kafka/netty-resolver-4.1.96.Final.jar:/usr/bin/../share/java/kafka/kafka-tools-api-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jaxb-api-2.3.1.jar:/usr/bin/../share/java/kafka/jetty-util-ajax-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/scala-logging_2.13-3.9.4.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.6.1.jar:/usr/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/usr/bin/../share/java/kafka/jakarta.xml.bind-api-2.3.3.jar:/usr/bin/../share/java/kafka/kafka-metadata-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/plexus-utils-3.3.0.jar:/usr/bin/../share/java/kafka/jakarta.activation-api-1.2.2.jar:/usr/bin/../share/java/kafka/argparse4j-0.7.0.jar:/usr/bin/../share/java/kafka/hk2-utils-2.6.1.jar:/usr/bin/../share/java/kafka/connect-api-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/connect-mirror-client-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.3.jar:/usr/bin/../share/java/kafka/javax.annotation-api-1.3.2.jar:/usr/bin/../share/java/kafka/jersey-hk2-2.39.1.jar:/usr/bin/../share/java/kafka/kafka-storage-api-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jetty-http-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/trogdor-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/maven-artifact-3.8.4.jar:/usr/bin/../share/java/kafka/connect-json-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/scala-java8-compat_2.13-1.0.2.jar:/usr/bin/../share/java/kafka/jetty-server-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/swagger-annotations-2.2.8.jar:/usr/bin/../share/java/kafka/jetty-util-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/commons-cli-1.4.jar:/usr/bin/../share/java/kafka/jetty-io-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/activation-1.1.1.jar:/usr/bin/../share/java/kafka/lz4-java-1.8.0.jar:/usr/bin/../share/java/kafka/kafka-shell-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/netty-common-4.1.96.Final.jar:/usr/bin/../share/java/kafka/jetty-client-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/jackson-module-scala_2.13-2.13.5.jar:/usr/bin/../share/java/kafka/connect-transforms-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jackson-core-2.13.5.jar:/usr/bin/../share/java/kafka/kafka_2.13-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/netty-codec-4.1.96.Final.jar:/usr/bin/../share/java/kafka/zookeeper-3.6.4.jar:/usr/bin/../share/java/kafka/kafka-streams-test-utils-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/hk2-api-2.6.1.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.39.1.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/reload4j-1.2.25.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.10.0.jar:/usr/bin/../share/java/kafka/netty-transport-classes-epoll-4.1.96.Final.jar:/usr/bin/../share/java/kafka/connect-mirror-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/kafka-streams-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/kafka-group-coordinator-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/connect-basic-auth-extension-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jersey-client-2.39.1.jar:/usr/bin/../share/java/kafka/kafka-tools-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/slf4j-reload4j-1.7.36.jar:/usr/bin/../share/java/kafka/jackson-dataformat-csv-2.13.5.jar:/usr/bin/../share/java/kafka/scala-library-2.13.10.jar:/usr/bin/../share/java/kafka/netty-handler-4.1.96.Final.jar:/usr/bin/../share/java/kafka/jakarta.validation-api-2.0.2.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.13.5.jar:/usr/bin/../share/java/kafka/audience-annotations-0.13.0.jar:/usr/bin/../share/java/kafka/hk2-locator-2.6.1.jar:/usr/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.6.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.13.5.jar:/usr/bin/../share/java/confluent-telemetry/* (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:07.466 | [2025-10-19 17:07:07,466] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:07.466 | [2025-10-19 17:07:07,466] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:07.466 | [2025-10-19 17:07:07,466] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:07.466 | [2025-10-19 17:07:07,466] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:07.466 | [2025-10-19 17:07:07,466] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:07.466 | [2025-10-19 17:07:07,466] INFO Client environment:os.version=6.6.87.1-microsoft-standard-WSL2 (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:07.466 | [2025-10-19 17:07:07,466] INFO Client environment:user.name=appuser (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:07.466 | [2025-10-19 17:07:07,466] INFO Client environment:user.home=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:07.466 | [2025-10-19 17:07:07,466] INFO Client environment:user.dir=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:07.466 | [2025-10-19 17:07:07,466] INFO Client environment:os.memory.free=1009MB (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:07.466 | [2025-10-19 17:07:07,466] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:07.466 | [2025-10-19 17:07:07,466] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:07.471 | [2025-10-19 17:07:07,470] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@13d73fa (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:07:07.483 | [2025-10-19 17:07:07,482] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
2025-10-19 12:07:07.496 | [2025-10-19 17:07:07,496] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
2025-10-19 12:07:07.501 | [2025-10-19 17:07:07,501] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
2025-10-19 12:07:07.508 | [2025-10-19 17:07:07,506] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. (org.apache.zookeeper.ClientCnxn)
2025-10-19 12:07:07.519 | [2025-10-19 17:07:07,518] INFO Socket connection established, initiating session, client: /172.18.0.3:44156, server: zookeeper/172.18.0.2:2181 (org.apache.zookeeper.ClientCnxn)
2025-10-19 12:07:07.546 | [2025-10-19 17:07:07,545] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, session id = 0x10000049fb70001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
2025-10-19 12:07:07.554 | [2025-10-19 17:07:07,553] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
2025-10-19 12:07:08.005 | [2025-10-19 17:07:08,004] INFO Cluster ID = DgiegCMhTNSyWQSymt96xQ (kafka.server.KafkaServer)
2025-10-19 12:07:08.083 | [2025-10-19 17:07:08,082] INFO KafkaConfig values: 
2025-10-19 12:07:08.083 | 	advertised.listeners = PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
2025-10-19 12:07:08.083 | 	alter.config.policy.class.name = null
2025-10-19 12:07:08.083 | 	alter.log.dirs.replication.quota.window.num = 11
2025-10-19 12:07:08.083 | 	alter.log.dirs.replication.quota.window.size.seconds = 1
2025-10-19 12:07:08.083 | 	authorizer.class.name = 
2025-10-19 12:07:08.083 | 	auto.create.topics.enable = true
2025-10-19 12:07:08.083 | 	auto.include.jmx.reporter = true
2025-10-19 12:07:08.083 | 	auto.leader.rebalance.enable = true
2025-10-19 12:07:08.083 | 	background.threads = 10
2025-10-19 12:07:08.083 | 	broker.heartbeat.interval.ms = 2000
2025-10-19 12:07:08.083 | 	broker.id = 1
2025-10-19 12:07:08.083 | 	broker.id.generation.enable = true
2025-10-19 12:07:08.083 | 	broker.rack = null
2025-10-19 12:07:08.083 | 	broker.session.timeout.ms = 9000
2025-10-19 12:07:08.083 | 	client.quota.callback.class = null
2025-10-19 12:07:08.083 | 	compression.type = producer
2025-10-19 12:07:08.083 | 	connection.failed.authentication.delay.ms = 100
2025-10-19 12:07:08.083 | 	connections.max.idle.ms = 600000
2025-10-19 12:07:08.083 | 	connections.max.reauth.ms = 0
2025-10-19 12:07:08.083 | 	control.plane.listener.name = null
2025-10-19 12:07:08.083 | 	controlled.shutdown.enable = true
2025-10-19 12:07:08.083 | 	controlled.shutdown.max.retries = 3
2025-10-19 12:07:08.083 | 	controlled.shutdown.retry.backoff.ms = 5000
2025-10-19 12:07:08.083 | 	controller.listener.names = null
2025-10-19 12:07:08.083 | 	controller.quorum.append.linger.ms = 25
2025-10-19 12:07:08.083 | 	controller.quorum.election.backoff.max.ms = 1000
2025-10-19 12:07:08.083 | 	controller.quorum.election.timeout.ms = 1000
2025-10-19 12:07:08.083 | 	controller.quorum.fetch.timeout.ms = 2000
2025-10-19 12:07:08.083 | 	controller.quorum.request.timeout.ms = 2000
2025-10-19 12:07:08.083 | 	controller.quorum.retry.backoff.ms = 20
2025-10-19 12:07:08.083 | 	controller.quorum.voters = []
2025-10-19 12:07:08.083 | 	controller.quota.window.num = 11
2025-10-19 12:07:08.083 | 	controller.quota.window.size.seconds = 1
2025-10-19 12:07:08.083 | 	controller.socket.timeout.ms = 30000
2025-10-19 12:07:08.083 | 	create.topic.policy.class.name = null
2025-10-19 12:07:08.083 | 	default.replication.factor = 1
2025-10-19 12:07:08.083 | 	delegation.token.expiry.check.interval.ms = 3600000
2025-10-19 12:07:08.083 | 	delegation.token.expiry.time.ms = 86400000
2025-10-19 12:07:08.083 | 	delegation.token.master.key = null
2025-10-19 12:07:08.083 | 	delegation.token.max.lifetime.ms = 604800000
2025-10-19 12:07:08.083 | 	delegation.token.secret.key = null
2025-10-19 12:07:08.083 | 	delete.records.purgatory.purge.interval.requests = 1
2025-10-19 12:07:08.083 | 	delete.topic.enable = true
2025-10-19 12:07:08.083 | 	early.start.listeners = null
2025-10-19 12:07:08.083 | 	fetch.max.bytes = 57671680
2025-10-19 12:07:08.083 | 	fetch.purgatory.purge.interval.requests = 1000
2025-10-19 12:07:08.083 | 	group.consumer.assignors = []
2025-10-19 12:07:08.083 | 	group.consumer.heartbeat.interval.ms = 5000
2025-10-19 12:07:08.083 | 	group.consumer.max.heartbeat.interval.ms = 15000
2025-10-19 12:07:08.083 | 	group.consumer.max.session.timeout.ms = 60000
2025-10-19 12:07:08.083 | 	group.consumer.max.size = 2147483647
2025-10-19 12:07:08.083 | 	group.consumer.min.heartbeat.interval.ms = 5000
2025-10-19 12:07:08.083 | 	group.consumer.min.session.timeout.ms = 45000
2025-10-19 12:07:08.083 | 	group.consumer.session.timeout.ms = 45000
2025-10-19 12:07:08.083 | 	group.coordinator.new.enable = false
2025-10-19 12:07:08.083 | 	group.coordinator.threads = 1
2025-10-19 12:07:08.083 | 	group.initial.rebalance.delay.ms = 3000
2025-10-19 12:07:08.083 | 	group.max.session.timeout.ms = 1800000
2025-10-19 12:07:08.083 | 	group.max.size = 2147483647
2025-10-19 12:07:08.083 | 	group.min.session.timeout.ms = 6000
2025-10-19 12:07:08.083 | 	initial.broker.registration.timeout.ms = 60000
2025-10-19 12:07:08.083 | 	inter.broker.listener.name = PLAINTEXT_INTERNAL
2025-10-19 12:07:08.083 | 	inter.broker.protocol.version = 3.5-IV2
2025-10-19 12:07:08.083 | 	kafka.metrics.polling.interval.secs = 10
2025-10-19 12:07:08.083 | 	kafka.metrics.reporters = []
2025-10-19 12:07:08.083 | 	leader.imbalance.check.interval.seconds = 300
2025-10-19 12:07:08.083 | 	leader.imbalance.per.broker.percentage = 10
2025-10-19 12:07:08.083 | 	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
2025-10-19 12:07:08.083 | 	listeners = PLAINTEXT://0.0.0.0:9092,PLAINTEXT_INTERNAL://0.0.0.0:29092
2025-10-19 12:07:08.083 | 	log.cleaner.backoff.ms = 15000
2025-10-19 12:07:08.083 | 	log.cleaner.dedupe.buffer.size = 134217728
2025-10-19 12:07:08.083 | 	log.cleaner.delete.retention.ms = 86400000
2025-10-19 12:07:08.083 | 	log.cleaner.enable = true
2025-10-19 12:07:08.083 | 	log.cleaner.io.buffer.load.factor = 0.9
2025-10-19 12:07:08.083 | 	log.cleaner.io.buffer.size = 524288
2025-10-19 12:07:08.083 | 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
2025-10-19 12:07:08.083 | 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
2025-10-19 12:07:08.083 | 	log.cleaner.min.cleanable.ratio = 0.5
2025-10-19 12:07:08.083 | 	log.cleaner.min.compaction.lag.ms = 0
2025-10-19 12:07:08.083 | 	log.cleaner.threads = 1
2025-10-19 12:07:08.083 | 	log.cleanup.policy = [delete]
2025-10-19 12:07:08.083 | 	log.dir = /tmp/kafka-logs
2025-10-19 12:07:08.083 | 	log.dirs = /var/lib/kafka/data
2025-10-19 12:07:08.083 | 	log.flush.interval.messages = 9223372036854775807
2025-10-19 12:07:08.083 | 	log.flush.interval.ms = null
2025-10-19 12:07:08.083 | 	log.flush.offset.checkpoint.interval.ms = 60000
2025-10-19 12:07:08.083 | 	log.flush.scheduler.interval.ms = 9223372036854775807
2025-10-19 12:07:08.083 | 	log.flush.start.offset.checkpoint.interval.ms = 60000
2025-10-19 12:07:08.083 | 	log.index.interval.bytes = 4096
2025-10-19 12:07:08.083 | 	log.index.size.max.bytes = 10485760
2025-10-19 12:07:08.083 | 	log.message.downconversion.enable = true
2025-10-19 12:07:08.083 | 	log.message.format.version = 3.0-IV1
2025-10-19 12:07:08.083 | 	log.message.timestamp.difference.max.ms = 9223372036854775807
2025-10-19 12:07:08.083 | 	log.message.timestamp.type = CreateTime
2025-10-19 12:07:08.083 | 	log.preallocate = false
2025-10-19 12:07:08.083 | 	log.retention.bytes = -1
2025-10-19 12:07:08.083 | 	log.retention.check.interval.ms = 300000
2025-10-19 12:07:08.083 | 	log.retention.hours = 168
2025-10-19 12:07:08.083 | 	log.retention.minutes = null
2025-10-19 12:07:08.083 | 	log.retention.ms = null
2025-10-19 12:07:08.083 | 	log.roll.hours = 168
2025-10-19 12:07:08.083 | 	log.roll.jitter.hours = 0
2025-10-19 12:07:08.083 | 	log.roll.jitter.ms = null
2025-10-19 12:07:08.083 | 	log.roll.ms = null
2025-10-19 12:07:08.083 | 	log.segment.bytes = 1073741824
2025-10-19 12:07:08.083 | 	log.segment.delete.delay.ms = 60000
2025-10-19 12:07:08.083 | 	max.connection.creation.rate = 2147483647
2025-10-19 12:07:08.083 | 	max.connections = 2147483647
2025-10-19 12:07:08.083 | 	max.connections.per.ip = 2147483647
2025-10-19 12:07:08.083 | 	max.connections.per.ip.overrides = 
2025-10-19 12:07:08.083 | 	max.incremental.fetch.session.cache.slots = 1000
2025-10-19 12:07:08.083 | 	message.max.bytes = 1048588
2025-10-19 12:07:08.083 | 	metadata.log.dir = null
2025-10-19 12:07:08.083 | 	metadata.log.max.record.bytes.between.snapshots = 20971520
2025-10-19 12:07:08.083 | 	metadata.log.max.snapshot.interval.ms = 3600000
2025-10-19 12:07:08.083 | 	metadata.log.segment.bytes = 1073741824
2025-10-19 12:07:08.083 | 	metadata.log.segment.min.bytes = 8388608
2025-10-19 12:07:08.083 | 	metadata.log.segment.ms = 604800000
2025-10-19 12:07:08.083 | 	metadata.max.idle.interval.ms = 500
2025-10-19 12:07:08.083 | 	metadata.max.retention.bytes = 104857600
2025-10-19 12:07:08.083 | 	metadata.max.retention.ms = 604800000
2025-10-19 12:07:08.083 | 	metric.reporters = []
2025-10-19 12:07:08.083 | 	metrics.num.samples = 2
2025-10-19 12:07:08.083 | 	metrics.recording.level = INFO
2025-10-19 12:07:08.083 | 	metrics.sample.window.ms = 30000
2025-10-19 12:07:08.083 | 	min.insync.replicas = 1
2025-10-19 12:07:08.083 | 	node.id = 1
2025-10-19 12:07:08.083 | 	num.io.threads = 8
2025-10-19 12:07:08.083 | 	num.network.threads = 3
2025-10-19 12:07:08.083 | 	num.partitions = 1
2025-10-19 12:07:08.083 | 	num.recovery.threads.per.data.dir = 1
2025-10-19 12:07:08.084 | 	num.replica.alter.log.dirs.threads = null
2025-10-19 12:07:08.084 | 	num.replica.fetchers = 1
2025-10-19 12:07:08.084 | 	offset.metadata.max.bytes = 4096
2025-10-19 12:07:08.084 | 	offsets.commit.required.acks = -1
2025-10-19 12:07:08.084 | 	offsets.commit.timeout.ms = 5000
2025-10-19 12:07:08.084 | 	offsets.load.buffer.size = 5242880
2025-10-19 12:07:08.084 | 	offsets.retention.check.interval.ms = 600000
2025-10-19 12:07:08.084 | 	offsets.retention.minutes = 10080
2025-10-19 12:07:08.084 | 	offsets.topic.compression.codec = 0
2025-10-19 12:07:08.084 | 	offsets.topic.num.partitions = 50
2025-10-19 12:07:08.084 | 	offsets.topic.replication.factor = 1
2025-10-19 12:07:08.084 | 	offsets.topic.segment.bytes = 104857600
2025-10-19 12:07:08.084 | 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
2025-10-19 12:07:08.084 | 	password.encoder.iterations = 4096
2025-10-19 12:07:08.084 | 	password.encoder.key.length = 128
2025-10-19 12:07:08.084 | 	password.encoder.keyfactory.algorithm = null
2025-10-19 12:07:08.084 | 	password.encoder.old.secret = null
2025-10-19 12:07:08.084 | 	password.encoder.secret = null
2025-10-19 12:07:08.084 | 	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
2025-10-19 12:07:08.084 | 	process.roles = []
2025-10-19 12:07:08.084 | 	producer.id.expiration.check.interval.ms = 600000
2025-10-19 12:07:08.084 | 	producer.id.expiration.ms = 86400000
2025-10-19 12:07:08.084 | 	producer.purgatory.purge.interval.requests = 1000
2025-10-19 12:07:08.084 | 	queued.max.request.bytes = -1
2025-10-19 12:07:08.084 | 	queued.max.requests = 500
2025-10-19 12:07:08.084 | 	quota.window.num = 11
2025-10-19 12:07:08.084 | 	quota.window.size.seconds = 1
2025-10-19 12:07:08.084 | 	remote.log.index.file.cache.total.size.bytes = 1073741824
2025-10-19 12:07:08.084 | 	remote.log.manager.task.interval.ms = 30000
2025-10-19 12:07:08.084 | 	remote.log.manager.task.retry.backoff.max.ms = 30000
2025-10-19 12:07:08.084 | 	remote.log.manager.task.retry.backoff.ms = 500
2025-10-19 12:07:08.084 | 	remote.log.manager.task.retry.jitter = 0.2
2025-10-19 12:07:08.084 | 	remote.log.manager.thread.pool.size = 10
2025-10-19 12:07:08.084 | 	remote.log.metadata.manager.class.name = null
2025-10-19 12:07:08.084 | 	remote.log.metadata.manager.class.path = null
2025-10-19 12:07:08.084 | 	remote.log.metadata.manager.impl.prefix = null
2025-10-19 12:07:08.084 | 	remote.log.metadata.manager.listener.name = null
2025-10-19 12:07:08.084 | 	remote.log.reader.max.pending.tasks = 100
2025-10-19 12:07:08.084 | 	remote.log.reader.threads = 10
2025-10-19 12:07:08.084 | 	remote.log.storage.manager.class.name = null
2025-10-19 12:07:08.084 | 	remote.log.storage.manager.class.path = null
2025-10-19 12:07:08.084 | 	remote.log.storage.manager.impl.prefix = null
2025-10-19 12:07:08.084 | 	remote.log.storage.system.enable = false
2025-10-19 12:07:08.084 | 	replica.fetch.backoff.ms = 1000
2025-10-19 12:07:08.084 | 	replica.fetch.max.bytes = 1048576
2025-10-19 12:07:08.084 | 	replica.fetch.min.bytes = 1
2025-10-19 12:07:08.084 | 	replica.fetch.response.max.bytes = 10485760
2025-10-19 12:07:08.084 | 	replica.fetch.wait.max.ms = 500
2025-10-19 12:07:08.084 | 	replica.high.watermark.checkpoint.interval.ms = 5000
2025-10-19 12:07:08.084 | 	replica.lag.time.max.ms = 30000
2025-10-19 12:07:08.084 | 	replica.selector.class = null
2025-10-19 12:07:08.084 | 	replica.socket.receive.buffer.bytes = 65536
2025-10-19 12:07:08.084 | 	replica.socket.timeout.ms = 30000
2025-10-19 12:07:08.084 | 	replication.quota.window.num = 11
2025-10-19 12:07:08.084 | 	replication.quota.window.size.seconds = 1
2025-10-19 12:07:08.084 | 	request.timeout.ms = 30000
2025-10-19 12:07:08.084 | 	reserved.broker.max.id = 1000
2025-10-19 12:07:08.084 | 	sasl.client.callback.handler.class = null
2025-10-19 12:07:08.084 | 	sasl.enabled.mechanisms = [GSSAPI]
2025-10-19 12:07:08.084 | 	sasl.jaas.config = null
2025-10-19 12:07:08.084 | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
2025-10-19 12:07:08.084 | 	sasl.kerberos.min.time.before.relogin = 60000
2025-10-19 12:07:08.084 | 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
2025-10-19 12:07:08.084 | 	sasl.kerberos.service.name = null
2025-10-19 12:07:08.084 | 	sasl.kerberos.ticket.renew.jitter = 0.05
2025-10-19 12:07:08.084 | 	sasl.kerberos.ticket.renew.window.factor = 0.8
2025-10-19 12:07:08.084 | 	sasl.login.callback.handler.class = null
2025-10-19 12:07:08.084 | 	sasl.login.class = null
2025-10-19 12:07:08.084 | 	sasl.login.connect.timeout.ms = null
2025-10-19 12:07:08.084 | 	sasl.login.read.timeout.ms = null
2025-10-19 12:07:08.084 | 	sasl.login.refresh.buffer.seconds = 300
2025-10-19 12:07:08.084 | 	sasl.login.refresh.min.period.seconds = 60
2025-10-19 12:07:08.084 | 	sasl.login.refresh.window.factor = 0.8
2025-10-19 12:07:08.084 | 	sasl.login.refresh.window.jitter = 0.05
2025-10-19 12:07:08.084 | 	sasl.login.retry.backoff.max.ms = 10000
2025-10-19 12:07:08.084 | 	sasl.login.retry.backoff.ms = 100
2025-10-19 12:07:08.084 | 	sasl.mechanism.controller.protocol = GSSAPI
2025-10-19 12:07:08.084 | 	sasl.mechanism.inter.broker.protocol = GSSAPI
2025-10-19 12:07:08.084 | 	sasl.oauthbearer.clock.skew.seconds = 30
2025-10-19 12:07:08.084 | 	sasl.oauthbearer.expected.audience = null
2025-10-19 12:07:08.084 | 	sasl.oauthbearer.expected.issuer = null
2025-10-19 12:07:08.084 | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
2025-10-19 12:07:08.084 | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
2025-10-19 12:07:08.084 | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
2025-10-19 12:07:08.084 | 	sasl.oauthbearer.jwks.endpoint.url = null
2025-10-19 12:07:08.084 | 	sasl.oauthbearer.scope.claim.name = scope
2025-10-19 12:07:08.084 | 	sasl.oauthbearer.sub.claim.name = sub
2025-10-19 12:07:08.084 | 	sasl.oauthbearer.token.endpoint.url = null
2025-10-19 12:07:08.084 | 	sasl.server.callback.handler.class = null
2025-10-19 12:07:08.084 | 	sasl.server.max.receive.size = 524288
2025-10-19 12:07:08.084 | 	security.inter.broker.protocol = PLAINTEXT
2025-10-19 12:07:08.084 | 	security.providers = null
2025-10-19 12:07:08.084 | 	server.max.startup.time.ms = 9223372036854775807
2025-10-19 12:07:08.084 | 	socket.connection.setup.timeout.max.ms = 30000
2025-10-19 12:07:08.084 | 	socket.connection.setup.timeout.ms = 10000
2025-10-19 12:07:08.084 | 	socket.listen.backlog.size = 50
2025-10-19 12:07:08.084 | 	socket.receive.buffer.bytes = 102400
2025-10-19 12:07:08.084 | 	socket.request.max.bytes = 104857600
2025-10-19 12:07:08.084 | 	socket.send.buffer.bytes = 102400
2025-10-19 12:07:08.084 | 	ssl.cipher.suites = []
2025-10-19 12:07:08.084 | 	ssl.client.auth = none
2025-10-19 12:07:08.084 | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
2025-10-19 12:07:08.084 | 	ssl.endpoint.identification.algorithm = https
2025-10-19 12:07:08.084 | 	ssl.engine.factory.class = null
2025-10-19 12:07:08.084 | 	ssl.key.password = null
2025-10-19 12:07:08.084 | 	ssl.keymanager.algorithm = SunX509
2025-10-19 12:07:08.084 | 	ssl.keystore.certificate.chain = null
2025-10-19 12:07:08.084 | 	ssl.keystore.key = null
2025-10-19 12:07:08.084 | 	ssl.keystore.location = null
2025-10-19 12:07:08.084 | 	ssl.keystore.password = null
2025-10-19 12:07:08.084 | 	ssl.keystore.type = JKS
2025-10-19 12:07:08.084 | 	ssl.principal.mapping.rules = DEFAULT
2025-10-19 12:07:08.084 | 	ssl.protocol = TLSv1.3
2025-10-19 12:07:08.084 | 	ssl.provider = null
2025-10-19 12:07:08.084 | 	ssl.secure.random.implementation = null
2025-10-19 12:07:08.084 | 	ssl.trustmanager.algorithm = PKIX
2025-10-19 12:07:08.084 | 	ssl.truststore.certificates = null
2025-10-19 12:07:08.084 | 	ssl.truststore.location = null
2025-10-19 12:07:08.084 | 	ssl.truststore.password = null
2025-10-19 12:07:08.084 | 	ssl.truststore.type = JKS
2025-10-19 12:07:08.084 | 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
2025-10-19 12:07:08.084 | 	transaction.max.timeout.ms = 900000
2025-10-19 12:07:08.084 | 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
2025-10-19 12:07:08.084 | 	transaction.state.log.load.buffer.size = 5242880
2025-10-19 12:07:08.084 | 	transaction.state.log.min.isr = 1
2025-10-19 12:07:08.084 | 	transaction.state.log.num.partitions = 50
2025-10-19 12:07:08.084 | 	transaction.state.log.replication.factor = 1
2025-10-19 12:07:08.084 | 	transaction.state.log.segment.bytes = 104857600
2025-10-19 12:07:08.084 | 	transactional.id.expiration.ms = 604800000
2025-10-19 12:07:08.084 | 	unclean.leader.election.enable = false
2025-10-19 12:07:08.084 | 	unstable.api.versions.enable = false
2025-10-19 12:07:08.084 | 	zookeeper.clientCnxnSocket = null
2025-10-19 12:07:08.084 | 	zookeeper.connect = zookeeper:2181
2025-10-19 12:07:08.084 | 	zookeeper.connection.timeout.ms = null
2025-10-19 12:07:08.084 | 	zookeeper.max.in.flight.requests = 10
2025-10-19 12:07:08.084 | 	zookeeper.metadata.migration.enable = false
2025-10-19 12:07:08.084 | 	zookeeper.session.timeout.ms = 18000
2025-10-19 12:07:08.084 | 	zookeeper.set.acl = false
2025-10-19 12:07:08.084 | 	zookeeper.ssl.cipher.suites = null
2025-10-19 12:07:08.084 | 	zookeeper.ssl.client.enable = false
2025-10-19 12:07:08.084 | 	zookeeper.ssl.crl.enable = false
2025-10-19 12:07:08.084 | 	zookeeper.ssl.enabled.protocols = null
2025-10-19 12:07:08.084 | 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
2025-10-19 12:07:08.084 | 	zookeeper.ssl.keystore.location = null
2025-10-19 12:07:08.084 | 	zookeeper.ssl.keystore.password = null
2025-10-19 12:07:08.084 | 	zookeeper.ssl.keystore.type = null
2025-10-19 12:07:08.084 | 	zookeeper.ssl.ocsp.enable = false
2025-10-19 12:07:08.084 | 	zookeeper.ssl.protocol = TLSv1.2
2025-10-19 12:07:08.084 | 	zookeeper.ssl.truststore.location = null
2025-10-19 12:07:08.084 | 	zookeeper.ssl.truststore.password = null
2025-10-19 12:07:08.084 | 	zookeeper.ssl.truststore.type = null
2025-10-19 12:07:08.084 |  (kafka.server.KafkaConfig)
2025-10-19 12:07:08.135 | [2025-10-19 17:07:08,133] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 12:07:08.136 | [2025-10-19 17:07:08,134] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 12:07:08.137 | [2025-10-19 17:07:08,137] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 12:07:08.141 | [2025-10-19 17:07:08,141] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 12:07:08.202 | [2025-10-19 17:07:08,202] INFO Loading logs from log dirs ArraySeq(/var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:08.226 | [2025-10-19 17:07:08,226] INFO Skipping recovery of 51 logs from /var/lib/kafka/data since clean shutdown file was found (kafka.log.LogManager)
2025-10-19 12:07:08.329 | [2025-10-19 17:07:08,329] INFO [LogLoader partition=__consumer_offsets-29, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:08.379 | [2025-10-19 17:07:08,378] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-29, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 144ms (1/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:08.395 | [2025-10-19 17:07:08,394] INFO [LogLoader partition=__consumer_offsets-49, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:08.398 | [2025-10-19 17:07:08,398] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-49, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (2/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:08.417 | [2025-10-19 17:07:08,417] INFO [LogLoader partition=__consumer_offsets-28, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:08.423 | [2025-10-19 17:07:08,422] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-28, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 24ms (3/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:08.443 | [2025-10-19 17:07:08,442] INFO [LogLoader partition=__consumer_offsets-5, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:08.447 | [2025-10-19 17:07:08,447] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-5, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 23ms (4/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:08.464 | [2025-10-19 17:07:08,463] INFO [LogLoader partition=__consumer_offsets-10, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:08.468 | [2025-10-19 17:07:08,467] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-10, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (5/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:08.482 | [2025-10-19 17:07:08,481] INFO [LogLoader partition=__consumer_offsets-14, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:08.485 | [2025-10-19 17:07:08,485] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-14, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (6/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:08.508 | [2025-10-19 17:07:08,508] INFO Deleted producer state snapshot /var/lib/kafka/data/__consumer_offsets-19/00000000000000000003.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
2025-10-19 12:07:08.509 | [2025-10-19 17:07:08,508] INFO [LogLoader partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Loading producer state till offset 4 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:08.509 | [2025-10-19 17:07:08,509] INFO [LogLoader partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 4 (kafka.log.UnifiedLog$)
2025-10-19 12:07:08.509 | [2025-10-19 17:07:08,509] INFO [ProducerStateManager partition=__consumer_offsets-19]Loading producer state from snapshot file 'SnapshotFile(offset=4, file=/var/lib/kafka/data/__consumer_offsets-19/00000000000000000004.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
2025-10-19 12:07:08.517 | [2025-10-19 17:07:08,517] INFO [LogLoader partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Producer state recovery took 8ms for snapshot load and 0ms for segment recovery from offset 4 (kafka.log.UnifiedLog$)
2025-10-19 12:07:08.522 | [2025-10-19 17:07:08,521] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-19, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=4) with 1 segments in 36ms (7/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:08.546 | [2025-10-19 17:07:08,545] INFO [LogLoader partition=__consumer_offsets-8, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:08.549 | [2025-10-19 17:07:08,549] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-8, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 27ms (8/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:08.569 | [2025-10-19 17:07:08,569] INFO [LogLoader partition=__consumer_offsets-17, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:08.573 | [2025-10-19 17:07:08,573] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-17, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 23ms (9/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:08.591 | [2025-10-19 17:07:08,590] INFO [LogLoader partition=__consumer_offsets-35, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:08.595 | [2025-10-19 17:07:08,594] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-35, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 21ms (10/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:08.613 | [2025-10-19 17:07:08,613] INFO [LogLoader partition=__consumer_offsets-31, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:08.616 | [2025-10-19 17:07:08,615] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-31, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (11/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:08.631 | [2025-10-19 17:07:08,630] INFO [LogLoader partition=__consumer_offsets-6, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:08.634 | [2025-10-19 17:07:08,634] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-6, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (12/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:08.652 | [2025-10-19 17:07:08,652] INFO [LogLoader partition=__consumer_offsets-32, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:08.655 | [2025-10-19 17:07:08,655] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-32, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 21ms (13/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:08.672 | [2025-10-19 17:07:08,672] INFO [LogLoader partition=__consumer_offsets-3, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:08.675 | [2025-10-19 17:07:08,675] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-3, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (14/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:08.692 | [2025-10-19 17:07:08,691] INFO [LogLoader partition=__consumer_offsets-30, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:08.694 | [2025-10-19 17:07:08,694] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-30, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (15/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:08.708 | [2025-10-19 17:07:08,707] INFO [LogLoader partition=__consumer_offsets-37, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:08.710 | [2025-10-19 17:07:08,710] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-37, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (16/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:08.729 | [2025-10-19 17:07:08,728] INFO [LogLoader partition=__consumer_offsets-41, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:08.732 | [2025-10-19 17:07:08,731] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-41, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 21ms (17/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:08.750 | [2025-10-19 17:07:08,750] INFO [LogLoader partition=__consumer_offsets-26, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:08.767 | [2025-10-19 17:07:08,767] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-26, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 35ms (18/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:08.782 | [2025-10-19 17:07:08,782] INFO [LogLoader partition=__consumer_offsets-4, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:08.785 | [2025-10-19 17:07:08,784] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-4, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (19/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:08.799 | [2025-10-19 17:07:08,799] INFO [LogLoader partition=__consumer_offsets-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:08.802 | [2025-10-19 17:07:08,801] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-1, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (20/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:08.817 | [2025-10-19 17:07:08,817] INFO [LogLoader partition=__consumer_offsets-33, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:08.820 | [2025-10-19 17:07:08,819] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-33, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (21/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:08.836 | [2025-10-19 17:07:08,835] INFO [LogLoader partition=__consumer_offsets-25, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:08.838 | [2025-10-19 17:07:08,838] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-25, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (22/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:08.853 | [2025-10-19 17:07:08,852] INFO [LogLoader partition=__consumer_offsets-42, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:08.855 | [2025-10-19 17:07:08,854] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-42, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (23/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:08.869 | [2025-10-19 17:07:08,868] INFO [LogLoader partition=__consumer_offsets-2, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:08.871 | [2025-10-19 17:07:08,870] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-2, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (24/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:08.886 | [2025-10-19 17:07:08,885] INFO [LogLoader partition=__consumer_offsets-34, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:08.888 | [2025-10-19 17:07:08,887] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-34, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (25/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:08.900 | [2025-10-19 17:07:08,899] INFO [LogLoader partition=__consumer_offsets-36, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:08.902 | [2025-10-19 17:07:08,902] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-36, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (26/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:08.915 | [2025-10-19 17:07:08,915] INFO [LogLoader partition=__consumer_offsets-12, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:08.917 | [2025-10-19 17:07:08,917] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-12, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (27/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:08.931 | [2025-10-19 17:07:08,930] INFO [LogLoader partition=__consumer_offsets-20, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:08.933 | [2025-10-19 17:07:08,933] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-20, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (28/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:08.946 | [2025-10-19 17:07:08,945] INFO [LogLoader partition=__consumer_offsets-23, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:08.951 | [2025-10-19 17:07:08,950] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-23, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (29/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:08.970 | [2025-10-19 17:07:08,969] INFO [LogLoader partition=__consumer_offsets-13, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:08.972 | [2025-10-19 17:07:08,971] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-13, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 21ms (30/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:08.987 | [2025-10-19 17:07:08,987] INFO [LogLoader partition=__consumer_offsets-40, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:08.989 | [2025-10-19 17:07:08,988] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-40, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (31/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:09.001 | [2025-10-19 17:07:09,001] INFO [LogLoader partition=__consumer_offsets-43, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:09.005 | [2025-10-19 17:07:09,004] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-43, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (32/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:09.018 | [2025-10-19 17:07:09,017] INFO [LogLoader partition=__consumer_offsets-39, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:09.021 | [2025-10-19 17:07:09,020] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-39, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (33/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:09.040 | [2025-10-19 17:07:09,039] INFO [LogLoader partition=__consumer_offsets-46, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:09.042 | [2025-10-19 17:07:09,042] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-46, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 22ms (34/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:09.066 | [2025-10-19 17:07:09,065] INFO [LogLoader partition=__consumer_offsets-7, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:09.071 | [2025-10-19 17:07:09,070] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-7, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 28ms (35/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:09.085 | [2025-10-19 17:07:09,085] INFO [LogLoader partition=__consumer_offsets-38, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:09.088 | [2025-10-19 17:07:09,087] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-38, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (36/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:09.102 | [2025-10-19 17:07:09,102] INFO [LogLoader partition=__consumer_offsets-47, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:09.106 | [2025-10-19 17:07:09,105] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-47, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (37/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:09.122 | [2025-10-19 17:07:09,121] INFO [LogLoader partition=__consumer_offsets-11, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:09.125 | [2025-10-19 17:07:09,124] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-11, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (38/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:09.144 | [2025-10-19 17:07:09,144] INFO [LogLoader partition=__consumer_offsets-21, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:09.148 | [2025-10-19 17:07:09,148] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-21, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 24ms (39/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:09.172 | [2025-10-19 17:07:09,172] INFO [LogLoader partition=__consumer_offsets-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:09.174 | [2025-10-19 17:07:09,174] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-0, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 26ms (40/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:09.188 | [2025-10-19 17:07:09,188] INFO [LogLoader partition=__consumer_offsets-16, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:09.192 | [2025-10-19 17:07:09,192] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-16, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (41/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:09.221 | [2025-10-19 17:07:09,221] INFO [LogLoader partition=__consumer_offsets-22, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:09.224 | [2025-10-19 17:07:09,224] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-22, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 31ms (42/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:09.250 | [2025-10-19 17:07:09,249] INFO [LogLoader partition=__consumer_offsets-15, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:09.252 | [2025-10-19 17:07:09,252] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-15, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 28ms (43/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:09.270 | [2025-10-19 17:07:09,270] INFO [LogLoader partition=__consumer_offsets-18, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:09.273 | [2025-10-19 17:07:09,272] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-18, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (44/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:09.286 | [2025-10-19 17:07:09,286] INFO [LogLoader partition=__consumer_offsets-27, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:09.288 | [2025-10-19 17:07:09,288] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-27, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (45/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:09.301 | [2025-10-19 17:07:09,301] INFO [LogLoader partition=__consumer_offsets-24, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:09.304 | [2025-10-19 17:07:09,303] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-24, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (46/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:09.323 | [2025-10-19 17:07:09,322] INFO [LogLoader partition=__consumer_offsets-9, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:09.326 | [2025-10-19 17:07:09,326] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-9, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 23ms (47/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:09.343 | [2025-10-19 17:07:09,342] INFO [LogLoader partition=__consumer_offsets-45, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:09.346 | [2025-10-19 17:07:09,346] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-45, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (48/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:09.366 | [2025-10-19 17:07:09,365] INFO [LogLoader partition=__consumer_offsets-44, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:09.368 | [2025-10-19 17:07:09,368] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-44, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 22ms (49/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:09.391 | [2025-10-19 17:07:09,390] INFO [LogLoader partition=mesa-ya.restaurants.created-0, dir=/var/lib/kafka/data] Loading producer state till offset 2 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:09.391 | [2025-10-19 17:07:09,391] INFO [LogLoader partition=mesa-ya.restaurants.created-0, dir=/var/lib/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:09.391 | [2025-10-19 17:07:09,391] INFO [ProducerStateManager partition=mesa-ya.restaurants.created-0]Loading producer state from snapshot file 'SnapshotFile(offset=2, file=/var/lib/kafka/data/mesa-ya.restaurants.created-0/00000000000000000002.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
2025-10-19 12:07:09.393 | [2025-10-19 17:07:09,392] INFO [LogLoader partition=mesa-ya.restaurants.created-0, dir=/var/lib/kafka/data] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:09.395 | [2025-10-19 17:07:09,395] INFO Completed load of Log(dir=/var/lib/kafka/data/mesa-ya.restaurants.created-0, topicId=yWm6W48_TyqOOX8W2L0ItA, topic=mesa-ya.restaurants.created, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=2) with 1 segments in 27ms (50/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:09.413 | [2025-10-19 17:07:09,413] INFO [LogLoader partition=__consumer_offsets-48, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:07:09.416 | [2025-10-19 17:07:09,415] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-48, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (51/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:07:09.425 | [2025-10-19 17:07:09,424] INFO Loaded 51 logs in 1221ms (kafka.log.LogManager)
2025-10-19 12:07:09.429 | [2025-10-19 17:07:09,428] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
2025-10-19 12:07:09.435 | [2025-10-19 17:07:09,434] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
2025-10-19 12:07:09.463 | [2025-10-19 17:07:09,462] INFO Starting the log cleaner (kafka.log.LogCleaner)
2025-10-19 12:07:09.792 | [2025-10-19 17:07:09,791] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
2025-10-19 12:07:09.824 | [2025-10-19 17:07:09,823] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-10-19 12:07:09.891 | [2025-10-19 17:07:09,891] INFO [MetadataCache brokerId=1] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0). (kafka.server.metadata.ZkMetadataCache)
2025-10-19 12:07:09.941 | [2025-10-19 17:07:09,940] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
2025-10-19 12:07:10.523 | [2025-10-19 17:07:10,522] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
2025-10-19 12:07:10.577 | [2025-10-19 17:07:10,577] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
2025-10-19 12:07:10.578 | [2025-10-19 17:07:10,578] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
2025-10-19 12:07:10.599 | [2025-10-19 17:07:10,598] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT_INTERNAL) (kafka.network.SocketServer)
2025-10-19 12:07:10.614 | [2025-10-19 17:07:10,613] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
2025-10-19 12:07:10.657 | [2025-10-19 17:07:10,656] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:07:10.659 | [2025-10-19 17:07:10,657] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:07:10.661 | [2025-10-19 17:07:10,661] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:07:10.665 | [2025-10-19 17:07:10,664] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:07:10.700 | [2025-10-19 17:07:10,699] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-10-19 12:07:10.788 | [2025-10-19 17:07:10,787] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
2025-10-19 12:07:10.827 | [2025-10-19 17:07:10,826] INFO Stat of the created znode at /brokers/ids/1 is: 223,223,1760893630814,1760893630814,1,0,0,72057613897367553,270,0,223
2025-10-19 12:07:10.827 |  (kafka.zk.KafkaZkClient)
2025-10-19 12:07:10.828 | [2025-10-19 17:07:10,828] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092, czxid (broker epoch): 223 (kafka.zk.KafkaZkClient)
2025-10-19 12:07:10.958 | [2025-10-19 17:07:10,957] INFO [ControllerEventThread controllerId=1] Starting (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-10-19 12:07:10.978 | [2025-10-19 17:07:10,977] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:07:10.992 | [2025-10-19 17:07:10,992] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:07:10.999 | [2025-10-19 17:07:10,998] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:07:11.017 | [2025-10-19 17:07:11,016] INFO [Controller id=1] 1 successfully elected as the controller. Epoch incremented to 5 and epoch zk version is now 5 (kafka.controller.KafkaController)
2025-10-19 12:07:11.022 | [2025-10-19 17:07:11,022] INFO [Controller id=1] Registering handlers (kafka.controller.KafkaController)
2025-10-19 12:07:11.034 | [2025-10-19 17:07:11,033] INFO [Controller id=1] Deleting log dir event notifications (kafka.controller.KafkaController)
2025-10-19 12:07:11.042 | [2025-10-19 17:07:11,042] INFO [Controller id=1] Deleting isr change notifications (kafka.controller.KafkaController)
2025-10-19 12:07:11.047 | [2025-10-19 17:07:11,046] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:11.048 | [2025-10-19 17:07:11,048] INFO [Controller id=1] Initializing controller context (kafka.controller.KafkaController)
2025-10-19 12:07:11.078 | [2025-10-19 17:07:11,077] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:11.094 | [2025-10-19 17:07:11,093] INFO [Controller id=1] Initialized broker epochs cache: HashMap(1 -> 223) (kafka.controller.KafkaController)
2025-10-19 12:07:11.121 | [2025-10-19 17:07:11,120] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
2025-10-19 12:07:11.124 | [2025-10-19 17:07:11,123] DEBUG [Controller id=1] Register BrokerModifications handler for Set(1) (kafka.controller.KafkaController)
2025-10-19 12:07:11.129 | [2025-10-19 17:07:11,128] INFO [TxnMarkerSenderThread-1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-10-19 12:07:11.129 | [2025-10-19 17:07:11,128] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
2025-10-19 12:07:11.243 | [2025-10-19 17:07:11,242] DEBUG [Channel manager on controller 1]: Controller 1 trying to connect to broker 1 (kafka.controller.ControllerChannelManager)
2025-10-19 12:07:11.251 | [2025-10-19 17:07:11,250] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:07:11.256 | [2025-10-19 17:07:11,255] INFO [RequestSendThread controllerId=1] Starting (kafka.controller.RequestSendThread)
2025-10-19 12:07:11.262 | [2025-10-19 17:07:11,261] INFO [Controller id=1] Currently active brokers in the cluster: Set(1) (kafka.controller.KafkaController)
2025-10-19 12:07:11.264 | [2025-10-19 17:07:11,263] INFO [Controller id=1] Currently shutting brokers in the cluster: HashSet() (kafka.controller.KafkaController)
2025-10-19 12:07:11.265 | [2025-10-19 17:07:11,265] INFO [Controller id=1] Current list of topics in the cluster: HashSet(__consumer_offsets, mesa-ya.restaurants.created) (kafka.controller.KafkaController)
2025-10-19 12:07:11.266 | [2025-10-19 17:07:11,265] INFO [Controller id=1] Fetching topic deletions in progress (kafka.controller.KafkaController)
2025-10-19 12:07:11.281 | [2025-10-19 17:07:11,281] INFO [Controller id=1] List of topics to be deleted:  (kafka.controller.KafkaController)
2025-10-19 12:07:11.282 | [2025-10-19 17:07:11,282] INFO [Controller id=1] List of topics ineligible for deletion:  (kafka.controller.KafkaController)
2025-10-19 12:07:11.283 | [2025-10-19 17:07:11,283] INFO [Controller id=1] Initializing topic deletion manager (kafka.controller.KafkaController)
2025-10-19 12:07:11.285 | [2025-10-19 17:07:11,285] INFO [Topic Deletion Manager 1] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet() (kafka.controller.TopicDeletionManager)
2025-10-19 12:07:11.289 | [2025-10-19 17:07:11,288] INFO [Controller id=1] Sending update metadata request (kafka.controller.KafkaController)
2025-10-19 12:07:11.297 | [2025-10-19 17:07:11,295] INFO [Controller id=1 epoch=5] Sending UpdateMetadata request to brokers HashSet(1) for 0 partitions (state.change.logger)
2025-10-19 12:07:11.311 | [2025-10-19 17:07:11,311] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-10-19 12:07:11.316 | [2025-10-19 17:07:11,315] INFO [ReplicaStateMachine controllerId=1] Initializing replica state (kafka.controller.ZkReplicaStateMachine)
2025-10-19 12:07:11.326 | [2025-10-19 17:07:11,326] INFO [ReplicaStateMachine controllerId=1] Triggering online replica state changes (kafka.controller.ZkReplicaStateMachine)
2025-10-19 12:07:11.329 | [2025-10-19 17:07:11,329] INFO [Controller id=1, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
2025-10-19 12:07:11.333 | [2025-10-19 17:07:11,332] WARN [Controller id=1, targetBrokerId=1] Connection to node 1 (kafka/172.18.0.3:29092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
2025-10-19 12:07:11.342 | [2025-10-19 17:07:11,336] WARN [RequestSendThread controllerId=1] Controller 1's connection to broker kafka:29092 (id: 1 rack: null) was unsuccessful (kafka.controller.RequestSendThread)
2025-10-19 12:07:11.342 | java.io.IOException: Connection to kafka:29092 (id: 1 rack: null) failed.
2025-10-19 12:07:11.342 | 	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
2025-10-19 12:07:11.342 | 	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:296)
2025-10-19 12:07:11.342 | 	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:249)
2025-10-19 12:07:11.342 | 	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:127)
2025-10-19 12:07:11.342 | [2025-10-19 17:07:11,341] INFO [Controller id=1, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
2025-10-19 12:07:11.364 | [2025-10-19 17:07:11,363] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-46 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.365 | [2025-10-19 17:07:11,365] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-37 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.367 | [2025-10-19 17:07:11,366] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-8 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.367 | [2025-10-19 17:07:11,367] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-49 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.368 | [2025-10-19 17:07:11,367] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-21 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.368 | [2025-10-19 17:07:11,368] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-20 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.369 | [2025-10-19 17:07:11,369] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-17 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.369 | [2025-10-19 17:07:11,369] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-19 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.370 | [2025-10-19 17:07:11,370] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-7 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.371 | [2025-10-19 17:07:11,370] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-43 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.371 | [2025-10-19 17:07:11,370] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
2025-10-19 12:07:11.372 | [2025-10-19 17:07:11,372] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-30 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.373 | [2025-10-19 17:07:11,372] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-35 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.373 | [2025-10-19 17:07:11,373] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-27 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.374 | [2025-10-19 17:07:11,373] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition mesa-ya.restaurants.created-0 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.374 | [2025-10-19 17:07:11,374] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-0 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.374 | [2025-10-19 17:07:11,374] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-40 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.375 | [2025-10-19 17:07:11,374] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-47 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.375 | [2025-10-19 17:07:11,375] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-10 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.376 | [2025-10-19 17:07:11,375] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-4 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.376 | [2025-10-19 17:07:11,376] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-31 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.376 | [2025-10-19 17:07:11,376] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-16 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.377 | [2025-10-19 17:07:11,376] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-23 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.377 | [2025-10-19 17:07:11,377] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-26 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.377 | [2025-10-19 17:07:11,377] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-39 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.377 | [2025-10-19 17:07:11,377] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-2 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.378 | [2025-10-19 17:07:11,377] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-34 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.380 | [2025-10-19 17:07:11,379] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-24 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.380 | [2025-10-19 17:07:11,380] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-32 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.380 | [2025-10-19 17:07:11,380] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-41 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.381 | [2025-10-19 17:07:11,380] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-5 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.381 | [2025-10-19 17:07:11,381] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-15 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.381 | [2025-10-19 17:07:11,381] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-1 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.382 | [2025-10-19 17:07:11,381] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-9 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.382 | [2025-10-19 17:07:11,382] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-45 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.382 | [2025-10-19 17:07:11,382] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-36 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.382 | [2025-10-19 17:07:11,382] INFO Awaiting socket connections on 0.0.0.0:29092. (kafka.network.DataPlaneAcceptor)
2025-10-19 12:07:11.382 | [2025-10-19 17:07:11,382] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-48 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.383 | [2025-10-19 17:07:11,382] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-3 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.383 | [2025-10-19 17:07:11,383] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-18 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.383 | [2025-10-19 17:07:11,383] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-44 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.383 | [2025-10-19 17:07:11,383] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-11 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.384 | [2025-10-19 17:07:11,383] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-25 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.384 | [2025-10-19 17:07:11,384] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-29 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.384 | [2025-10-19 17:07:11,384] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-6 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.385 | [2025-10-19 17:07:11,384] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-42 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.385 | [2025-10-19 17:07:11,385] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-28 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.386 | [2025-10-19 17:07:11,386] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-12 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.387 | [2025-10-19 17:07:11,387] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-38 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.390 | [2025-10-19 17:07:11,389] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-33 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.391 | [2025-10-19 17:07:11,390] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
2025-10-19 12:07:11.391 | [2025-10-19 17:07:11,390] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-14 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.392 | [2025-10-19 17:07:11,392] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-13 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.392 | [2025-10-19 17:07:11,392] TRACE [Controller id=1 epoch=5] Changed state of replica 1 for partition __consumer_offsets-22 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:07:11.402 | [2025-10-19 17:07:11,402] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-13 (state.change.logger)
2025-10-19 12:07:11.402 | [2025-10-19 17:07:11,402] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-46 (state.change.logger)
2025-10-19 12:07:11.402 | [2025-10-19 17:07:11,402] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-9 (state.change.logger)
2025-10-19 12:07:11.403 | [2025-10-19 17:07:11,402] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-42 (state.change.logger)
2025-10-19 12:07:11.403 | [2025-10-19 17:07:11,402] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-21 (state.change.logger)
2025-10-19 12:07:11.403 | [2025-10-19 17:07:11,403] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-17 (state.change.logger)
2025-10-19 12:07:11.403 | [2025-10-19 17:07:11,403] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-30 (state.change.logger)
2025-10-19 12:07:11.403 | [2025-10-19 17:07:11,403] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-26 (state.change.logger)
2025-10-19 12:07:11.405 | [2025-10-19 17:07:11,404] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-5 (state.change.logger)
2025-10-19 12:07:11.408 | [2025-10-19 17:07:11,407] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-38 (state.change.logger)
2025-10-19 12:07:11.408 | [2025-10-19 17:07:11,407] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-1 (state.change.logger)
2025-10-19 12:07:11.408 | [2025-10-19 17:07:11,407] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-34 (state.change.logger)
2025-10-19 12:07:11.408 | [2025-10-19 17:07:11,407] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-16 (state.change.logger)
2025-10-19 12:07:11.408 | [2025-10-19 17:07:11,407] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-45 (state.change.logger)
2025-10-19 12:07:11.408 | [2025-10-19 17:07:11,407] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-12 (state.change.logger)
2025-10-19 12:07:11.408 | [2025-10-19 17:07:11,407] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-41 (state.change.logger)
2025-10-19 12:07:11.408 | [2025-10-19 17:07:11,408] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-24 (state.change.logger)
2025-10-19 12:07:11.409 | [2025-10-19 17:07:11,408] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-20 (state.change.logger)
2025-10-19 12:07:11.409 | [2025-10-19 17:07:11,409] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-49 (state.change.logger)
2025-10-19 12:07:11.409 | [2025-10-19 17:07:11,409] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-0 (state.change.logger)
2025-10-19 12:07:11.409 | [2025-10-19 17:07:11,409] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-29 (state.change.logger)
2025-10-19 12:07:11.410 | [2025-10-19 17:07:11,409] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-25 (state.change.logger)
2025-10-19 12:07:11.410 | [2025-10-19 17:07:11,410] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-8 (state.change.logger)
2025-10-19 12:07:11.410 | [2025-10-19 17:07:11,410] INFO Kafka version: 7.5.0-ccs (org.apache.kafka.common.utils.AppInfoParser)
2025-10-19 12:07:11.410 | [2025-10-19 17:07:11,410] INFO Kafka commitId: ff3c201baa948d97889dc26c99d7cdc23d038f2e (org.apache.kafka.common.utils.AppInfoParser)
2025-10-19 12:07:11.410 | [2025-10-19 17:07:11,410] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-37 (state.change.logger)
2025-10-19 12:07:11.410 | [2025-10-19 17:07:11,410] INFO Kafka startTimeMs: 1760893631398 (org.apache.kafka.common.utils.AppInfoParser)
2025-10-19 12:07:11.410 | [2025-10-19 17:07:11,410] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-4 (state.change.logger)
2025-10-19 12:07:11.411 | [2025-10-19 17:07:11,410] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-33 (state.change.logger)
2025-10-19 12:07:11.411 | [2025-10-19 17:07:11,410] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-15 (state.change.logger)
2025-10-19 12:07:11.411 | [2025-10-19 17:07:11,411] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-48 (state.change.logger)
2025-10-19 12:07:11.411 | [2025-10-19 17:07:11,411] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-11 (state.change.logger)
2025-10-19 12:07:11.411 | [2025-10-19 17:07:11,411] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-44 (state.change.logger)
2025-10-19 12:07:11.411 | [2025-10-19 17:07:11,411] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-23 (state.change.logger)
2025-10-19 12:07:11.411 | [2025-10-19 17:07:11,411] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-19 (state.change.logger)
2025-10-19 12:07:11.412 | [2025-10-19 17:07:11,411] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-32 (state.change.logger)
2025-10-19 12:07:11.412 | [2025-10-19 17:07:11,411] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-28 (state.change.logger)
2025-10-19 12:07:11.412 | [2025-10-19 17:07:11,411] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-7 (state.change.logger)
2025-10-19 12:07:11.412 | [2025-10-19 17:07:11,411] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-40 (state.change.logger)
2025-10-19 12:07:11.412 | [2025-10-19 17:07:11,412] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-3 (state.change.logger)
2025-10-19 12:07:11.412 | [2025-10-19 17:07:11,412] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-36 (state.change.logger)
2025-10-19 12:07:11.412 | [2025-10-19 17:07:11,412] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-47 (state.change.logger)
2025-10-19 12:07:11.412 | [2025-10-19 17:07:11,412] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-14 (state.change.logger)
2025-10-19 12:07:11.412 | [2025-10-19 17:07:11,412] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-43 (state.change.logger)
2025-10-19 12:07:11.412 | [2025-10-19 17:07:11,412] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-10 (state.change.logger)
2025-10-19 12:07:11.412 | [2025-10-19 17:07:11,412] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-22 (state.change.logger)
2025-10-19 12:07:11.412 | [2025-10-19 17:07:11,412] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-18 (state.change.logger)
2025-10-19 12:07:11.413 | [2025-10-19 17:07:11,412] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-31 (state.change.logger)
2025-10-19 12:07:11.413 | [2025-10-19 17:07:11,412] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-27 (state.change.logger)
2025-10-19 12:07:11.413 | [2025-10-19 17:07:11,412] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
2025-10-19 12:07:11.413 | [2025-10-19 17:07:11,412] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-39 (state.change.logger)
2025-10-19 12:07:11.413 | [2025-10-19 17:07:11,413] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-6 (state.change.logger)
2025-10-19 12:07:11.413 | [2025-10-19 17:07:11,413] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-35 (state.change.logger)
2025-10-19 12:07:11.413 | [2025-10-19 17:07:11,413] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='mesa-ya.restaurants.created', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition mesa-ya.restaurants.created-0 (state.change.logger)
2025-10-19 12:07:11.413 | [2025-10-19 17:07:11,413] TRACE [Controller id=1 epoch=5] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-2 (state.change.logger)
2025-10-19 12:07:11.415 | [2025-10-19 17:07:11,415] INFO [Controller id=1 epoch=5] Sending LeaderAndIsr request to broker 1 with 51 become-leader and 0 become-follower partitions (state.change.logger)
2025-10-19 12:07:11.439 | [2025-10-19 17:07:11,438] INFO [Controller id=1 epoch=5] Sending UpdateMetadata request to brokers HashSet(1) for 51 partitions (state.change.logger)
2025-10-19 12:07:11.440 | [2025-10-19 17:07:11,439] INFO [ReplicaStateMachine controllerId=1] Triggering offline replica state changes (kafka.controller.ZkReplicaStateMachine)
2025-10-19 12:07:11.440 | [2025-10-19 17:07:11,440] DEBUG [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> HashMap([Topic=__consumer_offsets,Partition=46,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=37,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=8,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=49,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=21,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=20,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=17,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=19,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=7,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=43,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=30,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=35,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=27,Replica=1] -> OnlineReplica, [Topic=mesa-ya.restaurants.created,Partition=0,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=0,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=40,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=47,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=10,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=4,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=31,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=16,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=23,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=26,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=39,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=2,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=34,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=24,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=32,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=41,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=5,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=15,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=1,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=9,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=45,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=36,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=48,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=3,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=18,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=44,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=11,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=25,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=29,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=6,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=42,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=28,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=12,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=38,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=33,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=14,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=13,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=22,Replica=1] -> OnlineReplica) (kafka.controller.ZkReplicaStateMachine)
2025-10-19 12:07:11.441 | [2025-10-19 17:07:11,441] INFO [PartitionStateMachine controllerId=1] Initializing partition state (kafka.controller.ZkPartitionStateMachine)
2025-10-19 12:07:11.448 | [2025-10-19 17:07:11,447] INFO [PartitionStateMachine controllerId=1] Triggering online partition state changes (kafka.controller.ZkPartitionStateMachine)
2025-10-19 12:07:11.449 | [2025-10-19 17:07:11,447] INFO [RequestSendThread controllerId=1] Controller 1 connected to kafka:29092 (id: 1 rack: null) for sending state change requests (kafka.controller.RequestSendThread)
2025-10-19 12:07:11.455 | [2025-10-19 17:07:11,454] DEBUG [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> HashMap(__consumer_offsets-13 -> OnlinePartition, __consumer_offsets-46 -> OnlinePartition, __consumer_offsets-9 -> OnlinePartition, __consumer_offsets-42 -> OnlinePartition, __consumer_offsets-21 -> OnlinePartition, __consumer_offsets-17 -> OnlinePartition, __consumer_offsets-30 -> OnlinePartition, __consumer_offsets-26 -> OnlinePartition, __consumer_offsets-5 -> OnlinePartition, __consumer_offsets-38 -> OnlinePartition, __consumer_offsets-1 -> OnlinePartition, __consumer_offsets-34 -> OnlinePartition, __consumer_offsets-16 -> OnlinePartition, __consumer_offsets-45 -> OnlinePartition, __consumer_offsets-12 -> OnlinePartition, __consumer_offsets-41 -> OnlinePartition, __consumer_offsets-24 -> OnlinePartition, __consumer_offsets-20 -> OnlinePartition, __consumer_offsets-49 -> OnlinePartition, __consumer_offsets-0 -> OnlinePartition, __consumer_offsets-29 -> OnlinePartition, __consumer_offsets-25 -> OnlinePartition, __consumer_offsets-8 -> OnlinePartition, __consumer_offsets-37 -> OnlinePartition, __consumer_offsets-4 -> OnlinePartition, __consumer_offsets-33 -> OnlinePartition, __consumer_offsets-15 -> OnlinePartition, __consumer_offsets-48 -> OnlinePartition, __consumer_offsets-11 -> OnlinePartition, __consumer_offsets-44 -> OnlinePartition, __consumer_offsets-23 -> OnlinePartition, __consumer_offsets-19 -> OnlinePartition, __consumer_offsets-32 -> OnlinePartition, __consumer_offsets-28 -> OnlinePartition, __consumer_offsets-7 -> OnlinePartition, __consumer_offsets-40 -> OnlinePartition, __consumer_offsets-3 -> OnlinePartition, __consumer_offsets-36 -> OnlinePartition, __consumer_offsets-47 -> OnlinePartition, __consumer_offsets-14 -> OnlinePartition, __consumer_offsets-43 -> OnlinePartition, __consumer_offsets-10 -> OnlinePartition, __consumer_offsets-22 -> OnlinePartition, __consumer_offsets-18 -> OnlinePartition, __consumer_offsets-31 -> OnlinePartition, __consumer_offsets-27 -> OnlinePartition, __consumer_offsets-39 -> OnlinePartition, __consumer_offsets-6 -> OnlinePartition, __consumer_offsets-35 -> OnlinePartition, mesa-ya.restaurants.created-0 -> OnlinePartition, __consumer_offsets-2 -> OnlinePartition) (kafka.controller.ZkPartitionStateMachine)
2025-10-19 12:07:11.456 | [2025-10-19 17:07:11,455] INFO [Controller id=1] Ready to serve as the new controller with epoch 5 (kafka.controller.KafkaController)
2025-10-19 12:07:11.473 | [2025-10-19 17:07:11,473] INFO [Controller id=1] Partitions undergoing preferred replica election:  (kafka.controller.KafkaController)
2025-10-19 12:07:11.474 | [2025-10-19 17:07:11,474] INFO [Controller id=1] Partitions that completed preferred replica election:  (kafka.controller.KafkaController)
2025-10-19 12:07:11.475 | [2025-10-19 17:07:11,474] INFO [Controller id=1] Skipping preferred replica election for partitions due to topic deletion:  (kafka.controller.KafkaController)
2025-10-19 12:07:11.475 | [2025-10-19 17:07:11,475] INFO [Controller id=1] Resuming preferred replica election for partitions:  (kafka.controller.KafkaController)
2025-10-19 12:07:11.477 | [2025-10-19 17:07:11,476] INFO [Controller id=1] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered (kafka.controller.KafkaController)
2025-10-19 12:07:11.507 | [2025-10-19 17:07:11,506] INFO [Controller id=1] Starting the controller scheduler (kafka.controller.KafkaController)
2025-10-19 12:07:11.581 | [2025-10-19 17:07:11,579] TRACE [Controller id=1 epoch=5] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 0 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-10-19 12:07:11.606 | [2025-10-19 17:07:11,605] INFO [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 for 51 partitions (state.change.logger)
2025-10-19 12:07:11.612 | [2025-10-19 17:07:11,611] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Recorded new controller, from now on will use node kafka:29092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
2025-10-19 12:07:11.612 | [2025-10-19 17:07:11,611] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.612 | [2025-10-19 17:07:11,612] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.612 | [2025-10-19 17:07:11,612] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.612 | [2025-10-19 17:07:11,612] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.612 | [2025-10-19 17:07:11,612] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.612 | [2025-10-19 17:07:11,612] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.612 | [2025-10-19 17:07:11,612] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.612 | [2025-10-19 17:07:11,612] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.613 | [2025-10-19 17:07:11,612] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.613 | [2025-10-19 17:07:11,612] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.613 | [2025-10-19 17:07:11,613] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.613 | [2025-10-19 17:07:11,613] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,613] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,613] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,613] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,613] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,613] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,613] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,613] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,613] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,613] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,613] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,613] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,613] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,614] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,614] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,614] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,614] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,614] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,614] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,614] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,614] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,614] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,614] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,614] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,614] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,614] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,614] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,614] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,614] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,614] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,614] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,614] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,615] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,615] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,615] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,615] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,615] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,615] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,615] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.617 | [2025-10-19 17:07:11,615] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='mesa-ya.restaurants.created', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 5 (state.change.logger)
2025-10-19 12:07:11.636 | [2025-10-19 17:07:11,635] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Recorded new controller, from now on will use node kafka:29092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
2025-10-19 12:07:11.684 | [2025-10-19 17:07:11,684] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-3 (state.change.logger)
2025-10-19 12:07:11.684 | [2025-10-19 17:07:11,684] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-18 (state.change.logger)
2025-10-19 12:07:11.684 | [2025-10-19 17:07:11,684] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-41 (state.change.logger)
2025-10-19 12:07:11.685 | [2025-10-19 17:07:11,684] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-10 (state.change.logger)
2025-10-19 12:07:11.685 | [2025-10-19 17:07:11,684] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-33 (state.change.logger)
2025-10-19 12:07:11.685 | [2025-10-19 17:07:11,685] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-48 (state.change.logger)
2025-10-19 12:07:11.685 | [2025-10-19 17:07:11,685] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-19 (state.change.logger)
2025-10-19 12:07:11.685 | [2025-10-19 17:07:11,685] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-34 (state.change.logger)
2025-10-19 12:07:11.685 | [2025-10-19 17:07:11,685] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-4 (state.change.logger)
2025-10-19 12:07:11.685 | [2025-10-19 17:07:11,685] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-11 (state.change.logger)
2025-10-19 12:07:11.685 | [2025-10-19 17:07:11,685] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-26 (state.change.logger)
2025-10-19 12:07:11.685 | [2025-10-19 17:07:11,685] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-49 (state.change.logger)
2025-10-19 12:07:11.685 | [2025-10-19 17:07:11,685] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-39 (state.change.logger)
2025-10-19 12:07:11.685 | [2025-10-19 17:07:11,685] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-9 (state.change.logger)
2025-10-19 12:07:11.685 | [2025-10-19 17:07:11,685] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-24 (state.change.logger)
2025-10-19 12:07:11.685 | [2025-10-19 17:07:11,685] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-31 (state.change.logger)
2025-10-19 12:07:11.685 | [2025-10-19 17:07:11,685] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-46 (state.change.logger)
2025-10-19 12:07:11.685 | [2025-10-19 17:07:11,685] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-1 (state.change.logger)
2025-10-19 12:07:11.685 | [2025-10-19 17:07:11,685] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-16 (state.change.logger)
2025-10-19 12:07:11.686 | [2025-10-19 17:07:11,685] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-2 (state.change.logger)
2025-10-19 12:07:11.686 | [2025-10-19 17:07:11,685] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-25 (state.change.logger)
2025-10-19 12:07:11.686 | [2025-10-19 17:07:11,685] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-40 (state.change.logger)
2025-10-19 12:07:11.686 | [2025-10-19 17:07:11,685] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-47 (state.change.logger)
2025-10-19 12:07:11.686 | [2025-10-19 17:07:11,686] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-17 (state.change.logger)
2025-10-19 12:07:11.686 | [2025-10-19 17:07:11,686] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-32 (state.change.logger)
2025-10-19 12:07:11.686 | [2025-10-19 17:07:11,686] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-37 (state.change.logger)
2025-10-19 12:07:11.686 | [2025-10-19 17:07:11,686] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-7 (state.change.logger)
2025-10-19 12:07:11.686 | [2025-10-19 17:07:11,686] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-22 (state.change.logger)
2025-10-19 12:07:11.687 | [2025-10-19 17:07:11,686] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-29 (state.change.logger)
2025-10-19 12:07:11.687 | [2025-10-19 17:07:11,686] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-44 (state.change.logger)
2025-10-19 12:07:11.687 | [2025-10-19 17:07:11,686] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-14 (state.change.logger)
2025-10-19 12:07:11.687 | [2025-10-19 17:07:11,686] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-23 (state.change.logger)
2025-10-19 12:07:11.687 | [2025-10-19 17:07:11,686] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-38 (state.change.logger)
2025-10-19 12:07:11.687 | [2025-10-19 17:07:11,686] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-8 (state.change.logger)
2025-10-19 12:07:11.687 | [2025-10-19 17:07:11,686] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-45 (state.change.logger)
2025-10-19 12:07:11.687 | [2025-10-19 17:07:11,686] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-15 (state.change.logger)
2025-10-19 12:07:11.687 | [2025-10-19 17:07:11,686] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-30 (state.change.logger)
2025-10-19 12:07:11.687 | [2025-10-19 17:07:11,686] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition mesa-ya.restaurants.created-0 (state.change.logger)
2025-10-19 12:07:11.688 | [2025-10-19 17:07:11,686] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-0 (state.change.logger)
2025-10-19 12:07:11.689 | [2025-10-19 17:07:11,688] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-35 (state.change.logger)
2025-10-19 12:07:11.689 | [2025-10-19 17:07:11,688] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-5 (state.change.logger)
2025-10-19 12:07:11.689 | [2025-10-19 17:07:11,689] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-20 (state.change.logger)
2025-10-19 12:07:11.690 | [2025-10-19 17:07:11,689] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-27 (state.change.logger)
2025-10-19 12:07:11.690 | [2025-10-19 17:07:11,689] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-42 (state.change.logger)
2025-10-19 12:07:11.690 | [2025-10-19 17:07:11,689] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-12 (state.change.logger)
2025-10-19 12:07:11.690 | [2025-10-19 17:07:11,689] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-21 (state.change.logger)
2025-10-19 12:07:11.690 | [2025-10-19 17:07:11,689] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-36 (state.change.logger)
2025-10-19 12:07:11.690 | [2025-10-19 17:07:11,689] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-6 (state.change.logger)
2025-10-19 12:07:11.690 | [2025-10-19 17:07:11,689] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-43 (state.change.logger)
2025-10-19 12:07:11.690 | [2025-10-19 17:07:11,689] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-13 (state.change.logger)
2025-10-19 12:07:11.690 | [2025-10-19 17:07:11,689] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 5 starting the become-leader transition for partition __consumer_offsets-28 (state.change.logger)
2025-10-19 12:07:11.695 | [2025-10-19 17:07:11,693] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-37, __consumer_offsets-38, __consumer_offsets-13, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, mesa-ya.restaurants.created-0, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
2025-10-19 12:07:11.695 | [2025-10-19 17:07:11,694] INFO [Broker id=1] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 1 epoch 5 as part of the become-leader transition for 51 partitions (state.change.logger)
2025-10-19 12:07:11.719 | [2025-10-19 17:07:11,719] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:11.724 | [2025-10-19 17:07:11,724] INFO [Broker id=1] Leader __consumer_offsets-3 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:11.752 | [2025-10-19 17:07:11,751] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:11.752 | [2025-10-19 17:07:11,752] INFO [Broker id=1] Leader __consumer_offsets-18 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:11.765 | [2025-10-19 17:07:11,765] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:11.765 | [2025-10-19 17:07:11,765] INFO [Broker id=1] Leader __consumer_offsets-41 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:11.778 | [2025-10-19 17:07:11,777] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:11.778 | [2025-10-19 17:07:11,778] INFO [Broker id=1] Leader __consumer_offsets-10 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:11.790 | [2025-10-19 17:07:11,789] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:11.790 | [2025-10-19 17:07:11,789] INFO [Broker id=1] Leader __consumer_offsets-33 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:11.802 | [2025-10-19 17:07:11,802] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:11.802 | [2025-10-19 17:07:11,802] INFO [Broker id=1] Leader __consumer_offsets-48 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:11.814 | [2025-10-19 17:07:11,813] INFO [Partition __consumer_offsets-19 broker=1] Log loaded for partition __consumer_offsets-19 with initial high watermark 4 (kafka.cluster.Partition)
2025-10-19 12:07:11.814 | [2025-10-19 17:07:11,814] INFO [Broker id=1] Leader __consumer_offsets-19 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 4 with partition epoch 0, high watermark 4, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:11.815 | [2025-10-19 17:07:11,814] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:11.815 | [2025-10-19 17:07:11,815] INFO [Broker id=1] Leader __consumer_offsets-34 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:11.827 | [2025-10-19 17:07:11,826] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:11.827 | [2025-10-19 17:07:11,827] INFO [Broker id=1] Leader __consumer_offsets-4 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:11.838 | [2025-10-19 17:07:11,838] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:11.838 | [2025-10-19 17:07:11,838] INFO [Broker id=1] Leader __consumer_offsets-11 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:11.850 | [2025-10-19 17:07:11,850] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:11.850 | [2025-10-19 17:07:11,850] INFO [Broker id=1] Leader __consumer_offsets-26 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:11.863 | [2025-10-19 17:07:11,862] INFO [Partition __consumer_offsets-49 broker=1] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:11.863 | [2025-10-19 17:07:11,863] INFO [Broker id=1] Leader __consumer_offsets-49 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:11.874 | [2025-10-19 17:07:11,873] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:11.874 | [2025-10-19 17:07:11,873] INFO [Broker id=1] Leader __consumer_offsets-39 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:11.885 | [2025-10-19 17:07:11,884] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:11.885 | [2025-10-19 17:07:11,885] INFO [Broker id=1] Leader __consumer_offsets-9 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:11.898 | [2025-10-19 17:07:11,898] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:11.898 | [2025-10-19 17:07:11,898] INFO [Broker id=1] Leader __consumer_offsets-24 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:11.914 | [2025-10-19 17:07:11,913] INFO [Partition __consumer_offsets-31 broker=1] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:11.914 | [2025-10-19 17:07:11,914] INFO [Broker id=1] Leader __consumer_offsets-31 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:11.925 | [2025-10-19 17:07:11,925] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:11.925 | [2025-10-19 17:07:11,925] INFO [Broker id=1] Leader __consumer_offsets-46 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:11.939 | [2025-10-19 17:07:11,939] INFO [Partition __consumer_offsets-1 broker=1] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:11.939 | [2025-10-19 17:07:11,939] INFO [Broker id=1] Leader __consumer_offsets-1 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:11.950 | [2025-10-19 17:07:11,950] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:11.950 | [2025-10-19 17:07:11,950] INFO [Broker id=1] Leader __consumer_offsets-16 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:11.963 | [2025-10-19 17:07:11,962] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:11.963 | [2025-10-19 17:07:11,962] INFO [Broker id=1] Leader __consumer_offsets-2 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:11.975 | [2025-10-19 17:07:11,975] INFO [Partition __consumer_offsets-25 broker=1] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:11.975 | [2025-10-19 17:07:11,975] INFO [Broker id=1] Leader __consumer_offsets-25 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:11.989 | [2025-10-19 17:07:11,989] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:11.989 | [2025-10-19 17:07:11,989] INFO [Broker id=1] Leader __consumer_offsets-40 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:12.003 | [2025-10-19 17:07:12,002] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:12.003 | [2025-10-19 17:07:12,002] INFO [Broker id=1] Leader __consumer_offsets-47 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:12.016 | [2025-10-19 17:07:12,015] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:12.016 | [2025-10-19 17:07:12,016] INFO [Broker id=1] Leader __consumer_offsets-17 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:12.031 | [2025-10-19 17:07:12,031] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:12.032 | [2025-10-19 17:07:12,031] INFO [Broker id=1] Leader __consumer_offsets-32 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:12.045 | [2025-10-19 17:07:12,044] INFO [Partition __consumer_offsets-37 broker=1] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:12.045 | [2025-10-19 17:07:12,045] INFO [Broker id=1] Leader __consumer_offsets-37 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:12.060 | [2025-10-19 17:07:12,060] INFO [Partition __consumer_offsets-7 broker=1] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:12.060 | [2025-10-19 17:07:12,060] INFO [Broker id=1] Leader __consumer_offsets-7 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:12.078 | [2025-10-19 17:07:12,078] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:12.078 | [2025-10-19 17:07:12,078] INFO [Broker id=1] Leader __consumer_offsets-22 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:12.093 | [2025-10-19 17:07:12,092] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:12.093 | [2025-10-19 17:07:12,093] INFO [Broker id=1] Leader __consumer_offsets-29 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:12.106 | [2025-10-19 17:07:12,106] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:12.106 | [2025-10-19 17:07:12,106] INFO [Broker id=1] Leader __consumer_offsets-44 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:12.119 | [2025-10-19 17:07:12,119] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:12.119 | [2025-10-19 17:07:12,119] INFO [Broker id=1] Leader __consumer_offsets-14 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:12.141 | [2025-10-19 17:07:12,141] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:12.142 | [2025-10-19 17:07:12,141] INFO [Broker id=1] Leader __consumer_offsets-23 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:12.158 | [2025-10-19 17:07:12,158] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:12.159 | [2025-10-19 17:07:12,158] INFO [Broker id=1] Leader __consumer_offsets-38 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:12.172 | [2025-10-19 17:07:12,172] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:12.172 | [2025-10-19 17:07:12,172] INFO [Broker id=1] Leader __consumer_offsets-8 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:12.185 | [2025-10-19 17:07:12,184] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:12.185 | [2025-10-19 17:07:12,185] INFO [Broker id=1] Leader __consumer_offsets-45 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:12.196 | [2025-10-19 17:07:12,195] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:12.196 | [2025-10-19 17:07:12,196] INFO [Broker id=1] Leader __consumer_offsets-15 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:12.207 | [2025-10-19 17:07:12,207] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:12.208 | [2025-10-19 17:07:12,207] INFO [Broker id=1] Leader __consumer_offsets-30 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:12.220 | [2025-10-19 17:07:12,219] INFO [Partition mesa-ya.restaurants.created-0 broker=1] Log loaded for partition mesa-ya.restaurants.created-0 with initial high watermark 2 (kafka.cluster.Partition)
2025-10-19 12:07:12.220 | [2025-10-19 17:07:12,220] INFO [Broker id=1] Leader mesa-ya.restaurants.created-0 with topic id Some(yWm6W48_TyqOOX8W2L0ItA) starts at leader epoch 0 from offset 2 with partition epoch 0, high watermark 2, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:12.221 | [2025-10-19 17:07:12,221] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:12.221 | [2025-10-19 17:07:12,221] INFO [Broker id=1] Leader __consumer_offsets-0 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:12.234 | [2025-10-19 17:07:12,233] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:12.234 | [2025-10-19 17:07:12,233] INFO [Broker id=1] Leader __consumer_offsets-35 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:12.246 | [2025-10-19 17:07:12,245] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:12.246 | [2025-10-19 17:07:12,245] INFO [Broker id=1] Leader __consumer_offsets-5 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:12.258 | [2025-10-19 17:07:12,258] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:12.259 | [2025-10-19 17:07:12,258] INFO [Broker id=1] Leader __consumer_offsets-20 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:12.269 | [2025-10-19 17:07:12,268] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:12.269 | [2025-10-19 17:07:12,269] INFO [Broker id=1] Leader __consumer_offsets-27 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:12.281 | [2025-10-19 17:07:12,280] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:12.281 | [2025-10-19 17:07:12,280] INFO [Broker id=1] Leader __consumer_offsets-42 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:12.293 | [2025-10-19 17:07:12,292] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:12.293 | [2025-10-19 17:07:12,292] INFO [Broker id=1] Leader __consumer_offsets-12 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:12.311 | [2025-10-19 17:07:12,310] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:12.311 | [2025-10-19 17:07:12,310] INFO [Broker id=1] Leader __consumer_offsets-21 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:12.329 | [2025-10-19 17:07:12,328] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:12.329 | [2025-10-19 17:07:12,329] INFO [Broker id=1] Leader __consumer_offsets-36 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:12.344 | [2025-10-19 17:07:12,344] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:12.345 | [2025-10-19 17:07:12,344] INFO [Broker id=1] Leader __consumer_offsets-6 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:12.355 | [2025-10-19 17:07:12,354] INFO [Partition __consumer_offsets-43 broker=1] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:12.355 | [2025-10-19 17:07:12,355] INFO [Broker id=1] Leader __consumer_offsets-43 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:12.368 | [2025-10-19 17:07:12,368] INFO [Partition __consumer_offsets-13 broker=1] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:12.368 | [2025-10-19 17:07:12,368] INFO [Broker id=1] Leader __consumer_offsets-13 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:12.380 | [2025-10-19 17:07:12,379] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:07:12.380 | [2025-10-19 17:07:12,380] INFO [Broker id=1] Leader __consumer_offsets-28 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:07:12.403 | [2025-10-19 17:07:12,402] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-3 (state.change.logger)
2025-10-19 12:07:12.403 | [2025-10-19 17:07:12,402] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-18 (state.change.logger)
2025-10-19 12:07:12.403 | [2025-10-19 17:07:12,402] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-41 (state.change.logger)
2025-10-19 12:07:12.403 | [2025-10-19 17:07:12,402] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-10 (state.change.logger)
2025-10-19 12:07:12.403 | [2025-10-19 17:07:12,402] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-33 (state.change.logger)
2025-10-19 12:07:12.403 | [2025-10-19 17:07:12,402] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-48 (state.change.logger)
2025-10-19 12:07:12.403 | [2025-10-19 17:07:12,402] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-19 (state.change.logger)
2025-10-19 12:07:12.403 | [2025-10-19 17:07:12,402] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-34 (state.change.logger)
2025-10-19 12:07:12.403 | [2025-10-19 17:07:12,403] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-4 (state.change.logger)
2025-10-19 12:07:12.403 | [2025-10-19 17:07:12,403] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-11 (state.change.logger)
2025-10-19 12:07:12.403 | [2025-10-19 17:07:12,403] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-26 (state.change.logger)
2025-10-19 12:07:12.403 | [2025-10-19 17:07:12,403] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-49 (state.change.logger)
2025-10-19 12:07:12.403 | [2025-10-19 17:07:12,403] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-39 (state.change.logger)
2025-10-19 12:07:12.403 | [2025-10-19 17:07:12,403] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-9 (state.change.logger)
2025-10-19 12:07:12.403 | [2025-10-19 17:07:12,403] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-24 (state.change.logger)
2025-10-19 12:07:12.403 | [2025-10-19 17:07:12,403] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-31 (state.change.logger)
2025-10-19 12:07:12.403 | [2025-10-19 17:07:12,403] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-46 (state.change.logger)
2025-10-19 12:07:12.404 | [2025-10-19 17:07:12,403] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-1 (state.change.logger)
2025-10-19 12:07:12.404 | [2025-10-19 17:07:12,403] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-16 (state.change.logger)
2025-10-19 12:07:12.404 | [2025-10-19 17:07:12,403] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-2 (state.change.logger)
2025-10-19 12:07:12.404 | [2025-10-19 17:07:12,404] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-25 (state.change.logger)
2025-10-19 12:07:12.404 | [2025-10-19 17:07:12,404] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-40 (state.change.logger)
2025-10-19 12:07:12.404 | [2025-10-19 17:07:12,404] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-47 (state.change.logger)
2025-10-19 12:07:12.404 | [2025-10-19 17:07:12,404] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-17 (state.change.logger)
2025-10-19 12:07:12.404 | [2025-10-19 17:07:12,404] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-32 (state.change.logger)
2025-10-19 12:07:12.404 | [2025-10-19 17:07:12,404] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-37 (state.change.logger)
2025-10-19 12:07:12.404 | [2025-10-19 17:07:12,404] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-7 (state.change.logger)
2025-10-19 12:07:12.404 | [2025-10-19 17:07:12,404] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-22 (state.change.logger)
2025-10-19 12:07:12.404 | [2025-10-19 17:07:12,404] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-29 (state.change.logger)
2025-10-19 12:07:12.404 | [2025-10-19 17:07:12,404] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-44 (state.change.logger)
2025-10-19 12:07:12.404 | [2025-10-19 17:07:12,404] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-14 (state.change.logger)
2025-10-19 12:07:12.404 | [2025-10-19 17:07:12,404] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-23 (state.change.logger)
2025-10-19 12:07:12.405 | [2025-10-19 17:07:12,404] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-38 (state.change.logger)
2025-10-19 12:07:12.405 | [2025-10-19 17:07:12,404] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-8 (state.change.logger)
2025-10-19 12:07:12.405 | [2025-10-19 17:07:12,404] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-45 (state.change.logger)
2025-10-19 12:07:12.405 | [2025-10-19 17:07:12,404] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-15 (state.change.logger)
2025-10-19 12:07:12.405 | [2025-10-19 17:07:12,404] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-30 (state.change.logger)
2025-10-19 12:07:12.405 | [2025-10-19 17:07:12,405] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition mesa-ya.restaurants.created-0 (state.change.logger)
2025-10-19 12:07:12.405 | [2025-10-19 17:07:12,405] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-0 (state.change.logger)
2025-10-19 12:07:12.405 | [2025-10-19 17:07:12,405] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-35 (state.change.logger)
2025-10-19 12:07:12.405 | [2025-10-19 17:07:12,405] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-5 (state.change.logger)
2025-10-19 12:07:12.405 | [2025-10-19 17:07:12,405] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-20 (state.change.logger)
2025-10-19 12:07:12.405 | [2025-10-19 17:07:12,405] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-27 (state.change.logger)
2025-10-19 12:07:12.405 | [2025-10-19 17:07:12,405] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-42 (state.change.logger)
2025-10-19 12:07:12.405 | [2025-10-19 17:07:12,405] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-12 (state.change.logger)
2025-10-19 12:07:12.405 | [2025-10-19 17:07:12,405] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-21 (state.change.logger)
2025-10-19 12:07:12.405 | [2025-10-19 17:07:12,405] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-36 (state.change.logger)
2025-10-19 12:07:12.405 | [2025-10-19 17:07:12,405] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-6 (state.change.logger)
2025-10-19 12:07:12.405 | [2025-10-19 17:07:12,405] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-43 (state.change.logger)
2025-10-19 12:07:12.405 | [2025-10-19 17:07:12,405] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-13 (state.change.logger)
2025-10-19 12:07:12.405 | [2025-10-19 17:07:12,405] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 5 for the become-leader transition for partition __consumer_offsets-28 (state.change.logger)
2025-10-19 12:07:12.429 | [2025-10-19 17:07:12,428] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.433 | [2025-10-19 17:07:12,433] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.440 | [2025-10-19 17:07:12,439] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.440 | [2025-10-19 17:07:12,439] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.441 | [2025-10-19 17:07:12,439] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.442 | [2025-10-19 17:07:12,441] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.443 | [2025-10-19 17:07:12,442] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.445 | [2025-10-19 17:07:12,442] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.445 | [2025-10-19 17:07:12,442] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.445 | [2025-10-19 17:07:12,442] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.445 | [2025-10-19 17:07:12,442] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.445 | [2025-10-19 17:07:12,442] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.445 | [2025-10-19 17:07:12,442] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.445 | [2025-10-19 17:07:12,442] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.445 | [2025-10-19 17:07:12,442] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.445 | [2025-10-19 17:07:12,442] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.445 | [2025-10-19 17:07:12,442] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.446 | [2025-10-19 17:07:12,442] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.446 | [2025-10-19 17:07:12,442] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.446 | [2025-10-19 17:07:12,442] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.446 | [2025-10-19 17:07:12,442] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.446 | [2025-10-19 17:07:12,442] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.446 | [2025-10-19 17:07:12,442] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.446 | [2025-10-19 17:07:12,443] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.446 | [2025-10-19 17:07:12,443] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.446 | [2025-10-19 17:07:12,443] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.446 | [2025-10-19 17:07:12,443] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.446 | [2025-10-19 17:07:12,443] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.446 | [2025-10-19 17:07:12,443] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.446 | [2025-10-19 17:07:12,443] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.446 | [2025-10-19 17:07:12,443] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.446 | [2025-10-19 17:07:12,443] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.446 | [2025-10-19 17:07:12,443] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.446 | [2025-10-19 17:07:12,443] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.446 | [2025-10-19 17:07:12,443] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.446 | [2025-10-19 17:07:12,443] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.446 | [2025-10-19 17:07:12,443] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.446 | [2025-10-19 17:07:12,443] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.446 | [2025-10-19 17:07:12,443] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.446 | [2025-10-19 17:07:12,443] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.446 | [2025-10-19 17:07:12,443] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.446 | [2025-10-19 17:07:12,443] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.446 | [2025-10-19 17:07:12,443] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.446 | [2025-10-19 17:07:12,443] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.446 | [2025-10-19 17:07:12,444] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.446 | [2025-10-19 17:07:12,444] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.446 | [2025-10-19 17:07:12,444] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.446 | [2025-10-19 17:07:12,444] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.446 | [2025-10-19 17:07:12,444] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.446 | [2025-10-19 17:07:12,444] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.447 | [2025-10-19 17:07:12,444] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.447 | [2025-10-19 17:07:12,444] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.447 | [2025-10-19 17:07:12,444] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.447 | [2025-10-19 17:07:12,444] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.447 | [2025-10-19 17:07:12,444] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.447 | [2025-10-19 17:07:12,444] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.447 | [2025-10-19 17:07:12,444] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.447 | [2025-10-19 17:07:12,444] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.447 | [2025-10-19 17:07:12,444] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.447 | [2025-10-19 17:07:12,445] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.447 | [2025-10-19 17:07:12,445] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.447 | [2025-10-19 17:07:12,445] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.447 | [2025-10-19 17:07:12,445] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.447 | [2025-10-19 17:07:12,445] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.447 | [2025-10-19 17:07:12,445] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.447 | [2025-10-19 17:07:12,445] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.447 | [2025-10-19 17:07:12,445] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.447 | [2025-10-19 17:07:12,445] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.447 | [2025-10-19 17:07:12,445] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.447 | [2025-10-19 17:07:12,445] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.447 | [2025-10-19 17:07:12,445] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.447 | [2025-10-19 17:07:12,445] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.447 | [2025-10-19 17:07:12,445] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.447 | [2025-10-19 17:07:12,445] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.447 | [2025-10-19 17:07:12,445] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.447 | [2025-10-19 17:07:12,445] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.447 | [2025-10-19 17:07:12,445] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.447 | [2025-10-19 17:07:12,445] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.447 | [2025-10-19 17:07:12,445] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.447 | [2025-10-19 17:07:12,445] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.447 | [2025-10-19 17:07:12,445] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.448 | [2025-10-19 17:07:12,445] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.448 | [2025-10-19 17:07:12,445] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.448 | [2025-10-19 17:07:12,445] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.448 | [2025-10-19 17:07:12,445] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.448 | [2025-10-19 17:07:12,445] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.448 | [2025-10-19 17:07:12,446] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.448 | [2025-10-19 17:07:12,446] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.448 | [2025-10-19 17:07:12,446] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.448 | [2025-10-19 17:07:12,446] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.448 | [2025-10-19 17:07:12,446] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.448 | [2025-10-19 17:07:12,446] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.448 | [2025-10-19 17:07:12,446] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.448 | [2025-10-19 17:07:12,446] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.448 | [2025-10-19 17:07:12,446] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.448 | [2025-10-19 17:07:12,446] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.448 | [2025-10-19 17:07:12,446] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.448 | [2025-10-19 17:07:12,446] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.448 | [2025-10-19 17:07:12,446] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.448 | [2025-10-19 17:07:12,446] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.457 | [2025-10-19 17:07:12,453] INFO [Broker id=1] Finished LeaderAndIsr request in 854ms correlationId 1 from controller 1 for 51 partitions (state.change.logger)
2025-10-19 12:07:12.466 | [2025-10-19 17:07:12,464] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 28 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.467 | [2025-10-19 17:07:12,467] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 27 milliseconds for epoch 0, of which 27 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.468 | [2025-10-19 17:07:12,467] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 25 milliseconds for epoch 0, of which 25 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.468 | [2025-10-19 17:07:12,468] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 26 milliseconds for epoch 0, of which 25 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.468 | [2025-10-19 17:07:12,468] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 26 milliseconds for epoch 0, of which 26 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.469 | [2025-10-19 17:07:12,469] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 27 milliseconds for epoch 0, of which 26 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.472 | [2025-10-19 17:07:12,472] TRACE [Controller id=1 epoch=5] Received response LeaderAndIsrResponseData(errorCode=0, partitionErrors=[], topics=[LeaderAndIsrTopicError(topicId=6ep0dUNwQAaqKr79SJ8ITA, partitionErrors=[LeaderAndIsrPartitionError(topicName='', partitionIndex=13, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=46, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=9, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=42, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=21, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=17, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=30, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=26, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=5, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=38, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=1, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=34, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=16, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=45, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=12, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=41, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=24, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=20, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=49, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=0, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=29, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=25, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=8, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=37, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=4, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=33, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=15, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=48, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=11, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=44, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=23, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=19, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=32, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=28, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=7, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=40, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=3, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=36, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=47, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=14, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=43, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=10, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=22, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=18, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=31, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=27, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=39, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=6, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=35, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=2, errorCode=0)]), LeaderAndIsrTopicError(topicId=yWm6W48_TyqOOX8W2L0ItA, partitionErrors=[LeaderAndIsrPartitionError(topicName='', partitionIndex=0, errorCode=0)])]) for request LEADER_AND_ISR with correlation id 1 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-10-19 12:07:12.488 | [2025-10-19 17:07:12,488] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-13 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.488 | [2025-10-19 17:07:12,488] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-46 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.488 | [2025-10-19 17:07:12,488] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-9 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.488 | [2025-10-19 17:07:12,488] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-42 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.488 | [2025-10-19 17:07:12,488] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-21 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.488 | [2025-10-19 17:07:12,488] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-17 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.488 | [2025-10-19 17:07:12,488] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-30 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.488 | [2025-10-19 17:07:12,488] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-26 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.488 | [2025-10-19 17:07:12,488] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-5 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.494 | [2025-10-19 17:07:12,488] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-38 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.494 | [2025-10-19 17:07:12,494] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-1 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.494 | [2025-10-19 17:07:12,494] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-34 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.495 | [2025-10-19 17:07:12,494] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-16 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.496 | [2025-10-19 17:07:12,494] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-45 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.496 | [2025-10-19 17:07:12,495] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-12 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.496 | [2025-10-19 17:07:12,495] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-41 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.496 | [2025-10-19 17:07:12,495] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-24 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.496 | [2025-10-19 17:07:12,495] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-20 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.496 | [2025-10-19 17:07:12,495] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-49 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.496 | [2025-10-19 17:07:12,495] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-0 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.496 | [2025-10-19 17:07:12,495] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-29 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.500 | [2025-10-19 17:07:12,497] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-25 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.500 | [2025-10-19 17:07:12,497] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-8 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.500 | [2025-10-19 17:07:12,498] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-37 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.500 | [2025-10-19 17:07:12,498] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-4 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.500 | [2025-10-19 17:07:12,498] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-33 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.500 | [2025-10-19 17:07:12,498] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-15 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.500 | [2025-10-19 17:07:12,498] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-48 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.500 | [2025-10-19 17:07:12,498] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-11 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.500 | [2025-10-19 17:07:12,499] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-44 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.500 | [2025-10-19 17:07:12,499] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-23 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.500 | [2025-10-19 17:07:12,499] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-19 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.500 | [2025-10-19 17:07:12,499] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-32 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.500 | [2025-10-19 17:07:12,499] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-28 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.500 | [2025-10-19 17:07:12,499] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-7 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.500 | [2025-10-19 17:07:12,499] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-40 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.500 | [2025-10-19 17:07:12,499] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-3 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.500 | [2025-10-19 17:07:12,499] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-36 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.500 | [2025-10-19 17:07:12,499] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-47 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.500 | [2025-10-19 17:07:12,499] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-14 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.500 | [2025-10-19 17:07:12,499] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-43 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.500 | [2025-10-19 17:07:12,499] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-10 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.500 | [2025-10-19 17:07:12,499] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-22 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.500 | [2025-10-19 17:07:12,499] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-18 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.500 | [2025-10-19 17:07:12,500] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-31 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.505 | [2025-10-19 17:07:12,504] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-27 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.505 | [2025-10-19 17:07:12,504] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-39 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.505 | [2025-10-19 17:07:12,504] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-6 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.505 | [2025-10-19 17:07:12,504] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-35 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.505 | [2025-10-19 17:07:12,504] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-2 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.505 | [2025-10-19 17:07:12,504] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='mesa-ya.restaurants.created', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition mesa-ya.restaurants.created-0 in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.507 | [2025-10-19 17:07:12,506] INFO [Broker id=1] Add 51 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 5 with correlation id 2 (state.change.logger)
2025-10-19 12:07:12.512 | [2025-10-19 17:07:12,508] TRACE [Controller id=1 epoch=5] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 2 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-10-19 12:07:12.598 | [2025-10-19 17:07:12,597] INFO Loaded member MemberMetadata(memberId=mesa-ya-service-client-9a0094a4-6972-4e79-a5d6-5ed4ed5cfa65, groupInstanceId=None, clientId=mesa-ya-service-client, clientHost=/172.18.0.4, sessionTimeoutMs=30000, rebalanceTimeoutMs=60000, supportedProtocols=List(NestReplyPartitionAssigner)) in group nestjs-group-client with generation 1. (kafka.coordinator.group.GroupMetadata$)
2025-10-19 12:07:12.632 | [2025-10-19 17:07:12,631] INFO Loaded member MemberMetadata(memberId=mesa-ya-service-client-72bf5d0c-5531-4f4b-bc39-f00715991c39, groupInstanceId=None, clientId=mesa-ya-service-client, clientHost=/172.18.0.4, sessionTimeoutMs=30000, rebalanceTimeoutMs=60000, supportedProtocols=List(NestReplyPartitionAssigner)) in group nestjs-group-client with generation 3. (kafka.coordinator.group.GroupMetadata$)
2025-10-19 12:07:12.645 | [2025-10-19 17:07:12,645] INFO [GroupCoordinator 1]: Loading group metadata for nestjs-group-client with generation 4 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:07:12.646 | [2025-10-19 17:07:12,646] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 204 milliseconds for epoch 0, of which 27 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.647 | [2025-10-19 17:07:12,647] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 205 milliseconds for epoch 0, of which 204 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.647 | [2025-10-19 17:07:12,647] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 205 milliseconds for epoch 0, of which 205 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.648 | [2025-10-19 17:07:12,648] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 205 milliseconds for epoch 0, of which 205 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.648 | [2025-10-19 17:07:12,648] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 206 milliseconds for epoch 0, of which 206 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.649 | [2025-10-19 17:07:12,648] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 205 milliseconds for epoch 0, of which 205 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.649 | [2025-10-19 17:07:12,649] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 206 milliseconds for epoch 0, of which 206 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.649 | [2025-10-19 17:07:12,649] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 206 milliseconds for epoch 0, of which 206 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.650 | [2025-10-19 17:07:12,649] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 206 milliseconds for epoch 0, of which 206 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.650 | [2025-10-19 17:07:12,650] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 207 milliseconds for epoch 0, of which 207 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.660 | [2025-10-19 17:07:12,659] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 207 milliseconds for epoch 0, of which 207 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.661 | [2025-10-19 17:07:12,660] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 217 milliseconds for epoch 0, of which 217 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.661 | [2025-10-19 17:07:12,660] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 217 milliseconds for epoch 0, of which 217 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.661 | [2025-10-19 17:07:12,661] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 218 milliseconds for epoch 0, of which 218 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.662 | [2025-10-19 17:07:12,661] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 218 milliseconds for epoch 0, of which 218 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.662 | [2025-10-19 17:07:12,662] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 218 milliseconds for epoch 0, of which 217 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.662 | [2025-10-19 17:07:12,662] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 218 milliseconds for epoch 0, of which 218 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.663 | [2025-10-19 17:07:12,662] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 218 milliseconds for epoch 0, of which 218 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.663 | [2025-10-19 17:07:12,663] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 219 milliseconds for epoch 0, of which 219 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.664 | [2025-10-19 17:07:12,663] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 219 milliseconds for epoch 0, of which 219 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.664 | [2025-10-19 17:07:12,664] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 219 milliseconds for epoch 0, of which 219 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.664 | [2025-10-19 17:07:12,664] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 220 milliseconds for epoch 0, of which 220 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.664 | [2025-10-19 17:07:12,664] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 220 milliseconds for epoch 0, of which 220 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.665 | [2025-10-19 17:07:12,664] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 219 milliseconds for epoch 0, of which 219 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.665 | [2025-10-19 17:07:12,665] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 220 milliseconds for epoch 0, of which 220 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.665 | [2025-10-19 17:07:12,665] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 220 milliseconds for epoch 0, of which 220 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.666 | [2025-10-19 17:07:12,665] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 220 milliseconds for epoch 0, of which 220 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.699 | [2025-10-19 17:07:12,666] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 221 milliseconds for epoch 0, of which 221 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.699 | [2025-10-19 17:07:12,677] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 232 milliseconds for epoch 0, of which 231 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.709 | [2025-10-19 17:07:12,693] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 248 milliseconds for epoch 0, of which 247 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.709 | [2025-10-19 17:07:12,709] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 264 milliseconds for epoch 0, of which 264 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.710 | [2025-10-19 17:07:12,710] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 265 milliseconds for epoch 0, of which 264 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.710 | [2025-10-19 17:07:12,710] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 265 milliseconds for epoch 0, of which 265 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.711 | [2025-10-19 17:07:12,710] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 265 milliseconds for epoch 0, of which 265 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.711 | [2025-10-19 17:07:12,711] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 266 milliseconds for epoch 0, of which 266 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.712 | [2025-10-19 17:07:12,711] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 266 milliseconds for epoch 0, of which 266 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.712 | [2025-10-19 17:07:12,712] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 267 milliseconds for epoch 0, of which 266 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.712 | [2025-10-19 17:07:12,712] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 266 milliseconds for epoch 0, of which 266 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.712 | [2025-10-19 17:07:12,712] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 266 milliseconds for epoch 0, of which 266 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.713 | [2025-10-19 17:07:12,713] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 266 milliseconds for epoch 0, of which 266 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.713 | [2025-10-19 17:07:12,713] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 267 milliseconds for epoch 0, of which 267 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.714 | [2025-10-19 17:07:12,713] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 267 milliseconds for epoch 0, of which 267 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.714 | [2025-10-19 17:07:12,714] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 268 milliseconds for epoch 0, of which 268 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:12.714 | [2025-10-19 17:07:12,714] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 268 milliseconds for epoch 0, of which 268 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:07:16.513 | [2025-10-19 17:07:16,512] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 12:07:16.514 | [2025-10-19 17:07:16,513] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 12:07:16.521 | [2025-10-19 17:07:16,521] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 12:07:16.523 | [2025-10-19 17:07:16,523] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 12:12:09.481 | [2025-10-19 17:12:09,480] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 12:12:09.481 | [2025-10-19 17:12:09,481] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 12:12:09.484 | [2025-10-19 17:12:09,484] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 12:12:09.484 | [2025-10-19 17:12:09,484] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 12:16:56.626 | [2025-10-19 17:16:56,625] INFO [GroupMetadataManager brokerId=1] Group nestjs-group-client transitioned to Dead in generation 4 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:17:02.071 | [2025-10-19 17:17:02,070] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 12:17:02.071 | [2025-10-19 17:17:02,070] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 12:17:02.073 | [2025-10-19 17:17:02,073] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 12:17:02.073 | [2025-10-19 17:17:02,073] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 12:20:41.968 | [2025-10-19 17:20:41,967] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
2025-10-19 12:20:41.973 | [2025-10-19 17:20:41,972] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
2025-10-19 12:20:41.976 | [2025-10-19 17:20:41,976] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
2025-10-19 12:20:41.999 | [2025-10-19 17:20:41,998] INFO [Controller id=1] Shutting down broker 1 (kafka.controller.KafkaController)
2025-10-19 12:20:41.999 | [2025-10-19 17:20:41,999] DEBUG [Controller id=1] All shutting down brokers: 1 (kafka.controller.KafkaController)
2025-10-19 12:20:42.000 | [2025-10-19 17:20:41,999] DEBUG [Controller id=1] Live brokers:  (kafka.controller.KafkaController)
2025-10-19 12:20:42.003 | [2025-10-19 17:20:42,002] INFO [Controller id=1 epoch=5] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-10-19 12:20:42.004 | [2025-10-19 17:20:42,004] TRACE [Controller id=1] All leaders = __consumer_offsets-13 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-46 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-9 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-42 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-21 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-17 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-30 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-26 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-5 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-38 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-1 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-34 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-16 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-45 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-12 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-41 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-24 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-20 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-49 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-0 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-29 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-25 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-8 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-37 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-4 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-33 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-15 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-48 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-11 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-44 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-23 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-19 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-32 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-28 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-7 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-40 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-3 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-36 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-47 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-14 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-43 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-10 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-22 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-18 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-31 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-27 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-39 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-6 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-35 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),mesa-ya.restaurants.created-0 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-2 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1) (kafka.controller.KafkaController)
2025-10-19 12:20:42.014 | [2025-10-19 17:20:42,013] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 14ms (kafka.server.KafkaServer)
2025-10-19 12:20:42.022 | [2025-10-19 17:20:42,022] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-10-19 12:20:42.023 | [2025-10-19 17:20:42,022] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-10-19 12:20:42.023 | [2025-10-19 17:20:42,022] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-10-19 12:20:42.028 | [2025-10-19 17:20:42,026] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
2025-10-19 12:20:42.056 | [2025-10-19 17:20:42,055] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
2025-10-19 12:20:42.058 | [2025-10-19 17:20:42,057] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
2025-10-19 12:20:42.066 | [2025-10-19 17:20:42,066] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
2025-10-19 12:20:42.074 | [2025-10-19 17:20:42,074] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:20:42.080 | [2025-10-19 17:20:42,080] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:20:42.080 | [2025-10-19 17:20:42,080] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:20:42.082 | [2025-10-19 17:20:42,081] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
2025-10-19 12:20:42.084 | [2025-10-19 17:20:42,084] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:20:42.087 | [2025-10-19 17:20:42,087] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:20:42.087 | [2025-10-19 17:20:42,087] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:20:42.091 | [2025-10-19 17:20:42,090] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
2025-10-19 12:20:42.094 | [2025-10-19 17:20:42,094] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
2025-10-19 12:20:42.096 | [2025-10-19 17:20:42,095] INFO [TxnMarkerSenderThread-1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-10-19 12:20:42.097 | [2025-10-19 17:20:42,096] INFO [TxnMarkerSenderThread-1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-10-19 12:20:42.097 | [2025-10-19 17:20:42,096] INFO [TxnMarkerSenderThread-1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-10-19 12:20:42.099 | [2025-10-19 17:20:42,099] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
2025-10-19 12:20:42.100 | [2025-10-19 17:20:42,099] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:20:42.101 | [2025-10-19 17:20:42,101] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:20:42.103 | [2025-10-19 17:20:42,103] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:20:42.103 | [2025-10-19 17:20:42,103] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:20:42.105 | [2025-10-19 17:20:42,105] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:20:42.107 | [2025-10-19 17:20:42,107] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:20:42.108 | [2025-10-19 17:20:42,107] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:20:42.109 | [2025-10-19 17:20:42,108] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:20:42.109 | [2025-10-19 17:20:42,109] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
2025-10-19 12:20:42.112 | [2025-10-19 17:20:42,110] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-10-19 12:20:42.112 | [2025-10-19 17:20:42,111] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-10-19 12:20:42.112 | [2025-10-19 17:20:42,112] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-10-19 12:20:42.113 | [2025-10-19 17:20:42,112] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
2025-10-19 12:20:42.115 | [2025-10-19 17:20:42,114] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
2025-10-19 12:20:42.115 | [2025-10-19 17:20:42,115] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
2025-10-19 12:20:42.115 | [2025-10-19 17:20:42,115] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
2025-10-19 12:20:42.116 | [2025-10-19 17:20:42,116] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:20:42.119 | [2025-10-19 17:20:42,118] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:20:42.119 | [2025-10-19 17:20:42,118] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:20:42.121 | [2025-10-19 17:20:42,121] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:20:42.123 | [2025-10-19 17:20:42,123] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:20:42.124 | [2025-10-19 17:20:42,123] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:20:42.126 | [2025-10-19 17:20:42,125] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:20:42.129 | [2025-10-19 17:20:42,129] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:20:42.129 | [2025-10-19 17:20:42,129] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:20:42.131 | [2025-10-19 17:20:42,131] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:20:42.134 | [2025-10-19 17:20:42,134] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:20:42.134 | [2025-10-19 17:20:42,134] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:20:42.150 | [2025-10-19 17:20:42,149] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
2025-10-19 12:20:42.150 | [2025-10-19 17:20:42,150] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.BrokerToControllerRequestThread)
2025-10-19 12:20:42.151 | [2025-10-19 17:20:42,150] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.BrokerToControllerRequestThread)
2025-10-19 12:20:42.151 | [2025-10-19 17:20:42,150] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
2025-10-19 12:20:42.154 | [2025-10-19 17:20:42,153] INFO Broker to controller channel manager for alter-partition shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
2025-10-19 12:20:42.154 | [2025-10-19 17:20:42,153] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.BrokerToControllerRequestThread)
2025-10-19 12:20:42.154 | [2025-10-19 17:20:42,154] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Stopped (kafka.server.BrokerToControllerRequestThread)
2025-10-19 12:20:42.154 | [2025-10-19 17:20:42,154] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
2025-10-19 12:20:42.155 | [2025-10-19 17:20:42,155] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
2025-10-19 12:20:42.156 | [2025-10-19 17:20:42,156] INFO Shutting down. (kafka.log.LogManager)
2025-10-19 12:20:42.158 | [2025-10-19 17:20:42,157] INFO Shutting down the log cleaner. (kafka.log.LogCleaner)
2025-10-19 12:20:42.159 | [2025-10-19 17:20:42,158] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
2025-10-19 12:20:42.160 | [2025-10-19 17:20:42,159] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
2025-10-19 12:20:42.161 | [2025-10-19 17:20:42,159] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
2025-10-19 12:20:42.325 | [2025-10-19 17:20:42,325] INFO [ProducerStateManager partition=__consumer_offsets-19]Wrote producer snapshot at offset 5 with 0 producer ids in 8 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
2025-10-19 12:20:42.995 | [2025-10-19 17:20:42,994] INFO Shutdown complete. (kafka.log.LogManager)
2025-10-19 12:20:42.996 | [2025-10-19 17:20:42,995] INFO [ControllerEventThread controllerId=1] Shutting down (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-10-19 12:20:42.997 | [2025-10-19 17:20:42,996] INFO [ControllerEventThread controllerId=1] Shutdown completed (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-10-19 12:20:42.997 | [2025-10-19 17:20:42,996] INFO [ControllerEventThread controllerId=1] Stopped (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-10-19 12:20:42.997 | [2025-10-19 17:20:42,997] DEBUG [Controller id=1] Resigning (kafka.controller.KafkaController)
2025-10-19 12:20:42.998 | [2025-10-19 17:20:42,997] DEBUG [Controller id=1] Unregister BrokerModifications handler for Set(1) (kafka.controller.KafkaController)
2025-10-19 12:20:43.001 | [2025-10-19 17:20:43,001] INFO [PartitionStateMachine controllerId=1] Stopped partition state machine (kafka.controller.ZkPartitionStateMachine)
2025-10-19 12:20:43.003 | [2025-10-19 17:20:43,002] INFO [ReplicaStateMachine controllerId=1] Stopped replica state machine (kafka.controller.ZkReplicaStateMachine)
2025-10-19 12:20:43.004 | [2025-10-19 17:20:43,003] INFO [RequestSendThread controllerId=1] Shutting down (kafka.controller.RequestSendThread)
2025-10-19 12:20:43.005 | [2025-10-19 17:20:43,003] INFO [RequestSendThread controllerId=1] Shutdown completed (kafka.controller.RequestSendThread)
2025-10-19 12:20:43.005 | [2025-10-19 17:20:43,003] INFO [RequestSendThread controllerId=1] Stopped (kafka.controller.RequestSendThread)
2025-10-19 12:20:43.010 | [2025-10-19 17:20:43,009] INFO [Controller id=1] Resigned (kafka.controller.KafkaController)
2025-10-19 12:20:43.012 | [2025-10-19 17:20:43,011] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-10-19 12:20:43.012 | [2025-10-19 17:20:43,012] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-10-19 12:20:43.013 | [2025-10-19 17:20:43,012] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-10-19 12:20:43.013 | [2025-10-19 17:20:43,013] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
2025-10-19 12:20:43.130 | [2025-10-19 17:20:43,129] INFO Session: 0x10000049fb70001 closed (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:20:43.130 | [2025-10-19 17:20:43,129] INFO EventThread shut down for session: 0x10000049fb70001 (org.apache.zookeeper.ClientCnxn)
2025-10-19 12:20:43.132 | [2025-10-19 17:20:43,132] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
2025-10-19 12:20:43.133 | [2025-10-19 17:20:43,133] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 12:20:43.136 | [2025-10-19 17:20:43,136] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 12:20:43.136 | [2025-10-19 17:20:43,136] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 12:20:43.137 | [2025-10-19 17:20:43,136] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 12:20:43.137 | [2025-10-19 17:20:43,137] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 12:20:43.137 | [2025-10-19 17:20:43,137] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 12:20:43.138 | [2025-10-19 17:20:43,137] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 12:20:43.138 | [2025-10-19 17:20:43,138] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 12:20:43.138 | [2025-10-19 17:20:43,138] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 12:20:43.139 | [2025-10-19 17:20:43,139] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 12:20:43.140 | [2025-10-19 17:20:43,139] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 12:20:43.140 | [2025-10-19 17:20:43,139] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 12:20:43.142 | [2025-10-19 17:20:43,141] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
2025-10-19 12:20:43.168 | [2025-10-19 17:20:43,167] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
2025-10-19 12:20:43.169 | [2025-10-19 17:20:43,168] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
2025-10-19 12:20:43.169 | [2025-10-19 17:20:43,169] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
2025-10-19 12:20:43.169 | [2025-10-19 17:20:43,169] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
2025-10-19 12:20:43.175 | [2025-10-19 17:20:43,174] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
2025-10-19 12:20:43.176 | [2025-10-19 17:20:43,175] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
2025-10-19 12:20:43.178 | [2025-10-19 17:20:43,177] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
2025-10-19 12:43:02.962 | ===> User
2025-10-19 12:43:02.969 | uid=1000(appuser) gid=1000(appuser) groups=1000(appuser)
2025-10-19 12:43:02.970 | ===> Configuring ...
2025-10-19 12:43:02.999 | Running in Zookeeper mode...
2025-10-19 12:43:06.009 | ===> Running preflight checks ... 
2025-10-19 12:43:06.015 | ===> Check if /var/lib/kafka/data is writable ...
2025-10-19 12:43:06.715 | ===> Check if Zookeeper is healthy ...
2025-10-19 12:43:08.416 | [2025-10-19 17:43:08,414] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:08.416 | [2025-10-19 17:43:08,416] INFO Client environment:host.name=2ae4b23f74a4 (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:08.416 | [2025-10-19 17:43:08,416] INFO Client environment:java.version=11.0.20 (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:08.416 | [2025-10-19 17:43:08,416] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:08.416 | [2025-10-19 17:43:08,416] INFO Client environment:java.home=/usr/lib/jvm/java-11-zulu-openjdk-ca (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:08.416 | [2025-10-19 17:43:08,416] INFO Client environment:java.class.path=/usr/share/java/cp-base-new/minimal-json-0.9.5.jar:/usr/share/java/cp-base-new/kafka-clients-7.5.0-ccs.jar:/usr/share/java/cp-base-new/slf4j-api-1.7.36.jar:/usr/share/java/cp-base-new/jmx_prometheus_javaagent-0.18.0.jar:/usr/share/java/cp-base-new/jackson-annotations-2.14.2.jar:/usr/share/java/cp-base-new/scala-collection-compat_2.13-2.10.0.jar:/usr/share/java/cp-base-new/gson-2.9.0.jar:/usr/share/java/cp-base-new/kafka-server-common-7.5.0-ccs.jar:/usr/share/java/cp-base-new/jose4j-0.9.3.jar:/usr/share/java/cp-base-new/scala-reflect-2.13.10.jar:/usr/share/java/cp-base-new/zstd-jni-1.5.5-1.jar:/usr/share/java/cp-base-new/jackson-datatype-jdk8-2.14.2.jar:/usr/share/java/cp-base-new/kafka-storage-7.5.0-ccs.jar:/usr/share/java/cp-base-new/reload4j-1.2.19.jar:/usr/share/java/cp-base-new/kafka-raft-7.5.0-ccs.jar:/usr/share/java/cp-base-new/logredactor-1.0.12.jar:/usr/share/java/cp-base-new/jackson-module-scala_2.13-2.14.2.jar:/usr/share/java/cp-base-new/paranamer-2.8.jar:/usr/share/java/cp-base-new/utility-belt-7.5.0.jar:/usr/share/java/cp-base-new/snakeyaml-2.0.jar:/usr/share/java/cp-base-new/metrics-core-2.2.0.jar:/usr/share/java/cp-base-new/metrics-core-4.1.12.1.jar:/usr/share/java/cp-base-new/kafka-tools-api-7.5.0-ccs.jar:/usr/share/java/cp-base-new/logredactor-metrics-1.0.12.jar:/usr/share/java/cp-base-new/scala-logging_2.13-3.9.4.jar:/usr/share/java/cp-base-new/jolokia-core-1.7.1.jar:/usr/share/java/cp-base-new/kafka-metadata-7.5.0-ccs.jar:/usr/share/java/cp-base-new/audience-annotations-0.5.0.jar:/usr/share/java/cp-base-new/argparse4j-0.7.0.jar:/usr/share/java/cp-base-new/kafka-storage-api-7.5.0-ccs.jar:/usr/share/java/cp-base-new/jopt-simple-5.0.4.jar:/usr/share/java/cp-base-new/jackson-dataformat-csv-2.14.2.jar:/usr/share/java/cp-base-new/jackson-core-2.14.2.jar:/usr/share/java/cp-base-new/snappy-java-1.1.10.1.jar:/usr/share/java/cp-base-new/scala-java8-compat_2.13-1.0.2.jar:/usr/share/java/cp-base-new/disk-usage-agent-7.5.0.jar:/usr/share/java/cp-base-new/commons-cli-1.4.jar:/usr/share/java/cp-base-new/common-utils-7.5.0.jar:/usr/share/java/cp-base-new/jolokia-jvm-1.7.1.jar:/usr/share/java/cp-base-new/lz4-java-1.8.0.jar:/usr/share/java/cp-base-new/json-simple-1.1.1.jar:/usr/share/java/cp-base-new/zookeeper-3.6.3.jar:/usr/share/java/cp-base-new/kafka_2.13-7.5.0-ccs.jar:/usr/share/java/cp-base-new/jackson-databind-2.14.2.jar:/usr/share/java/cp-base-new/kafka-group-coordinator-7.5.0-ccs.jar:/usr/share/java/cp-base-new/slf4j-reload4j-1.7.36.jar:/usr/share/java/cp-base-new/zookeeper-jute-3.6.3.jar:/usr/share/java/cp-base-new/scala-library-2.13.10.jar:/usr/share/java/cp-base-new/re2j-1.6.jar:/usr/share/java/cp-base-new/jackson-dataformat-yaml-2.14.2.jar (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:08.416 | [2025-10-19 17:43:08,416] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:08.417 | [2025-10-19 17:43:08,416] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:08.417 | [2025-10-19 17:43:08,416] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:08.417 | [2025-10-19 17:43:08,416] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:08.417 | [2025-10-19 17:43:08,417] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:08.417 | [2025-10-19 17:43:08,417] INFO Client environment:os.version=6.6.87.1-microsoft-standard-WSL2 (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:08.417 | [2025-10-19 17:43:08,417] INFO Client environment:user.name=appuser (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:08.417 | [2025-10-19 17:43:08,417] INFO Client environment:user.home=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:08.417 | [2025-10-19 17:43:08,417] INFO Client environment:user.dir=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:08.417 | [2025-10-19 17:43:08,417] INFO Client environment:os.memory.free=112MB (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:08.417 | [2025-10-19 17:43:08,417] INFO Client environment:os.memory.max=1948MB (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:08.417 | [2025-10-19 17:43:08,417] INFO Client environment:os.memory.total=122MB (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:08.430 | [2025-10-19 17:43:08,430] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=40000 watcher=io.confluent.admin.utils.ZookeeperConnectionWatcher@221af3c0 (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:08.456 | [2025-10-19 17:43:08,455] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
2025-10-19 12:43:08.481 | [2025-10-19 17:43:08,480] INFO jute.maxbuffer value is 1048575 Bytes (org.apache.zookeeper.ClientCnxnSocket)
2025-10-19 12:43:08.497 | [2025-10-19 17:43:08,496] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
2025-10-19 12:43:08.545 | [2025-10-19 17:43:08,543] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. (org.apache.zookeeper.ClientCnxn)
2025-10-19 12:43:08.545 | [2025-10-19 17:43:08,545] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-10-19 12:43:08.560 | [2025-10-19 17:43:08,560] INFO Socket connection established, initiating session, client: /172.18.0.3:55506, server: zookeeper/172.18.0.2:2181 (org.apache.zookeeper.ClientCnxn)
2025-10-19 12:43:08.608 | [2025-10-19 17:43:08,608] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, session id = 0x10000268ea80000, negotiated timeout = 40000 (org.apache.zookeeper.ClientCnxn)
2025-10-19 12:43:08.649 | [2025-10-19 17:43:08,645] WARN An exception was thrown while closing send thread for session 0x10000268ea80000. (org.apache.zookeeper.ClientCnxn)
2025-10-19 12:43:08.649 | EndOfStreamException: Unable to read additional data from server sessionid 0x10000268ea80000, likely server has closed socket
2025-10-19 12:43:08.649 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
2025-10-19 12:43:08.649 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
2025-10-19 12:43:08.649 | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-10-19 12:43:08.765 | [2025-10-19 17:43:08,764] INFO Session: 0x10000268ea80000 closed (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:08.765 | [2025-10-19 17:43:08,764] INFO EventThread shut down for session: 0x10000268ea80000 (org.apache.zookeeper.ClientCnxn)
2025-10-19 12:43:08.807 | Using log4j config /etc/kafka/log4j.properties
2025-10-19 12:43:08.952 | ===> Launching ... 
2025-10-19 12:43:08.967 | ===> Launching kafka ... 
2025-10-19 12:43:10.167 | [2025-10-19 17:43:10,166] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
2025-10-19 12:43:10.973 | [2025-10-19 17:43:10,972] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
2025-10-19 12:43:11.151 | [2025-10-19 17:43:11,150] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
2025-10-19 12:43:11.153 | [2025-10-19 17:43:11,153] INFO starting (kafka.server.KafkaServer)
2025-10-19 12:43:11.154 | [2025-10-19 17:43:11,153] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
2025-10-19 12:43:11.213 | [2025-10-19 17:43:11,212] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
2025-10-19 12:43:11.250 | [2025-10-19 17:43:11,249] INFO Client environment:zookeeper.version=3.6.4--d65253dcf68e9097c6e95a126463fd5fdeb4521c, built on 12/18/2022 18:10 GMT (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:11.250 | [2025-10-19 17:43:11,249] INFO Client environment:host.name=2ae4b23f74a4 (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:11.250 | [2025-10-19 17:43:11,249] INFO Client environment:java.version=11.0.20 (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:11.250 | [2025-10-19 17:43:11,249] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:11.250 | [2025-10-19 17:43:11,249] INFO Client environment:java.home=/usr/lib/jvm/java-11-zulu-openjdk-ca (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:11.250 | [2025-10-19 17:43:11,249] INFO Client environment:java.class.path=/usr/bin/../share/java/kafka/zookeeper-jute-3.6.4.jar:/usr/bin/../share/java/kafka/jackson-datatype-jdk8-2.13.5.jar:/usr/bin/../share/java/kafka/jakarta.inject-2.6.1.jar:/usr/bin/../share/java/kafka/netty-transport-native-epoll-4.1.96.Final.jar:/usr/bin/../share/java/kafka/kafka-clients-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jline-3.22.0.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.36.jar:/usr/bin/../share/java/kafka/reflections-0.9.12.jar:/usr/bin/../share/java/kafka/scala-collection-compat_2.13-2.10.0.jar:/usr/bin/../share/java/kafka/javassist-3.29.2-GA.jar:/usr/bin/../share/java/kafka/connect-runtime-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jakarta.annotation-api-1.3.5.jar:/usr/bin/../share/java/kafka/jackson-databind-2.13.5.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/kafka-streams-scala_2.13-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/javax.activation-api-1.2.0.jar:/usr/bin/../share/java/kafka/rocksdbjni-7.1.2.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/usr/bin/../share/java/kafka/kafka-server-common-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jose4j-0.9.3.jar:/usr/bin/../share/java/kafka/scala-reflect-2.13.10.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.13.5.jar:/usr/bin/../share/java/kafka/zstd-jni-1.5.5-1.jar:/usr/bin/../share/java/kafka/kafka-storage-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jetty-security-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.39.1.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/kafka-raft-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/netty-transport-native-unix-common-4.1.96.Final.jar:/usr/bin/../share/java/kafka/jersey-server-2.39.1.jar:/usr/bin/../share/java/kafka/paranamer-2.8.jar:/usr/bin/../share/java/kafka/jersey-common-2.39.1.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/netty-transport-4.1.96.Final.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/metrics-core-4.1.12.1.jar:/usr/bin/../share/java/kafka/netty-buffer-4.1.96.Final.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.13.5.jar:/usr/bin/../share/java/kafka/netty-resolver-4.1.96.Final.jar:/usr/bin/../share/java/kafka/kafka-tools-api-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jaxb-api-2.3.1.jar:/usr/bin/../share/java/kafka/jetty-util-ajax-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/scala-logging_2.13-3.9.4.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.6.1.jar:/usr/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/usr/bin/../share/java/kafka/jakarta.xml.bind-api-2.3.3.jar:/usr/bin/../share/java/kafka/kafka-metadata-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/plexus-utils-3.3.0.jar:/usr/bin/../share/java/kafka/jakarta.activation-api-1.2.2.jar:/usr/bin/../share/java/kafka/argparse4j-0.7.0.jar:/usr/bin/../share/java/kafka/hk2-utils-2.6.1.jar:/usr/bin/../share/java/kafka/connect-api-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/connect-mirror-client-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.3.jar:/usr/bin/../share/java/kafka/javax.annotation-api-1.3.2.jar:/usr/bin/../share/java/kafka/jersey-hk2-2.39.1.jar:/usr/bin/../share/java/kafka/kafka-storage-api-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jetty-http-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/trogdor-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/maven-artifact-3.8.4.jar:/usr/bin/../share/java/kafka/connect-json-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/scala-java8-compat_2.13-1.0.2.jar:/usr/bin/../share/java/kafka/jetty-server-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/swagger-annotations-2.2.8.jar:/usr/bin/../share/java/kafka/jetty-util-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/commons-cli-1.4.jar:/usr/bin/../share/java/kafka/jetty-io-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/activation-1.1.1.jar:/usr/bin/../share/java/kafka/lz4-java-1.8.0.jar:/usr/bin/../share/java/kafka/kafka-shell-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/netty-common-4.1.96.Final.jar:/usr/bin/../share/java/kafka/jetty-client-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/jackson-module-scala_2.13-2.13.5.jar:/usr/bin/../share/java/kafka/connect-transforms-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jackson-core-2.13.5.jar:/usr/bin/../share/java/kafka/kafka_2.13-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/netty-codec-4.1.96.Final.jar:/usr/bin/../share/java/kafka/zookeeper-3.6.4.jar:/usr/bin/../share/java/kafka/kafka-streams-test-utils-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/hk2-api-2.6.1.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.39.1.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/reload4j-1.2.25.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.10.0.jar:/usr/bin/../share/java/kafka/netty-transport-classes-epoll-4.1.96.Final.jar:/usr/bin/../share/java/kafka/connect-mirror-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/kafka-streams-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/kafka-group-coordinator-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/connect-basic-auth-extension-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jersey-client-2.39.1.jar:/usr/bin/../share/java/kafka/kafka-tools-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/slf4j-reload4j-1.7.36.jar:/usr/bin/../share/java/kafka/jackson-dataformat-csv-2.13.5.jar:/usr/bin/../share/java/kafka/scala-library-2.13.10.jar:/usr/bin/../share/java/kafka/netty-handler-4.1.96.Final.jar:/usr/bin/../share/java/kafka/jakarta.validation-api-2.0.2.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.13.5.jar:/usr/bin/../share/java/kafka/audience-annotations-0.13.0.jar:/usr/bin/../share/java/kafka/hk2-locator-2.6.1.jar:/usr/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.6.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.13.5.jar:/usr/bin/../share/java/confluent-telemetry/* (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:11.250 | [2025-10-19 17:43:11,250] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:11.250 | [2025-10-19 17:43:11,250] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:11.250 | [2025-10-19 17:43:11,250] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:11.250 | [2025-10-19 17:43:11,250] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:11.250 | [2025-10-19 17:43:11,250] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:11.250 | [2025-10-19 17:43:11,250] INFO Client environment:os.version=6.6.87.1-microsoft-standard-WSL2 (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:11.250 | [2025-10-19 17:43:11,250] INFO Client environment:user.name=appuser (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:11.250 | [2025-10-19 17:43:11,250] INFO Client environment:user.home=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:11.250 | [2025-10-19 17:43:11,250] INFO Client environment:user.dir=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:11.250 | [2025-10-19 17:43:11,250] INFO Client environment:os.memory.free=1009MB (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:11.251 | [2025-10-19 17:43:11,250] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:11.251 | [2025-10-19 17:43:11,250] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:11.256 | [2025-10-19 17:43:11,256] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@13d73fa (org.apache.zookeeper.ZooKeeper)
2025-10-19 12:43:11.271 | [2025-10-19 17:43:11,270] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
2025-10-19 12:43:11.284 | [2025-10-19 17:43:11,283] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
2025-10-19 12:43:11.290 | [2025-10-19 17:43:11,289] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
2025-10-19 12:43:11.303 | [2025-10-19 17:43:11,298] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. (org.apache.zookeeper.ClientCnxn)
2025-10-19 12:43:11.311 | [2025-10-19 17:43:11,310] INFO Socket connection established, initiating session, client: /172.18.0.3:55510, server: zookeeper/172.18.0.2:2181 (org.apache.zookeeper.ClientCnxn)
2025-10-19 12:43:11.339 | [2025-10-19 17:43:11,339] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, session id = 0x10000268ea80001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
2025-10-19 12:43:11.348 | [2025-10-19 17:43:11,346] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
2025-10-19 12:43:11.903 | [2025-10-19 17:43:11,903] INFO Cluster ID = DgiegCMhTNSyWQSymt96xQ (kafka.server.KafkaServer)
2025-10-19 12:43:11.997 | [2025-10-19 17:43:11,997] INFO KafkaConfig values: 
2025-10-19 12:43:11.997 | 	advertised.listeners = PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
2025-10-19 12:43:11.997 | 	alter.config.policy.class.name = null
2025-10-19 12:43:11.997 | 	alter.log.dirs.replication.quota.window.num = 11
2025-10-19 12:43:11.997 | 	alter.log.dirs.replication.quota.window.size.seconds = 1
2025-10-19 12:43:11.997 | 	authorizer.class.name = 
2025-10-19 12:43:11.997 | 	auto.create.topics.enable = true
2025-10-19 12:43:11.997 | 	auto.include.jmx.reporter = true
2025-10-19 12:43:11.997 | 	auto.leader.rebalance.enable = true
2025-10-19 12:43:11.997 | 	background.threads = 10
2025-10-19 12:43:11.997 | 	broker.heartbeat.interval.ms = 2000
2025-10-19 12:43:11.997 | 	broker.id = 1
2025-10-19 12:43:11.997 | 	broker.id.generation.enable = true
2025-10-19 12:43:11.997 | 	broker.rack = null
2025-10-19 12:43:11.997 | 	broker.session.timeout.ms = 9000
2025-10-19 12:43:11.997 | 	client.quota.callback.class = null
2025-10-19 12:43:11.997 | 	compression.type = producer
2025-10-19 12:43:11.997 | 	connection.failed.authentication.delay.ms = 100
2025-10-19 12:43:11.997 | 	connections.max.idle.ms = 600000
2025-10-19 12:43:11.997 | 	connections.max.reauth.ms = 0
2025-10-19 12:43:11.997 | 	control.plane.listener.name = null
2025-10-19 12:43:11.997 | 	controlled.shutdown.enable = true
2025-10-19 12:43:11.997 | 	controlled.shutdown.max.retries = 3
2025-10-19 12:43:11.997 | 	controlled.shutdown.retry.backoff.ms = 5000
2025-10-19 12:43:11.997 | 	controller.listener.names = null
2025-10-19 12:43:11.997 | 	controller.quorum.append.linger.ms = 25
2025-10-19 12:43:11.997 | 	controller.quorum.election.backoff.max.ms = 1000
2025-10-19 12:43:11.997 | 	controller.quorum.election.timeout.ms = 1000
2025-10-19 12:43:11.997 | 	controller.quorum.fetch.timeout.ms = 2000
2025-10-19 12:43:11.997 | 	controller.quorum.request.timeout.ms = 2000
2025-10-19 12:43:11.997 | 	controller.quorum.retry.backoff.ms = 20
2025-10-19 12:43:11.997 | 	controller.quorum.voters = []
2025-10-19 12:43:11.997 | 	controller.quota.window.num = 11
2025-10-19 12:43:11.997 | 	controller.quota.window.size.seconds = 1
2025-10-19 12:43:11.997 | 	controller.socket.timeout.ms = 30000
2025-10-19 12:43:11.997 | 	create.topic.policy.class.name = null
2025-10-19 12:43:11.997 | 	default.replication.factor = 1
2025-10-19 12:43:11.997 | 	delegation.token.expiry.check.interval.ms = 3600000
2025-10-19 12:43:11.997 | 	delegation.token.expiry.time.ms = 86400000
2025-10-19 12:43:11.997 | 	delegation.token.master.key = null
2025-10-19 12:43:11.997 | 	delegation.token.max.lifetime.ms = 604800000
2025-10-19 12:43:11.997 | 	delegation.token.secret.key = null
2025-10-19 12:43:11.997 | 	delete.records.purgatory.purge.interval.requests = 1
2025-10-19 12:43:11.997 | 	delete.topic.enable = true
2025-10-19 12:43:11.997 | 	early.start.listeners = null
2025-10-19 12:43:11.997 | 	fetch.max.bytes = 57671680
2025-10-19 12:43:11.997 | 	fetch.purgatory.purge.interval.requests = 1000
2025-10-19 12:43:11.997 | 	group.consumer.assignors = []
2025-10-19 12:43:11.997 | 	group.consumer.heartbeat.interval.ms = 5000
2025-10-19 12:43:11.997 | 	group.consumer.max.heartbeat.interval.ms = 15000
2025-10-19 12:43:11.997 | 	group.consumer.max.session.timeout.ms = 60000
2025-10-19 12:43:11.997 | 	group.consumer.max.size = 2147483647
2025-10-19 12:43:11.997 | 	group.consumer.min.heartbeat.interval.ms = 5000
2025-10-19 12:43:11.997 | 	group.consumer.min.session.timeout.ms = 45000
2025-10-19 12:43:11.997 | 	group.consumer.session.timeout.ms = 45000
2025-10-19 12:43:11.997 | 	group.coordinator.new.enable = false
2025-10-19 12:43:11.997 | 	group.coordinator.threads = 1
2025-10-19 12:43:11.997 | 	group.initial.rebalance.delay.ms = 3000
2025-10-19 12:43:11.997 | 	group.max.session.timeout.ms = 1800000
2025-10-19 12:43:11.997 | 	group.max.size = 2147483647
2025-10-19 12:43:11.997 | 	group.min.session.timeout.ms = 6000
2025-10-19 12:43:11.997 | 	initial.broker.registration.timeout.ms = 60000
2025-10-19 12:43:11.997 | 	inter.broker.listener.name = PLAINTEXT_INTERNAL
2025-10-19 12:43:11.997 | 	inter.broker.protocol.version = 3.5-IV2
2025-10-19 12:43:11.997 | 	kafka.metrics.polling.interval.secs = 10
2025-10-19 12:43:11.997 | 	kafka.metrics.reporters = []
2025-10-19 12:43:11.997 | 	leader.imbalance.check.interval.seconds = 300
2025-10-19 12:43:11.997 | 	leader.imbalance.per.broker.percentage = 10
2025-10-19 12:43:11.997 | 	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
2025-10-19 12:43:11.997 | 	listeners = PLAINTEXT://0.0.0.0:9092,PLAINTEXT_INTERNAL://0.0.0.0:29092
2025-10-19 12:43:11.997 | 	log.cleaner.backoff.ms = 15000
2025-10-19 12:43:11.997 | 	log.cleaner.dedupe.buffer.size = 134217728
2025-10-19 12:43:11.997 | 	log.cleaner.delete.retention.ms = 86400000
2025-10-19 12:43:11.997 | 	log.cleaner.enable = true
2025-10-19 12:43:11.997 | 	log.cleaner.io.buffer.load.factor = 0.9
2025-10-19 12:43:11.997 | 	log.cleaner.io.buffer.size = 524288
2025-10-19 12:43:11.997 | 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
2025-10-19 12:43:11.997 | 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
2025-10-19 12:43:11.997 | 	log.cleaner.min.cleanable.ratio = 0.5
2025-10-19 12:43:11.997 | 	log.cleaner.min.compaction.lag.ms = 0
2025-10-19 12:43:11.997 | 	log.cleaner.threads = 1
2025-10-19 12:43:11.997 | 	log.cleanup.policy = [delete]
2025-10-19 12:43:11.997 | 	log.dir = /tmp/kafka-logs
2025-10-19 12:43:11.997 | 	log.dirs = /var/lib/kafka/data
2025-10-19 12:43:11.997 | 	log.flush.interval.messages = 9223372036854775807
2025-10-19 12:43:11.997 | 	log.flush.interval.ms = null
2025-10-19 12:43:11.997 | 	log.flush.offset.checkpoint.interval.ms = 60000
2025-10-19 12:43:11.997 | 	log.flush.scheduler.interval.ms = 9223372036854775807
2025-10-19 12:43:11.997 | 	log.flush.start.offset.checkpoint.interval.ms = 60000
2025-10-19 12:43:11.997 | 	log.index.interval.bytes = 4096
2025-10-19 12:43:11.998 | 	log.index.size.max.bytes = 10485760
2025-10-19 12:43:11.998 | 	log.message.downconversion.enable = true
2025-10-19 12:43:11.998 | 	log.message.format.version = 3.0-IV1
2025-10-19 12:43:11.998 | 	log.message.timestamp.difference.max.ms = 9223372036854775807
2025-10-19 12:43:11.998 | 	log.message.timestamp.type = CreateTime
2025-10-19 12:43:11.998 | 	log.preallocate = false
2025-10-19 12:43:11.998 | 	log.retention.bytes = -1
2025-10-19 12:43:11.998 | 	log.retention.check.interval.ms = 300000
2025-10-19 12:43:11.998 | 	log.retention.hours = 168
2025-10-19 12:43:11.998 | 	log.retention.minutes = null
2025-10-19 12:43:11.998 | 	log.retention.ms = null
2025-10-19 12:43:11.998 | 	log.roll.hours = 168
2025-10-19 12:43:11.998 | 	log.roll.jitter.hours = 0
2025-10-19 12:43:11.998 | 	log.roll.jitter.ms = null
2025-10-19 12:43:11.998 | 	log.roll.ms = null
2025-10-19 12:43:11.998 | 	log.segment.bytes = 1073741824
2025-10-19 12:43:11.998 | 	log.segment.delete.delay.ms = 60000
2025-10-19 12:43:11.998 | 	max.connection.creation.rate = 2147483647
2025-10-19 12:43:11.998 | 	max.connections = 2147483647
2025-10-19 12:43:11.998 | 	max.connections.per.ip = 2147483647
2025-10-19 12:43:11.998 | 	max.connections.per.ip.overrides = 
2025-10-19 12:43:11.998 | 	max.incremental.fetch.session.cache.slots = 1000
2025-10-19 12:43:11.998 | 	message.max.bytes = 1048588
2025-10-19 12:43:11.998 | 	metadata.log.dir = null
2025-10-19 12:43:11.998 | 	metadata.log.max.record.bytes.between.snapshots = 20971520
2025-10-19 12:43:11.998 | 	metadata.log.max.snapshot.interval.ms = 3600000
2025-10-19 12:43:11.998 | 	metadata.log.segment.bytes = 1073741824
2025-10-19 12:43:11.998 | 	metadata.log.segment.min.bytes = 8388608
2025-10-19 12:43:11.998 | 	metadata.log.segment.ms = 604800000
2025-10-19 12:43:11.998 | 	metadata.max.idle.interval.ms = 500
2025-10-19 12:43:11.998 | 	metadata.max.retention.bytes = 104857600
2025-10-19 12:43:11.998 | 	metadata.max.retention.ms = 604800000
2025-10-19 12:43:11.998 | 	metric.reporters = []
2025-10-19 12:43:11.998 | 	metrics.num.samples = 2
2025-10-19 12:43:11.998 | 	metrics.recording.level = INFO
2025-10-19 12:43:11.998 | 	metrics.sample.window.ms = 30000
2025-10-19 12:43:11.998 | 	min.insync.replicas = 1
2025-10-19 12:43:11.998 | 	node.id = 1
2025-10-19 12:43:11.998 | 	num.io.threads = 8
2025-10-19 12:43:11.998 | 	num.network.threads = 3
2025-10-19 12:43:11.998 | 	num.partitions = 1
2025-10-19 12:43:11.998 | 	num.recovery.threads.per.data.dir = 1
2025-10-19 12:43:11.998 | 	num.replica.alter.log.dirs.threads = null
2025-10-19 12:43:11.998 | 	num.replica.fetchers = 1
2025-10-19 12:43:11.998 | 	offset.metadata.max.bytes = 4096
2025-10-19 12:43:11.998 | 	offsets.commit.required.acks = -1
2025-10-19 12:43:11.998 | 	offsets.commit.timeout.ms = 5000
2025-10-19 12:43:11.998 | 	offsets.load.buffer.size = 5242880
2025-10-19 12:43:11.998 | 	offsets.retention.check.interval.ms = 600000
2025-10-19 12:43:11.998 | 	offsets.retention.minutes = 10080
2025-10-19 12:43:11.998 | 	offsets.topic.compression.codec = 0
2025-10-19 12:43:11.998 | 	offsets.topic.num.partitions = 50
2025-10-19 12:43:11.998 | 	offsets.topic.replication.factor = 1
2025-10-19 12:43:11.998 | 	offsets.topic.segment.bytes = 104857600
2025-10-19 12:43:11.998 | 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
2025-10-19 12:43:11.998 | 	password.encoder.iterations = 4096
2025-10-19 12:43:11.998 | 	password.encoder.key.length = 128
2025-10-19 12:43:11.998 | 	password.encoder.keyfactory.algorithm = null
2025-10-19 12:43:11.998 | 	password.encoder.old.secret = null
2025-10-19 12:43:11.998 | 	password.encoder.secret = null
2025-10-19 12:43:11.998 | 	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
2025-10-19 12:43:11.998 | 	process.roles = []
2025-10-19 12:43:11.998 | 	producer.id.expiration.check.interval.ms = 600000
2025-10-19 12:43:11.998 | 	producer.id.expiration.ms = 86400000
2025-10-19 12:43:11.998 | 	producer.purgatory.purge.interval.requests = 1000
2025-10-19 12:43:11.998 | 	queued.max.request.bytes = -1
2025-10-19 12:43:11.998 | 	queued.max.requests = 500
2025-10-19 12:43:11.998 | 	quota.window.num = 11
2025-10-19 12:43:11.998 | 	quota.window.size.seconds = 1
2025-10-19 12:43:11.998 | 	remote.log.index.file.cache.total.size.bytes = 1073741824
2025-10-19 12:43:11.998 | 	remote.log.manager.task.interval.ms = 30000
2025-10-19 12:43:11.998 | 	remote.log.manager.task.retry.backoff.max.ms = 30000
2025-10-19 12:43:11.998 | 	remote.log.manager.task.retry.backoff.ms = 500
2025-10-19 12:43:11.998 | 	remote.log.manager.task.retry.jitter = 0.2
2025-10-19 12:43:11.998 | 	remote.log.manager.thread.pool.size = 10
2025-10-19 12:43:11.998 | 	remote.log.metadata.manager.class.name = null
2025-10-19 12:43:11.998 | 	remote.log.metadata.manager.class.path = null
2025-10-19 12:43:11.998 | 	remote.log.metadata.manager.impl.prefix = null
2025-10-19 12:43:11.998 | 	remote.log.metadata.manager.listener.name = null
2025-10-19 12:43:11.998 | 	remote.log.reader.max.pending.tasks = 100
2025-10-19 12:43:11.998 | 	remote.log.reader.threads = 10
2025-10-19 12:43:11.998 | 	remote.log.storage.manager.class.name = null
2025-10-19 12:43:11.998 | 	remote.log.storage.manager.class.path = null
2025-10-19 12:43:11.998 | 	remote.log.storage.manager.impl.prefix = null
2025-10-19 12:43:11.998 | 	remote.log.storage.system.enable = false
2025-10-19 12:43:11.998 | 	replica.fetch.backoff.ms = 1000
2025-10-19 12:43:11.998 | 	replica.fetch.max.bytes = 1048576
2025-10-19 12:43:11.998 | 	replica.fetch.min.bytes = 1
2025-10-19 12:43:11.998 | 	replica.fetch.response.max.bytes = 10485760
2025-10-19 12:43:11.998 | 	replica.fetch.wait.max.ms = 500
2025-10-19 12:43:11.998 | 	replica.high.watermark.checkpoint.interval.ms = 5000
2025-10-19 12:43:11.998 | 	replica.lag.time.max.ms = 30000
2025-10-19 12:43:11.998 | 	replica.selector.class = null
2025-10-19 12:43:11.998 | 	replica.socket.receive.buffer.bytes = 65536
2025-10-19 12:43:11.998 | 	replica.socket.timeout.ms = 30000
2025-10-19 12:43:11.998 | 	replication.quota.window.num = 11
2025-10-19 12:43:11.998 | 	replication.quota.window.size.seconds = 1
2025-10-19 12:43:11.998 | 	request.timeout.ms = 30000
2025-10-19 12:43:11.998 | 	reserved.broker.max.id = 1000
2025-10-19 12:43:11.998 | 	sasl.client.callback.handler.class = null
2025-10-19 12:43:11.998 | 	sasl.enabled.mechanisms = [GSSAPI]
2025-10-19 12:43:11.998 | 	sasl.jaas.config = null
2025-10-19 12:43:11.998 | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
2025-10-19 12:43:11.998 | 	sasl.kerberos.min.time.before.relogin = 60000
2025-10-19 12:43:11.998 | 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
2025-10-19 12:43:11.998 | 	sasl.kerberos.service.name = null
2025-10-19 12:43:11.998 | 	sasl.kerberos.ticket.renew.jitter = 0.05
2025-10-19 12:43:11.998 | 	sasl.kerberos.ticket.renew.window.factor = 0.8
2025-10-19 12:43:11.998 | 	sasl.login.callback.handler.class = null
2025-10-19 12:43:11.998 | 	sasl.login.class = null
2025-10-19 12:43:11.998 | 	sasl.login.connect.timeout.ms = null
2025-10-19 12:43:11.998 | 	sasl.login.read.timeout.ms = null
2025-10-19 12:43:11.998 | 	sasl.login.refresh.buffer.seconds = 300
2025-10-19 12:43:11.998 | 	sasl.login.refresh.min.period.seconds = 60
2025-10-19 12:43:11.998 | 	sasl.login.refresh.window.factor = 0.8
2025-10-19 12:43:11.998 | 	sasl.login.refresh.window.jitter = 0.05
2025-10-19 12:43:11.998 | 	sasl.login.retry.backoff.max.ms = 10000
2025-10-19 12:43:11.998 | 	sasl.login.retry.backoff.ms = 100
2025-10-19 12:43:11.998 | 	sasl.mechanism.controller.protocol = GSSAPI
2025-10-19 12:43:11.998 | 	sasl.mechanism.inter.broker.protocol = GSSAPI
2025-10-19 12:43:11.998 | 	sasl.oauthbearer.clock.skew.seconds = 30
2025-10-19 12:43:11.998 | 	sasl.oauthbearer.expected.audience = null
2025-10-19 12:43:11.998 | 	sasl.oauthbearer.expected.issuer = null
2025-10-19 12:43:11.998 | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
2025-10-19 12:43:11.998 | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
2025-10-19 12:43:11.998 | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
2025-10-19 12:43:11.998 | 	sasl.oauthbearer.jwks.endpoint.url = null
2025-10-19 12:43:11.998 | 	sasl.oauthbearer.scope.claim.name = scope
2025-10-19 12:43:11.998 | 	sasl.oauthbearer.sub.claim.name = sub
2025-10-19 12:43:11.998 | 	sasl.oauthbearer.token.endpoint.url = null
2025-10-19 12:43:11.998 | 	sasl.server.callback.handler.class = null
2025-10-19 12:43:11.998 | 	sasl.server.max.receive.size = 524288
2025-10-19 12:43:11.998 | 	security.inter.broker.protocol = PLAINTEXT
2025-10-19 12:43:11.998 | 	security.providers = null
2025-10-19 12:43:11.998 | 	server.max.startup.time.ms = 9223372036854775807
2025-10-19 12:43:11.998 | 	socket.connection.setup.timeout.max.ms = 30000
2025-10-19 12:43:11.998 | 	socket.connection.setup.timeout.ms = 10000
2025-10-19 12:43:11.998 | 	socket.listen.backlog.size = 50
2025-10-19 12:43:11.998 | 	socket.receive.buffer.bytes = 102400
2025-10-19 12:43:11.998 | 	socket.request.max.bytes = 104857600
2025-10-19 12:43:11.998 | 	socket.send.buffer.bytes = 102400
2025-10-19 12:43:11.998 | 	ssl.cipher.suites = []
2025-10-19 12:43:11.998 | 	ssl.client.auth = none
2025-10-19 12:43:11.998 | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
2025-10-19 12:43:11.998 | 	ssl.endpoint.identification.algorithm = https
2025-10-19 12:43:11.998 | 	ssl.engine.factory.class = null
2025-10-19 12:43:11.998 | 	ssl.key.password = null
2025-10-19 12:43:11.998 | 	ssl.keymanager.algorithm = SunX509
2025-10-19 12:43:11.998 | 	ssl.keystore.certificate.chain = null
2025-10-19 12:43:11.998 | 	ssl.keystore.key = null
2025-10-19 12:43:11.998 | 	ssl.keystore.location = null
2025-10-19 12:43:11.998 | 	ssl.keystore.password = null
2025-10-19 12:43:11.998 | 	ssl.keystore.type = JKS
2025-10-19 12:43:11.998 | 	ssl.principal.mapping.rules = DEFAULT
2025-10-19 12:43:11.998 | 	ssl.protocol = TLSv1.3
2025-10-19 12:43:11.998 | 	ssl.provider = null
2025-10-19 12:43:11.998 | 	ssl.secure.random.implementation = null
2025-10-19 12:43:11.998 | 	ssl.trustmanager.algorithm = PKIX
2025-10-19 12:43:11.998 | 	ssl.truststore.certificates = null
2025-10-19 12:43:11.998 | 	ssl.truststore.location = null
2025-10-19 12:43:11.998 | 	ssl.truststore.password = null
2025-10-19 12:43:11.998 | 	ssl.truststore.type = JKS
2025-10-19 12:43:11.998 | 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
2025-10-19 12:43:11.998 | 	transaction.max.timeout.ms = 900000
2025-10-19 12:43:11.998 | 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
2025-10-19 12:43:11.998 | 	transaction.state.log.load.buffer.size = 5242880
2025-10-19 12:43:11.998 | 	transaction.state.log.min.isr = 1
2025-10-19 12:43:11.998 | 	transaction.state.log.num.partitions = 50
2025-10-19 12:43:11.998 | 	transaction.state.log.replication.factor = 1
2025-10-19 12:43:11.998 | 	transaction.state.log.segment.bytes = 104857600
2025-10-19 12:43:11.998 | 	transactional.id.expiration.ms = 604800000
2025-10-19 12:43:11.998 | 	unclean.leader.election.enable = false
2025-10-19 12:43:11.998 | 	unstable.api.versions.enable = false
2025-10-19 12:43:11.998 | 	zookeeper.clientCnxnSocket = null
2025-10-19 12:43:11.998 | 	zookeeper.connect = zookeeper:2181
2025-10-19 12:43:11.998 | 	zookeeper.connection.timeout.ms = null
2025-10-19 12:43:11.998 | 	zookeeper.max.in.flight.requests = 10
2025-10-19 12:43:11.998 | 	zookeeper.metadata.migration.enable = false
2025-10-19 12:43:11.998 | 	zookeeper.session.timeout.ms = 18000
2025-10-19 12:43:11.998 | 	zookeeper.set.acl = false
2025-10-19 12:43:11.998 | 	zookeeper.ssl.cipher.suites = null
2025-10-19 12:43:11.998 | 	zookeeper.ssl.client.enable = false
2025-10-19 12:43:11.998 | 	zookeeper.ssl.crl.enable = false
2025-10-19 12:43:11.998 | 	zookeeper.ssl.enabled.protocols = null
2025-10-19 12:43:11.998 | 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
2025-10-19 12:43:11.998 | 	zookeeper.ssl.keystore.location = null
2025-10-19 12:43:11.998 | 	zookeeper.ssl.keystore.password = null
2025-10-19 12:43:11.998 | 	zookeeper.ssl.keystore.type = null
2025-10-19 12:43:11.998 | 	zookeeper.ssl.ocsp.enable = false
2025-10-19 12:43:11.998 | 	zookeeper.ssl.protocol = TLSv1.2
2025-10-19 12:43:11.998 | 	zookeeper.ssl.truststore.location = null
2025-10-19 12:43:11.998 | 	zookeeper.ssl.truststore.password = null
2025-10-19 12:43:11.998 | 	zookeeper.ssl.truststore.type = null
2025-10-19 12:43:11.998 |  (kafka.server.KafkaConfig)
2025-10-19 12:43:12.061 | [2025-10-19 17:43:12,060] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 12:43:12.065 | [2025-10-19 17:43:12,062] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 12:43:12.066 | [2025-10-19 17:43:12,066] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 12:43:12.075 | [2025-10-19 17:43:12,074] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 12:43:12.149 | [2025-10-19 17:43:12,148] INFO Loading logs from log dirs ArraySeq(/var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:12.177 | [2025-10-19 17:43:12,176] INFO Skipping recovery of 51 logs from /var/lib/kafka/data since clean shutdown file was found (kafka.log.LogManager)
2025-10-19 12:43:12.304 | [2025-10-19 17:43:12,303] INFO [LogLoader partition=__consumer_offsets-29, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:12.360 | [2025-10-19 17:43:12,358] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-29, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 173ms (1/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:12.380 | [2025-10-19 17:43:12,380] INFO [LogLoader partition=__consumer_offsets-49, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:12.384 | [2025-10-19 17:43:12,384] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-49, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 24ms (2/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:12.402 | [2025-10-19 17:43:12,402] INFO [LogLoader partition=__consumer_offsets-28, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:12.407 | [2025-10-19 17:43:12,406] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-28, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 22ms (3/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:12.425 | [2025-10-19 17:43:12,425] INFO [LogLoader partition=__consumer_offsets-5, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:12.431 | [2025-10-19 17:43:12,430] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-5, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 23ms (4/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:12.457 | [2025-10-19 17:43:12,456] INFO [LogLoader partition=__consumer_offsets-10, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:12.463 | [2025-10-19 17:43:12,462] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-10, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 30ms (5/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:12.486 | [2025-10-19 17:43:12,486] INFO [LogLoader partition=__consumer_offsets-14, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:12.491 | [2025-10-19 17:43:12,491] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-14, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 27ms (6/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:12.522 | [2025-10-19 17:43:12,521] INFO Deleted producer state snapshot /var/lib/kafka/data/__consumer_offsets-19/00000000000000000004.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
2025-10-19 12:43:12.522 | [2025-10-19 17:43:12,522] INFO [LogLoader partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Loading producer state till offset 5 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:12.522 | [2025-10-19 17:43:12,522] INFO [LogLoader partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 5 (kafka.log.UnifiedLog$)
2025-10-19 12:43:12.522 | [2025-10-19 17:43:12,522] INFO [ProducerStateManager partition=__consumer_offsets-19]Loading producer state from snapshot file 'SnapshotFile(offset=5, file=/var/lib/kafka/data/__consumer_offsets-19/00000000000000000005.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
2025-10-19 12:43:12.536 | [2025-10-19 17:43:12,536] INFO [LogLoader partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Producer state recovery took 14ms for snapshot load and 0ms for segment recovery from offset 5 (kafka.log.UnifiedLog$)
2025-10-19 12:43:12.541 | [2025-10-19 17:43:12,540] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-19, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=5) with 1 segments in 49ms (7/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:12.559 | [2025-10-19 17:43:12,559] INFO [LogLoader partition=__consumer_offsets-8, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:12.565 | [2025-10-19 17:43:12,564] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-8, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 24ms (8/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:12.589 | [2025-10-19 17:43:12,589] INFO [LogLoader partition=__consumer_offsets-17, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:12.594 | [2025-10-19 17:43:12,594] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-17, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 29ms (9/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:12.623 | [2025-10-19 17:43:12,622] INFO [LogLoader partition=__consumer_offsets-35, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:12.629 | [2025-10-19 17:43:12,629] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-35, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 34ms (10/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:12.659 | [2025-10-19 17:43:12,658] INFO [LogLoader partition=__consumer_offsets-31, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:12.663 | [2025-10-19 17:43:12,663] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-31, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 34ms (11/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:12.684 | [2025-10-19 17:43:12,683] INFO [LogLoader partition=__consumer_offsets-6, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:12.689 | [2025-10-19 17:43:12,689] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-6, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 26ms (12/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:12.715 | [2025-10-19 17:43:12,714] INFO [LogLoader partition=__consumer_offsets-32, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:12.726 | [2025-10-19 17:43:12,725] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-32, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 36ms (13/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:12.747 | [2025-10-19 17:43:12,747] INFO [LogLoader partition=__consumer_offsets-3, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:12.753 | [2025-10-19 17:43:12,752] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-3, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 26ms (14/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:12.777 | [2025-10-19 17:43:12,777] INFO [LogLoader partition=__consumer_offsets-30, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:12.783 | [2025-10-19 17:43:12,782] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-30, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 30ms (15/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:12.807 | [2025-10-19 17:43:12,806] INFO [LogLoader partition=__consumer_offsets-37, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:12.811 | [2025-10-19 17:43:12,811] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-37, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 29ms (16/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:12.835 | [2025-10-19 17:43:12,835] INFO [LogLoader partition=__consumer_offsets-41, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:12.839 | [2025-10-19 17:43:12,838] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-41, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 27ms (17/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:12.861 | [2025-10-19 17:43:12,860] INFO [LogLoader partition=__consumer_offsets-26, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:12.900 | [2025-10-19 17:43:12,899] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-26, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 60ms (18/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:12.916 | [2025-10-19 17:43:12,915] INFO [LogLoader partition=__consumer_offsets-4, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:12.919 | [2025-10-19 17:43:12,918] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-4, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (19/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:12.935 | [2025-10-19 17:43:12,934] INFO [LogLoader partition=__consumer_offsets-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:12.938 | [2025-10-19 17:43:12,937] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-1, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (20/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:12.956 | [2025-10-19 17:43:12,955] INFO [LogLoader partition=__consumer_offsets-33, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:12.959 | [2025-10-19 17:43:12,959] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-33, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 22ms (21/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:12.977 | [2025-10-19 17:43:12,976] INFO [LogLoader partition=__consumer_offsets-25, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:12.980 | [2025-10-19 17:43:12,980] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-25, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 21ms (22/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:12.996 | [2025-10-19 17:43:12,995] INFO [LogLoader partition=__consumer_offsets-42, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:12.999 | [2025-10-19 17:43:12,999] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-42, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (23/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:13.015 | [2025-10-19 17:43:13,014] INFO [LogLoader partition=__consumer_offsets-2, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:13.018 | [2025-10-19 17:43:13,017] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-2, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (24/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:13.034 | [2025-10-19 17:43:13,033] INFO [LogLoader partition=__consumer_offsets-34, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:13.037 | [2025-10-19 17:43:13,037] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-34, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (25/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:13.055 | [2025-10-19 17:43:13,054] INFO [LogLoader partition=__consumer_offsets-36, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:13.057 | [2025-10-19 17:43:13,057] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-36, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (26/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:13.074 | [2025-10-19 17:43:13,073] INFO [LogLoader partition=__consumer_offsets-12, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:13.077 | [2025-10-19 17:43:13,076] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-12, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (27/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:13.093 | [2025-10-19 17:43:13,093] INFO [LogLoader partition=__consumer_offsets-20, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:13.097 | [2025-10-19 17:43:13,096] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-20, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (28/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:13.112 | [2025-10-19 17:43:13,111] INFO [LogLoader partition=__consumer_offsets-23, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:13.115 | [2025-10-19 17:43:13,114] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-23, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (29/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:13.131 | [2025-10-19 17:43:13,130] INFO [LogLoader partition=__consumer_offsets-13, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:13.134 | [2025-10-19 17:43:13,133] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-13, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (30/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:13.153 | [2025-10-19 17:43:13,152] INFO [LogLoader partition=__consumer_offsets-40, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:13.156 | [2025-10-19 17:43:13,155] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-40, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 21ms (31/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:13.172 | [2025-10-19 17:43:13,172] INFO [LogLoader partition=__consumer_offsets-43, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:13.175 | [2025-10-19 17:43:13,174] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-43, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (32/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:13.191 | [2025-10-19 17:43:13,190] INFO [LogLoader partition=__consumer_offsets-39, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:13.193 | [2025-10-19 17:43:13,192] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-39, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (33/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:13.208 | [2025-10-19 17:43:13,207] INFO [LogLoader partition=__consumer_offsets-46, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:13.210 | [2025-10-19 17:43:13,209] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-46, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (34/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:13.224 | [2025-10-19 17:43:13,224] INFO [LogLoader partition=__consumer_offsets-7, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:13.228 | [2025-10-19 17:43:13,227] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-7, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (35/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:13.244 | [2025-10-19 17:43:13,243] INFO [LogLoader partition=__consumer_offsets-38, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:13.247 | [2025-10-19 17:43:13,246] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-38, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (36/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:13.263 | [2025-10-19 17:43:13,263] INFO [LogLoader partition=__consumer_offsets-47, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:13.266 | [2025-10-19 17:43:13,265] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-47, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (37/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:13.284 | [2025-10-19 17:43:13,283] INFO [LogLoader partition=__consumer_offsets-11, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:13.287 | [2025-10-19 17:43:13,287] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-11, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 22ms (38/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:13.305 | [2025-10-19 17:43:13,304] INFO [LogLoader partition=__consumer_offsets-21, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:13.307 | [2025-10-19 17:43:13,306] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-21, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (39/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:13.321 | [2025-10-19 17:43:13,321] INFO [LogLoader partition=__consumer_offsets-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:13.323 | [2025-10-19 17:43:13,322] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-0, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (40/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:13.340 | [2025-10-19 17:43:13,339] INFO [LogLoader partition=__consumer_offsets-16, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:13.343 | [2025-10-19 17:43:13,343] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-16, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (41/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:13.359 | [2025-10-19 17:43:13,358] INFO [LogLoader partition=__consumer_offsets-22, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:13.361 | [2025-10-19 17:43:13,361] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-22, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (42/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:13.379 | [2025-10-19 17:43:13,379] INFO [LogLoader partition=__consumer_offsets-15, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:13.382 | [2025-10-19 17:43:13,382] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-15, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (43/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:13.399 | [2025-10-19 17:43:13,398] INFO [LogLoader partition=__consumer_offsets-18, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:13.401 | [2025-10-19 17:43:13,400] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-18, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (44/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:13.418 | [2025-10-19 17:43:13,418] INFO [LogLoader partition=__consumer_offsets-27, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:13.420 | [2025-10-19 17:43:13,419] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-27, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (45/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:13.436 | [2025-10-19 17:43:13,436] INFO [LogLoader partition=__consumer_offsets-24, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:13.439 | [2025-10-19 17:43:13,439] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-24, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (46/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:13.458 | [2025-10-19 17:43:13,457] INFO [LogLoader partition=__consumer_offsets-9, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:13.460 | [2025-10-19 17:43:13,460] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-9, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 21ms (47/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:13.479 | [2025-10-19 17:43:13,478] INFO [LogLoader partition=__consumer_offsets-45, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:13.482 | [2025-10-19 17:43:13,482] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-45, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 21ms (48/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:13.501 | [2025-10-19 17:43:13,500] INFO [LogLoader partition=__consumer_offsets-44, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:13.503 | [2025-10-19 17:43:13,502] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-44, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (49/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:13.520 | [2025-10-19 17:43:13,519] INFO [LogLoader partition=mesa-ya.restaurants.created-0, dir=/var/lib/kafka/data] Loading producer state till offset 2 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:13.520 | [2025-10-19 17:43:13,520] INFO [LogLoader partition=mesa-ya.restaurants.created-0, dir=/var/lib/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:13.520 | [2025-10-19 17:43:13,520] INFO [ProducerStateManager partition=mesa-ya.restaurants.created-0]Loading producer state from snapshot file 'SnapshotFile(offset=2, file=/var/lib/kafka/data/mesa-ya.restaurants.created-0/00000000000000000002.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
2025-10-19 12:43:13.521 | [2025-10-19 17:43:13,520] INFO [LogLoader partition=mesa-ya.restaurants.created-0, dir=/var/lib/kafka/data] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:13.523 | [2025-10-19 17:43:13,522] INFO Completed load of Log(dir=/var/lib/kafka/data/mesa-ya.restaurants.created-0, topicId=yWm6W48_TyqOOX8W2L0ItA, topic=mesa-ya.restaurants.created, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=2) with 1 segments in 20ms (50/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:13.540 | [2025-10-19 17:43:13,539] INFO [LogLoader partition=__consumer_offsets-48, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 12:43:13.543 | [2025-10-19 17:43:13,542] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-48, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (51/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 12:43:13.550 | [2025-10-19 17:43:13,549] INFO Loaded 51 logs in 1399ms (kafka.log.LogManager)
2025-10-19 12:43:13.554 | [2025-10-19 17:43:13,553] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
2025-10-19 12:43:13.555 | [2025-10-19 17:43:13,555] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
2025-10-19 12:43:13.574 | [2025-10-19 17:43:13,574] INFO Starting the log cleaner (kafka.log.LogCleaner)
2025-10-19 12:43:13.784 | [2025-10-19 17:43:13,783] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
2025-10-19 12:43:13.815 | [2025-10-19 17:43:13,814] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-10-19 12:43:13.876 | [2025-10-19 17:43:13,875] INFO [MetadataCache brokerId=1] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0). (kafka.server.metadata.ZkMetadataCache)
2025-10-19 12:43:13.932 | [2025-10-19 17:43:13,931] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
2025-10-19 12:43:14.417 | [2025-10-19 17:43:14,416] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
2025-10-19 12:43:14.462 | [2025-10-19 17:43:14,461] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
2025-10-19 12:43:14.463 | [2025-10-19 17:43:14,462] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
2025-10-19 12:43:14.471 | [2025-10-19 17:43:14,471] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT_INTERNAL) (kafka.network.SocketServer)
2025-10-19 12:43:14.479 | [2025-10-19 17:43:14,478] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
2025-10-19 12:43:14.510 | [2025-10-19 17:43:14,509] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:43:14.512 | [2025-10-19 17:43:14,511] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:43:14.514 | [2025-10-19 17:43:14,513] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:43:14.515 | [2025-10-19 17:43:14,515] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:43:14.533 | [2025-10-19 17:43:14,532] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-10-19 12:43:14.597 | [2025-10-19 17:43:14,596] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
2025-10-19 12:43:14.636 | [2025-10-19 17:43:14,636] INFO Stat of the created znode at /brokers/ids/1 is: 244,244,1760895794620,1760895794620,1,0,0,72057759640059905,270,0,244
2025-10-19 12:43:14.637 |  (kafka.zk.KafkaZkClient)
2025-10-19 12:43:14.637 | [2025-10-19 17:43:14,637] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092, czxid (broker epoch): 244 (kafka.zk.KafkaZkClient)
2025-10-19 12:43:14.748 | [2025-10-19 17:43:14,746] INFO [ControllerEventThread controllerId=1] Starting (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-10-19 12:43:14.761 | [2025-10-19 17:43:14,760] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:43:14.770 | [2025-10-19 17:43:14,770] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:43:14.773 | [2025-10-19 17:43:14,772] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:43:14.800 | [2025-10-19 17:43:14,799] INFO [Controller id=1] 1 successfully elected as the controller. Epoch incremented to 6 and epoch zk version is now 6 (kafka.controller.KafkaController)
2025-10-19 12:43:14.807 | [2025-10-19 17:43:14,806] INFO [Controller id=1] Registering handlers (kafka.controller.KafkaController)
2025-10-19 12:43:14.818 | [2025-10-19 17:43:14,818] INFO [Controller id=1] Deleting log dir event notifications (kafka.controller.KafkaController)
2025-10-19 12:43:14.820 | [2025-10-19 17:43:14,819] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:14.826 | [2025-10-19 17:43:14,825] INFO [Controller id=1] Deleting isr change notifications (kafka.controller.KafkaController)
2025-10-19 12:43:14.831 | [2025-10-19 17:43:14,831] INFO [Controller id=1] Initializing controller context (kafka.controller.KafkaController)
2025-10-19 12:43:14.846 | [2025-10-19 17:43:14,845] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:14.855 | [2025-10-19 17:43:14,855] INFO [Controller id=1] Initialized broker epochs cache: HashMap(1 -> 244) (kafka.controller.KafkaController)
2025-10-19 12:43:14.871 | [2025-10-19 17:43:14,870] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
2025-10-19 12:43:14.880 | [2025-10-19 17:43:14,879] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
2025-10-19 12:43:14.880 | [2025-10-19 17:43:14,880] INFO [TxnMarkerSenderThread-1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-10-19 12:43:14.888 | [2025-10-19 17:43:14,888] DEBUG [Controller id=1] Register BrokerModifications handler for Set(1) (kafka.controller.KafkaController)
2025-10-19 12:43:14.967 | [2025-10-19 17:43:14,967] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 12:43:14.969 | [2025-10-19 17:43:14,968] DEBUG [Channel manager on controller 1]: Controller 1 trying to connect to broker 1 (kafka.controller.ControllerChannelManager)
2025-10-19 12:43:14.980 | [2025-10-19 17:43:14,980] INFO [RequestSendThread controllerId=1] Starting (kafka.controller.RequestSendThread)
2025-10-19 12:43:14.982 | [2025-10-19 17:43:14,982] INFO [Controller id=1] Currently active brokers in the cluster: Set(1) (kafka.controller.KafkaController)
2025-10-19 12:43:14.983 | [2025-10-19 17:43:14,982] INFO [Controller id=1] Currently shutting brokers in the cluster: HashSet() (kafka.controller.KafkaController)
2025-10-19 12:43:14.983 | [2025-10-19 17:43:14,983] INFO [Controller id=1] Current list of topics in the cluster: HashSet(__consumer_offsets, mesa-ya.restaurants.created) (kafka.controller.KafkaController)
2025-10-19 12:43:14.983 | [2025-10-19 17:43:14,983] INFO [Controller id=1] Fetching topic deletions in progress (kafka.controller.KafkaController)
2025-10-19 12:43:14.997 | [2025-10-19 17:43:14,996] INFO [Controller id=1] List of topics to be deleted:  (kafka.controller.KafkaController)
2025-10-19 12:43:14.997 | [2025-10-19 17:43:14,996] INFO [Controller id=1] List of topics ineligible for deletion:  (kafka.controller.KafkaController)
2025-10-19 12:43:14.997 | [2025-10-19 17:43:14,997] INFO [Controller id=1] Initializing topic deletion manager (kafka.controller.KafkaController)
2025-10-19 12:43:14.998 | [2025-10-19 17:43:14,998] INFO [Topic Deletion Manager 1] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet() (kafka.controller.TopicDeletionManager)
2025-10-19 12:43:14.999 | [2025-10-19 17:43:14,999] INFO [Controller id=1] Sending update metadata request (kafka.controller.KafkaController)
2025-10-19 12:43:15.007 | [2025-10-19 17:43:15,005] INFO [Controller id=1 epoch=6] Sending UpdateMetadata request to brokers HashSet(1) for 0 partitions (state.change.logger)
2025-10-19 12:43:15.013 | [2025-10-19 17:43:15,012] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-10-19 12:43:15.018 | [2025-10-19 17:43:15,017] INFO [ReplicaStateMachine controllerId=1] Initializing replica state (kafka.controller.ZkReplicaStateMachine)
2025-10-19 12:43:15.030 | [2025-10-19 17:43:15,030] INFO [ReplicaStateMachine controllerId=1] Triggering online replica state changes (kafka.controller.ZkReplicaStateMachine)
2025-10-19 12:43:15.033 | [2025-10-19 17:43:15,033] INFO [Controller id=1, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
2025-10-19 12:43:15.037 | [2025-10-19 17:43:15,036] WARN [Controller id=1, targetBrokerId=1] Connection to node 1 (kafka/172.18.0.3:29092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
2025-10-19 12:43:15.046 | [2025-10-19 17:43:15,041] WARN [RequestSendThread controllerId=1] Controller 1's connection to broker kafka:29092 (id: 1 rack: null) was unsuccessful (kafka.controller.RequestSendThread)
2025-10-19 12:43:15.047 | java.io.IOException: Connection to kafka:29092 (id: 1 rack: null) failed.
2025-10-19 12:43:15.047 | 	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
2025-10-19 12:43:15.047 | 	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:296)
2025-10-19 12:43:15.047 | 	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:249)
2025-10-19 12:43:15.047 | 	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:127)
2025-10-19 12:43:15.047 | [2025-10-19 17:43:15,046] INFO [Controller id=1, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
2025-10-19 12:43:15.061 | [2025-10-19 17:43:15,060] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-46 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.062 | [2025-10-19 17:43:15,061] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-37 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.062 | [2025-10-19 17:43:15,062] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-8 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.063 | [2025-10-19 17:43:15,062] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-49 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.063 | [2025-10-19 17:43:15,063] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-21 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.063 | [2025-10-19 17:43:15,063] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-20 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.064 | [2025-10-19 17:43:15,064] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-17 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.065 | [2025-10-19 17:43:15,065] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-19 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.066 | [2025-10-19 17:43:15,065] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-7 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.066 | [2025-10-19 17:43:15,066] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-43 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.066 | [2025-10-19 17:43:15,066] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
2025-10-19 12:43:15.066 | [2025-10-19 17:43:15,066] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-30 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.067 | [2025-10-19 17:43:15,067] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-35 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.067 | [2025-10-19 17:43:15,067] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-27 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.068 | [2025-10-19 17:43:15,067] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition mesa-ya.restaurants.created-0 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.068 | [2025-10-19 17:43:15,068] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-0 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.068 | [2025-10-19 17:43:15,068] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-40 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.068 | [2025-10-19 17:43:15,068] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-47 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.068 | [2025-10-19 17:43:15,068] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-10 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.069 | [2025-10-19 17:43:15,068] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-4 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.069 | [2025-10-19 17:43:15,068] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-31 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.069 | [2025-10-19 17:43:15,069] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-16 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.069 | [2025-10-19 17:43:15,069] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-23 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.069 | [2025-10-19 17:43:15,069] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-26 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.069 | [2025-10-19 17:43:15,069] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-39 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.072 | [2025-10-19 17:43:15,071] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-2 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.073 | [2025-10-19 17:43:15,072] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-34 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.073 | [2025-10-19 17:43:15,073] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-24 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.074 | [2025-10-19 17:43:15,073] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-32 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.074 | [2025-10-19 17:43:15,074] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-41 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.075 | [2025-10-19 17:43:15,074] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-5 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.075 | [2025-10-19 17:43:15,075] INFO Awaiting socket connections on 0.0.0.0:29092. (kafka.network.DataPlaneAcceptor)
2025-10-19 12:43:15.075 | [2025-10-19 17:43:15,075] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-15 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.076 | [2025-10-19 17:43:15,075] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-1 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.076 | [2025-10-19 17:43:15,076] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-9 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.077 | [2025-10-19 17:43:15,076] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-45 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.090 | [2025-10-19 17:43:15,089] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-36 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.091 | [2025-10-19 17:43:15,090] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-48 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.091 | [2025-10-19 17:43:15,091] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-3 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.091 | [2025-10-19 17:43:15,091] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-18 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.093 | [2025-10-19 17:43:15,093] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-44 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.093 | [2025-10-19 17:43:15,093] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
2025-10-19 12:43:15.094 | [2025-10-19 17:43:15,093] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-11 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.094 | [2025-10-19 17:43:15,094] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-25 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.095 | [2025-10-19 17:43:15,094] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-29 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.095 | [2025-10-19 17:43:15,095] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-6 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.096 | [2025-10-19 17:43:15,095] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-42 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.096 | [2025-10-19 17:43:15,096] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-28 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.097 | [2025-10-19 17:43:15,096] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-12 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.097 | [2025-10-19 17:43:15,097] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-38 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.097 | [2025-10-19 17:43:15,097] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-33 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.097 | [2025-10-19 17:43:15,097] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-14 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.097 | [2025-10-19 17:43:15,097] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-13 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.098 | [2025-10-19 17:43:15,097] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition __consumer_offsets-22 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 12:43:15.106 | [2025-10-19 17:43:15,106] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-13 (state.change.logger)
2025-10-19 12:43:15.107 | [2025-10-19 17:43:15,106] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-46 (state.change.logger)
2025-10-19 12:43:15.107 | [2025-10-19 17:43:15,106] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-9 (state.change.logger)
2025-10-19 12:43:15.107 | [2025-10-19 17:43:15,106] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-42 (state.change.logger)
2025-10-19 12:43:15.107 | [2025-10-19 17:43:15,106] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-21 (state.change.logger)
2025-10-19 12:43:15.107 | [2025-10-19 17:43:15,106] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-17 (state.change.logger)
2025-10-19 12:43:15.107 | [2025-10-19 17:43:15,107] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-30 (state.change.logger)
2025-10-19 12:43:15.107 | [2025-10-19 17:43:15,107] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-26 (state.change.logger)
2025-10-19 12:43:15.107 | [2025-10-19 17:43:15,107] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-5 (state.change.logger)
2025-10-19 12:43:15.108 | [2025-10-19 17:43:15,107] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-38 (state.change.logger)
2025-10-19 12:43:15.108 | [2025-10-19 17:43:15,107] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-1 (state.change.logger)
2025-10-19 12:43:15.108 | [2025-10-19 17:43:15,108] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-34 (state.change.logger)
2025-10-19 12:43:15.108 | [2025-10-19 17:43:15,108] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-16 (state.change.logger)
2025-10-19 12:43:15.108 | [2025-10-19 17:43:15,108] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-45 (state.change.logger)
2025-10-19 12:43:15.108 | [2025-10-19 17:43:15,108] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-12 (state.change.logger)
2025-10-19 12:43:15.108 | [2025-10-19 17:43:15,108] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-41 (state.change.logger)
2025-10-19 12:43:15.108 | [2025-10-19 17:43:15,108] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-24 (state.change.logger)
2025-10-19 12:43:15.108 | [2025-10-19 17:43:15,108] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-20 (state.change.logger)
2025-10-19 12:43:15.109 | [2025-10-19 17:43:15,108] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-49 (state.change.logger)
2025-10-19 12:43:15.109 | [2025-10-19 17:43:15,109] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-0 (state.change.logger)
2025-10-19 12:43:15.109 | [2025-10-19 17:43:15,109] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-29 (state.change.logger)
2025-10-19 12:43:15.109 | [2025-10-19 17:43:15,109] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-25 (state.change.logger)
2025-10-19 12:43:15.109 | [2025-10-19 17:43:15,109] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-8 (state.change.logger)
2025-10-19 12:43:15.109 | [2025-10-19 17:43:15,109] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-37 (state.change.logger)
2025-10-19 12:43:15.109 | [2025-10-19 17:43:15,109] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-4 (state.change.logger)
2025-10-19 12:43:15.110 | [2025-10-19 17:43:15,109] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-33 (state.change.logger)
2025-10-19 12:43:15.110 | [2025-10-19 17:43:15,110] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-15 (state.change.logger)
2025-10-19 12:43:15.110 | [2025-10-19 17:43:15,110] INFO Kafka version: 7.5.0-ccs (org.apache.kafka.common.utils.AppInfoParser)
2025-10-19 12:43:15.110 | [2025-10-19 17:43:15,110] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-48 (state.change.logger)
2025-10-19 12:43:15.111 | [2025-10-19 17:43:15,110] INFO Kafka commitId: ff3c201baa948d97889dc26c99d7cdc23d038f2e (org.apache.kafka.common.utils.AppInfoParser)
2025-10-19 12:43:15.111 | [2025-10-19 17:43:15,110] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-11 (state.change.logger)
2025-10-19 12:43:15.111 | [2025-10-19 17:43:15,110] INFO Kafka startTimeMs: 1760895795100 (org.apache.kafka.common.utils.AppInfoParser)
2025-10-19 12:43:15.111 | [2025-10-19 17:43:15,110] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-44 (state.change.logger)
2025-10-19 12:43:15.111 | [2025-10-19 17:43:15,111] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-23 (state.change.logger)
2025-10-19 12:43:15.111 | [2025-10-19 17:43:15,111] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-19 (state.change.logger)
2025-10-19 12:43:15.111 | [2025-10-19 17:43:15,111] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-32 (state.change.logger)
2025-10-19 12:43:15.111 | [2025-10-19 17:43:15,111] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-28 (state.change.logger)
2025-10-19 12:43:15.111 | [2025-10-19 17:43:15,111] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-7 (state.change.logger)
2025-10-19 12:43:15.111 | [2025-10-19 17:43:15,111] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-40 (state.change.logger)
2025-10-19 12:43:15.112 | [2025-10-19 17:43:15,111] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-3 (state.change.logger)
2025-10-19 12:43:15.112 | [2025-10-19 17:43:15,111] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-36 (state.change.logger)
2025-10-19 12:43:15.112 | [2025-10-19 17:43:15,111] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-47 (state.change.logger)
2025-10-19 12:43:15.112 | [2025-10-19 17:43:15,111] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-14 (state.change.logger)
2025-10-19 12:43:15.112 | [2025-10-19 17:43:15,112] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-43 (state.change.logger)
2025-10-19 12:43:15.112 | [2025-10-19 17:43:15,112] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-10 (state.change.logger)
2025-10-19 12:43:15.112 | [2025-10-19 17:43:15,112] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-22 (state.change.logger)
2025-10-19 12:43:15.112 | [2025-10-19 17:43:15,112] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-18 (state.change.logger)
2025-10-19 12:43:15.112 | [2025-10-19 17:43:15,112] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-31 (state.change.logger)
2025-10-19 12:43:15.112 | [2025-10-19 17:43:15,112] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-27 (state.change.logger)
2025-10-19 12:43:15.112 | [2025-10-19 17:43:15,112] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-39 (state.change.logger)
2025-10-19 12:43:15.113 | [2025-10-19 17:43:15,112] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-6 (state.change.logger)
2025-10-19 12:43:15.113 | [2025-10-19 17:43:15,112] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-35 (state.change.logger)
2025-10-19 12:43:15.113 | [2025-10-19 17:43:15,113] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='mesa-ya.restaurants.created', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition mesa-ya.restaurants.created-0 (state.change.logger)
2025-10-19 12:43:15.113 | [2025-10-19 17:43:15,113] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-2 (state.change.logger)
2025-10-19 12:43:15.114 | [2025-10-19 17:43:15,113] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
2025-10-19 12:43:15.117 | [2025-10-19 17:43:15,116] INFO [Controller id=1 epoch=6] Sending LeaderAndIsr request to broker 1 with 51 become-leader and 0 become-follower partitions (state.change.logger)
2025-10-19 12:43:15.124 | [2025-10-19 17:43:15,123] INFO [Controller id=1 epoch=6] Sending UpdateMetadata request to brokers HashSet(1) for 51 partitions (state.change.logger)
2025-10-19 12:43:15.126 | [2025-10-19 17:43:15,126] INFO [ReplicaStateMachine controllerId=1] Triggering offline replica state changes (kafka.controller.ZkReplicaStateMachine)
2025-10-19 12:43:15.128 | [2025-10-19 17:43:15,127] DEBUG [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> HashMap([Topic=__consumer_offsets,Partition=46,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=37,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=8,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=49,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=21,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=20,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=17,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=19,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=7,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=43,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=30,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=35,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=27,Replica=1] -> OnlineReplica, [Topic=mesa-ya.restaurants.created,Partition=0,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=0,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=40,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=47,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=10,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=4,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=31,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=16,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=23,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=26,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=39,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=2,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=34,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=24,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=32,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=41,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=5,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=15,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=1,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=9,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=45,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=36,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=48,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=3,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=18,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=44,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=11,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=25,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=29,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=6,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=42,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=28,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=12,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=38,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=33,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=14,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=13,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=22,Replica=1] -> OnlineReplica) (kafka.controller.ZkReplicaStateMachine)
2025-10-19 12:43:15.130 | [2025-10-19 17:43:15,130] INFO [PartitionStateMachine controllerId=1] Initializing partition state (kafka.controller.ZkPartitionStateMachine)
2025-10-19 12:43:15.140 | [2025-10-19 17:43:15,140] INFO [PartitionStateMachine controllerId=1] Triggering online partition state changes (kafka.controller.ZkPartitionStateMachine)
2025-10-19 12:43:15.147 | [2025-10-19 17:43:15,146] DEBUG [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> HashMap(__consumer_offsets-13 -> OnlinePartition, __consumer_offsets-46 -> OnlinePartition, __consumer_offsets-9 -> OnlinePartition, __consumer_offsets-42 -> OnlinePartition, __consumer_offsets-21 -> OnlinePartition, __consumer_offsets-17 -> OnlinePartition, __consumer_offsets-30 -> OnlinePartition, __consumer_offsets-26 -> OnlinePartition, __consumer_offsets-5 -> OnlinePartition, __consumer_offsets-38 -> OnlinePartition, __consumer_offsets-1 -> OnlinePartition, __consumer_offsets-34 -> OnlinePartition, __consumer_offsets-16 -> OnlinePartition, __consumer_offsets-45 -> OnlinePartition, __consumer_offsets-12 -> OnlinePartition, __consumer_offsets-41 -> OnlinePartition, __consumer_offsets-24 -> OnlinePartition, __consumer_offsets-20 -> OnlinePartition, __consumer_offsets-49 -> OnlinePartition, __consumer_offsets-0 -> OnlinePartition, __consumer_offsets-29 -> OnlinePartition, __consumer_offsets-25 -> OnlinePartition, __consumer_offsets-8 -> OnlinePartition, __consumer_offsets-37 -> OnlinePartition, __consumer_offsets-4 -> OnlinePartition, __consumer_offsets-33 -> OnlinePartition, __consumer_offsets-15 -> OnlinePartition, __consumer_offsets-48 -> OnlinePartition, __consumer_offsets-11 -> OnlinePartition, __consumer_offsets-44 -> OnlinePartition, __consumer_offsets-23 -> OnlinePartition, __consumer_offsets-19 -> OnlinePartition, __consumer_offsets-32 -> OnlinePartition, __consumer_offsets-28 -> OnlinePartition, __consumer_offsets-7 -> OnlinePartition, __consumer_offsets-40 -> OnlinePartition, __consumer_offsets-3 -> OnlinePartition, __consumer_offsets-36 -> OnlinePartition, __consumer_offsets-47 -> OnlinePartition, __consumer_offsets-14 -> OnlinePartition, __consumer_offsets-43 -> OnlinePartition, __consumer_offsets-10 -> OnlinePartition, __consumer_offsets-22 -> OnlinePartition, __consumer_offsets-18 -> OnlinePartition, __consumer_offsets-31 -> OnlinePartition, __consumer_offsets-27 -> OnlinePartition, __consumer_offsets-39 -> OnlinePartition, __consumer_offsets-6 -> OnlinePartition, __consumer_offsets-35 -> OnlinePartition, mesa-ya.restaurants.created-0 -> OnlinePartition, __consumer_offsets-2 -> OnlinePartition) (kafka.controller.ZkPartitionStateMachine)
2025-10-19 12:43:15.148 | [2025-10-19 17:43:15,147] INFO [Controller id=1] Ready to serve as the new controller with epoch 6 (kafka.controller.KafkaController)
2025-10-19 12:43:15.156 | [2025-10-19 17:43:15,154] INFO [RequestSendThread controllerId=1] Controller 1 connected to kafka:29092 (id: 1 rack: null) for sending state change requests (kafka.controller.RequestSendThread)
2025-10-19 12:43:15.163 | [2025-10-19 17:43:15,163] INFO [Controller id=1] Partitions undergoing preferred replica election:  (kafka.controller.KafkaController)
2025-10-19 12:43:15.166 | [2025-10-19 17:43:15,165] INFO [Controller id=1] Partitions that completed preferred replica election:  (kafka.controller.KafkaController)
2025-10-19 12:43:15.168 | [2025-10-19 17:43:15,168] INFO [Controller id=1] Skipping preferred replica election for partitions due to topic deletion:  (kafka.controller.KafkaController)
2025-10-19 12:43:15.169 | [2025-10-19 17:43:15,168] INFO [Controller id=1] Resuming preferred replica election for partitions:  (kafka.controller.KafkaController)
2025-10-19 12:43:15.174 | [2025-10-19 17:43:15,174] INFO [Controller id=1] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered (kafka.controller.KafkaController)
2025-10-19 12:43:15.211 | [2025-10-19 17:43:15,210] INFO [Controller id=1] Starting the controller scheduler (kafka.controller.KafkaController)
2025-10-19 12:43:15.261 | [2025-10-19 17:43:15,260] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Recorded new controller, from now on will use node kafka:29092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
2025-10-19 12:43:15.287 | [2025-10-19 17:43:15,286] TRACE [Controller id=1 epoch=6] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 0 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-10-19 12:43:15.291 | [2025-10-19 17:43:15,290] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Recorded new controller, from now on will use node kafka:29092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
2025-10-19 12:43:15.306 | [2025-10-19 17:43:15,305] INFO [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 for 51 partitions (state.change.logger)
2025-10-19 12:43:15.309 | [2025-10-19 17:43:15,308] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.309 | [2025-10-19 17:43:15,308] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.309 | [2025-10-19 17:43:15,308] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.309 | [2025-10-19 17:43:15,308] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.309 | [2025-10-19 17:43:15,308] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.309 | [2025-10-19 17:43:15,308] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.309 | [2025-10-19 17:43:15,309] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.309 | [2025-10-19 17:43:15,309] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.309 | [2025-10-19 17:43:15,309] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.309 | [2025-10-19 17:43:15,309] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.309 | [2025-10-19 17:43:15,309] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.309 | [2025-10-19 17:43:15,309] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.310 | [2025-10-19 17:43:15,309] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.310 | [2025-10-19 17:43:15,310] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.310 | [2025-10-19 17:43:15,310] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.310 | [2025-10-19 17:43:15,310] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.310 | [2025-10-19 17:43:15,310] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.310 | [2025-10-19 17:43:15,310] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.310 | [2025-10-19 17:43:15,310] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.311 | [2025-10-19 17:43:15,310] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.311 | [2025-10-19 17:43:15,310] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.311 | [2025-10-19 17:43:15,310] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.311 | [2025-10-19 17:43:15,310] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.311 | [2025-10-19 17:43:15,310] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.311 | [2025-10-19 17:43:15,310] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.311 | [2025-10-19 17:43:15,311] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.312 | [2025-10-19 17:43:15,311] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.312 | [2025-10-19 17:43:15,312] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.313 | [2025-10-19 17:43:15,312] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.313 | [2025-10-19 17:43:15,312] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.313 | [2025-10-19 17:43:15,312] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.313 | [2025-10-19 17:43:15,312] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.313 | [2025-10-19 17:43:15,313] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.314 | [2025-10-19 17:43:15,313] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.314 | [2025-10-19 17:43:15,313] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.314 | [2025-10-19 17:43:15,313] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.314 | [2025-10-19 17:43:15,313] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.314 | [2025-10-19 17:43:15,313] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.314 | [2025-10-19 17:43:15,313] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.314 | [2025-10-19 17:43:15,313] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.314 | [2025-10-19 17:43:15,314] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.314 | [2025-10-19 17:43:15,314] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.314 | [2025-10-19 17:43:15,314] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.314 | [2025-10-19 17:43:15,314] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.314 | [2025-10-19 17:43:15,314] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.315 | [2025-10-19 17:43:15,314] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.315 | [2025-10-19 17:43:15,314] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.315 | [2025-10-19 17:43:15,314] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.315 | [2025-10-19 17:43:15,315] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.318 | [2025-10-19 17:43:15,315] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.318 | [2025-10-19 17:43:15,317] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='mesa-ya.restaurants.created', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 6 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,382] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-3 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,382] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-18 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,382] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-41 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,382] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-10 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,382] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-33 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,382] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-48 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,382] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-19 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,382] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-34 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,382] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-4 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,382] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-11 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,383] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-26 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,383] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-49 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,383] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-39 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,383] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-9 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,383] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-24 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,383] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-31 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,383] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-46 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,383] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-1 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,383] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-16 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,383] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-2 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,383] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-25 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,383] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-40 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,383] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-47 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,383] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-17 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,383] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-32 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,383] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-37 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,383] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-7 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,383] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-22 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,383] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-29 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,383] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-44 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,383] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-14 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,383] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-23 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,383] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-38 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,383] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-8 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,383] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-45 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,383] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-15 (state.change.logger)
2025-10-19 12:43:15.383 | [2025-10-19 17:43:15,383] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-30 (state.change.logger)
2025-10-19 12:43:15.384 | [2025-10-19 17:43:15,383] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition mesa-ya.restaurants.created-0 (state.change.logger)
2025-10-19 12:43:15.384 | [2025-10-19 17:43:15,383] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-0 (state.change.logger)
2025-10-19 12:43:15.384 | [2025-10-19 17:43:15,383] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-35 (state.change.logger)
2025-10-19 12:43:15.384 | [2025-10-19 17:43:15,384] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-5 (state.change.logger)
2025-10-19 12:43:15.384 | [2025-10-19 17:43:15,384] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-20 (state.change.logger)
2025-10-19 12:43:15.384 | [2025-10-19 17:43:15,384] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-27 (state.change.logger)
2025-10-19 12:43:15.384 | [2025-10-19 17:43:15,384] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-42 (state.change.logger)
2025-10-19 12:43:15.384 | [2025-10-19 17:43:15,384] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-12 (state.change.logger)
2025-10-19 12:43:15.384 | [2025-10-19 17:43:15,384] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-21 (state.change.logger)
2025-10-19 12:43:15.384 | [2025-10-19 17:43:15,384] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-36 (state.change.logger)
2025-10-19 12:43:15.384 | [2025-10-19 17:43:15,384] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-6 (state.change.logger)
2025-10-19 12:43:15.384 | [2025-10-19 17:43:15,384] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-43 (state.change.logger)
2025-10-19 12:43:15.384 | [2025-10-19 17:43:15,384] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-13 (state.change.logger)
2025-10-19 12:43:15.384 | [2025-10-19 17:43:15,384] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-leader transition for partition __consumer_offsets-28 (state.change.logger)
2025-10-19 12:43:15.388 | [2025-10-19 17:43:15,388] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-37, __consumer_offsets-38, __consumer_offsets-13, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, mesa-ya.restaurants.created-0, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
2025-10-19 12:43:15.389 | [2025-10-19 17:43:15,389] INFO [Broker id=1] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 1 epoch 6 as part of the become-leader transition for 51 partitions (state.change.logger)
2025-10-19 12:43:15.414 | [2025-10-19 17:43:15,413] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.421 | [2025-10-19 17:43:15,420] INFO [Broker id=1] Leader __consumer_offsets-3 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.445 | [2025-10-19 17:43:15,444] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.445 | [2025-10-19 17:43:15,445] INFO [Broker id=1] Leader __consumer_offsets-18 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.459 | [2025-10-19 17:43:15,459] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.459 | [2025-10-19 17:43:15,459] INFO [Broker id=1] Leader __consumer_offsets-41 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.473 | [2025-10-19 17:43:15,472] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.473 | [2025-10-19 17:43:15,472] INFO [Broker id=1] Leader __consumer_offsets-10 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.485 | [2025-10-19 17:43:15,484] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.485 | [2025-10-19 17:43:15,485] INFO [Broker id=1] Leader __consumer_offsets-33 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.498 | [2025-10-19 17:43:15,497] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.498 | [2025-10-19 17:43:15,498] INFO [Broker id=1] Leader __consumer_offsets-48 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.510 | [2025-10-19 17:43:15,509] INFO [Partition __consumer_offsets-19 broker=1] Log loaded for partition __consumer_offsets-19 with initial high watermark 5 (kafka.cluster.Partition)
2025-10-19 12:43:15.510 | [2025-10-19 17:43:15,509] INFO [Broker id=1] Leader __consumer_offsets-19 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 5 with partition epoch 0, high watermark 5, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.510 | [2025-10-19 17:43:15,510] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.510 | [2025-10-19 17:43:15,510] INFO [Broker id=1] Leader __consumer_offsets-34 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.524 | [2025-10-19 17:43:15,523] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.524 | [2025-10-19 17:43:15,524] INFO [Broker id=1] Leader __consumer_offsets-4 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.541 | [2025-10-19 17:43:15,540] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.541 | [2025-10-19 17:43:15,541] INFO [Broker id=1] Leader __consumer_offsets-11 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.557 | [2025-10-19 17:43:15,556] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.557 | [2025-10-19 17:43:15,556] INFO [Broker id=1] Leader __consumer_offsets-26 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.573 | [2025-10-19 17:43:15,573] INFO [Partition __consumer_offsets-49 broker=1] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.573 | [2025-10-19 17:43:15,573] INFO [Broker id=1] Leader __consumer_offsets-49 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.590 | [2025-10-19 17:43:15,589] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.590 | [2025-10-19 17:43:15,589] INFO [Broker id=1] Leader __consumer_offsets-39 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.606 | [2025-10-19 17:43:15,605] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.606 | [2025-10-19 17:43:15,606] INFO [Broker id=1] Leader __consumer_offsets-9 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.622 | [2025-10-19 17:43:15,622] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.623 | [2025-10-19 17:43:15,622] INFO [Broker id=1] Leader __consumer_offsets-24 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.641 | [2025-10-19 17:43:15,640] INFO [Partition __consumer_offsets-31 broker=1] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.641 | [2025-10-19 17:43:15,640] INFO [Broker id=1] Leader __consumer_offsets-31 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.663 | [2025-10-19 17:43:15,662] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.663 | [2025-10-19 17:43:15,663] INFO [Broker id=1] Leader __consumer_offsets-46 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.682 | [2025-10-19 17:43:15,681] INFO [Partition __consumer_offsets-1 broker=1] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.682 | [2025-10-19 17:43:15,681] INFO [Broker id=1] Leader __consumer_offsets-1 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.698 | [2025-10-19 17:43:15,697] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.698 | [2025-10-19 17:43:15,697] INFO [Broker id=1] Leader __consumer_offsets-16 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.714 | [2025-10-19 17:43:15,713] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.714 | [2025-10-19 17:43:15,714] INFO [Broker id=1] Leader __consumer_offsets-2 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.729 | [2025-10-19 17:43:15,728] INFO [Partition __consumer_offsets-25 broker=1] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.729 | [2025-10-19 17:43:15,729] INFO [Broker id=1] Leader __consumer_offsets-25 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.744 | [2025-10-19 17:43:15,744] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.744 | [2025-10-19 17:43:15,744] INFO [Broker id=1] Leader __consumer_offsets-40 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.759 | [2025-10-19 17:43:15,758] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.759 | [2025-10-19 17:43:15,758] INFO [Broker id=1] Leader __consumer_offsets-47 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.773 | [2025-10-19 17:43:15,773] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.773 | [2025-10-19 17:43:15,773] INFO [Broker id=1] Leader __consumer_offsets-17 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.789 | [2025-10-19 17:43:15,788] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.789 | [2025-10-19 17:43:15,789] INFO [Broker id=1] Leader __consumer_offsets-32 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.804 | [2025-10-19 17:43:15,803] INFO [Partition __consumer_offsets-37 broker=1] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.804 | [2025-10-19 17:43:15,804] INFO [Broker id=1] Leader __consumer_offsets-37 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.817 | [2025-10-19 17:43:15,816] INFO [Partition __consumer_offsets-7 broker=1] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.817 | [2025-10-19 17:43:15,816] INFO [Broker id=1] Leader __consumer_offsets-7 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.832 | [2025-10-19 17:43:15,831] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.832 | [2025-10-19 17:43:15,831] INFO [Broker id=1] Leader __consumer_offsets-22 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.847 | [2025-10-19 17:43:15,846] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.847 | [2025-10-19 17:43:15,847] INFO [Broker id=1] Leader __consumer_offsets-29 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.863 | [2025-10-19 17:43:15,862] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.863 | [2025-10-19 17:43:15,863] INFO [Broker id=1] Leader __consumer_offsets-44 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.878 | [2025-10-19 17:43:15,877] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.879 | [2025-10-19 17:43:15,878] INFO [Broker id=1] Leader __consumer_offsets-14 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.896 | [2025-10-19 17:43:15,895] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.896 | [2025-10-19 17:43:15,896] INFO [Broker id=1] Leader __consumer_offsets-23 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.910 | [2025-10-19 17:43:15,909] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.910 | [2025-10-19 17:43:15,910] INFO [Broker id=1] Leader __consumer_offsets-38 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.923 | [2025-10-19 17:43:15,922] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.923 | [2025-10-19 17:43:15,922] INFO [Broker id=1] Leader __consumer_offsets-8 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.936 | [2025-10-19 17:43:15,936] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.936 | [2025-10-19 17:43:15,936] INFO [Broker id=1] Leader __consumer_offsets-45 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.948 | [2025-10-19 17:43:15,948] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.948 | [2025-10-19 17:43:15,948] INFO [Broker id=1] Leader __consumer_offsets-15 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.962 | [2025-10-19 17:43:15,962] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.962 | [2025-10-19 17:43:15,962] INFO [Broker id=1] Leader __consumer_offsets-30 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.979 | [2025-10-19 17:43:15,978] INFO [Partition mesa-ya.restaurants.created-0 broker=1] Log loaded for partition mesa-ya.restaurants.created-0 with initial high watermark 2 (kafka.cluster.Partition)
2025-10-19 12:43:15.979 | [2025-10-19 17:43:15,979] INFO [Broker id=1] Leader mesa-ya.restaurants.created-0 with topic id Some(yWm6W48_TyqOOX8W2L0ItA) starts at leader epoch 0 from offset 2 with partition epoch 0, high watermark 2, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.979 | [2025-10-19 17:43:15,979] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.979 | [2025-10-19 17:43:15,979] INFO [Broker id=1] Leader __consumer_offsets-0 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:15.993 | [2025-10-19 17:43:15,992] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:15.993 | [2025-10-19 17:43:15,992] INFO [Broker id=1] Leader __consumer_offsets-35 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:16.005 | [2025-10-19 17:43:16,004] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:16.005 | [2025-10-19 17:43:16,005] INFO [Broker id=1] Leader __consumer_offsets-5 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:16.023 | [2025-10-19 17:43:16,023] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:16.023 | [2025-10-19 17:43:16,023] INFO [Broker id=1] Leader __consumer_offsets-20 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:16.037 | [2025-10-19 17:43:16,036] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:16.037 | [2025-10-19 17:43:16,037] INFO [Broker id=1] Leader __consumer_offsets-27 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:16.050 | [2025-10-19 17:43:16,050] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:16.050 | [2025-10-19 17:43:16,050] INFO [Broker id=1] Leader __consumer_offsets-42 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:16.064 | [2025-10-19 17:43:16,063] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:16.064 | [2025-10-19 17:43:16,064] INFO [Broker id=1] Leader __consumer_offsets-12 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:16.077 | [2025-10-19 17:43:16,077] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:16.077 | [2025-10-19 17:43:16,077] INFO [Broker id=1] Leader __consumer_offsets-21 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:16.092 | [2025-10-19 17:43:16,091] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:16.092 | [2025-10-19 17:43:16,091] INFO [Broker id=1] Leader __consumer_offsets-36 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:16.105 | [2025-10-19 17:43:16,104] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:16.105 | [2025-10-19 17:43:16,104] INFO [Broker id=1] Leader __consumer_offsets-6 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:16.118 | [2025-10-19 17:43:16,117] INFO [Partition __consumer_offsets-43 broker=1] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:16.118 | [2025-10-19 17:43:16,118] INFO [Broker id=1] Leader __consumer_offsets-43 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:16.137 | [2025-10-19 17:43:16,137] INFO [Partition __consumer_offsets-13 broker=1] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:16.137 | [2025-10-19 17:43:16,137] INFO [Broker id=1] Leader __consumer_offsets-13 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:16.156 | [2025-10-19 17:43:16,155] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 12:43:16.156 | [2025-10-19 17:43:16,155] INFO [Broker id=1] Leader __consumer_offsets-28 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 12:43:16.175 | [2025-10-19 17:43:16,174] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-3 (state.change.logger)
2025-10-19 12:43:16.175 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-18 (state.change.logger)
2025-10-19 12:43:16.175 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-41 (state.change.logger)
2025-10-19 12:43:16.175 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-10 (state.change.logger)
2025-10-19 12:43:16.175 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-33 (state.change.logger)
2025-10-19 12:43:16.175 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-48 (state.change.logger)
2025-10-19 12:43:16.175 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-19 (state.change.logger)
2025-10-19 12:43:16.175 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-34 (state.change.logger)
2025-10-19 12:43:16.175 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-4 (state.change.logger)
2025-10-19 12:43:16.175 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-11 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-26 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-49 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-39 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-9 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-24 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-31 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-46 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-1 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-16 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-2 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-25 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-40 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-47 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-17 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-32 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-37 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-7 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-22 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-29 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-44 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-14 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-23 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-38 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-8 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-45 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-15 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-30 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition mesa-ya.restaurants.created-0 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-0 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-35 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-5 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-20 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-27 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-42 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-12 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-21 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-36 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,175] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-6 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,176] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-43 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,176] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-13 (state.change.logger)
2025-10-19 12:43:16.176 | [2025-10-19 17:43:16,176] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 6 for the become-leader transition for partition __consumer_offsets-28 (state.change.logger)
2025-10-19 12:43:16.193 | [2025-10-19 17:43:16,191] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.196 | [2025-10-19 17:43:16,195] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.199 | [2025-10-19 17:43:16,199] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.199 | [2025-10-19 17:43:16,199] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.199 | [2025-10-19 17:43:16,199] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.199 | [2025-10-19 17:43:16,199] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.199 | [2025-10-19 17:43:16,199] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.199 | [2025-10-19 17:43:16,199] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.199 | [2025-10-19 17:43:16,199] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.199 | [2025-10-19 17:43:16,199] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.199 | [2025-10-19 17:43:16,199] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.199 | [2025-10-19 17:43:16,199] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.199 | [2025-10-19 17:43:16,199] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.200 | [2025-10-19 17:43:16,199] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.200 | [2025-10-19 17:43:16,199] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.200 | [2025-10-19 17:43:16,199] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.200 | [2025-10-19 17:43:16,199] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.200 | [2025-10-19 17:43:16,200] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.200 | [2025-10-19 17:43:16,200] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.200 | [2025-10-19 17:43:16,200] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.200 | [2025-10-19 17:43:16,200] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.200 | [2025-10-19 17:43:16,200] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.200 | [2025-10-19 17:43:16,200] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.200 | [2025-10-19 17:43:16,200] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.200 | [2025-10-19 17:43:16,200] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.200 | [2025-10-19 17:43:16,200] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.200 | [2025-10-19 17:43:16,200] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.200 | [2025-10-19 17:43:16,200] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.200 | [2025-10-19 17:43:16,200] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.200 | [2025-10-19 17:43:16,200] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.200 | [2025-10-19 17:43:16,200] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.200 | [2025-10-19 17:43:16,200] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.201 | [2025-10-19 17:43:16,200] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.201 | [2025-10-19 17:43:16,200] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.201 | [2025-10-19 17:43:16,200] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.201 | [2025-10-19 17:43:16,200] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.201 | [2025-10-19 17:43:16,201] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.201 | [2025-10-19 17:43:16,201] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.201 | [2025-10-19 17:43:16,201] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.201 | [2025-10-19 17:43:16,201] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.201 | [2025-10-19 17:43:16,201] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.201 | [2025-10-19 17:43:16,201] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.201 | [2025-10-19 17:43:16,201] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.201 | [2025-10-19 17:43:16,201] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.201 | [2025-10-19 17:43:16,201] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.201 | [2025-10-19 17:43:16,201] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.201 | [2025-10-19 17:43:16,201] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.201 | [2025-10-19 17:43:16,201] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.201 | [2025-10-19 17:43:16,201] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.201 | [2025-10-19 17:43:16,201] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.202 | [2025-10-19 17:43:16,201] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.202 | [2025-10-19 17:43:16,201] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.202 | [2025-10-19 17:43:16,202] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.202 | [2025-10-19 17:43:16,202] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.202 | [2025-10-19 17:43:16,202] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.202 | [2025-10-19 17:43:16,202] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.202 | [2025-10-19 17:43:16,202] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.202 | [2025-10-19 17:43:16,202] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.202 | [2025-10-19 17:43:16,202] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.202 | [2025-10-19 17:43:16,202] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.202 | [2025-10-19 17:43:16,202] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.202 | [2025-10-19 17:43:16,202] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.202 | [2025-10-19 17:43:16,202] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.202 | [2025-10-19 17:43:16,202] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.202 | [2025-10-19 17:43:16,202] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.202 | [2025-10-19 17:43:16,202] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.203 | [2025-10-19 17:43:16,202] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.203 | [2025-10-19 17:43:16,202] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.203 | [2025-10-19 17:43:16,202] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.203 | [2025-10-19 17:43:16,203] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.203 | [2025-10-19 17:43:16,203] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.203 | [2025-10-19 17:43:16,203] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.203 | [2025-10-19 17:43:16,203] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.203 | [2025-10-19 17:43:16,203] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.203 | [2025-10-19 17:43:16,203] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.203 | [2025-10-19 17:43:16,203] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.203 | [2025-10-19 17:43:16,203] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.203 | [2025-10-19 17:43:16,203] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.203 | [2025-10-19 17:43:16,203] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.203 | [2025-10-19 17:43:16,203] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.203 | [2025-10-19 17:43:16,203] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.203 | [2025-10-19 17:43:16,203] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.203 | [2025-10-19 17:43:16,203] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.203 | [2025-10-19 17:43:16,203] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.203 | [2025-10-19 17:43:16,203] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.203 | [2025-10-19 17:43:16,203] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.203 | [2025-10-19 17:43:16,203] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.204 | [2025-10-19 17:43:16,203] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.204 | [2025-10-19 17:43:16,203] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.204 | [2025-10-19 17:43:16,203] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.204 | [2025-10-19 17:43:16,203] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.204 | [2025-10-19 17:43:16,203] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.204 | [2025-10-19 17:43:16,203] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.204 | [2025-10-19 17:43:16,203] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.204 | [2025-10-19 17:43:16,203] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.204 | [2025-10-19 17:43:16,203] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.204 | [2025-10-19 17:43:16,203] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.204 | [2025-10-19 17:43:16,203] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.204 | [2025-10-19 17:43:16,203] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 12:43:16.204 | [2025-10-19 17:43:16,204] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.212 | [2025-10-19 17:43:16,210] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 14 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.212 | [2025-10-19 17:43:16,211] INFO [Broker id=1] Finished LeaderAndIsr request in 907ms correlationId 1 from controller 1 for 51 partitions (state.change.logger)
2025-10-19 12:43:16.213 | [2025-10-19 17:43:16,212] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.213 | [2025-10-19 17:43:16,213] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.214 | [2025-10-19 17:43:16,213] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.214 | [2025-10-19 17:43:16,214] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 15 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.214 | [2025-10-19 17:43:16,214] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.223 | [2025-10-19 17:43:16,222] TRACE [Controller id=1 epoch=6] Received response LeaderAndIsrResponseData(errorCode=0, partitionErrors=[], topics=[LeaderAndIsrTopicError(topicId=6ep0dUNwQAaqKr79SJ8ITA, partitionErrors=[LeaderAndIsrPartitionError(topicName='', partitionIndex=13, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=46, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=9, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=42, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=21, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=17, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=30, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=26, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=5, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=38, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=1, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=34, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=16, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=45, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=12, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=41, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=24, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=20, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=49, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=0, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=29, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=25, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=8, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=37, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=4, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=33, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=15, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=48, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=11, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=44, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=23, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=19, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=32, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=28, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=7, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=40, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=3, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=36, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=47, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=14, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=43, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=10, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=22, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=18, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=31, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=27, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=39, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=6, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=35, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=2, errorCode=0)]), LeaderAndIsrTopicError(topicId=yWm6W48_TyqOOX8W2L0ItA, partitionErrors=[LeaderAndIsrPartitionError(topicName='', partitionIndex=0, errorCode=0)])]) for request LEADER_AND_ISR with correlation id 1 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-10-19 12:43:16.231 | [2025-10-19 17:43:16,231] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-13 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.231 | [2025-10-19 17:43:16,231] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-46 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.231 | [2025-10-19 17:43:16,231] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-9 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.231 | [2025-10-19 17:43:16,231] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-42 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.231 | [2025-10-19 17:43:16,231] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-21 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.231 | [2025-10-19 17:43:16,231] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-17 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,231] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-30 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,231] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-26 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,231] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-5 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,231] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-38 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,231] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-1 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,231] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-34 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,231] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-16 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,231] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-45 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,231] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-12 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,231] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-41 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,231] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-24 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,231] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-20 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,231] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-49 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,231] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-0 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,231] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-29 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,231] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-25 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,232] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-8 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,232] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-37 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,232] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-4 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,232] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-33 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,232] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-15 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,232] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-48 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,232] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-11 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,232] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-44 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,232] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-23 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,232] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-19 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,232] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-32 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,232] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-28 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,232] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-7 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,232] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-40 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,232] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-3 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,232] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-36 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,232] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-47 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,232] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-14 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,232] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-43 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,232] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-10 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,232] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-22 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,232] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-18 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,232] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-31 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,232] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-27 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,232] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-39 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,232] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-6 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,232] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-35 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,232] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-2 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.232 | [2025-10-19 17:43:16,232] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='mesa-ya.restaurants.created', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition mesa-ya.restaurants.created-0 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.233 | [2025-10-19 17:43:16,233] INFO [Broker id=1] Add 51 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 2 (state.change.logger)
2025-10-19 12:43:16.239 | [2025-10-19 17:43:16,235] TRACE [Controller id=1 epoch=6] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 2 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-10-19 12:43:16.271 | [2025-10-19 17:43:16,271] INFO Loaded member MemberMetadata(memberId=mesa-ya-service-client-9a0094a4-6972-4e79-a5d6-5ed4ed5cfa65, groupInstanceId=None, clientId=mesa-ya-service-client, clientHost=/172.18.0.4, sessionTimeoutMs=30000, rebalanceTimeoutMs=60000, supportedProtocols=List(NestReplyPartitionAssigner)) in group nestjs-group-client with generation 1. (kafka.coordinator.group.GroupMetadata$)
2025-10-19 12:43:16.282 | [2025-10-19 17:43:16,282] INFO Loaded member MemberMetadata(memberId=mesa-ya-service-client-72bf5d0c-5531-4f4b-bc39-f00715991c39, groupInstanceId=None, clientId=mesa-ya-service-client, clientHost=/172.18.0.4, sessionTimeoutMs=30000, rebalanceTimeoutMs=60000, supportedProtocols=List(NestReplyPartitionAssigner)) in group nestjs-group-client with generation 3. (kafka.coordinator.group.GroupMetadata$)
2025-10-19 12:43:16.283 | [2025-10-19 17:43:16,283] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 84 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.283 | [2025-10-19 17:43:16,283] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 84 milliseconds for epoch 0, of which 84 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.284 | [2025-10-19 17:43:16,283] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 83 milliseconds for epoch 0, of which 83 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.284 | [2025-10-19 17:43:16,284] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 84 milliseconds for epoch 0, of which 83 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.284 | [2025-10-19 17:43:16,284] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 84 milliseconds for epoch 0, of which 84 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.285 | [2025-10-19 17:43:16,284] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 84 milliseconds for epoch 0, of which 84 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.285 | [2025-10-19 17:43:16,284] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 84 milliseconds for epoch 0, of which 84 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.285 | [2025-10-19 17:43:16,285] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 85 milliseconds for epoch 0, of which 85 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.285 | [2025-10-19 17:43:16,285] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 85 milliseconds for epoch 0, of which 85 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.285 | [2025-10-19 17:43:16,285] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 85 milliseconds for epoch 0, of which 85 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.286 | [2025-10-19 17:43:16,285] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 85 milliseconds for epoch 0, of which 85 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.286 | [2025-10-19 17:43:16,285] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 85 milliseconds for epoch 0, of which 85 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.286 | [2025-10-19 17:43:16,286] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 85 milliseconds for epoch 0, of which 84 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.286 | [2025-10-19 17:43:16,286] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 85 milliseconds for epoch 0, of which 85 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.286 | [2025-10-19 17:43:16,286] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 85 milliseconds for epoch 0, of which 85 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.287 | [2025-10-19 17:43:16,286] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 85 milliseconds for epoch 0, of which 85 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.287 | [2025-10-19 17:43:16,286] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 85 milliseconds for epoch 0, of which 85 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.287 | [2025-10-19 17:43:16,287] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 86 milliseconds for epoch 0, of which 85 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.287 | [2025-10-19 17:43:16,287] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 86 milliseconds for epoch 0, of which 86 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.287 | [2025-10-19 17:43:16,287] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 86 milliseconds for epoch 0, of which 86 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.288 | [2025-10-19 17:43:16,287] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 85 milliseconds for epoch 0, of which 85 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.288 | [2025-10-19 17:43:16,288] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 86 milliseconds for epoch 0, of which 85 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.288 | [2025-10-19 17:43:16,288] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 86 milliseconds for epoch 0, of which 86 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.288 | [2025-10-19 17:43:16,288] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 86 milliseconds for epoch 0, of which 86 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.288 | [2025-10-19 17:43:16,288] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 86 milliseconds for epoch 0, of which 86 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.289 | [2025-10-19 17:43:16,288] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 86 milliseconds for epoch 0, of which 86 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.289 | [2025-10-19 17:43:16,288] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 86 milliseconds for epoch 0, of which 86 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.289 | [2025-10-19 17:43:16,289] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 87 milliseconds for epoch 0, of which 86 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.289 | [2025-10-19 17:43:16,289] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 86 milliseconds for epoch 0, of which 86 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.289 | [2025-10-19 17:43:16,289] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 86 milliseconds for epoch 0, of which 86 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.289 | [2025-10-19 17:43:16,289] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 86 milliseconds for epoch 0, of which 86 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.289 | [2025-10-19 17:43:16,289] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 86 milliseconds for epoch 0, of which 86 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.290 | [2025-10-19 17:43:16,289] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 86 milliseconds for epoch 0, of which 86 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.290 | [2025-10-19 17:43:16,290] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 87 milliseconds for epoch 0, of which 86 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.290 | [2025-10-19 17:43:16,290] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 87 milliseconds for epoch 0, of which 87 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.290 | [2025-10-19 17:43:16,290] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 87 milliseconds for epoch 0, of which 87 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.291 | [2025-10-19 17:43:16,290] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 87 milliseconds for epoch 0, of which 87 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.291 | [2025-10-19 17:43:16,291] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 88 milliseconds for epoch 0, of which 87 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.291 | [2025-10-19 17:43:16,291] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 88 milliseconds for epoch 0, of which 88 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.292 | [2025-10-19 17:43:16,291] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 88 milliseconds for epoch 0, of which 88 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.293 | [2025-10-19 17:43:16,292] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 89 milliseconds for epoch 0, of which 89 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.293 | [2025-10-19 17:43:16,293] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 90 milliseconds for epoch 0, of which 89 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.294 | [2025-10-19 17:43:16,293] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 90 milliseconds for epoch 0, of which 90 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:16.294 | [2025-10-19 17:43:16,294] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 90 milliseconds for epoch 0, of which 90 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 12:43:20.213 | [2025-10-19 17:43:20,213] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 12:43:20.214 | [2025-10-19 17:43:20,213] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 12:43:20.220 | [2025-10-19 17:43:20,219] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 12:43:20.221 | [2025-10-19 17:43:20,221] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 12:48:11.249 | [2025-10-19 17:48:11,248] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 12:48:11.249 | [2025-10-19 17:48:11,249] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 12:48:11.253 | [2025-10-19 17:48:11,252] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 12:48:11.253 | [2025-10-19 17:48:11,253] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 12:53:02.146 | [2025-10-19 17:53:02,145] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 12:53:02.146 | [2025-10-19 17:53:02,146] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 12:53:02.151 | [2025-10-19 17:53:02,150] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 12:53:02.151 | [2025-10-19 17:53:02,151] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 12:57:52.919 | [2025-10-19 17:57:52,918] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 12:57:52.919 | [2025-10-19 17:57:52,918] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 12:57:52.921 | [2025-10-19 17:57:52,920] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 12:57:52.921 | [2025-10-19 17:57:52,920] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 13:02:43.669 | [2025-10-19 18:02:43,668] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 13:02:43.669 | [2025-10-19 18:02:43,669] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 13:02:43.671 | [2025-10-19 18:02:43,671] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 13:02:43.671 | [2025-10-19 18:02:43,671] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 13:07:34.165 | [2025-10-19 18:07:34,164] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 13:07:34.165 | [2025-10-19 18:07:34,164] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 13:07:34.169 | [2025-10-19 18:07:34,168] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 13:07:34.169 | [2025-10-19 18:07:34,169] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 13:12:24.782 | [2025-10-19 18:12:24,781] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 13:12:24.782 | [2025-10-19 18:12:24,781] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 13:12:24.785 | [2025-10-19 18:12:24,785] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 13:12:24.786 | [2025-10-19 18:12:24,785] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 13:17:15.183 | [2025-10-19 18:17:15,182] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 13:17:15.185 | [2025-10-19 18:17:15,184] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 13:17:15.191 | [2025-10-19 18:17:15,190] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 13:17:15.191 | [2025-10-19 18:17:15,190] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 13:22:05.487 | [2025-10-19 18:22:05,486] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 13:22:05.487 | [2025-10-19 18:22:05,487] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 13:22:05.490 | [2025-10-19 18:22:05,489] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 13:22:05.490 | [2025-10-19 18:22:05,490] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 13:26:55.861 | [2025-10-19 18:26:55,860] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 13:26:55.861 | [2025-10-19 18:26:55,861] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 13:26:55.863 | [2025-10-19 18:26:55,863] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 13:26:55.863 | [2025-10-19 18:26:55,863] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 13:31:46.196 | [2025-10-19 18:31:46,195] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 13:31:46.196 | [2025-10-19 18:31:46,196] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 13:31:46.199 | [2025-10-19 18:31:46,198] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 13:31:46.199 | [2025-10-19 18:31:46,198] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 13:36:36.577 | [2025-10-19 18:36:36,576] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 13:36:36.578 | [2025-10-19 18:36:36,577] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 13:36:36.580 | [2025-10-19 18:36:36,579] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 13:36:36.580 | [2025-10-19 18:36:36,579] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 13:41:26.972 | [2025-10-19 18:41:26,971] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 13:41:26.972 | [2025-10-19 18:41:26,972] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 13:41:26.976 | [2025-10-19 18:41:26,976] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 13:41:26.976 | [2025-10-19 18:41:26,976] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 13:46:17.391 | [2025-10-19 18:46:17,390] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 13:46:17.391 | [2025-10-19 18:46:17,391] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 13:46:17.397 | [2025-10-19 18:46:17,396] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 13:46:17.398 | [2025-10-19 18:46:17,397] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 13:51:07.866 | [2025-10-19 18:51:07,864] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 13:51:07.866 | [2025-10-19 18:51:07,865] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 13:51:07.867 | [2025-10-19 18:51:07,866] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 13:51:07.867 | [2025-10-19 18:51:07,867] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 13:55:58.439 | [2025-10-19 18:55:58,438] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 13:55:58.439 | [2025-10-19 18:55:58,439] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 13:55:58.441 | [2025-10-19 18:55:58,440] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 13:55:58.441 | [2025-10-19 18:55:58,441] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 14:00:49.023 | [2025-10-19 19:00:49,023] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 14:00:49.023 | [2025-10-19 19:00:49,023] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 14:00:49.024 | [2025-10-19 19:00:49,024] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 14:00:49.024 | [2025-10-19 19:00:49,024] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 14:05:39.614 | [2025-10-19 19:05:39,613] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 14:05:39.614 | [2025-10-19 19:05:39,613] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 14:05:39.615 | [2025-10-19 19:05:39,615] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 14:05:39.615 | [2025-10-19 19:05:39,615] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 14:10:30.273 | [2025-10-19 19:10:30,272] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 14:10:30.273 | [2025-10-19 19:10:30,272] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 14:10:30.273 | [2025-10-19 19:10:30,273] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 14:10:30.274 | [2025-10-19 19:10:30,273] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 14:15:20.926 | [2025-10-19 19:15:20,925] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 14:15:20.926 | [2025-10-19 19:15:20,925] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 14:15:20.927 | [2025-10-19 19:15:20,926] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 14:15:20.927 | [2025-10-19 19:15:20,926] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 14:20:11.601 | [2025-10-19 19:20:11,600] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 14:20:11.601 | [2025-10-19 19:20:11,601] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 14:20:11.603 | [2025-10-19 19:20:11,602] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 14:20:11.603 | [2025-10-19 19:20:11,602] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 14:25:02.325 | [2025-10-19 19:25:02,324] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 14:25:02.325 | [2025-10-19 19:25:02,324] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 14:25:02.326 | [2025-10-19 19:25:02,325] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 14:25:02.326 | [2025-10-19 19:25:02,326] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 14:29:52.704 | [2025-10-19 19:29:52,704] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group nestjs-group-client in Empty state. Created a new member id mesa-ya-service-client-f2aeaef7-4be2-4f30-b0ef-3c4276477e2c and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:29:52.742 | [2025-10-19 19:29:52,741] INFO [GroupCoordinator 1]: Preparing to rebalance group nestjs-group-client in state PreparingRebalance with old generation 0 (__consumer_offsets-19) (reason: Adding new member mesa-ya-service-client-f2aeaef7-4be2-4f30-b0ef-3c4276477e2c with group instance id None; client reason: not provided) (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:29:53.057 | [2025-10-19 19:29:53,056] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 14:29:53.057 | [2025-10-19 19:29:53,057] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 14:29:53.059 | [2025-10-19 19:29:53,058] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 14:29:53.059 | [2025-10-19 19:29:53,058] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 14:29:55.762 | [2025-10-19 19:29:55,762] INFO [GroupCoordinator 1]: Stabilized group nestjs-group-client generation 1 (__consumer_offsets-19) with 1 members (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:29:55.786 | [2025-10-19 19:29:55,786] INFO [GroupCoordinator 1]: Assignment received from leader mesa-ya-service-client-f2aeaef7-4be2-4f30-b0ef-3c4276477e2c for group nestjs-group-client for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:30:20.571 | [2025-10-19 19:30:20,571] INFO Creating topic mesa-ya.sections.created with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
2025-10-19 14:30:20.659 | [2025-10-19 19:30:20,659] INFO [Controller id=1] New topics: [Set(mesa-ya.sections.created)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(mesa-ya.sections.created,Some(NwfGy3exRLOrYp5JWPfRlA),Map(mesa-ya.sections.created-0 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=))))] (kafka.controller.KafkaController)
2025-10-19 14:30:20.661 | [2025-10-19 19:30:20,660] INFO [Controller id=1] New partition creation callback for mesa-ya.sections.created-0 (kafka.controller.KafkaController)
2025-10-19 14:30:20.665 | [2025-10-19 19:30:20,664] INFO [Controller id=1 epoch=6] Changed partition mesa-ya.sections.created-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-19 14:30:20.665 | [2025-10-19 19:30:20,665] INFO [Controller id=1 epoch=6] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-10-19 14:30:20.667 | [2025-10-19 19:30:20,667] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition mesa-ya.sections.created-0 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-19 14:30:20.667 | [2025-10-19 19:30:20,667] INFO [Controller id=1 epoch=6] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-10-19 14:30:20.699 | [2025-10-19 19:30:20,698] INFO [Controller id=1 epoch=6] Changed partition mesa-ya.sections.created-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-19 14:30:20.699 | [2025-10-19 19:30:20,699] TRACE [Controller id=1 epoch=6] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='mesa-ya.sections.created', partitionIndex=0, controllerEpoch=6, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition mesa-ya.sections.created-0 (state.change.logger)
2025-10-19 14:30:20.699 | [2025-10-19 19:30:20,699] INFO [Controller id=1 epoch=6] Sending LeaderAndIsr request to broker 1 with 1 become-leader and 0 become-follower partitions (state.change.logger)
2025-10-19 14:30:20.701 | [2025-10-19 19:30:20,701] INFO [Controller id=1 epoch=6] Sending UpdateMetadata request to brokers HashSet(1) for 1 partitions (state.change.logger)
2025-10-19 14:30:20.702 | [2025-10-19 19:30:20,701] TRACE [Controller id=1 epoch=6] Changed state of replica 1 for partition mesa-ya.sections.created-0 from NewReplica to OnlineReplica (state.change.logger)
2025-10-19 14:30:20.702 | [2025-10-19 19:30:20,702] INFO [Controller id=1 epoch=6] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-10-19 14:30:20.704 | [2025-10-19 19:30:20,704] INFO [Controller id=1, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
2025-10-19 14:30:20.710 | [2025-10-19 19:30:20,710] INFO [RequestSendThread controllerId=1] Controller 1 connected to kafka:29092 (id: 1 rack: null) for sending state change requests (kafka.controller.RequestSendThread)
2025-10-19 14:30:20.713 | [2025-10-19 19:30:20,713] INFO [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 for 1 partitions (state.change.logger)
2025-10-19 14:30:20.713 | [2025-10-19 19:30:20,713] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='mesa-ya.sections.created', partitionIndex=0, controllerEpoch=6, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 6 (state.change.logger)
2025-10-19 14:30:20.715 | [2025-10-19 19:30:20,714] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 6 starting the become-leader transition for partition mesa-ya.sections.created-0 (state.change.logger)
2025-10-19 14:30:20.716 | [2025-10-19 19:30:20,715] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(mesa-ya.sections.created-0) (kafka.server.ReplicaFetcherManager)
2025-10-19 14:30:20.716 | [2025-10-19 19:30:20,715] INFO [Broker id=1] Stopped fetchers as part of LeaderAndIsr request correlationId 3 from controller 1 epoch 6 as part of the become-leader transition for 1 partitions (state.change.logger)
2025-10-19 14:30:20.733 | [2025-10-19 19:30:20,732] INFO [LogLoader partition=mesa-ya.sections.created-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:30:20.738 | [2025-10-19 19:30:20,737] INFO Created log for partition mesa-ya.sections.created-0 in /var/lib/kafka/data/mesa-ya.sections.created-0 with properties {} (kafka.log.LogManager)
2025-10-19 14:30:20.740 | [2025-10-19 19:30:20,739] INFO [Partition mesa-ya.sections.created-0 broker=1] No checkpointed highwatermark is found for partition mesa-ya.sections.created-0 (kafka.cluster.Partition)
2025-10-19 14:30:20.740 | [2025-10-19 19:30:20,740] INFO [Partition mesa-ya.sections.created-0 broker=1] Log loaded for partition mesa-ya.sections.created-0 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:30:20.741 | [2025-10-19 19:30:20,741] INFO [Broker id=1] Leader mesa-ya.sections.created-0 with topic id Some(NwfGy3exRLOrYp5JWPfRlA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:30:20.754 | [2025-10-19 19:30:20,753] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 6 for the become-leader transition for partition mesa-ya.sections.created-0 (state.change.logger)
2025-10-19 14:30:20.754 | [2025-10-19 19:30:20,754] INFO [Broker id=1] Finished LeaderAndIsr request in 42ms correlationId 3 from controller 1 for 1 partitions (state.change.logger)
2025-10-19 14:30:20.756 | [2025-10-19 19:30:20,756] TRACE [Controller id=1 epoch=6] Received response LeaderAndIsrResponseData(errorCode=0, partitionErrors=[], topics=[LeaderAndIsrTopicError(topicId=NwfGy3exRLOrYp5JWPfRlA, partitionErrors=[LeaderAndIsrPartitionError(topicName='', partitionIndex=0, errorCode=0)])]) for request LEADER_AND_ISR with correlation id 3 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-10-19 14:30:20.759 | [2025-10-19 19:30:20,758] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='mesa-ya.sections.created', partitionIndex=0, controllerEpoch=6, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition mesa-ya.sections.created-0 in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 4 (state.change.logger)
2025-10-19 14:30:20.759 | [2025-10-19 19:30:20,758] INFO [Broker id=1] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 6 with correlation id 4 (state.change.logger)
2025-10-19 14:30:20.760 | [2025-10-19 19:30:20,760] TRACE [Controller id=1 epoch=6] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 4 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-10-19 14:34:43.830 | [2025-10-19 19:34:43,829] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 14:34:43.830 | [2025-10-19 19:34:43,829] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 14:34:43.832 | [2025-10-19 19:34:43,831] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 14:34:43.832 | [2025-10-19 19:34:43,831] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 14:38:00.297 | [2025-10-19 19:38:00,296] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
2025-10-19 14:38:00.306 | [2025-10-19 19:38:00,305] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
2025-10-19 14:38:00.311 | [2025-10-19 19:38:00,311] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
2025-10-19 14:38:00.331 | [2025-10-19 19:38:00,331] INFO [Controller id=1] Shutting down broker 1 (kafka.controller.KafkaController)
2025-10-19 14:38:00.332 | [2025-10-19 19:38:00,331] DEBUG [Controller id=1] All shutting down brokers: 1 (kafka.controller.KafkaController)
2025-10-19 14:38:00.332 | [2025-10-19 19:38:00,332] DEBUG [Controller id=1] Live brokers:  (kafka.controller.KafkaController)
2025-10-19 14:38:00.338 | [2025-10-19 19:38:00,337] INFO [Controller id=1 epoch=6] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-10-19 14:38:00.340 | [2025-10-19 19:38:00,339] TRACE [Controller id=1] All leaders = __consumer_offsets-13 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-46 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-9 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-42 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-21 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-17 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-30 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-26 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-5 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-38 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-1 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-34 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-16 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-45 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-12 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-41 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-24 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-20 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-49 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-0 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-29 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-25 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-8 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-37 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-4 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-33 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-15 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-48 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-11 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-44 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-23 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-19 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-32 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-28 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-7 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-40 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-3 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-36 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-47 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-14 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-43 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-10 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-22 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-18 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-31 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-27 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),mesa-ya.sections.created-0 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:6),__consumer_offsets-39 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-6 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-35 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),mesa-ya.restaurants.created-0 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-2 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1) (kafka.controller.KafkaController)
2025-10-19 14:38:00.343 | [2025-10-19 19:38:00,343] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 15ms (kafka.server.KafkaServer)
2025-10-19 14:38:00.351 | [2025-10-19 19:38:00,351] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-10-19 14:38:00.353 | [2025-10-19 19:38:00,352] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-10-19 14:38:00.353 | [2025-10-19 19:38:00,352] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-10-19 14:38:00.357 | [2025-10-19 19:38:00,356] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
2025-10-19 14:38:00.398 | [2025-10-19 19:38:00,398] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
2025-10-19 14:38:00.400 | [2025-10-19 19:38:00,400] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
2025-10-19 14:38:00.405 | [2025-10-19 19:38:00,404] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
2025-10-19 14:38:00.414 | [2025-10-19 19:38:00,413] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 14:38:00.418 | [2025-10-19 19:38:00,418] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 14:38:00.418 | [2025-10-19 19:38:00,418] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 14:38:00.420 | [2025-10-19 19:38:00,419] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
2025-10-19 14:38:00.422 | [2025-10-19 19:38:00,422] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 14:38:00.425 | [2025-10-19 19:38:00,424] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 14:38:00.425 | [2025-10-19 19:38:00,424] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 14:38:00.429 | [2025-10-19 19:38:00,428] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
2025-10-19 14:38:00.433 | [2025-10-19 19:38:00,433] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
2025-10-19 14:38:00.435 | [2025-10-19 19:38:00,434] INFO [TxnMarkerSenderThread-1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-10-19 14:38:00.435 | [2025-10-19 19:38:00,435] INFO [TxnMarkerSenderThread-1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-10-19 14:38:00.435 | [2025-10-19 19:38:00,435] INFO [TxnMarkerSenderThread-1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-10-19 14:38:00.437 | [2025-10-19 19:38:00,437] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
2025-10-19 14:38:00.438 | [2025-10-19 19:38:00,438] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:38:00.440 | [2025-10-19 19:38:00,440] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 14:38:00.442 | [2025-10-19 19:38:00,442] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 14:38:00.442 | [2025-10-19 19:38:00,442] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 14:38:00.443 | [2025-10-19 19:38:00,443] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 14:38:00.445 | [2025-10-19 19:38:00,445] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 14:38:00.445 | [2025-10-19 19:38:00,445] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 14:38:00.446 | [2025-10-19 19:38:00,446] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:38:00.447 | [2025-10-19 19:38:00,447] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
2025-10-19 14:38:00.450 | [2025-10-19 19:38:00,448] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-10-19 14:38:00.451 | [2025-10-19 19:38:00,450] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-10-19 14:38:00.451 | [2025-10-19 19:38:00,450] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-10-19 14:38:00.452 | [2025-10-19 19:38:00,451] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
2025-10-19 14:38:00.453 | [2025-10-19 19:38:00,453] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
2025-10-19 14:38:00.454 | [2025-10-19 19:38:00,454] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
2025-10-19 14:38:00.454 | [2025-10-19 19:38:00,454] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
2025-10-19 14:38:00.455 | [2025-10-19 19:38:00,454] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 14:38:00.457 | [2025-10-19 19:38:00,457] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 14:38:00.457 | [2025-10-19 19:38:00,457] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 14:38:00.458 | [2025-10-19 19:38:00,457] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 14:38:00.459 | [2025-10-19 19:38:00,459] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 14:38:00.459 | [2025-10-19 19:38:00,459] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 14:38:00.460 | [2025-10-19 19:38:00,460] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 14:38:00.461 | [2025-10-19 19:38:00,461] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 14:38:00.461 | [2025-10-19 19:38:00,461] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 14:38:00.462 | [2025-10-19 19:38:00,462] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 14:38:00.463 | [2025-10-19 19:38:00,463] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 14:38:00.463 | [2025-10-19 19:38:00,463] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 14:38:00.476 | [2025-10-19 19:38:00,475] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
2025-10-19 14:38:00.477 | [2025-10-19 19:38:00,477] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.BrokerToControllerRequestThread)
2025-10-19 14:38:00.478 | [2025-10-19 19:38:00,477] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.BrokerToControllerRequestThread)
2025-10-19 14:38:00.478 | [2025-10-19 19:38:00,477] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
2025-10-19 14:38:00.481 | [2025-10-19 19:38:00,481] INFO Broker to controller channel manager for alter-partition shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
2025-10-19 14:38:00.481 | [2025-10-19 19:38:00,481] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.BrokerToControllerRequestThread)
2025-10-19 14:38:00.482 | [2025-10-19 19:38:00,481] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Stopped (kafka.server.BrokerToControllerRequestThread)
2025-10-19 14:38:00.482 | [2025-10-19 19:38:00,481] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
2025-10-19 14:38:00.483 | [2025-10-19 19:38:00,483] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
2025-10-19 14:38:00.484 | [2025-10-19 19:38:00,483] INFO Shutting down. (kafka.log.LogManager)
2025-10-19 14:38:00.485 | [2025-10-19 19:38:00,485] INFO Shutting down the log cleaner. (kafka.log.LogCleaner)
2025-10-19 14:38:00.486 | [2025-10-19 19:38:00,486] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
2025-10-19 14:38:00.487 | [2025-10-19 19:38:00,486] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
2025-10-19 14:38:00.487 | [2025-10-19 19:38:00,486] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
2025-10-19 14:38:00.514 | [2025-10-19 19:38:00,513] INFO [ProducerStateManager partition=mesa-ya.sections.created-0]Wrote producer snapshot at offset 1 with 0 producer ids in 6 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
2025-10-19 14:38:00.647 | [2025-10-19 19:38:00,646] INFO [ProducerStateManager partition=__consumer_offsets-19]Wrote producer snapshot at offset 6 with 0 producer ids in 5 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
2025-10-19 14:38:00.918 | [2025-10-19 19:38:00,918] INFO [ProducerStateManager partition=mesa-ya.restaurants.created-0]Wrote producer snapshot at offset 3 with 0 producer ids in 6 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
2025-10-19 14:38:01.187 | [2025-10-19 19:38:01,187] INFO Shutdown complete. (kafka.log.LogManager)
2025-10-19 14:38:01.188 | [2025-10-19 19:38:01,187] INFO [ControllerEventThread controllerId=1] Shutting down (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-10-19 14:38:01.188 | [2025-10-19 19:38:01,188] INFO [ControllerEventThread controllerId=1] Shutdown completed (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-10-19 14:38:01.189 | [2025-10-19 19:38:01,188] INFO [ControllerEventThread controllerId=1] Stopped (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-10-19 14:38:01.190 | [2025-10-19 19:38:01,189] DEBUG [Controller id=1] Resigning (kafka.controller.KafkaController)
2025-10-19 14:38:01.192 | [2025-10-19 19:38:01,191] DEBUG [Controller id=1] Unregister BrokerModifications handler for Set(1) (kafka.controller.KafkaController)
2025-10-19 14:38:01.194 | [2025-10-19 19:38:01,194] INFO [PartitionStateMachine controllerId=1] Stopped partition state machine (kafka.controller.ZkPartitionStateMachine)
2025-10-19 14:38:01.195 | [2025-10-19 19:38:01,195] INFO [ReplicaStateMachine controllerId=1] Stopped replica state machine (kafka.controller.ZkReplicaStateMachine)
2025-10-19 14:38:01.196 | [2025-10-19 19:38:01,196] INFO [RequestSendThread controllerId=1] Shutting down (kafka.controller.RequestSendThread)
2025-10-19 14:38:01.196 | [2025-10-19 19:38:01,196] INFO [RequestSendThread controllerId=1] Shutdown completed (kafka.controller.RequestSendThread)
2025-10-19 14:38:01.197 | [2025-10-19 19:38:01,196] INFO [RequestSendThread controllerId=1] Stopped (kafka.controller.RequestSendThread)
2025-10-19 14:38:01.199 | [2025-10-19 19:38:01,199] INFO [Controller id=1] Resigned (kafka.controller.KafkaController)
2025-10-19 14:38:01.200 | [2025-10-19 19:38:01,200] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-10-19 14:38:01.201 | [2025-10-19 19:38:01,200] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-10-19 14:38:01.201 | [2025-10-19 19:38:01,200] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-10-19 14:38:01.202 | [2025-10-19 19:38:01,201] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
2025-10-19 14:38:01.318 | [2025-10-19 19:38:01,317] INFO Session: 0x10000268ea80001 closed (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:38:01.318 | [2025-10-19 19:38:01,317] INFO EventThread shut down for session: 0x10000268ea80001 (org.apache.zookeeper.ClientCnxn)
2025-10-19 14:38:01.320 | [2025-10-19 19:38:01,319] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
2025-10-19 14:38:01.321 | [2025-10-19 19:38:01,320] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 14:38:01.323 | [2025-10-19 19:38:01,323] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 14:38:01.323 | [2025-10-19 19:38:01,323] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 14:38:01.324 | [2025-10-19 19:38:01,323] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 14:38:01.324 | [2025-10-19 19:38:01,324] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 14:38:01.324 | [2025-10-19 19:38:01,324] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 14:38:01.325 | [2025-10-19 19:38:01,324] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 14:38:01.325 | [2025-10-19 19:38:01,325] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 14:38:01.325 | [2025-10-19 19:38:01,325] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 14:38:01.326 | [2025-10-19 19:38:01,325] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 14:38:01.326 | [2025-10-19 19:38:01,325] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 14:38:01.326 | [2025-10-19 19:38:01,326] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 14:38:01.327 | [2025-10-19 19:38:01,327] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
2025-10-19 14:38:01.354 | [2025-10-19 19:38:01,353] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
2025-10-19 14:38:01.355 | [2025-10-19 19:38:01,354] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
2025-10-19 14:38:01.355 | [2025-10-19 19:38:01,354] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
2025-10-19 14:38:01.355 | [2025-10-19 19:38:01,355] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
2025-10-19 14:38:01.356 | [2025-10-19 19:38:01,355] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
2025-10-19 14:38:01.357 | [2025-10-19 19:38:01,357] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
2025-10-19 14:38:01.357 | [2025-10-19 19:38:01,357] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
2025-10-19 14:45:07.348 | ===> User
2025-10-19 14:45:07.350 | uid=1000(appuser) gid=1000(appuser) groups=1000(appuser)
2025-10-19 14:45:07.351 | ===> Configuring ...
2025-10-19 14:45:07.354 | Running in Zookeeper mode...
2025-10-19 14:45:08.936 | ===> Running preflight checks ... 
2025-10-19 14:45:08.940 | ===> Check if /var/lib/kafka/data is writable ...
2025-10-19 14:45:09.340 | ===> Check if Zookeeper is healthy ...
2025-10-19 14:45:10.046 | [2025-10-19 19:45:10,045] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:10.046 | [2025-10-19 19:45:10,046] INFO Client environment:host.name=2ae4b23f74a4 (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:10.046 | [2025-10-19 19:45:10,046] INFO Client environment:java.version=11.0.20 (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:10.046 | [2025-10-19 19:45:10,046] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:10.046 | [2025-10-19 19:45:10,046] INFO Client environment:java.home=/usr/lib/jvm/java-11-zulu-openjdk-ca (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:10.046 | [2025-10-19 19:45:10,046] INFO Client environment:java.class.path=/usr/share/java/cp-base-new/minimal-json-0.9.5.jar:/usr/share/java/cp-base-new/kafka-clients-7.5.0-ccs.jar:/usr/share/java/cp-base-new/slf4j-api-1.7.36.jar:/usr/share/java/cp-base-new/jmx_prometheus_javaagent-0.18.0.jar:/usr/share/java/cp-base-new/jackson-annotations-2.14.2.jar:/usr/share/java/cp-base-new/scala-collection-compat_2.13-2.10.0.jar:/usr/share/java/cp-base-new/gson-2.9.0.jar:/usr/share/java/cp-base-new/kafka-server-common-7.5.0-ccs.jar:/usr/share/java/cp-base-new/jose4j-0.9.3.jar:/usr/share/java/cp-base-new/scala-reflect-2.13.10.jar:/usr/share/java/cp-base-new/zstd-jni-1.5.5-1.jar:/usr/share/java/cp-base-new/jackson-datatype-jdk8-2.14.2.jar:/usr/share/java/cp-base-new/kafka-storage-7.5.0-ccs.jar:/usr/share/java/cp-base-new/reload4j-1.2.19.jar:/usr/share/java/cp-base-new/kafka-raft-7.5.0-ccs.jar:/usr/share/java/cp-base-new/logredactor-1.0.12.jar:/usr/share/java/cp-base-new/jackson-module-scala_2.13-2.14.2.jar:/usr/share/java/cp-base-new/paranamer-2.8.jar:/usr/share/java/cp-base-new/utility-belt-7.5.0.jar:/usr/share/java/cp-base-new/snakeyaml-2.0.jar:/usr/share/java/cp-base-new/metrics-core-2.2.0.jar:/usr/share/java/cp-base-new/metrics-core-4.1.12.1.jar:/usr/share/java/cp-base-new/kafka-tools-api-7.5.0-ccs.jar:/usr/share/java/cp-base-new/logredactor-metrics-1.0.12.jar:/usr/share/java/cp-base-new/scala-logging_2.13-3.9.4.jar:/usr/share/java/cp-base-new/jolokia-core-1.7.1.jar:/usr/share/java/cp-base-new/kafka-metadata-7.5.0-ccs.jar:/usr/share/java/cp-base-new/audience-annotations-0.5.0.jar:/usr/share/java/cp-base-new/argparse4j-0.7.0.jar:/usr/share/java/cp-base-new/kafka-storage-api-7.5.0-ccs.jar:/usr/share/java/cp-base-new/jopt-simple-5.0.4.jar:/usr/share/java/cp-base-new/jackson-dataformat-csv-2.14.2.jar:/usr/share/java/cp-base-new/jackson-core-2.14.2.jar:/usr/share/java/cp-base-new/snappy-java-1.1.10.1.jar:/usr/share/java/cp-base-new/scala-java8-compat_2.13-1.0.2.jar:/usr/share/java/cp-base-new/disk-usage-agent-7.5.0.jar:/usr/share/java/cp-base-new/commons-cli-1.4.jar:/usr/share/java/cp-base-new/common-utils-7.5.0.jar:/usr/share/java/cp-base-new/jolokia-jvm-1.7.1.jar:/usr/share/java/cp-base-new/lz4-java-1.8.0.jar:/usr/share/java/cp-base-new/json-simple-1.1.1.jar:/usr/share/java/cp-base-new/zookeeper-3.6.3.jar:/usr/share/java/cp-base-new/kafka_2.13-7.5.0-ccs.jar:/usr/share/java/cp-base-new/jackson-databind-2.14.2.jar:/usr/share/java/cp-base-new/kafka-group-coordinator-7.5.0-ccs.jar:/usr/share/java/cp-base-new/slf4j-reload4j-1.7.36.jar:/usr/share/java/cp-base-new/zookeeper-jute-3.6.3.jar:/usr/share/java/cp-base-new/scala-library-2.13.10.jar:/usr/share/java/cp-base-new/re2j-1.6.jar:/usr/share/java/cp-base-new/jackson-dataformat-yaml-2.14.2.jar (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:10.046 | [2025-10-19 19:45:10,046] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:10.046 | [2025-10-19 19:45:10,046] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:10.046 | [2025-10-19 19:45:10,046] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:10.046 | [2025-10-19 19:45:10,046] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:10.046 | [2025-10-19 19:45:10,046] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:10.046 | [2025-10-19 19:45:10,046] INFO Client environment:os.version=6.6.87.1-microsoft-standard-WSL2 (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:10.046 | [2025-10-19 19:45:10,046] INFO Client environment:user.name=appuser (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:10.046 | [2025-10-19 19:45:10,046] INFO Client environment:user.home=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:10.046 | [2025-10-19 19:45:10,046] INFO Client environment:user.dir=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:10.046 | [2025-10-19 19:45:10,046] INFO Client environment:os.memory.free=112MB (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:10.046 | [2025-10-19 19:45:10,046] INFO Client environment:os.memory.max=1948MB (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:10.046 | [2025-10-19 19:45:10,046] INFO Client environment:os.memory.total=122MB (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:10.051 | [2025-10-19 19:45:10,051] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=40000 watcher=io.confluent.admin.utils.ZookeeperConnectionWatcher@221af3c0 (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:10.057 | [2025-10-19 19:45:10,056] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
2025-10-19 14:45:10.064 | [2025-10-19 19:45:10,063] INFO jute.maxbuffer value is 1048575 Bytes (org.apache.zookeeper.ClientCnxnSocket)
2025-10-19 14:45:10.074 | [2025-10-19 19:45:10,073] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
2025-10-19 14:45:10.103 | [2025-10-19 19:45:10,102] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. (org.apache.zookeeper.ClientCnxn)
2025-10-19 14:45:10.104 | [2025-10-19 19:45:10,103] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-10-19 14:45:10.114 | [2025-10-19 19:45:10,114] INFO Socket connection established, initiating session, client: /172.18.0.3:58456, server: zookeeper/172.18.0.2:2181 (org.apache.zookeeper.ClientCnxn)
2025-10-19 14:45:10.145 | [2025-10-19 19:45:10,145] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, session id = 0x1000099de360000, negotiated timeout = 40000 (org.apache.zookeeper.ClientCnxn)
2025-10-19 14:45:10.168 | [2025-10-19 19:45:10,165] WARN An exception was thrown while closing send thread for session 0x1000099de360000. (org.apache.zookeeper.ClientCnxn)
2025-10-19 14:45:10.168 | EndOfStreamException: Unable to read additional data from server sessionid 0x1000099de360000, likely server has closed socket
2025-10-19 14:45:10.168 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
2025-10-19 14:45:10.168 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
2025-10-19 14:45:10.168 | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-10-19 14:45:10.276 | [2025-10-19 19:45:10,275] INFO Session: 0x1000099de360000 closed (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:10.276 | [2025-10-19 19:45:10,275] INFO EventThread shut down for session: 0x1000099de360000 (org.apache.zookeeper.ClientCnxn)
2025-10-19 14:45:10.287 | Using log4j config /etc/kafka/log4j.properties
2025-10-19 14:45:10.363 | ===> Launching ... 
2025-10-19 14:45:10.371 | ===> Launching kafka ... 
2025-10-19 14:45:10.922 | [2025-10-19 19:45:10,922] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
2025-10-19 14:45:11.283 | [2025-10-19 19:45:11,282] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
2025-10-19 14:45:11.371 | [2025-10-19 19:45:11,370] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
2025-10-19 14:45:11.372 | [2025-10-19 19:45:11,372] INFO starting (kafka.server.KafkaServer)
2025-10-19 14:45:11.373 | [2025-10-19 19:45:11,372] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
2025-10-19 14:45:11.391 | [2025-10-19 19:45:11,391] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
2025-10-19 14:45:11.398 | [2025-10-19 19:45:11,397] INFO Client environment:zookeeper.version=3.6.4--d65253dcf68e9097c6e95a126463fd5fdeb4521c, built on 12/18/2022 18:10 GMT (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:11.398 | [2025-10-19 19:45:11,397] INFO Client environment:host.name=2ae4b23f74a4 (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:11.398 | [2025-10-19 19:45:11,397] INFO Client environment:java.version=11.0.20 (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:11.398 | [2025-10-19 19:45:11,397] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:11.398 | [2025-10-19 19:45:11,397] INFO Client environment:java.home=/usr/lib/jvm/java-11-zulu-openjdk-ca (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:11.398 | [2025-10-19 19:45:11,398] INFO Client environment:java.class.path=/usr/bin/../share/java/kafka/zookeeper-jute-3.6.4.jar:/usr/bin/../share/java/kafka/jackson-datatype-jdk8-2.13.5.jar:/usr/bin/../share/java/kafka/jakarta.inject-2.6.1.jar:/usr/bin/../share/java/kafka/netty-transport-native-epoll-4.1.96.Final.jar:/usr/bin/../share/java/kafka/kafka-clients-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jline-3.22.0.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.36.jar:/usr/bin/../share/java/kafka/reflections-0.9.12.jar:/usr/bin/../share/java/kafka/scala-collection-compat_2.13-2.10.0.jar:/usr/bin/../share/java/kafka/javassist-3.29.2-GA.jar:/usr/bin/../share/java/kafka/connect-runtime-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jakarta.annotation-api-1.3.5.jar:/usr/bin/../share/java/kafka/jackson-databind-2.13.5.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/kafka-streams-scala_2.13-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/javax.activation-api-1.2.0.jar:/usr/bin/../share/java/kafka/rocksdbjni-7.1.2.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/usr/bin/../share/java/kafka/kafka-server-common-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jose4j-0.9.3.jar:/usr/bin/../share/java/kafka/scala-reflect-2.13.10.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.13.5.jar:/usr/bin/../share/java/kafka/zstd-jni-1.5.5-1.jar:/usr/bin/../share/java/kafka/kafka-storage-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jetty-security-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.39.1.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/kafka-raft-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/netty-transport-native-unix-common-4.1.96.Final.jar:/usr/bin/../share/java/kafka/jersey-server-2.39.1.jar:/usr/bin/../share/java/kafka/paranamer-2.8.jar:/usr/bin/../share/java/kafka/jersey-common-2.39.1.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/netty-transport-4.1.96.Final.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/metrics-core-4.1.12.1.jar:/usr/bin/../share/java/kafka/netty-buffer-4.1.96.Final.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.13.5.jar:/usr/bin/../share/java/kafka/netty-resolver-4.1.96.Final.jar:/usr/bin/../share/java/kafka/kafka-tools-api-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jaxb-api-2.3.1.jar:/usr/bin/../share/java/kafka/jetty-util-ajax-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/scala-logging_2.13-3.9.4.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.6.1.jar:/usr/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/usr/bin/../share/java/kafka/jakarta.xml.bind-api-2.3.3.jar:/usr/bin/../share/java/kafka/kafka-metadata-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/plexus-utils-3.3.0.jar:/usr/bin/../share/java/kafka/jakarta.activation-api-1.2.2.jar:/usr/bin/../share/java/kafka/argparse4j-0.7.0.jar:/usr/bin/../share/java/kafka/hk2-utils-2.6.1.jar:/usr/bin/../share/java/kafka/connect-api-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/connect-mirror-client-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.3.jar:/usr/bin/../share/java/kafka/javax.annotation-api-1.3.2.jar:/usr/bin/../share/java/kafka/jersey-hk2-2.39.1.jar:/usr/bin/../share/java/kafka/kafka-storage-api-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jetty-http-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/trogdor-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/maven-artifact-3.8.4.jar:/usr/bin/../share/java/kafka/connect-json-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/scala-java8-compat_2.13-1.0.2.jar:/usr/bin/../share/java/kafka/jetty-server-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/swagger-annotations-2.2.8.jar:/usr/bin/../share/java/kafka/jetty-util-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/commons-cli-1.4.jar:/usr/bin/../share/java/kafka/jetty-io-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/activation-1.1.1.jar:/usr/bin/../share/java/kafka/lz4-java-1.8.0.jar:/usr/bin/../share/java/kafka/kafka-shell-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/netty-common-4.1.96.Final.jar:/usr/bin/../share/java/kafka/jetty-client-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/jackson-module-scala_2.13-2.13.5.jar:/usr/bin/../share/java/kafka/connect-transforms-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jackson-core-2.13.5.jar:/usr/bin/../share/java/kafka/kafka_2.13-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/netty-codec-4.1.96.Final.jar:/usr/bin/../share/java/kafka/zookeeper-3.6.4.jar:/usr/bin/../share/java/kafka/kafka-streams-test-utils-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/hk2-api-2.6.1.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.39.1.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.4.51.v20230217.jar:/usr/bin/../share/java/kafka/reload4j-1.2.25.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.10.0.jar:/usr/bin/../share/java/kafka/netty-transport-classes-epoll-4.1.96.Final.jar:/usr/bin/../share/java/kafka/connect-mirror-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/kafka-streams-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/kafka-group-coordinator-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/connect-basic-auth-extension-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/jersey-client-2.39.1.jar:/usr/bin/../share/java/kafka/kafka-tools-7.5.0-ccs.jar:/usr/bin/../share/java/kafka/slf4j-reload4j-1.7.36.jar:/usr/bin/../share/java/kafka/jackson-dataformat-csv-2.13.5.jar:/usr/bin/../share/java/kafka/scala-library-2.13.10.jar:/usr/bin/../share/java/kafka/netty-handler-4.1.96.Final.jar:/usr/bin/../share/java/kafka/jakarta.validation-api-2.0.2.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.13.5.jar:/usr/bin/../share/java/kafka/audience-annotations-0.13.0.jar:/usr/bin/../share/java/kafka/hk2-locator-2.6.1.jar:/usr/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.6.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.13.5.jar:/usr/bin/../share/java/confluent-telemetry/* (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:11.398 | [2025-10-19 19:45:11,398] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:11.398 | [2025-10-19 19:45:11,398] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:11.398 | [2025-10-19 19:45:11,398] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:11.398 | [2025-10-19 19:45:11,398] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:11.398 | [2025-10-19 19:45:11,398] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:11.398 | [2025-10-19 19:45:11,398] INFO Client environment:os.version=6.6.87.1-microsoft-standard-WSL2 (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:11.398 | [2025-10-19 19:45:11,398] INFO Client environment:user.name=appuser (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:11.398 | [2025-10-19 19:45:11,398] INFO Client environment:user.home=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:11.398 | [2025-10-19 19:45:11,398] INFO Client environment:user.dir=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:11.398 | [2025-10-19 19:45:11,398] INFO Client environment:os.memory.free=1009MB (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:11.398 | [2025-10-19 19:45:11,398] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:11.398 | [2025-10-19 19:45:11,398] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:11.400 | [2025-10-19 19:45:11,400] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@13d73fa (org.apache.zookeeper.ZooKeeper)
2025-10-19 14:45:11.405 | [2025-10-19 19:45:11,404] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
2025-10-19 14:45:11.414 | [2025-10-19 19:45:11,413] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
2025-10-19 14:45:11.416 | [2025-10-19 19:45:11,416] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
2025-10-19 14:45:11.422 | [2025-10-19 19:45:11,421] INFO Opening socket connection to server zookeeper/172.18.0.2:2181. (org.apache.zookeeper.ClientCnxn)
2025-10-19 14:45:11.427 | [2025-10-19 19:45:11,427] INFO Socket connection established, initiating session, client: /172.18.0.3:58468, server: zookeeper/172.18.0.2:2181 (org.apache.zookeeper.ClientCnxn)
2025-10-19 14:45:11.440 | [2025-10-19 19:45:11,440] INFO Session establishment complete on server zookeeper/172.18.0.2:2181, session id = 0x1000099de360001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
2025-10-19 14:45:11.443 | [2025-10-19 19:45:11,443] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
2025-10-19 14:45:11.821 | [2025-10-19 19:45:11,820] INFO Cluster ID = DgiegCMhTNSyWQSymt96xQ (kafka.server.KafkaServer)
2025-10-19 14:45:11.877 | [2025-10-19 19:45:11,877] INFO KafkaConfig values: 
2025-10-19 14:45:11.877 | 	advertised.listeners = PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
2025-10-19 14:45:11.877 | 	alter.config.policy.class.name = null
2025-10-19 14:45:11.877 | 	alter.log.dirs.replication.quota.window.num = 11
2025-10-19 14:45:11.877 | 	alter.log.dirs.replication.quota.window.size.seconds = 1
2025-10-19 14:45:11.877 | 	authorizer.class.name = 
2025-10-19 14:45:11.877 | 	auto.create.topics.enable = true
2025-10-19 14:45:11.877 | 	auto.include.jmx.reporter = true
2025-10-19 14:45:11.877 | 	auto.leader.rebalance.enable = true
2025-10-19 14:45:11.877 | 	background.threads = 10
2025-10-19 14:45:11.877 | 	broker.heartbeat.interval.ms = 2000
2025-10-19 14:45:11.877 | 	broker.id = 1
2025-10-19 14:45:11.877 | 	broker.id.generation.enable = true
2025-10-19 14:45:11.877 | 	broker.rack = null
2025-10-19 14:45:11.877 | 	broker.session.timeout.ms = 9000
2025-10-19 14:45:11.877 | 	client.quota.callback.class = null
2025-10-19 14:45:11.877 | 	compression.type = producer
2025-10-19 14:45:11.877 | 	connection.failed.authentication.delay.ms = 100
2025-10-19 14:45:11.877 | 	connections.max.idle.ms = 600000
2025-10-19 14:45:11.877 | 	connections.max.reauth.ms = 0
2025-10-19 14:45:11.877 | 	control.plane.listener.name = null
2025-10-19 14:45:11.877 | 	controlled.shutdown.enable = true
2025-10-19 14:45:11.877 | 	controlled.shutdown.max.retries = 3
2025-10-19 14:45:11.877 | 	controlled.shutdown.retry.backoff.ms = 5000
2025-10-19 14:45:11.877 | 	controller.listener.names = null
2025-10-19 14:45:11.877 | 	controller.quorum.append.linger.ms = 25
2025-10-19 14:45:11.877 | 	controller.quorum.election.backoff.max.ms = 1000
2025-10-19 14:45:11.877 | 	controller.quorum.election.timeout.ms = 1000
2025-10-19 14:45:11.877 | 	controller.quorum.fetch.timeout.ms = 2000
2025-10-19 14:45:11.877 | 	controller.quorum.request.timeout.ms = 2000
2025-10-19 14:45:11.877 | 	controller.quorum.retry.backoff.ms = 20
2025-10-19 14:45:11.877 | 	controller.quorum.voters = []
2025-10-19 14:45:11.877 | 	controller.quota.window.num = 11
2025-10-19 14:45:11.877 | 	controller.quota.window.size.seconds = 1
2025-10-19 14:45:11.877 | 	controller.socket.timeout.ms = 30000
2025-10-19 14:45:11.877 | 	create.topic.policy.class.name = null
2025-10-19 14:45:11.877 | 	default.replication.factor = 1
2025-10-19 14:45:11.877 | 	delegation.token.expiry.check.interval.ms = 3600000
2025-10-19 14:45:11.877 | 	delegation.token.expiry.time.ms = 86400000
2025-10-19 14:45:11.877 | 	delegation.token.master.key = null
2025-10-19 14:45:11.877 | 	delegation.token.max.lifetime.ms = 604800000
2025-10-19 14:45:11.877 | 	delegation.token.secret.key = null
2025-10-19 14:45:11.877 | 	delete.records.purgatory.purge.interval.requests = 1
2025-10-19 14:45:11.877 | 	delete.topic.enable = true
2025-10-19 14:45:11.877 | 	early.start.listeners = null
2025-10-19 14:45:11.877 | 	fetch.max.bytes = 57671680
2025-10-19 14:45:11.877 | 	fetch.purgatory.purge.interval.requests = 1000
2025-10-19 14:45:11.877 | 	group.consumer.assignors = []
2025-10-19 14:45:11.877 | 	group.consumer.heartbeat.interval.ms = 5000
2025-10-19 14:45:11.877 | 	group.consumer.max.heartbeat.interval.ms = 15000
2025-10-19 14:45:11.877 | 	group.consumer.max.session.timeout.ms = 60000
2025-10-19 14:45:11.877 | 	group.consumer.max.size = 2147483647
2025-10-19 14:45:11.877 | 	group.consumer.min.heartbeat.interval.ms = 5000
2025-10-19 14:45:11.877 | 	group.consumer.min.session.timeout.ms = 45000
2025-10-19 14:45:11.877 | 	group.consumer.session.timeout.ms = 45000
2025-10-19 14:45:11.877 | 	group.coordinator.new.enable = false
2025-10-19 14:45:11.877 | 	group.coordinator.threads = 1
2025-10-19 14:45:11.877 | 	group.initial.rebalance.delay.ms = 3000
2025-10-19 14:45:11.877 | 	group.max.session.timeout.ms = 1800000
2025-10-19 14:45:11.877 | 	group.max.size = 2147483647
2025-10-19 14:45:11.877 | 	group.min.session.timeout.ms = 6000
2025-10-19 14:45:11.877 | 	initial.broker.registration.timeout.ms = 60000
2025-10-19 14:45:11.877 | 	inter.broker.listener.name = PLAINTEXT_INTERNAL
2025-10-19 14:45:11.878 | 	inter.broker.protocol.version = 3.5-IV2
2025-10-19 14:45:11.878 | 	kafka.metrics.polling.interval.secs = 10
2025-10-19 14:45:11.878 | 	kafka.metrics.reporters = []
2025-10-19 14:45:11.878 | 	leader.imbalance.check.interval.seconds = 300
2025-10-19 14:45:11.878 | 	leader.imbalance.per.broker.percentage = 10
2025-10-19 14:45:11.878 | 	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
2025-10-19 14:45:11.878 | 	listeners = PLAINTEXT://0.0.0.0:9092,PLAINTEXT_INTERNAL://0.0.0.0:29092
2025-10-19 14:45:11.878 | 	log.cleaner.backoff.ms = 15000
2025-10-19 14:45:11.878 | 	log.cleaner.dedupe.buffer.size = 134217728
2025-10-19 14:45:11.878 | 	log.cleaner.delete.retention.ms = 86400000
2025-10-19 14:45:11.878 | 	log.cleaner.enable = true
2025-10-19 14:45:11.878 | 	log.cleaner.io.buffer.load.factor = 0.9
2025-10-19 14:45:11.878 | 	log.cleaner.io.buffer.size = 524288
2025-10-19 14:45:11.878 | 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
2025-10-19 14:45:11.878 | 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
2025-10-19 14:45:11.878 | 	log.cleaner.min.cleanable.ratio = 0.5
2025-10-19 14:45:11.878 | 	log.cleaner.min.compaction.lag.ms = 0
2025-10-19 14:45:11.878 | 	log.cleaner.threads = 1
2025-10-19 14:45:11.878 | 	log.cleanup.policy = [delete]
2025-10-19 14:45:11.878 | 	log.dir = /tmp/kafka-logs
2025-10-19 14:45:11.878 | 	log.dirs = /var/lib/kafka/data
2025-10-19 14:45:11.878 | 	log.flush.interval.messages = 9223372036854775807
2025-10-19 14:45:11.878 | 	log.flush.interval.ms = null
2025-10-19 14:45:11.878 | 	log.flush.offset.checkpoint.interval.ms = 60000
2025-10-19 14:45:11.878 | 	log.flush.scheduler.interval.ms = 9223372036854775807
2025-10-19 14:45:11.878 | 	log.flush.start.offset.checkpoint.interval.ms = 60000
2025-10-19 14:45:11.878 | 	log.index.interval.bytes = 4096
2025-10-19 14:45:11.878 | 	log.index.size.max.bytes = 10485760
2025-10-19 14:45:11.878 | 	log.message.downconversion.enable = true
2025-10-19 14:45:11.878 | 	log.message.format.version = 3.0-IV1
2025-10-19 14:45:11.878 | 	log.message.timestamp.difference.max.ms = 9223372036854775807
2025-10-19 14:45:11.878 | 	log.message.timestamp.type = CreateTime
2025-10-19 14:45:11.878 | 	log.preallocate = false
2025-10-19 14:45:11.878 | 	log.retention.bytes = -1
2025-10-19 14:45:11.878 | 	log.retention.check.interval.ms = 300000
2025-10-19 14:45:11.878 | 	log.retention.hours = 168
2025-10-19 14:45:11.878 | 	log.retention.minutes = null
2025-10-19 14:45:11.878 | 	log.retention.ms = null
2025-10-19 14:45:11.878 | 	log.roll.hours = 168
2025-10-19 14:45:11.878 | 	log.roll.jitter.hours = 0
2025-10-19 14:45:11.878 | 	log.roll.jitter.ms = null
2025-10-19 14:45:11.878 | 	log.roll.ms = null
2025-10-19 14:45:11.878 | 	log.segment.bytes = 1073741824
2025-10-19 14:45:11.878 | 	log.segment.delete.delay.ms = 60000
2025-10-19 14:45:11.878 | 	max.connection.creation.rate = 2147483647
2025-10-19 14:45:11.878 | 	max.connections = 2147483647
2025-10-19 14:45:11.878 | 	max.connections.per.ip = 2147483647
2025-10-19 14:45:11.878 | 	max.connections.per.ip.overrides = 
2025-10-19 14:45:11.878 | 	max.incremental.fetch.session.cache.slots = 1000
2025-10-19 14:45:11.878 | 	message.max.bytes = 1048588
2025-10-19 14:45:11.878 | 	metadata.log.dir = null
2025-10-19 14:45:11.878 | 	metadata.log.max.record.bytes.between.snapshots = 20971520
2025-10-19 14:45:11.878 | 	metadata.log.max.snapshot.interval.ms = 3600000
2025-10-19 14:45:11.878 | 	metadata.log.segment.bytes = 1073741824
2025-10-19 14:45:11.878 | 	metadata.log.segment.min.bytes = 8388608
2025-10-19 14:45:11.878 | 	metadata.log.segment.ms = 604800000
2025-10-19 14:45:11.878 | 	metadata.max.idle.interval.ms = 500
2025-10-19 14:45:11.878 | 	metadata.max.retention.bytes = 104857600
2025-10-19 14:45:11.878 | 	metadata.max.retention.ms = 604800000
2025-10-19 14:45:11.878 | 	metric.reporters = []
2025-10-19 14:45:11.878 | 	metrics.num.samples = 2
2025-10-19 14:45:11.878 | 	metrics.recording.level = INFO
2025-10-19 14:45:11.878 | 	metrics.sample.window.ms = 30000
2025-10-19 14:45:11.878 | 	min.insync.replicas = 1
2025-10-19 14:45:11.878 | 	node.id = 1
2025-10-19 14:45:11.878 | 	num.io.threads = 8
2025-10-19 14:45:11.878 | 	num.network.threads = 3
2025-10-19 14:45:11.878 | 	num.partitions = 1
2025-10-19 14:45:11.878 | 	num.recovery.threads.per.data.dir = 1
2025-10-19 14:45:11.878 | 	num.replica.alter.log.dirs.threads = null
2025-10-19 14:45:11.878 | 	num.replica.fetchers = 1
2025-10-19 14:45:11.878 | 	offset.metadata.max.bytes = 4096
2025-10-19 14:45:11.878 | 	offsets.commit.required.acks = -1
2025-10-19 14:45:11.878 | 	offsets.commit.timeout.ms = 5000
2025-10-19 14:45:11.878 | 	offsets.load.buffer.size = 5242880
2025-10-19 14:45:11.878 | 	offsets.retention.check.interval.ms = 600000
2025-10-19 14:45:11.878 | 	offsets.retention.minutes = 10080
2025-10-19 14:45:11.878 | 	offsets.topic.compression.codec = 0
2025-10-19 14:45:11.878 | 	offsets.topic.num.partitions = 50
2025-10-19 14:45:11.878 | 	offsets.topic.replication.factor = 1
2025-10-19 14:45:11.878 | 	offsets.topic.segment.bytes = 104857600
2025-10-19 14:45:11.878 | 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
2025-10-19 14:45:11.878 | 	password.encoder.iterations = 4096
2025-10-19 14:45:11.878 | 	password.encoder.key.length = 128
2025-10-19 14:45:11.878 | 	password.encoder.keyfactory.algorithm = null
2025-10-19 14:45:11.878 | 	password.encoder.old.secret = null
2025-10-19 14:45:11.878 | 	password.encoder.secret = null
2025-10-19 14:45:11.878 | 	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
2025-10-19 14:45:11.878 | 	process.roles = []
2025-10-19 14:45:11.878 | 	producer.id.expiration.check.interval.ms = 600000
2025-10-19 14:45:11.878 | 	producer.id.expiration.ms = 86400000
2025-10-19 14:45:11.878 | 	producer.purgatory.purge.interval.requests = 1000
2025-10-19 14:45:11.878 | 	queued.max.request.bytes = -1
2025-10-19 14:45:11.878 | 	queued.max.requests = 500
2025-10-19 14:45:11.878 | 	quota.window.num = 11
2025-10-19 14:45:11.878 | 	quota.window.size.seconds = 1
2025-10-19 14:45:11.878 | 	remote.log.index.file.cache.total.size.bytes = 1073741824
2025-10-19 14:45:11.878 | 	remote.log.manager.task.interval.ms = 30000
2025-10-19 14:45:11.878 | 	remote.log.manager.task.retry.backoff.max.ms = 30000
2025-10-19 14:45:11.878 | 	remote.log.manager.task.retry.backoff.ms = 500
2025-10-19 14:45:11.878 | 	remote.log.manager.task.retry.jitter = 0.2
2025-10-19 14:45:11.878 | 	remote.log.manager.thread.pool.size = 10
2025-10-19 14:45:11.878 | 	remote.log.metadata.manager.class.name = null
2025-10-19 14:45:11.878 | 	remote.log.metadata.manager.class.path = null
2025-10-19 14:45:11.878 | 	remote.log.metadata.manager.impl.prefix = null
2025-10-19 14:45:11.878 | 	remote.log.metadata.manager.listener.name = null
2025-10-19 14:45:11.878 | 	remote.log.reader.max.pending.tasks = 100
2025-10-19 14:45:11.878 | 	remote.log.reader.threads = 10
2025-10-19 14:45:11.878 | 	remote.log.storage.manager.class.name = null
2025-10-19 14:45:11.878 | 	remote.log.storage.manager.class.path = null
2025-10-19 14:45:11.878 | 	remote.log.storage.manager.impl.prefix = null
2025-10-19 14:45:11.878 | 	remote.log.storage.system.enable = false
2025-10-19 14:45:11.878 | 	replica.fetch.backoff.ms = 1000
2025-10-19 14:45:11.878 | 	replica.fetch.max.bytes = 1048576
2025-10-19 14:45:11.878 | 	replica.fetch.min.bytes = 1
2025-10-19 14:45:11.878 | 	replica.fetch.response.max.bytes = 10485760
2025-10-19 14:45:11.878 | 	replica.fetch.wait.max.ms = 500
2025-10-19 14:45:11.878 | 	replica.high.watermark.checkpoint.interval.ms = 5000
2025-10-19 14:45:11.878 | 	replica.lag.time.max.ms = 30000
2025-10-19 14:45:11.878 | 	replica.selector.class = null
2025-10-19 14:45:11.878 | 	replica.socket.receive.buffer.bytes = 65536
2025-10-19 14:45:11.878 | 	replica.socket.timeout.ms = 30000
2025-10-19 14:45:11.878 | 	replication.quota.window.num = 11
2025-10-19 14:45:11.878 | 	replication.quota.window.size.seconds = 1
2025-10-19 14:45:11.878 | 	request.timeout.ms = 30000
2025-10-19 14:45:11.878 | 	reserved.broker.max.id = 1000
2025-10-19 14:45:11.878 | 	sasl.client.callback.handler.class = null
2025-10-19 14:45:11.878 | 	sasl.enabled.mechanisms = [GSSAPI]
2025-10-19 14:45:11.878 | 	sasl.jaas.config = null
2025-10-19 14:45:11.878 | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
2025-10-19 14:45:11.878 | 	sasl.kerberos.min.time.before.relogin = 60000
2025-10-19 14:45:11.878 | 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
2025-10-19 14:45:11.878 | 	sasl.kerberos.service.name = null
2025-10-19 14:45:11.878 | 	sasl.kerberos.ticket.renew.jitter = 0.05
2025-10-19 14:45:11.878 | 	sasl.kerberos.ticket.renew.window.factor = 0.8
2025-10-19 14:45:11.878 | 	sasl.login.callback.handler.class = null
2025-10-19 14:45:11.878 | 	sasl.login.class = null
2025-10-19 14:45:11.878 | 	sasl.login.connect.timeout.ms = null
2025-10-19 14:45:11.878 | 	sasl.login.read.timeout.ms = null
2025-10-19 14:45:11.878 | 	sasl.login.refresh.buffer.seconds = 300
2025-10-19 14:45:11.878 | 	sasl.login.refresh.min.period.seconds = 60
2025-10-19 14:45:11.878 | 	sasl.login.refresh.window.factor = 0.8
2025-10-19 14:45:11.878 | 	sasl.login.refresh.window.jitter = 0.05
2025-10-19 14:45:11.878 | 	sasl.login.retry.backoff.max.ms = 10000
2025-10-19 14:45:11.878 | 	sasl.login.retry.backoff.ms = 100
2025-10-19 14:45:11.878 | 	sasl.mechanism.controller.protocol = GSSAPI
2025-10-19 14:45:11.878 | 	sasl.mechanism.inter.broker.protocol = GSSAPI
2025-10-19 14:45:11.878 | 	sasl.oauthbearer.clock.skew.seconds = 30
2025-10-19 14:45:11.878 | 	sasl.oauthbearer.expected.audience = null
2025-10-19 14:45:11.878 | 	sasl.oauthbearer.expected.issuer = null
2025-10-19 14:45:11.878 | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
2025-10-19 14:45:11.878 | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
2025-10-19 14:45:11.878 | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
2025-10-19 14:45:11.878 | 	sasl.oauthbearer.jwks.endpoint.url = null
2025-10-19 14:45:11.878 | 	sasl.oauthbearer.scope.claim.name = scope
2025-10-19 14:45:11.878 | 	sasl.oauthbearer.sub.claim.name = sub
2025-10-19 14:45:11.878 | 	sasl.oauthbearer.token.endpoint.url = null
2025-10-19 14:45:11.878 | 	sasl.server.callback.handler.class = null
2025-10-19 14:45:11.878 | 	sasl.server.max.receive.size = 524288
2025-10-19 14:45:11.878 | 	security.inter.broker.protocol = PLAINTEXT
2025-10-19 14:45:11.878 | 	security.providers = null
2025-10-19 14:45:11.878 | 	server.max.startup.time.ms = 9223372036854775807
2025-10-19 14:45:11.878 | 	socket.connection.setup.timeout.max.ms = 30000
2025-10-19 14:45:11.878 | 	socket.connection.setup.timeout.ms = 10000
2025-10-19 14:45:11.878 | 	socket.listen.backlog.size = 50
2025-10-19 14:45:11.878 | 	socket.receive.buffer.bytes = 102400
2025-10-19 14:45:11.878 | 	socket.request.max.bytes = 104857600
2025-10-19 14:45:11.878 | 	socket.send.buffer.bytes = 102400
2025-10-19 14:45:11.878 | 	ssl.cipher.suites = []
2025-10-19 14:45:11.878 | 	ssl.client.auth = none
2025-10-19 14:45:11.878 | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
2025-10-19 14:45:11.878 | 	ssl.endpoint.identification.algorithm = https
2025-10-19 14:45:11.878 | 	ssl.engine.factory.class = null
2025-10-19 14:45:11.878 | 	ssl.key.password = null
2025-10-19 14:45:11.878 | 	ssl.keymanager.algorithm = SunX509
2025-10-19 14:45:11.878 | 	ssl.keystore.certificate.chain = null
2025-10-19 14:45:11.878 | 	ssl.keystore.key = null
2025-10-19 14:45:11.878 | 	ssl.keystore.location = null
2025-10-19 14:45:11.878 | 	ssl.keystore.password = null
2025-10-19 14:45:11.878 | 	ssl.keystore.type = JKS
2025-10-19 14:45:11.878 | 	ssl.principal.mapping.rules = DEFAULT
2025-10-19 14:45:11.878 | 	ssl.protocol = TLSv1.3
2025-10-19 14:45:11.878 | 	ssl.provider = null
2025-10-19 14:45:11.878 | 	ssl.secure.random.implementation = null
2025-10-19 14:45:11.878 | 	ssl.trustmanager.algorithm = PKIX
2025-10-19 14:45:11.878 | 	ssl.truststore.certificates = null
2025-10-19 14:45:11.878 | 	ssl.truststore.location = null
2025-10-19 14:45:11.878 | 	ssl.truststore.password = null
2025-10-19 14:45:11.878 | 	ssl.truststore.type = JKS
2025-10-19 14:45:11.878 | 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
2025-10-19 14:45:11.878 | 	transaction.max.timeout.ms = 900000
2025-10-19 14:45:11.878 | 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
2025-10-19 14:45:11.878 | 	transaction.state.log.load.buffer.size = 5242880
2025-10-19 14:45:11.878 | 	transaction.state.log.min.isr = 1
2025-10-19 14:45:11.878 | 	transaction.state.log.num.partitions = 50
2025-10-19 14:45:11.878 | 	transaction.state.log.replication.factor = 1
2025-10-19 14:45:11.878 | 	transaction.state.log.segment.bytes = 104857600
2025-10-19 14:45:11.878 | 	transactional.id.expiration.ms = 604800000
2025-10-19 14:45:11.878 | 	unclean.leader.election.enable = false
2025-10-19 14:45:11.878 | 	unstable.api.versions.enable = false
2025-10-19 14:45:11.878 | 	zookeeper.clientCnxnSocket = null
2025-10-19 14:45:11.878 | 	zookeeper.connect = zookeeper:2181
2025-10-19 14:45:11.878 | 	zookeeper.connection.timeout.ms = null
2025-10-19 14:45:11.878 | 	zookeeper.max.in.flight.requests = 10
2025-10-19 14:45:11.878 | 	zookeeper.metadata.migration.enable = false
2025-10-19 14:45:11.878 | 	zookeeper.session.timeout.ms = 18000
2025-10-19 14:45:11.878 | 	zookeeper.set.acl = false
2025-10-19 14:45:11.878 | 	zookeeper.ssl.cipher.suites = null
2025-10-19 14:45:11.878 | 	zookeeper.ssl.client.enable = false
2025-10-19 14:45:11.878 | 	zookeeper.ssl.crl.enable = false
2025-10-19 14:45:11.878 | 	zookeeper.ssl.enabled.protocols = null
2025-10-19 14:45:11.878 | 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
2025-10-19 14:45:11.878 | 	zookeeper.ssl.keystore.location = null
2025-10-19 14:45:11.878 | 	zookeeper.ssl.keystore.password = null
2025-10-19 14:45:11.878 | 	zookeeper.ssl.keystore.type = null
2025-10-19 14:45:11.878 | 	zookeeper.ssl.ocsp.enable = false
2025-10-19 14:45:11.878 | 	zookeeper.ssl.protocol = TLSv1.2
2025-10-19 14:45:11.878 | 	zookeeper.ssl.truststore.location = null
2025-10-19 14:45:11.878 | 	zookeeper.ssl.truststore.password = null
2025-10-19 14:45:11.878 | 	zookeeper.ssl.truststore.type = null
2025-10-19 14:45:11.878 |  (kafka.server.KafkaConfig)
2025-10-19 14:45:11.914 | [2025-10-19 19:45:11,913] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 14:45:11.916 | [2025-10-19 19:45:11,914] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 14:45:11.916 | [2025-10-19 19:45:11,916] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 14:45:11.919 | [2025-10-19 19:45:11,918] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-10-19 14:45:11.970 | [2025-10-19 19:45:11,970] INFO Loading logs from log dirs ArraySeq(/var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:11.986 | [2025-10-19 19:45:11,985] INFO Skipping recovery of 52 logs from /var/lib/kafka/data since clean shutdown file was found (kafka.log.LogManager)
2025-10-19 14:45:12.057 | [2025-10-19 19:45:12,057] INFO [LogLoader partition=__consumer_offsets-29, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.104 | [2025-10-19 19:45:12,103] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-29, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 111ms (1/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.120 | [2025-10-19 19:45:12,120] INFO [LogLoader partition=__consumer_offsets-49, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.123 | [2025-10-19 19:45:12,123] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-49, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (2/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.136 | [2025-10-19 19:45:12,135] INFO [LogLoader partition=__consumer_offsets-28, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.139 | [2025-10-19 19:45:12,139] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-28, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (3/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.154 | [2025-10-19 19:45:12,154] INFO [LogLoader partition=__consumer_offsets-5, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.157 | [2025-10-19 19:45:12,156] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-5, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (4/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.171 | [2025-10-19 19:45:12,170] INFO [LogLoader partition=__consumer_offsets-10, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.174 | [2025-10-19 19:45:12,174] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-10, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (5/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.190 | [2025-10-19 19:45:12,190] INFO [LogLoader partition=__consumer_offsets-14, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.195 | [2025-10-19 19:45:12,195] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-14, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 21ms (6/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.216 | [2025-10-19 19:45:12,216] INFO Deleted producer state snapshot /var/lib/kafka/data/__consumer_offsets-19/00000000000000000005.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
2025-10-19 14:45:12.217 | [2025-10-19 19:45:12,216] INFO [LogLoader partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Loading producer state till offset 6 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.217 | [2025-10-19 19:45:12,216] INFO [LogLoader partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 6 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.217 | [2025-10-19 19:45:12,217] INFO [ProducerStateManager partition=__consumer_offsets-19]Loading producer state from snapshot file 'SnapshotFile(offset=6, file=/var/lib/kafka/data/__consumer_offsets-19/00000000000000000006.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
2025-10-19 14:45:12.227 | [2025-10-19 19:45:12,227] INFO [LogLoader partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Producer state recovery took 10ms for snapshot load and 0ms for segment recovery from offset 6 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.231 | [2025-10-19 19:45:12,231] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-19, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=6) with 1 segments in 35ms (7/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.245 | [2025-10-19 19:45:12,244] INFO [LogLoader partition=__consumer_offsets-8, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.248 | [2025-10-19 19:45:12,248] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-8, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (8/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.267 | [2025-10-19 19:45:12,267] INFO [LogLoader partition=__consumer_offsets-17, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.274 | [2025-10-19 19:45:12,274] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-17, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 25ms (9/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.292 | [2025-10-19 19:45:12,291] INFO [LogLoader partition=__consumer_offsets-35, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.296 | [2025-10-19 19:45:12,296] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-35, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 21ms (10/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.315 | [2025-10-19 19:45:12,315] INFO [LogLoader partition=__consumer_offsets-31, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.319 | [2025-10-19 19:45:12,319] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-31, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 23ms (11/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.336 | [2025-10-19 19:45:12,336] INFO [LogLoader partition=__consumer_offsets-6, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.339 | [2025-10-19 19:45:12,339] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-6, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (12/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.353 | [2025-10-19 19:45:12,352] INFO [LogLoader partition=__consumer_offsets-32, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.355 | [2025-10-19 19:45:12,354] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-32, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (13/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.368 | [2025-10-19 19:45:12,367] INFO [LogLoader partition=__consumer_offsets-3, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.370 | [2025-10-19 19:45:12,369] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-3, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (14/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.383 | [2025-10-19 19:45:12,383] INFO [LogLoader partition=__consumer_offsets-30, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.385 | [2025-10-19 19:45:12,384] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-30, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (15/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.399 | [2025-10-19 19:45:12,399] INFO [LogLoader partition=__consumer_offsets-37, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.401 | [2025-10-19 19:45:12,400] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-37, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (16/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.412 | [2025-10-19 19:45:12,412] INFO [LogLoader partition=__consumer_offsets-41, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.414 | [2025-10-19 19:45:12,413] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-41, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (17/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.425 | [2025-10-19 19:45:12,424] INFO [LogLoader partition=__consumer_offsets-26, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.434 | [2025-10-19 19:45:12,434] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-26, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 21ms (18/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.444 | [2025-10-19 19:45:12,444] INFO [LogLoader partition=__consumer_offsets-4, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.446 | [2025-10-19 19:45:12,445] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-4, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (19/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.456 | [2025-10-19 19:45:12,455] INFO [LogLoader partition=__consumer_offsets-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.457 | [2025-10-19 19:45:12,457] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-1, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (20/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.469 | [2025-10-19 19:45:12,468] INFO [LogLoader partition=__consumer_offsets-33, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.470 | [2025-10-19 19:45:12,470] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-33, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (21/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.481 | [2025-10-19 19:45:12,480] INFO [LogLoader partition=__consumer_offsets-25, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.482 | [2025-10-19 19:45:12,482] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-25, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (22/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.493 | [2025-10-19 19:45:12,492] INFO [LogLoader partition=__consumer_offsets-42, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.495 | [2025-10-19 19:45:12,494] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-42, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (23/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.508 | [2025-10-19 19:45:12,507] INFO [LogLoader partition=__consumer_offsets-2, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.509 | [2025-10-19 19:45:12,508] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-2, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (24/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.519 | [2025-10-19 19:45:12,518] INFO [LogLoader partition=__consumer_offsets-34, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.520 | [2025-10-19 19:45:12,520] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-34, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (25/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.531 | [2025-10-19 19:45:12,531] INFO [LogLoader partition=__consumer_offsets-36, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.532 | [2025-10-19 19:45:12,532] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-36, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (26/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.543 | [2025-10-19 19:45:12,542] INFO [LogLoader partition=__consumer_offsets-12, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.544 | [2025-10-19 19:45:12,544] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-12, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (27/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.554 | [2025-10-19 19:45:12,553] INFO [LogLoader partition=__consumer_offsets-20, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.555 | [2025-10-19 19:45:12,555] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-20, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (28/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.566 | [2025-10-19 19:45:12,565] INFO [LogLoader partition=__consumer_offsets-23, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.567 | [2025-10-19 19:45:12,567] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-23, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (29/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.579 | [2025-10-19 19:45:12,579] INFO [LogLoader partition=__consumer_offsets-13, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.581 | [2025-10-19 19:45:12,580] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-13, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (30/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.595 | [2025-10-19 19:45:12,594] INFO [LogLoader partition=__consumer_offsets-40, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.596 | [2025-10-19 19:45:12,595] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-40, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (31/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.610 | [2025-10-19 19:45:12,609] INFO [LogLoader partition=__consumer_offsets-43, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.613 | [2025-10-19 19:45:12,612] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-43, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (32/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.626 | [2025-10-19 19:45:12,625] INFO [LogLoader partition=__consumer_offsets-39, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.626 | [2025-10-19 19:45:12,626] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-39, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (33/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.637 | [2025-10-19 19:45:12,636] INFO [LogLoader partition=__consumer_offsets-46, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.638 | [2025-10-19 19:45:12,638] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-46, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (34/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.649 | [2025-10-19 19:45:12,649] INFO [LogLoader partition=__consumer_offsets-7, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.651 | [2025-10-19 19:45:12,651] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-7, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (35/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.664 | [2025-10-19 19:45:12,663] INFO [LogLoader partition=__consumer_offsets-38, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.665 | [2025-10-19 19:45:12,664] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-38, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (36/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.680 | [2025-10-19 19:45:12,679] INFO [LogLoader partition=__consumer_offsets-47, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.681 | [2025-10-19 19:45:12,680] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-47, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (37/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.699 | [2025-10-19 19:45:12,698] INFO [LogLoader partition=__consumer_offsets-11, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.701 | [2025-10-19 19:45:12,700] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-11, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (38/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.713 | [2025-10-19 19:45:12,713] INFO [LogLoader partition=__consumer_offsets-21, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.715 | [2025-10-19 19:45:12,714] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-21, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (39/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.725 | [2025-10-19 19:45:12,724] INFO [LogLoader partition=__consumer_offsets-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.726 | [2025-10-19 19:45:12,726] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-0, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (40/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.736 | [2025-10-19 19:45:12,735] INFO [LogLoader partition=__consumer_offsets-16, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.738 | [2025-10-19 19:45:12,737] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-16, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (41/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.750 | [2025-10-19 19:45:12,749] INFO [LogLoader partition=__consumer_offsets-22, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.752 | [2025-10-19 19:45:12,751] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-22, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (42/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.765 | [2025-10-19 19:45:12,764] INFO [LogLoader partition=__consumer_offsets-15, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.767 | [2025-10-19 19:45:12,766] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-15, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (43/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.780 | [2025-10-19 19:45:12,779] INFO [LogLoader partition=__consumer_offsets-18, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.782 | [2025-10-19 19:45:12,781] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-18, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (44/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.801 | [2025-10-19 19:45:12,800] INFO [LogLoader partition=__consumer_offsets-27, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.802 | [2025-10-19 19:45:12,802] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-27, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 21ms (45/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.817 | [2025-10-19 19:45:12,817] INFO [LogLoader partition=__consumer_offsets-24, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.818 | [2025-10-19 19:45:12,818] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-24, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (46/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.830 | [2025-10-19 19:45:12,830] INFO [LogLoader partition=__consumer_offsets-9, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.831 | [2025-10-19 19:45:12,831] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-9, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (47/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.842 | [2025-10-19 19:45:12,842] INFO [LogLoader partition=__consumer_offsets-45, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.843 | [2025-10-19 19:45:12,843] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-45, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (48/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.855 | [2025-10-19 19:45:12,854] INFO [LogLoader partition=__consumer_offsets-44, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.856 | [2025-10-19 19:45:12,856] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-44, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (49/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.869 | [2025-10-19 19:45:12,869] INFO Deleted producer state snapshot /var/lib/kafka/data/mesa-ya.restaurants.created-0/00000000000000000002.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
2025-10-19 14:45:12.869 | [2025-10-19 19:45:12,869] INFO [LogLoader partition=mesa-ya.restaurants.created-0, dir=/var/lib/kafka/data] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.869 | [2025-10-19 19:45:12,869] INFO [LogLoader partition=mesa-ya.restaurants.created-0, dir=/var/lib/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.869 | [2025-10-19 19:45:12,869] INFO [ProducerStateManager partition=mesa-ya.restaurants.created-0]Loading producer state from snapshot file 'SnapshotFile(offset=3, file=/var/lib/kafka/data/mesa-ya.restaurants.created-0/00000000000000000003.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
2025-10-19 14:45:12.870 | [2025-10-19 19:45:12,869] INFO [LogLoader partition=mesa-ya.restaurants.created-0, dir=/var/lib/kafka/data] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.871 | [2025-10-19 19:45:12,870] INFO Completed load of Log(dir=/var/lib/kafka/data/mesa-ya.restaurants.created-0, topicId=yWm6W48_TyqOOX8W2L0ItA, topic=mesa-ya.restaurants.created, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments in 14ms (50/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.884 | [2025-10-19 19:45:12,884] INFO [LogLoader partition=mesa-ya.sections.created-0, dir=/var/lib/kafka/data] Loading producer state till offset 1 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.884 | [2025-10-19 19:45:12,884] INFO [LogLoader partition=mesa-ya.sections.created-0, dir=/var/lib/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 1 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.884 | [2025-10-19 19:45:12,884] INFO [ProducerStateManager partition=mesa-ya.sections.created-0]Loading producer state from snapshot file 'SnapshotFile(offset=1, file=/var/lib/kafka/data/mesa-ya.sections.created-0/00000000000000000001.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
2025-10-19 14:45:12.885 | [2025-10-19 19:45:12,884] INFO [LogLoader partition=mesa-ya.sections.created-0, dir=/var/lib/kafka/data] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 1 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.886 | [2025-10-19 19:45:12,886] INFO Completed load of Log(dir=/var/lib/kafka/data/mesa-ya.sections.created-0, topicId=NwfGy3exRLOrYp5JWPfRlA, topic=mesa-ya.sections.created, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=1) with 1 segments in 15ms (51/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.899 | [2025-10-19 19:45:12,898] INFO [LogLoader partition=__consumer_offsets-48, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 14:45:12.900 | [2025-10-19 19:45:12,900] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-48, topicId=6ep0dUNwQAaqKr79SJ8ITA, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (52/52 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-10-19 14:45:12.906 | [2025-10-19 19:45:12,906] INFO Loaded 52 logs in 935ms (kafka.log.LogManager)
2025-10-19 14:45:12.911 | [2025-10-19 19:45:12,910] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
2025-10-19 14:45:12.913 | [2025-10-19 19:45:12,912] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
2025-10-19 14:45:12.926 | [2025-10-19 19:45:12,926] INFO Starting the log cleaner (kafka.log.LogCleaner)
2025-10-19 14:45:13.065 | [2025-10-19 19:45:13,064] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
2025-10-19 14:45:13.092 | [2025-10-19 19:45:13,091] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-10-19 14:45:13.123 | [2025-10-19 19:45:13,122] INFO [MetadataCache brokerId=1] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0). (kafka.server.metadata.ZkMetadataCache)
2025-10-19 14:45:13.146 | [2025-10-19 19:45:13,146] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
2025-10-19 14:45:13.473 | [2025-10-19 19:45:13,473] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
2025-10-19 14:45:13.504 | [2025-10-19 19:45:13,504] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
2025-10-19 14:45:13.505 | [2025-10-19 19:45:13,505] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
2025-10-19 14:45:13.515 | [2025-10-19 19:45:13,514] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT_INTERNAL) (kafka.network.SocketServer)
2025-10-19 14:45:13.524 | [2025-10-19 19:45:13,523] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
2025-10-19 14:45:13.547 | [2025-10-19 19:45:13,547] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 14:45:13.550 | [2025-10-19 19:45:13,549] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 14:45:13.551 | [2025-10-19 19:45:13,551] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 14:45:13.552 | [2025-10-19 19:45:13,552] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 14:45:13.567 | [2025-10-19 19:45:13,567] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-10-19 14:45:13.627 | [2025-10-19 19:45:13,627] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
2025-10-19 14:45:13.660 | [2025-10-19 19:45:13,660] INFO Stat of the created znode at /brokers/ids/1 is: 271,271,1760903113649,1760903113649,1,0,0,72058254896005121,270,0,271
2025-10-19 14:45:13.660 |  (kafka.zk.KafkaZkClient)
2025-10-19 14:45:13.660 | [2025-10-19 19:45:13,660] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092, czxid (broker epoch): 271 (kafka.zk.KafkaZkClient)
2025-10-19 14:45:13.746 | [2025-10-19 19:45:13,746] INFO [ControllerEventThread controllerId=1] Starting (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-10-19 14:45:13.758 | [2025-10-19 19:45:13,757] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 14:45:13.769 | [2025-10-19 19:45:13,768] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 14:45:13.770 | [2025-10-19 19:45:13,770] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 14:45:13.780 | [2025-10-19 19:45:13,780] INFO [Controller id=1] 1 successfully elected as the controller. Epoch incremented to 7 and epoch zk version is now 7 (kafka.controller.KafkaController)
2025-10-19 14:45:13.785 | [2025-10-19 19:45:13,784] INFO [Controller id=1] Registering handlers (kafka.controller.KafkaController)
2025-10-19 14:45:13.789 | [2025-10-19 19:45:13,788] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:13.790 | [2025-10-19 19:45:13,790] INFO [Controller id=1] Deleting log dir event notifications (kafka.controller.KafkaController)
2025-10-19 14:45:13.794 | [2025-10-19 19:45:13,794] INFO [Controller id=1] Deleting isr change notifications (kafka.controller.KafkaController)
2025-10-19 14:45:13.798 | [2025-10-19 19:45:13,797] INFO [Controller id=1] Initializing controller context (kafka.controller.KafkaController)
2025-10-19 14:45:13.809 | [2025-10-19 19:45:13,808] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:13.822 | [2025-10-19 19:45:13,821] INFO [Controller id=1] Initialized broker epochs cache: HashMap(1 -> 271) (kafka.controller.KafkaController)
2025-10-19 14:45:13.838 | [2025-10-19 19:45:13,838] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
2025-10-19 14:45:13.844 | [2025-10-19 19:45:13,844] INFO [TxnMarkerSenderThread-1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-10-19 14:45:13.844 | [2025-10-19 19:45:13,844] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
2025-10-19 14:45:13.850 | [2025-10-19 19:45:13,849] DEBUG [Controller id=1] Register BrokerModifications handler for Set(1) (kafka.controller.KafkaController)
2025-10-19 14:45:13.910 | [2025-10-19 19:45:13,910] DEBUG [Channel manager on controller 1]: Controller 1 trying to connect to broker 1 (kafka.controller.ControllerChannelManager)
2025-10-19 14:45:13.913 | [2025-10-19 19:45:13,912] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-10-19 14:45:13.919 | [2025-10-19 19:45:13,919] INFO [RequestSendThread controllerId=1] Starting (kafka.controller.RequestSendThread)
2025-10-19 14:45:13.925 | [2025-10-19 19:45:13,924] INFO [Controller id=1] Currently active brokers in the cluster: Set(1) (kafka.controller.KafkaController)
2025-10-19 14:45:13.925 | [2025-10-19 19:45:13,925] INFO [Controller id=1] Currently shutting brokers in the cluster: HashSet() (kafka.controller.KafkaController)
2025-10-19 14:45:13.926 | [2025-10-19 19:45:13,925] INFO [Controller id=1] Current list of topics in the cluster: HashSet(mesa-ya.sections.created, __consumer_offsets, mesa-ya.restaurants.created) (kafka.controller.KafkaController)
2025-10-19 14:45:13.926 | [2025-10-19 19:45:13,926] INFO [Controller id=1] Fetching topic deletions in progress (kafka.controller.KafkaController)
2025-10-19 14:45:13.935 | [2025-10-19 19:45:13,935] INFO [Controller id=1] List of topics to be deleted:  (kafka.controller.KafkaController)
2025-10-19 14:45:13.935 | [2025-10-19 19:45:13,935] INFO [Controller id=1] List of topics ineligible for deletion:  (kafka.controller.KafkaController)
2025-10-19 14:45:13.936 | [2025-10-19 19:45:13,936] INFO [Controller id=1] Initializing topic deletion manager (kafka.controller.KafkaController)
2025-10-19 14:45:13.937 | [2025-10-19 19:45:13,936] INFO [Topic Deletion Manager 1] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet() (kafka.controller.TopicDeletionManager)
2025-10-19 14:45:13.939 | [2025-10-19 19:45:13,938] INFO [Controller id=1] Sending update metadata request (kafka.controller.KafkaController)
2025-10-19 14:45:13.946 | [2025-10-19 19:45:13,944] INFO [Controller id=1 epoch=7] Sending UpdateMetadata request to brokers HashSet(1) for 0 partitions (state.change.logger)
2025-10-19 14:45:13.954 | [2025-10-19 19:45:13,954] INFO [ReplicaStateMachine controllerId=1] Initializing replica state (kafka.controller.ZkReplicaStateMachine)
2025-10-19 14:45:13.957 | [2025-10-19 19:45:13,956] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-10-19 14:45:13.965 | [2025-10-19 19:45:13,965] INFO [ReplicaStateMachine controllerId=1] Triggering online replica state changes (kafka.controller.ZkReplicaStateMachine)
2025-10-19 14:45:13.968 | [2025-10-19 19:45:13,968] INFO [Controller id=1, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
2025-10-19 14:45:13.970 | [2025-10-19 19:45:13,970] WARN [Controller id=1, targetBrokerId=1] Connection to node 1 (kafka/172.18.0.3:29092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
2025-10-19 14:45:13.976 | [2025-10-19 19:45:13,972] WARN [RequestSendThread controllerId=1] Controller 1's connection to broker kafka:29092 (id: 1 rack: null) was unsuccessful (kafka.controller.RequestSendThread)
2025-10-19 14:45:13.976 | java.io.IOException: Connection to kafka:29092 (id: 1 rack: null) failed.
2025-10-19 14:45:13.976 | 	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
2025-10-19 14:45:13.976 | 	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:296)
2025-10-19 14:45:13.976 | 	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:249)
2025-10-19 14:45:13.976 | 	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:127)
2025-10-19 14:45:13.976 | [2025-10-19 19:45:13,975] INFO [Controller id=1, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
2025-10-19 14:45:13.993 | [2025-10-19 19:45:13,993] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-46 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:13.994 | [2025-10-19 19:45:13,993] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-37 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:13.994 | [2025-10-19 19:45:13,994] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-8 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:13.995 | [2025-10-19 19:45:13,994] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-49 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:13.995 | [2025-10-19 19:45:13,995] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-21 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:13.995 | [2025-10-19 19:45:13,995] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-20 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:13.996 | [2025-10-19 19:45:13,995] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-17 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:13.996 | [2025-10-19 19:45:13,996] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
2025-10-19 14:45:13.996 | [2025-10-19 19:45:13,996] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-19 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:13.996 | [2025-10-19 19:45:13,996] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-7 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:13.997 | [2025-10-19 19:45:13,996] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-43 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:13.997 | [2025-10-19 19:45:13,997] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-30 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:13.997 | [2025-10-19 19:45:13,997] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-35 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:13.998 | [2025-10-19 19:45:13,997] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-27 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:13.999 | [2025-10-19 19:45:13,999] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition mesa-ya.restaurants.created-0 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:13.999 | [2025-10-19 19:45:13,999] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-0 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.000 | [2025-10-19 19:45:13,999] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-40 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.000 | [2025-10-19 19:45:14,000] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-47 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.000 | [2025-10-19 19:45:14,000] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-10 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.000 | [2025-10-19 19:45:14,000] INFO Awaiting socket connections on 0.0.0.0:29092. (kafka.network.DataPlaneAcceptor)
2025-10-19 14:45:14.001 | [2025-10-19 19:45:14,000] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-4 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.001 | [2025-10-19 19:45:14,001] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-31 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.001 | [2025-10-19 19:45:14,001] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-16 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.002 | [2025-10-19 19:45:14,001] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-23 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.002 | [2025-10-19 19:45:14,002] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-26 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.002 | [2025-10-19 19:45:14,002] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-39 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.003 | [2025-10-19 19:45:14,002] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-2 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.003 | [2025-10-19 19:45:14,003] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-34 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.003 | [2025-10-19 19:45:14,003] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-24 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.012 | [2025-10-19 19:45:14,012] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-32 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.013 | [2025-10-19 19:45:14,013] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition mesa-ya.sections.created-0 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.013 | [2025-10-19 19:45:14,013] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-41 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.014 | [2025-10-19 19:45:14,014] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-5 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.015 | [2025-10-19 19:45:14,014] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
2025-10-19 14:45:14.015 | [2025-10-19 19:45:14,015] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-15 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.015 | [2025-10-19 19:45:14,015] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-1 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.016 | [2025-10-19 19:45:14,016] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-9 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.017 | [2025-10-19 19:45:14,016] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-45 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.018 | [2025-10-19 19:45:14,017] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-36 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.019 | [2025-10-19 19:45:14,019] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-48 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.020 | [2025-10-19 19:45:14,019] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-3 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.020 | [2025-10-19 19:45:14,020] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-18 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.020 | [2025-10-19 19:45:14,020] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-44 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.021 | [2025-10-19 19:45:14,021] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-11 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.021 | [2025-10-19 19:45:14,021] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-25 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.022 | [2025-10-19 19:45:14,021] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-29 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.022 | [2025-10-19 19:45:14,022] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-6 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.022 | [2025-10-19 19:45:14,022] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-42 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.023 | [2025-10-19 19:45:14,022] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-28 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.023 | [2025-10-19 19:45:14,022] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-12 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.023 | [2025-10-19 19:45:14,023] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-38 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.023 | [2025-10-19 19:45:14,023] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-33 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.023 | [2025-10-19 19:45:14,023] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-14 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.024 | [2025-10-19 19:45:14,024] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-13 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.025 | [2025-10-19 19:45:14,024] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition __consumer_offsets-22 from OnlineReplica to OnlineReplica (state.change.logger)
2025-10-19 14:45:14.030 | [2025-10-19 19:45:14,029] INFO Kafka version: 7.5.0-ccs (org.apache.kafka.common.utils.AppInfoParser)
2025-10-19 14:45:14.030 | [2025-10-19 19:45:14,029] INFO Kafka commitId: ff3c201baa948d97889dc26c99d7cdc23d038f2e (org.apache.kafka.common.utils.AppInfoParser)
2025-10-19 14:45:14.030 | [2025-10-19 19:45:14,029] INFO Kafka startTimeMs: 1760903114020 (org.apache.kafka.common.utils.AppInfoParser)
2025-10-19 14:45:14.032 | [2025-10-19 19:45:14,032] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
2025-10-19 14:45:14.034 | [2025-10-19 19:45:14,033] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-13 (state.change.logger)
2025-10-19 14:45:14.034 | [2025-10-19 19:45:14,034] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-46 (state.change.logger)
2025-10-19 14:45:14.034 | [2025-10-19 19:45:14,034] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-9 (state.change.logger)
2025-10-19 14:45:14.034 | [2025-10-19 19:45:14,034] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-42 (state.change.logger)
2025-10-19 14:45:14.034 | [2025-10-19 19:45:14,034] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-21 (state.change.logger)
2025-10-19 14:45:14.034 | [2025-10-19 19:45:14,034] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-17 (state.change.logger)
2025-10-19 14:45:14.034 | [2025-10-19 19:45:14,034] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-30 (state.change.logger)
2025-10-19 14:45:14.034 | [2025-10-19 19:45:14,034] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-26 (state.change.logger)
2025-10-19 14:45:14.034 | [2025-10-19 19:45:14,034] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-5 (state.change.logger)
2025-10-19 14:45:14.034 | [2025-10-19 19:45:14,034] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-38 (state.change.logger)
2025-10-19 14:45:14.034 | [2025-10-19 19:45:14,034] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-1 (state.change.logger)
2025-10-19 14:45:14.034 | [2025-10-19 19:45:14,034] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-34 (state.change.logger)
2025-10-19 14:45:14.034 | [2025-10-19 19:45:14,034] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-16 (state.change.logger)
2025-10-19 14:45:14.034 | [2025-10-19 19:45:14,034] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-45 (state.change.logger)
2025-10-19 14:45:14.035 | [2025-10-19 19:45:14,034] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-12 (state.change.logger)
2025-10-19 14:45:14.035 | [2025-10-19 19:45:14,034] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-41 (state.change.logger)
2025-10-19 14:45:14.035 | [2025-10-19 19:45:14,034] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-24 (state.change.logger)
2025-10-19 14:45:14.035 | [2025-10-19 19:45:14,034] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-20 (state.change.logger)
2025-10-19 14:45:14.035 | [2025-10-19 19:45:14,034] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-49 (state.change.logger)
2025-10-19 14:45:14.035 | [2025-10-19 19:45:14,034] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-0 (state.change.logger)
2025-10-19 14:45:14.035 | [2025-10-19 19:45:14,034] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-29 (state.change.logger)
2025-10-19 14:45:14.035 | [2025-10-19 19:45:14,035] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-25 (state.change.logger)
2025-10-19 14:45:14.035 | [2025-10-19 19:45:14,035] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-8 (state.change.logger)
2025-10-19 14:45:14.035 | [2025-10-19 19:45:14,035] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-37 (state.change.logger)
2025-10-19 14:45:14.035 | [2025-10-19 19:45:14,035] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-4 (state.change.logger)
2025-10-19 14:45:14.035 | [2025-10-19 19:45:14,035] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-33 (state.change.logger)
2025-10-19 14:45:14.035 | [2025-10-19 19:45:14,035] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-15 (state.change.logger)
2025-10-19 14:45:14.035 | [2025-10-19 19:45:14,035] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-48 (state.change.logger)
2025-10-19 14:45:14.035 | [2025-10-19 19:45:14,035] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-11 (state.change.logger)
2025-10-19 14:45:14.035 | [2025-10-19 19:45:14,035] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-44 (state.change.logger)
2025-10-19 14:45:14.035 | [2025-10-19 19:45:14,035] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-23 (state.change.logger)
2025-10-19 14:45:14.035 | [2025-10-19 19:45:14,035] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-19 (state.change.logger)
2025-10-19 14:45:14.035 | [2025-10-19 19:45:14,035] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-32 (state.change.logger)
2025-10-19 14:45:14.035 | [2025-10-19 19:45:14,035] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-28 (state.change.logger)
2025-10-19 14:45:14.035 | [2025-10-19 19:45:14,035] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-7 (state.change.logger)
2025-10-19 14:45:14.035 | [2025-10-19 19:45:14,035] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-40 (state.change.logger)
2025-10-19 14:45:14.035 | [2025-10-19 19:45:14,035] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-3 (state.change.logger)
2025-10-19 14:45:14.035 | [2025-10-19 19:45:14,035] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-36 (state.change.logger)
2025-10-19 14:45:14.035 | [2025-10-19 19:45:14,035] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-47 (state.change.logger)
2025-10-19 14:45:14.035 | [2025-10-19 19:45:14,035] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-14 (state.change.logger)
2025-10-19 14:45:14.035 | [2025-10-19 19:45:14,035] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-43 (state.change.logger)
2025-10-19 14:45:14.036 | [2025-10-19 19:45:14,035] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-10 (state.change.logger)
2025-10-19 14:45:14.036 | [2025-10-19 19:45:14,035] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-22 (state.change.logger)
2025-10-19 14:45:14.036 | [2025-10-19 19:45:14,035] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-18 (state.change.logger)
2025-10-19 14:45:14.036 | [2025-10-19 19:45:14,035] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-31 (state.change.logger)
2025-10-19 14:45:14.036 | [2025-10-19 19:45:14,035] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-27 (state.change.logger)
2025-10-19 14:45:14.036 | [2025-10-19 19:45:14,035] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='mesa-ya.sections.created', partitionIndex=0, controllerEpoch=6, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition mesa-ya.sections.created-0 (state.change.logger)
2025-10-19 14:45:14.036 | [2025-10-19 19:45:14,036] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-39 (state.change.logger)
2025-10-19 14:45:14.036 | [2025-10-19 19:45:14,036] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-6 (state.change.logger)
2025-10-19 14:45:14.036 | [2025-10-19 19:45:14,036] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-35 (state.change.logger)
2025-10-19 14:45:14.036 | [2025-10-19 19:45:14,036] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='mesa-ya.restaurants.created', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition mesa-ya.restaurants.created-0 (state.change.logger)
2025-10-19 14:45:14.036 | [2025-10-19 19:45:14,036] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-2 (state.change.logger)
2025-10-19 14:45:14.038 | [2025-10-19 19:45:14,037] INFO [Controller id=1 epoch=7] Sending LeaderAndIsr request to broker 1 with 52 become-leader and 0 become-follower partitions (state.change.logger)
2025-10-19 14:45:14.044 | [2025-10-19 19:45:14,044] INFO [Controller id=1 epoch=7] Sending UpdateMetadata request to brokers HashSet(1) for 52 partitions (state.change.logger)
2025-10-19 14:45:14.045 | [2025-10-19 19:45:14,045] INFO [ReplicaStateMachine controllerId=1] Triggering offline replica state changes (kafka.controller.ZkReplicaStateMachine)
2025-10-19 14:45:14.046 | [2025-10-19 19:45:14,046] DEBUG [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> HashMap([Topic=__consumer_offsets,Partition=46,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=37,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=8,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=49,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=21,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=20,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=17,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=19,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=7,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=43,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=30,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=35,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=27,Replica=1] -> OnlineReplica, [Topic=mesa-ya.restaurants.created,Partition=0,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=0,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=40,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=47,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=10,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=4,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=31,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=16,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=23,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=26,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=39,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=2,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=34,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=24,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=32,Replica=1] -> OnlineReplica, [Topic=mesa-ya.sections.created,Partition=0,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=41,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=5,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=15,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=1,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=9,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=45,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=36,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=48,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=3,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=18,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=44,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=11,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=25,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=29,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=6,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=42,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=28,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=12,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=38,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=33,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=14,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=13,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=22,Replica=1] -> OnlineReplica) (kafka.controller.ZkReplicaStateMachine)
2025-10-19 14:45:14.047 | [2025-10-19 19:45:14,047] INFO [PartitionStateMachine controllerId=1] Initializing partition state (kafka.controller.ZkPartitionStateMachine)
2025-10-19 14:45:14.054 | [2025-10-19 19:45:14,053] INFO [PartitionStateMachine controllerId=1] Triggering online partition state changes (kafka.controller.ZkPartitionStateMachine)
2025-10-19 14:45:14.056 | [2025-10-19 19:45:14,056] DEBUG [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> HashMap(__consumer_offsets-13 -> OnlinePartition, __consumer_offsets-46 -> OnlinePartition, __consumer_offsets-9 -> OnlinePartition, __consumer_offsets-42 -> OnlinePartition, __consumer_offsets-21 -> OnlinePartition, __consumer_offsets-17 -> OnlinePartition, __consumer_offsets-30 -> OnlinePartition, __consumer_offsets-26 -> OnlinePartition, __consumer_offsets-5 -> OnlinePartition, __consumer_offsets-38 -> OnlinePartition, __consumer_offsets-1 -> OnlinePartition, __consumer_offsets-34 -> OnlinePartition, __consumer_offsets-16 -> OnlinePartition, __consumer_offsets-45 -> OnlinePartition, __consumer_offsets-12 -> OnlinePartition, __consumer_offsets-41 -> OnlinePartition, __consumer_offsets-24 -> OnlinePartition, __consumer_offsets-20 -> OnlinePartition, __consumer_offsets-49 -> OnlinePartition, __consumer_offsets-0 -> OnlinePartition, __consumer_offsets-29 -> OnlinePartition, __consumer_offsets-25 -> OnlinePartition, __consumer_offsets-8 -> OnlinePartition, __consumer_offsets-37 -> OnlinePartition, __consumer_offsets-4 -> OnlinePartition, __consumer_offsets-33 -> OnlinePartition, __consumer_offsets-15 -> OnlinePartition, __consumer_offsets-48 -> OnlinePartition, __consumer_offsets-11 -> OnlinePartition, __consumer_offsets-44 -> OnlinePartition, __consumer_offsets-23 -> OnlinePartition, __consumer_offsets-19 -> OnlinePartition, __consumer_offsets-32 -> OnlinePartition, __consumer_offsets-28 -> OnlinePartition, __consumer_offsets-7 -> OnlinePartition, __consumer_offsets-40 -> OnlinePartition, __consumer_offsets-3 -> OnlinePartition, __consumer_offsets-36 -> OnlinePartition, __consumer_offsets-47 -> OnlinePartition, __consumer_offsets-14 -> OnlinePartition, __consumer_offsets-43 -> OnlinePartition, __consumer_offsets-10 -> OnlinePartition, __consumer_offsets-22 -> OnlinePartition, __consumer_offsets-18 -> OnlinePartition, __consumer_offsets-31 -> OnlinePartition, __consumer_offsets-27 -> OnlinePartition, mesa-ya.sections.created-0 -> OnlinePartition, __consumer_offsets-39 -> OnlinePartition, __consumer_offsets-6 -> OnlinePartition, __consumer_offsets-35 -> OnlinePartition, mesa-ya.restaurants.created-0 -> OnlinePartition, __consumer_offsets-2 -> OnlinePartition) (kafka.controller.ZkPartitionStateMachine)
2025-10-19 14:45:14.057 | [2025-10-19 19:45:14,057] INFO [Controller id=1] Ready to serve as the new controller with epoch 7 (kafka.controller.KafkaController)
2025-10-19 14:45:14.065 | [2025-10-19 19:45:14,065] INFO [Controller id=1] Partitions undergoing preferred replica election:  (kafka.controller.KafkaController)
2025-10-19 14:45:14.066 | [2025-10-19 19:45:14,066] INFO [Controller id=1] Partitions that completed preferred replica election:  (kafka.controller.KafkaController)
2025-10-19 14:45:14.066 | [2025-10-19 19:45:14,066] INFO [Controller id=1] Skipping preferred replica election for partitions due to topic deletion:  (kafka.controller.KafkaController)
2025-10-19 14:45:14.067 | [2025-10-19 19:45:14,066] INFO [Controller id=1] Resuming preferred replica election for partitions:  (kafka.controller.KafkaController)
2025-10-19 14:45:14.069 | [2025-10-19 19:45:14,069] INFO [Controller id=1] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered (kafka.controller.KafkaController)
2025-10-19 14:45:14.080 | [2025-10-19 19:45:14,079] INFO [RequestSendThread controllerId=1] Controller 1 connected to kafka:29092 (id: 1 rack: null) for sending state change requests (kafka.controller.RequestSendThread)
2025-10-19 14:45:14.087 | [2025-10-19 19:45:14,087] INFO [Controller id=1] Starting the controller scheduler (kafka.controller.KafkaController)
2025-10-19 14:45:14.154 | [2025-10-19 19:45:14,153] TRACE [Controller id=1 epoch=7] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 0 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-10-19 14:45:14.165 | [2025-10-19 19:45:14,164] INFO [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 for 52 partitions (state.change.logger)
2025-10-19 14:45:14.166 | [2025-10-19 19:45:14,165] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='mesa-ya.sections.created', partitionIndex=0, controllerEpoch=6, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.166 | [2025-10-19 19:45:14,166] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.166 | [2025-10-19 19:45:14,166] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.166 | [2025-10-19 19:45:14,166] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.166 | [2025-10-19 19:45:14,166] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.166 | [2025-10-19 19:45:14,166] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.166 | [2025-10-19 19:45:14,166] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.166 | [2025-10-19 19:45:14,166] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.166 | [2025-10-19 19:45:14,166] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.166 | [2025-10-19 19:45:14,166] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.166 | [2025-10-19 19:45:14,166] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.166 | [2025-10-19 19:45:14,166] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.166 | [2025-10-19 19:45:14,166] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.166 | [2025-10-19 19:45:14,166] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.166 | [2025-10-19 19:45:14,166] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.166 | [2025-10-19 19:45:14,166] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.166 | [2025-10-19 19:45:14,166] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.166 | [2025-10-19 19:45:14,166] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.166 | [2025-10-19 19:45:14,166] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.166 | [2025-10-19 19:45:14,166] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.166 | [2025-10-19 19:45:14,166] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.166 | [2025-10-19 19:45:14,166] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.166 | [2025-10-19 19:45:14,166] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.166 | [2025-10-19 19:45:14,166] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.166 | [2025-10-19 19:45:14,166] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.166 | [2025-10-19 19:45:14,166] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.166 | [2025-10-19 19:45:14,166] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.166 | [2025-10-19 19:45:14,166] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.166 | [2025-10-19 19:45:14,166] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.167 | [2025-10-19 19:45:14,166] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.167 | [2025-10-19 19:45:14,166] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.167 | [2025-10-19 19:45:14,166] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.167 | [2025-10-19 19:45:14,167] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Recorded new controller, from now on will use node kafka:29092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
2025-10-19 14:45:14.167 | [2025-10-19 19:45:14,167] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.167 | [2025-10-19 19:45:14,167] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.167 | [2025-10-19 19:45:14,167] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.167 | [2025-10-19 19:45:14,167] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.167 | [2025-10-19 19:45:14,167] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.167 | [2025-10-19 19:45:14,167] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.167 | [2025-10-19 19:45:14,167] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.167 | [2025-10-19 19:45:14,167] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.167 | [2025-10-19 19:45:14,167] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.167 | [2025-10-19 19:45:14,167] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.167 | [2025-10-19 19:45:14,167] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.167 | [2025-10-19 19:45:14,167] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.167 | [2025-10-19 19:45:14,167] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.168 | [2025-10-19 19:45:14,167] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.168 | [2025-10-19 19:45:14,167] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.168 | [2025-10-19 19:45:14,167] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.168 | [2025-10-19 19:45:14,167] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.168 | [2025-10-19 19:45:14,167] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.168 | [2025-10-19 19:45:14,167] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.168 | [2025-10-19 19:45:14,167] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='mesa-ya.restaurants.created', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 7 (state.change.logger)
2025-10-19 14:45:14.219 | [2025-10-19 19:45:14,219] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-3 (state.change.logger)
2025-10-19 14:45:14.219 | [2025-10-19 19:45:14,219] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-18 (state.change.logger)
2025-10-19 14:45:14.219 | [2025-10-19 19:45:14,219] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-41 (state.change.logger)
2025-10-19 14:45:14.219 | [2025-10-19 19:45:14,219] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-10 (state.change.logger)
2025-10-19 14:45:14.219 | [2025-10-19 19:45:14,219] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-33 (state.change.logger)
2025-10-19 14:45:14.220 | [2025-10-19 19:45:14,219] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-48 (state.change.logger)
2025-10-19 14:45:14.220 | [2025-10-19 19:45:14,219] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-19 (state.change.logger)
2025-10-19 14:45:14.220 | [2025-10-19 19:45:14,219] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-34 (state.change.logger)
2025-10-19 14:45:14.220 | [2025-10-19 19:45:14,219] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-4 (state.change.logger)
2025-10-19 14:45:14.220 | [2025-10-19 19:45:14,219] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-11 (state.change.logger)
2025-10-19 14:45:14.220 | [2025-10-19 19:45:14,219] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-26 (state.change.logger)
2025-10-19 14:45:14.220 | [2025-10-19 19:45:14,219] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-49 (state.change.logger)
2025-10-19 14:45:14.220 | [2025-10-19 19:45:14,219] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-39 (state.change.logger)
2025-10-19 14:45:14.220 | [2025-10-19 19:45:14,219] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-9 (state.change.logger)
2025-10-19 14:45:14.220 | [2025-10-19 19:45:14,219] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-24 (state.change.logger)
2025-10-19 14:45:14.220 | [2025-10-19 19:45:14,220] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-31 (state.change.logger)
2025-10-19 14:45:14.220 | [2025-10-19 19:45:14,220] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-46 (state.change.logger)
2025-10-19 14:45:14.220 | [2025-10-19 19:45:14,220] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-1 (state.change.logger)
2025-10-19 14:45:14.220 | [2025-10-19 19:45:14,220] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-16 (state.change.logger)
2025-10-19 14:45:14.220 | [2025-10-19 19:45:14,220] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-2 (state.change.logger)
2025-10-19 14:45:14.220 | [2025-10-19 19:45:14,220] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-25 (state.change.logger)
2025-10-19 14:45:14.220 | [2025-10-19 19:45:14,220] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-40 (state.change.logger)
2025-10-19 14:45:14.220 | [2025-10-19 19:45:14,220] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-47 (state.change.logger)
2025-10-19 14:45:14.220 | [2025-10-19 19:45:14,220] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-17 (state.change.logger)
2025-10-19 14:45:14.220 | [2025-10-19 19:45:14,220] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-32 (state.change.logger)
2025-10-19 14:45:14.220 | [2025-10-19 19:45:14,220] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-37 (state.change.logger)
2025-10-19 14:45:14.220 | [2025-10-19 19:45:14,220] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-7 (state.change.logger)
2025-10-19 14:45:14.221 | [2025-10-19 19:45:14,220] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-22 (state.change.logger)
2025-10-19 14:45:14.221 | [2025-10-19 19:45:14,220] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-29 (state.change.logger)
2025-10-19 14:45:14.221 | [2025-10-19 19:45:14,221] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-44 (state.change.logger)
2025-10-19 14:45:14.221 | [2025-10-19 19:45:14,221] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-14 (state.change.logger)
2025-10-19 14:45:14.221 | [2025-10-19 19:45:14,221] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-23 (state.change.logger)
2025-10-19 14:45:14.221 | [2025-10-19 19:45:14,221] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-38 (state.change.logger)
2025-10-19 14:45:14.221 | [2025-10-19 19:45:14,221] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-8 (state.change.logger)
2025-10-19 14:45:14.221 | [2025-10-19 19:45:14,221] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-45 (state.change.logger)
2025-10-19 14:45:14.221 | [2025-10-19 19:45:14,221] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition mesa-ya.sections.created-0 (state.change.logger)
2025-10-19 14:45:14.221 | [2025-10-19 19:45:14,221] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-15 (state.change.logger)
2025-10-19 14:45:14.221 | [2025-10-19 19:45:14,221] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-30 (state.change.logger)
2025-10-19 14:45:14.221 | [2025-10-19 19:45:14,221] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition mesa-ya.restaurants.created-0 (state.change.logger)
2025-10-19 14:45:14.221 | [2025-10-19 19:45:14,221] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-0 (state.change.logger)
2025-10-19 14:45:14.221 | [2025-10-19 19:45:14,221] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-35 (state.change.logger)
2025-10-19 14:45:14.221 | [2025-10-19 19:45:14,221] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-5 (state.change.logger)
2025-10-19 14:45:14.221 | [2025-10-19 19:45:14,221] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-20 (state.change.logger)
2025-10-19 14:45:14.221 | [2025-10-19 19:45:14,221] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-27 (state.change.logger)
2025-10-19 14:45:14.221 | [2025-10-19 19:45:14,221] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-42 (state.change.logger)
2025-10-19 14:45:14.221 | [2025-10-19 19:45:14,221] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-12 (state.change.logger)
2025-10-19 14:45:14.221 | [2025-10-19 19:45:14,221] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-21 (state.change.logger)
2025-10-19 14:45:14.221 | [2025-10-19 19:45:14,221] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-36 (state.change.logger)
2025-10-19 14:45:14.221 | [2025-10-19 19:45:14,221] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-6 (state.change.logger)
2025-10-19 14:45:14.221 | [2025-10-19 19:45:14,221] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-43 (state.change.logger)
2025-10-19 14:45:14.221 | [2025-10-19 19:45:14,221] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-13 (state.change.logger)
2025-10-19 14:45:14.221 | [2025-10-19 19:45:14,221] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 7 starting the become-leader transition for partition __consumer_offsets-28 (state.change.logger)
2025-10-19 14:45:14.223 | [2025-10-19 19:45:14,222] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-37, __consumer_offsets-38, __consumer_offsets-13, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, mesa-ya.restaurants.created-0, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40, mesa-ya.sections.created-0) (kafka.server.ReplicaFetcherManager)
2025-10-19 14:45:14.223 | [2025-10-19 19:45:14,223] INFO [Broker id=1] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 1 epoch 7 as part of the become-leader transition for 52 partitions (state.change.logger)
2025-10-19 14:45:14.232 | [2025-10-19 19:45:14,231] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Recorded new controller, from now on will use node kafka:29092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
2025-10-19 14:45:14.241 | [2025-10-19 19:45:14,240] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.245 | [2025-10-19 19:45:14,245] INFO [Broker id=1] Leader __consumer_offsets-3 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.267 | [2025-10-19 19:45:14,266] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.267 | [2025-10-19 19:45:14,266] INFO [Broker id=1] Leader __consumer_offsets-18 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.276 | [2025-10-19 19:45:14,276] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.276 | [2025-10-19 19:45:14,276] INFO [Broker id=1] Leader __consumer_offsets-41 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.287 | [2025-10-19 19:45:14,286] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.287 | [2025-10-19 19:45:14,287] INFO [Broker id=1] Leader __consumer_offsets-10 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.295 | [2025-10-19 19:45:14,294] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.295 | [2025-10-19 19:45:14,295] INFO [Broker id=1] Leader __consumer_offsets-33 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.305 | [2025-10-19 19:45:14,304] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.305 | [2025-10-19 19:45:14,305] INFO [Broker id=1] Leader __consumer_offsets-48 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.316 | [2025-10-19 19:45:14,315] INFO [Partition __consumer_offsets-19 broker=1] Log loaded for partition __consumer_offsets-19 with initial high watermark 6 (kafka.cluster.Partition)
2025-10-19 14:45:14.316 | [2025-10-19 19:45:14,316] INFO [Broker id=1] Leader __consumer_offsets-19 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 6 with partition epoch 0, high watermark 6, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.317 | [2025-10-19 19:45:14,316] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.317 | [2025-10-19 19:45:14,316] INFO [Broker id=1] Leader __consumer_offsets-34 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.330 | [2025-10-19 19:45:14,330] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.330 | [2025-10-19 19:45:14,330] INFO [Broker id=1] Leader __consumer_offsets-4 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.342 | [2025-10-19 19:45:14,341] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.342 | [2025-10-19 19:45:14,342] INFO [Broker id=1] Leader __consumer_offsets-11 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.353 | [2025-10-19 19:45:14,352] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.353 | [2025-10-19 19:45:14,352] INFO [Broker id=1] Leader __consumer_offsets-26 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.368 | [2025-10-19 19:45:14,367] INFO [Partition __consumer_offsets-49 broker=1] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.368 | [2025-10-19 19:45:14,367] INFO [Broker id=1] Leader __consumer_offsets-49 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.380 | [2025-10-19 19:45:14,379] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.380 | [2025-10-19 19:45:14,380] INFO [Broker id=1] Leader __consumer_offsets-39 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.391 | [2025-10-19 19:45:14,390] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.391 | [2025-10-19 19:45:14,390] INFO [Broker id=1] Leader __consumer_offsets-9 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.400 | [2025-10-19 19:45:14,400] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.400 | [2025-10-19 19:45:14,400] INFO [Broker id=1] Leader __consumer_offsets-24 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.410 | [2025-10-19 19:45:14,409] INFO [Partition __consumer_offsets-31 broker=1] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.410 | [2025-10-19 19:45:14,410] INFO [Broker id=1] Leader __consumer_offsets-31 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.420 | [2025-10-19 19:45:14,420] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.420 | [2025-10-19 19:45:14,420] INFO [Broker id=1] Leader __consumer_offsets-46 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.433 | [2025-10-19 19:45:14,432] INFO [Partition __consumer_offsets-1 broker=1] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.433 | [2025-10-19 19:45:14,433] INFO [Broker id=1] Leader __consumer_offsets-1 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.450 | [2025-10-19 19:45:14,450] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.451 | [2025-10-19 19:45:14,450] INFO [Broker id=1] Leader __consumer_offsets-16 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.469 | [2025-10-19 19:45:14,469] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.470 | [2025-10-19 19:45:14,469] INFO [Broker id=1] Leader __consumer_offsets-2 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.483 | [2025-10-19 19:45:14,483] INFO [Partition __consumer_offsets-25 broker=1] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.483 | [2025-10-19 19:45:14,483] INFO [Broker id=1] Leader __consumer_offsets-25 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.494 | [2025-10-19 19:45:14,493] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.494 | [2025-10-19 19:45:14,494] INFO [Broker id=1] Leader __consumer_offsets-40 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.504 | [2025-10-19 19:45:14,504] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.504 | [2025-10-19 19:45:14,504] INFO [Broker id=1] Leader __consumer_offsets-47 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.515 | [2025-10-19 19:45:14,514] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.515 | [2025-10-19 19:45:14,514] INFO [Broker id=1] Leader __consumer_offsets-17 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.527 | [2025-10-19 19:45:14,526] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.527 | [2025-10-19 19:45:14,526] INFO [Broker id=1] Leader __consumer_offsets-32 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.538 | [2025-10-19 19:45:14,537] INFO [Partition __consumer_offsets-37 broker=1] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.538 | [2025-10-19 19:45:14,537] INFO [Broker id=1] Leader __consumer_offsets-37 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.547 | [2025-10-19 19:45:14,547] INFO [Partition __consumer_offsets-7 broker=1] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.547 | [2025-10-19 19:45:14,547] INFO [Broker id=1] Leader __consumer_offsets-7 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.558 | [2025-10-19 19:45:14,557] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.558 | [2025-10-19 19:45:14,557] INFO [Broker id=1] Leader __consumer_offsets-22 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.568 | [2025-10-19 19:45:14,568] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.568 | [2025-10-19 19:45:14,568] INFO [Broker id=1] Leader __consumer_offsets-29 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.577 | [2025-10-19 19:45:14,577] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.578 | [2025-10-19 19:45:14,577] INFO [Broker id=1] Leader __consumer_offsets-44 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.587 | [2025-10-19 19:45:14,586] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.587 | [2025-10-19 19:45:14,586] INFO [Broker id=1] Leader __consumer_offsets-14 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.596 | [2025-10-19 19:45:14,595] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.596 | [2025-10-19 19:45:14,596] INFO [Broker id=1] Leader __consumer_offsets-23 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.605 | [2025-10-19 19:45:14,605] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.605 | [2025-10-19 19:45:14,605] INFO [Broker id=1] Leader __consumer_offsets-38 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.615 | [2025-10-19 19:45:14,615] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.615 | [2025-10-19 19:45:14,615] INFO [Broker id=1] Leader __consumer_offsets-8 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.625 | [2025-10-19 19:45:14,624] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.625 | [2025-10-19 19:45:14,625] INFO [Broker id=1] Leader __consumer_offsets-45 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.637 | [2025-10-19 19:45:14,637] INFO [Partition mesa-ya.sections.created-0 broker=1] Log loaded for partition mesa-ya.sections.created-0 with initial high watermark 1 (kafka.cluster.Partition)
2025-10-19 14:45:14.637 | [2025-10-19 19:45:14,637] INFO [Broker id=1] Leader mesa-ya.sections.created-0 with topic id Some(NwfGy3exRLOrYp5JWPfRlA) starts at leader epoch 0 from offset 1 with partition epoch 0, high watermark 1, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.637 | [2025-10-19 19:45:14,637] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.638 | [2025-10-19 19:45:14,637] INFO [Broker id=1] Leader __consumer_offsets-15 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.652 | [2025-10-19 19:45:14,652] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.652 | [2025-10-19 19:45:14,652] INFO [Broker id=1] Leader __consumer_offsets-30 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.663 | [2025-10-19 19:45:14,662] INFO [Partition mesa-ya.restaurants.created-0 broker=1] Log loaded for partition mesa-ya.restaurants.created-0 with initial high watermark 3 (kafka.cluster.Partition)
2025-10-19 14:45:14.664 | [2025-10-19 19:45:14,663] INFO [Broker id=1] Leader mesa-ya.restaurants.created-0 with topic id Some(yWm6W48_TyqOOX8W2L0ItA) starts at leader epoch 0 from offset 3 with partition epoch 0, high watermark 3, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.665 | [2025-10-19 19:45:14,664] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.665 | [2025-10-19 19:45:14,664] INFO [Broker id=1] Leader __consumer_offsets-0 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.674 | [2025-10-19 19:45:14,674] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.674 | [2025-10-19 19:45:14,674] INFO [Broker id=1] Leader __consumer_offsets-35 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.686 | [2025-10-19 19:45:14,685] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.686 | [2025-10-19 19:45:14,685] INFO [Broker id=1] Leader __consumer_offsets-5 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.695 | [2025-10-19 19:45:14,694] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.695 | [2025-10-19 19:45:14,695] INFO [Broker id=1] Leader __consumer_offsets-20 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.706 | [2025-10-19 19:45:14,706] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.706 | [2025-10-19 19:45:14,706] INFO [Broker id=1] Leader __consumer_offsets-27 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.718 | [2025-10-19 19:45:14,717] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.718 | [2025-10-19 19:45:14,717] INFO [Broker id=1] Leader __consumer_offsets-42 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.735 | [2025-10-19 19:45:14,734] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.738 | [2025-10-19 19:45:14,736] INFO [Broker id=1] Leader __consumer_offsets-12 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.751 | [2025-10-19 19:45:14,751] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.751 | [2025-10-19 19:45:14,751] INFO [Broker id=1] Leader __consumer_offsets-21 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.762 | [2025-10-19 19:45:14,762] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.762 | [2025-10-19 19:45:14,762] INFO [Broker id=1] Leader __consumer_offsets-36 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.778 | [2025-10-19 19:45:14,778] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.778 | [2025-10-19 19:45:14,778] INFO [Broker id=1] Leader __consumer_offsets-6 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.792 | [2025-10-19 19:45:14,792] INFO [Partition __consumer_offsets-43 broker=1] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.793 | [2025-10-19 19:45:14,792] INFO [Broker id=1] Leader __consumer_offsets-43 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.802 | [2025-10-19 19:45:14,802] INFO [Partition __consumer_offsets-13 broker=1] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.802 | [2025-10-19 19:45:14,802] INFO [Broker id=1] Leader __consumer_offsets-13 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.813 | [2025-10-19 19:45:14,812] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 14:45:14.813 | [2025-10-19 19:45:14,812] INFO [Broker id=1] Leader __consumer_offsets-28 with topic id Some(6ep0dUNwQAaqKr79SJ8ITA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-3 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-18 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-41 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-10 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-33 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-48 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-19 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-34 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-4 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-11 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-26 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-49 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-39 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-9 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-24 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-31 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-46 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-1 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-16 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-2 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-25 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-40 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-47 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-17 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-32 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-37 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-7 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-22 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-29 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-44 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-14 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-23 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-38 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-8 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-45 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition mesa-ya.sections.created-0 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-15 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-30 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition mesa-ya.restaurants.created-0 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-0 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-35 (state.change.logger)
2025-10-19 14:45:14.826 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-5 (state.change.logger)
2025-10-19 14:45:14.827 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-20 (state.change.logger)
2025-10-19 14:45:14.827 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-27 (state.change.logger)
2025-10-19 14:45:14.827 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-42 (state.change.logger)
2025-10-19 14:45:14.827 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-12 (state.change.logger)
2025-10-19 14:45:14.827 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-21 (state.change.logger)
2025-10-19 14:45:14.827 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-36 (state.change.logger)
2025-10-19 14:45:14.827 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-6 (state.change.logger)
2025-10-19 14:45:14.827 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-43 (state.change.logger)
2025-10-19 14:45:14.827 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-13 (state.change.logger)
2025-10-19 14:45:14.827 | [2025-10-19 19:45:14,826] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 7 for the become-leader transition for partition __consumer_offsets-28 (state.change.logger)
2025-10-19 14:45:14.836 | [2025-10-19 19:45:14,834] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.842 | [2025-10-19 19:45:14,841] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.848 | [2025-10-19 19:45:14,846] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.848 | [2025-10-19 19:45:14,847] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.848 | [2025-10-19 19:45:14,847] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.848 | [2025-10-19 19:45:14,847] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.848 | [2025-10-19 19:45:14,847] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.848 | [2025-10-19 19:45:14,847] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.848 | [2025-10-19 19:45:14,847] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.848 | [2025-10-19 19:45:14,847] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.848 | [2025-10-19 19:45:14,847] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.848 | [2025-10-19 19:45:14,847] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.848 | [2025-10-19 19:45:14,847] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.848 | [2025-10-19 19:45:14,847] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.848 | [2025-10-19 19:45:14,847] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.848 | [2025-10-19 19:45:14,847] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.848 | [2025-10-19 19:45:14,847] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.848 | [2025-10-19 19:45:14,847] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.848 | [2025-10-19 19:45:14,847] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.848 | [2025-10-19 19:45:14,848] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.848 | [2025-10-19 19:45:14,848] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.848 | [2025-10-19 19:45:14,848] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.848 | [2025-10-19 19:45:14,848] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.848 | [2025-10-19 19:45:14,848] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.848 | [2025-10-19 19:45:14,848] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.848 | [2025-10-19 19:45:14,848] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.849 | [2025-10-19 19:45:14,848] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.849 | [2025-10-19 19:45:14,848] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.849 | [2025-10-19 19:45:14,848] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.849 | [2025-10-19 19:45:14,848] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.849 | [2025-10-19 19:45:14,848] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.849 | [2025-10-19 19:45:14,848] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.849 | [2025-10-19 19:45:14,848] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.849 | [2025-10-19 19:45:14,848] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.849 | [2025-10-19 19:45:14,848] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.850 | [2025-10-19 19:45:14,848] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.850 | [2025-10-19 19:45:14,849] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.850 | [2025-10-19 19:45:14,849] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.850 | [2025-10-19 19:45:14,849] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.850 | [2025-10-19 19:45:14,849] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.850 | [2025-10-19 19:45:14,849] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.850 | [2025-10-19 19:45:14,849] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.850 | [2025-10-19 19:45:14,849] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.850 | [2025-10-19 19:45:14,849] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.850 | [2025-10-19 19:45:14,849] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.850 | [2025-10-19 19:45:14,849] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.850 | [2025-10-19 19:45:14,849] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.850 | [2025-10-19 19:45:14,849] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.850 | [2025-10-19 19:45:14,849] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.850 | [2025-10-19 19:45:14,849] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.850 | [2025-10-19 19:45:14,849] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.850 | [2025-10-19 19:45:14,849] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.850 | [2025-10-19 19:45:14,849] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.850 | [2025-10-19 19:45:14,849] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.850 | [2025-10-19 19:45:14,849] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.850 | [2025-10-19 19:45:14,849] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.850 | [2025-10-19 19:45:14,849] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.850 | [2025-10-19 19:45:14,849] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.850 | [2025-10-19 19:45:14,849] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.850 | [2025-10-19 19:45:14,849] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.850 | [2025-10-19 19:45:14,849] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.850 | [2025-10-19 19:45:14,849] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.850 | [2025-10-19 19:45:14,849] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.850 | [2025-10-19 19:45:14,849] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.850 | [2025-10-19 19:45:14,849] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.850 | [2025-10-19 19:45:14,849] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.851 | [2025-10-19 19:45:14,849] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.851 | [2025-10-19 19:45:14,849] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.851 | [2025-10-19 19:45:14,849] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.851 | [2025-10-19 19:45:14,849] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.851 | [2025-10-19 19:45:14,849] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.851 | [2025-10-19 19:45:14,849] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.851 | [2025-10-19 19:45:14,850] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.851 | [2025-10-19 19:45:14,850] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.851 | [2025-10-19 19:45:14,850] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.851 | [2025-10-19 19:45:14,850] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.851 | [2025-10-19 19:45:14,850] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.851 | [2025-10-19 19:45:14,850] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.851 | [2025-10-19 19:45:14,850] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.851 | [2025-10-19 19:45:14,850] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.851 | [2025-10-19 19:45:14,850] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.851 | [2025-10-19 19:45:14,850] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.853 | [2025-10-19 19:45:14,851] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.854 | [2025-10-19 19:45:14,853] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.855 | [2025-10-19 19:45:14,854] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.855 | [2025-10-19 19:45:14,854] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.855 | [2025-10-19 19:45:14,854] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.855 | [2025-10-19 19:45:14,854] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.855 | [2025-10-19 19:45:14,854] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.855 | [2025-10-19 19:45:14,854] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.855 | [2025-10-19 19:45:14,854] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.855 | [2025-10-19 19:45:14,854] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.855 | [2025-10-19 19:45:14,854] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.855 | [2025-10-19 19:45:14,854] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.855 | [2025-10-19 19:45:14,854] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.855 | [2025-10-19 19:45:14,854] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.855 | [2025-10-19 19:45:14,854] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.855 | [2025-10-19 19:45:14,854] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.855 | [2025-10-19 19:45:14,855] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.855 | [2025-10-19 19:45:14,855] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.863 | [2025-10-19 19:45:14,862] INFO [Broker id=1] Finished LeaderAndIsr request in 698ms correlationId 1 from controller 1 for 52 partitions (state.change.logger)
2025-10-19 14:45:14.865 | [2025-10-19 19:45:14,863] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 21 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.865 | [2025-10-19 19:45:14,865] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 18 milliseconds for epoch 0, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.865 | [2025-10-19 19:45:14,865] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 18 milliseconds for epoch 0, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.866 | [2025-10-19 19:45:14,865] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 18 milliseconds for epoch 0, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.866 | [2025-10-19 19:45:14,866] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 19 milliseconds for epoch 0, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.866 | [2025-10-19 19:45:14,866] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 19 milliseconds for epoch 0, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.869 | [2025-10-19 19:45:14,868] TRACE [Controller id=1 epoch=7] Received response LeaderAndIsrResponseData(errorCode=0, partitionErrors=[], topics=[LeaderAndIsrTopicError(topicId=6ep0dUNwQAaqKr79SJ8ITA, partitionErrors=[LeaderAndIsrPartitionError(topicName='', partitionIndex=13, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=46, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=9, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=42, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=21, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=17, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=30, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=26, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=5, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=38, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=1, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=34, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=16, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=45, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=12, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=41, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=24, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=20, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=49, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=0, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=29, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=25, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=8, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=37, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=4, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=33, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=15, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=48, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=11, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=44, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=23, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=19, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=32, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=28, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=7, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=40, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=3, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=36, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=47, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=14, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=43, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=10, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=22, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=18, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=31, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=27, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=39, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=6, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=35, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=2, errorCode=0)]), LeaderAndIsrTopicError(topicId=NwfGy3exRLOrYp5JWPfRlA, partitionErrors=[LeaderAndIsrPartitionError(topicName='', partitionIndex=0, errorCode=0)]), LeaderAndIsrTopicError(topicId=yWm6W48_TyqOOX8W2L0ItA, partitionErrors=[LeaderAndIsrPartitionError(topicName='', partitionIndex=0, errorCode=0)])]) for request LEADER_AND_ISR with correlation id 1 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-10-19 14:45:14.879 | [2025-10-19 19:45:14,878] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='mesa-ya.sections.created', partitionIndex=0, controllerEpoch=6, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition mesa-ya.sections.created-0 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.879 | [2025-10-19 19:45:14,878] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-13 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.879 | [2025-10-19 19:45:14,879] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-46 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.879 | [2025-10-19 19:45:14,879] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-9 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.879 | [2025-10-19 19:45:14,879] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-42 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.879 | [2025-10-19 19:45:14,879] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-21 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.879 | [2025-10-19 19:45:14,879] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-17 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.879 | [2025-10-19 19:45:14,879] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-30 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.879 | [2025-10-19 19:45:14,879] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-26 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.879 | [2025-10-19 19:45:14,879] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-5 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.879 | [2025-10-19 19:45:14,879] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-38 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.879 | [2025-10-19 19:45:14,879] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-1 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.879 | [2025-10-19 19:45:14,879] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-34 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.879 | [2025-10-19 19:45:14,879] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-16 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.879 | [2025-10-19 19:45:14,879] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-45 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.879 | [2025-10-19 19:45:14,879] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-12 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.879 | [2025-10-19 19:45:14,879] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-41 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.879 | [2025-10-19 19:45:14,879] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-24 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.879 | [2025-10-19 19:45:14,879] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-20 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.879 | [2025-10-19 19:45:14,879] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-49 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.879 | [2025-10-19 19:45:14,879] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-0 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.879 | [2025-10-19 19:45:14,879] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-29 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.879 | [2025-10-19 19:45:14,879] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-25 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.880 | [2025-10-19 19:45:14,879] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-8 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.880 | [2025-10-19 19:45:14,879] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-37 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.880 | [2025-10-19 19:45:14,879] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-4 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.880 | [2025-10-19 19:45:14,879] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-33 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.880 | [2025-10-19 19:45:14,880] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-15 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.880 | [2025-10-19 19:45:14,880] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-48 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.880 | [2025-10-19 19:45:14,880] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-11 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.880 | [2025-10-19 19:45:14,880] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-44 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.880 | [2025-10-19 19:45:14,880] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-23 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.880 | [2025-10-19 19:45:14,880] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-19 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.880 | [2025-10-19 19:45:14,880] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-32 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.880 | [2025-10-19 19:45:14,880] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-28 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.880 | [2025-10-19 19:45:14,880] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-7 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.880 | [2025-10-19 19:45:14,880] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-40 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.880 | [2025-10-19 19:45:14,880] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-3 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.880 | [2025-10-19 19:45:14,880] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-36 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.880 | [2025-10-19 19:45:14,880] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-47 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.880 | [2025-10-19 19:45:14,880] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-14 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.881 | [2025-10-19 19:45:14,880] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-43 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.881 | [2025-10-19 19:45:14,881] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-10 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.881 | [2025-10-19 19:45:14,881] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-22 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.881 | [2025-10-19 19:45:14,881] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-18 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.881 | [2025-10-19 19:45:14,881] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-31 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.881 | [2025-10-19 19:45:14,881] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-27 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.881 | [2025-10-19 19:45:14,881] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-39 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.881 | [2025-10-19 19:45:14,881] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-6 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.881 | [2025-10-19 19:45:14,881] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-35 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.881 | [2025-10-19 19:45:14,881] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-2 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.881 | [2025-10-19 19:45:14,881] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='mesa-ya.restaurants.created', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition mesa-ya.restaurants.created-0 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.883 | [2025-10-19 19:45:14,882] INFO [Broker id=1] Add 52 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 2 (state.change.logger)
2025-10-19 14:45:14.887 | [2025-10-19 19:45:14,883] TRACE [Controller id=1 epoch=7] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 2 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-10-19 14:45:14.902 | [2025-10-19 19:45:14,902] INFO Loaded member MemberMetadata(memberId=mesa-ya-service-client-9a0094a4-6972-4e79-a5d6-5ed4ed5cfa65, groupInstanceId=None, clientId=mesa-ya-service-client, clientHost=/172.18.0.4, sessionTimeoutMs=30000, rebalanceTimeoutMs=60000, supportedProtocols=List(NestReplyPartitionAssigner)) in group nestjs-group-client with generation 1. (kafka.coordinator.group.GroupMetadata$)
2025-10-19 14:45:14.908 | [2025-10-19 19:45:14,908] INFO Loaded member MemberMetadata(memberId=mesa-ya-service-client-72bf5d0c-5531-4f4b-bc39-f00715991c39, groupInstanceId=None, clientId=mesa-ya-service-client, clientHost=/172.18.0.4, sessionTimeoutMs=30000, rebalanceTimeoutMs=60000, supportedProtocols=List(NestReplyPartitionAssigner)) in group nestjs-group-client with generation 3. (kafka.coordinator.group.GroupMetadata$)
2025-10-19 14:45:14.908 | [2025-10-19 19:45:14,908] INFO Loaded member MemberMetadata(memberId=mesa-ya-service-client-f2aeaef7-4be2-4f30-b0ef-3c4276477e2c, groupInstanceId=None, clientId=mesa-ya-service-client, clientHost=/172.18.0.4, sessionTimeoutMs=30000, rebalanceTimeoutMs=60000, supportedProtocols=List(NestReplyPartitionAssigner)) in group nestjs-group-client with generation 1. (kafka.coordinator.group.GroupMetadata$)
2025-10-19 14:45:14.909 | [2025-10-19 19:45:14,909] INFO [GroupCoordinator 1]: Loading group metadata for nestjs-group-client with generation 1 (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:14.914 | [2025-10-19 19:45:14,914] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 67 milliseconds for epoch 0, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.914 | [2025-10-19 19:45:14,914] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 67 milliseconds for epoch 0, of which 67 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.914 | [2025-10-19 19:45:14,914] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 67 milliseconds for epoch 0, of which 67 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.914 | [2025-10-19 19:45:14,914] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 66 milliseconds for epoch 0, of which 66 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.914 | [2025-10-19 19:45:14,914] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 66 milliseconds for epoch 0, of which 66 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.915 | [2025-10-19 19:45:14,914] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 66 milliseconds for epoch 0, of which 66 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.915 | [2025-10-19 19:45:14,914] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 66 milliseconds for epoch 0, of which 66 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.915 | [2025-10-19 19:45:14,915] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 66 milliseconds for epoch 0, of which 66 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.915 | [2025-10-19 19:45:14,915] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 67 milliseconds for epoch 0, of which 67 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.915 | [2025-10-19 19:45:14,915] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 67 milliseconds for epoch 0, of which 67 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.915 | [2025-10-19 19:45:14,915] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 67 milliseconds for epoch 0, of which 67 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.915 | [2025-10-19 19:45:14,915] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 67 milliseconds for epoch 0, of which 67 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.915 | [2025-10-19 19:45:14,915] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 66 milliseconds for epoch 0, of which 66 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.916 | [2025-10-19 19:45:14,915] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 66 milliseconds for epoch 0, of which 66 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.916 | [2025-10-19 19:45:14,916] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 67 milliseconds for epoch 0, of which 66 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.916 | [2025-10-19 19:45:14,916] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 67 milliseconds for epoch 0, of which 67 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.916 | [2025-10-19 19:45:14,916] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 67 milliseconds for epoch 0, of which 67 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.917 | [2025-10-19 19:45:14,916] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 67 milliseconds for epoch 0, of which 67 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.917 | [2025-10-19 19:45:14,916] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 67 milliseconds for epoch 0, of which 67 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.917 | [2025-10-19 19:45:14,917] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 68 milliseconds for epoch 0, of which 67 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.917 | [2025-10-19 19:45:14,917] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 68 milliseconds for epoch 0, of which 68 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.917 | [2025-10-19 19:45:14,917] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 68 milliseconds for epoch 0, of which 68 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.917 | [2025-10-19 19:45:14,917] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 68 milliseconds for epoch 0, of which 68 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.917 | [2025-10-19 19:45:14,917] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 68 milliseconds for epoch 0, of which 68 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.918 | [2025-10-19 19:45:14,917] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 68 milliseconds for epoch 0, of which 68 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.918 | [2025-10-19 19:45:14,917] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 68 milliseconds for epoch 0, of which 68 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.918 | [2025-10-19 19:45:14,917] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 68 milliseconds for epoch 0, of which 68 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.918 | [2025-10-19 19:45:14,918] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 69 milliseconds for epoch 0, of which 69 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.918 | [2025-10-19 19:45:14,918] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 69 milliseconds for epoch 0, of which 69 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.918 | [2025-10-19 19:45:14,918] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 69 milliseconds for epoch 0, of which 69 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.919 | [2025-10-19 19:45:14,918] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 68 milliseconds for epoch 0, of which 68 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.919 | [2025-10-19 19:45:14,919] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 68 milliseconds for epoch 0, of which 68 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.919 | [2025-10-19 19:45:14,919] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 69 milliseconds for epoch 0, of which 69 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.919 | [2025-10-19 19:45:14,919] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 69 milliseconds for epoch 0, of which 69 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.919 | [2025-10-19 19:45:14,919] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 69 milliseconds for epoch 0, of which 69 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.919 | [2025-10-19 19:45:14,919] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 66 milliseconds for epoch 0, of which 66 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.920 | [2025-10-19 19:45:14,919] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 65 milliseconds for epoch 0, of which 65 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.920 | [2025-10-19 19:45:14,919] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 65 milliseconds for epoch 0, of which 65 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.920 | [2025-10-19 19:45:14,919] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 65 milliseconds for epoch 0, of which 65 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.920 | [2025-10-19 19:45:14,920] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 66 milliseconds for epoch 0, of which 65 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.920 | [2025-10-19 19:45:14,920] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 66 milliseconds for epoch 0, of which 66 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.920 | [2025-10-19 19:45:14,920] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 66 milliseconds for epoch 0, of which 66 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.920 | [2025-10-19 19:45:14,920] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 66 milliseconds for epoch 0, of which 66 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:14.921 | [2025-10-19 19:45:14,920] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 65 milliseconds for epoch 0, of which 65 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:45:19.088 | [2025-10-19 19:45:19,088] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 14:45:19.089 | [2025-10-19 19:45:19,089] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 14:45:19.092 | [2025-10-19 19:45:19,092] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 14:45:19.093 | [2025-10-19 19:45:19,092] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 14:45:44.011 | [2025-10-19 19:45:44,010] INFO [GroupCoordinator 1]: Member mesa-ya-service-client-f2aeaef7-4be2-4f30-b0ef-3c4276477e2c in group nestjs-group-client has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:44.015 | [2025-10-19 19:45:44,015] INFO [GroupCoordinator 1]: Preparing to rebalance group nestjs-group-client in state PreparingRebalance with old generation 1 (__consumer_offsets-19) (reason: removing member mesa-ya-service-client-f2aeaef7-4be2-4f30-b0ef-3c4276477e2c on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:45:44.018 | [2025-10-19 19:45:44,017] INFO [GroupCoordinator 1]: Group nestjs-group-client with generation 2 is now empty (__consumer_offsets-19) (kafka.coordinator.group.GroupCoordinator)
2025-10-19 14:50:09.979 | [2025-10-19 19:50:09,977] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 14:50:09.979 | [2025-10-19 19:50:09,978] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 14:50:09.987 | [2025-10-19 19:50:09,986] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 14:50:09.988 | [2025-10-19 19:50:09,987] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 14:54:55.647 | [2025-10-19 19:54:55,646] INFO [GroupMetadataManager brokerId=1] Group nestjs-group-client transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
2025-10-19 14:55:00.937 | [2025-10-19 19:55:00,937] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 14:55:00.937 | [2025-10-19 19:55:00,937] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 14:55:00.939 | [2025-10-19 19:55:00,939] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 14:55:00.939 | [2025-10-19 19:55:00,939] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 14:59:51.914 | [2025-10-19 19:59:51,913] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 14:59:51.915 | [2025-10-19 19:59:51,914] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 14:59:51.917 | [2025-10-19 19:59:51,917] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 14:59:51.918 | [2025-10-19 19:59:51,917] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 15:04:42.950 | [2025-10-19 20:04:42,949] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 15:04:42.950 | [2025-10-19 20:04:42,949] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 15:04:42.951 | [2025-10-19 20:04:42,951] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 15:04:42.951 | [2025-10-19 20:04:42,951] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 15:09:33.976 | [2025-10-19 20:09:33,975] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 15:09:33.976 | [2025-10-19 20:09:33,975] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 15:09:33.980 | [2025-10-19 20:09:33,979] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 15:09:33.982 | [2025-10-19 20:09:33,981] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 15:14:25.036 | [2025-10-19 20:14:25,035] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 15:14:25.036 | [2025-10-19 20:14:25,036] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 15:14:25.039 | [2025-10-19 20:14:25,038] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 15:14:25.039 | [2025-10-19 20:14:25,039] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 15:19:16.142 | [2025-10-19 20:19:16,141] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 15:19:16.142 | [2025-10-19 20:19:16,141] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 15:19:16.144 | [2025-10-19 20:19:16,144] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 15:19:16.145 | [2025-10-19 20:19:16,145] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 15:20:55.109 | [2025-10-19 20:20:55,108] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group nestjs-group-client in Empty state. Created a new member id mesa-ya-service-client-5d66b4bc-a27d-4658-aa99-4a27d5c92465 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
2025-10-19 15:20:55.126 | [2025-10-19 20:20:55,125] INFO [GroupCoordinator 1]: Preparing to rebalance group nestjs-group-client in state PreparingRebalance with old generation 0 (__consumer_offsets-19) (reason: Adding new member mesa-ya-service-client-5d66b4bc-a27d-4658-aa99-4a27d5c92465 with group instance id None; client reason: not provided) (kafka.coordinator.group.GroupCoordinator)
2025-10-19 15:20:58.148 | [2025-10-19 20:20:58,148] INFO [GroupCoordinator 1]: Stabilized group nestjs-group-client generation 1 (__consumer_offsets-19) with 1 members (kafka.coordinator.group.GroupCoordinator)
2025-10-19 15:20:58.168 | [2025-10-19 20:20:58,168] INFO [GroupCoordinator 1]: Assignment received from leader mesa-ya-service-client-5d66b4bc-a27d-4658-aa99-4a27d5c92465 for group nestjs-group-client for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
2025-10-19 15:24:07.303 | [2025-10-19 20:24:07,302] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 15:24:07.303 | [2025-10-19 20:24:07,302] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 15:24:07.306 | [2025-10-19 20:24:07,305] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 15:24:07.306 | [2025-10-19 20:24:07,305] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 15:28:58.478 | [2025-10-19 20:28:58,477] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 15:28:58.478 | [2025-10-19 20:28:58,477] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 15:28:58.480 | [2025-10-19 20:28:58,480] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 15:28:58.480 | [2025-10-19 20:28:58,480] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 15:33:49.702 | [2025-10-19 20:33:49,701] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 15:33:49.702 | [2025-10-19 20:33:49,701] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 15:33:49.703 | [2025-10-19 20:33:49,702] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 15:33:49.703 | [2025-10-19 20:33:49,702] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 15:38:40.932 | [2025-10-19 20:38:40,932] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 15:38:40.933 | [2025-10-19 20:38:40,932] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 15:38:40.935 | [2025-10-19 20:38:40,934] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 15:38:40.935 | [2025-10-19 20:38:40,935] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 15:43:32.189 | [2025-10-19 20:43:32,188] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 15:43:32.189 | [2025-10-19 20:43:32,188] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 15:43:32.191 | [2025-10-19 20:43:32,190] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 15:43:32.191 | [2025-10-19 20:43:32,190] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 15:48:23.483 | [2025-10-19 20:48:23,481] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 15:48:23.483 | [2025-10-19 20:48:23,482] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 15:48:23.485 | [2025-10-19 20:48:23,484] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 15:48:23.485 | [2025-10-19 20:48:23,484] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 15:53:14.827 | [2025-10-19 20:53:14,826] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 15:53:14.827 | [2025-10-19 20:53:14,826] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 15:53:14.828 | [2025-10-19 20:53:14,828] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 15:53:14.828 | [2025-10-19 20:53:14,828] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 15:58:06.236 | [2025-10-19 20:58:06,234] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 15:58:06.237 | [2025-10-19 20:58:06,236] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 15:58:06.240 | [2025-10-19 20:58:06,239] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 15:58:06.240 | [2025-10-19 20:58:06,239] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 16:02:57.663 | [2025-10-19 21:02:57,662] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 16:02:57.663 | [2025-10-19 21:02:57,662] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 16:02:57.665 | [2025-10-19 21:02:57,665] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 16:02:57.665 | [2025-10-19 21:02:57,665] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 16:07:49.088 | [2025-10-19 21:07:49,087] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 16:07:49.088 | [2025-10-19 21:07:49,088] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 16:07:49.092 | [2025-10-19 21:07:49,092] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 16:07:49.092 | [2025-10-19 21:07:49,092] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 16:12:40.570 | [2025-10-19 21:12:40,569] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 16:12:40.570 | [2025-10-19 21:12:40,569] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 16:12:40.571 | [2025-10-19 21:12:40,571] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 16:12:40.571 | [2025-10-19 21:12:40,571] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 16:17:32.107 | [2025-10-19 21:17:32,106] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 16:17:32.107 | [2025-10-19 21:17:32,107] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 16:17:32.108 | [2025-10-19 21:17:32,108] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 16:17:32.109 | [2025-10-19 21:17:32,108] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 16:22:23.683 | [2025-10-19 21:22:23,682] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 16:22:23.683 | [2025-10-19 21:22:23,682] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 16:22:23.685 | [2025-10-19 21:22:23,684] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 16:22:23.685 | [2025-10-19 21:22:23,685] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 16:27:15.233 | [2025-10-19 21:27:15,232] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 16:27:15.233 | [2025-10-19 21:27:15,232] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 16:27:15.234 | [2025-10-19 21:27:15,233] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 16:27:15.234 | [2025-10-19 21:27:15,234] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 16:32:06.884 | [2025-10-19 21:32:06,883] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 16:32:06.884 | [2025-10-19 21:32:06,884] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 16:32:06.885 | [2025-10-19 21:32:06,885] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 16:32:06.886 | [2025-10-19 21:32:06,885] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 16:36:58.506 | [2025-10-19 21:36:58,504] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 16:36:58.506 | [2025-10-19 21:36:58,505] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 16:36:58.508 | [2025-10-19 21:36:58,507] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 16:36:58.508 | [2025-10-19 21:36:58,508] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 16:41:50.350 | [2025-10-19 21:41:50,349] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 16:41:50.350 | [2025-10-19 21:41:50,350] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 16:41:50.351 | [2025-10-19 21:41:50,351] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 16:41:50.352 | [2025-10-19 21:41:50,351] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 16:46:42.125 | [2025-10-19 21:46:42,123] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 16:46:42.125 | [2025-10-19 21:46:42,124] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 16:46:42.127 | [2025-10-19 21:46:42,126] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 16:46:42.127 | [2025-10-19 21:46:42,126] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 16:51:33.958 | [2025-10-19 21:51:33,958] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 16:51:33.958 | [2025-10-19 21:51:33,958] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 16:51:33.960 | [2025-10-19 21:51:33,959] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 16:51:33.960 | [2025-10-19 21:51:33,959] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 16:56:25.839 | [2025-10-19 21:56:25,839] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 16:56:25.840 | [2025-10-19 21:56:25,839] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 16:56:25.841 | [2025-10-19 21:56:25,841] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 16:56:25.841 | [2025-10-19 21:56:25,841] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 17:01:17.668 | [2025-10-19 22:01:17,667] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 17:01:17.668 | [2025-10-19 22:01:17,668] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 17:01:17.669 | [2025-10-19 22:01:17,669] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 17:01:17.669 | [2025-10-19 22:01:17,669] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 17:06:09.378 | [2025-10-19 22:06:09,378] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 17:06:09.379 | [2025-10-19 22:06:09,378] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 17:06:09.380 | [2025-10-19 22:06:09,379] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 17:06:09.380 | [2025-10-19 22:06:09,380] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 17:11:01.453 | [2025-10-19 22:11:01,452] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 17:11:01.453 | [2025-10-19 22:11:01,452] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 17:11:01.454 | [2025-10-19 22:11:01,453] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 17:11:01.454 | [2025-10-19 22:11:01,453] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 17:15:53.363 | [2025-10-19 22:15:53,362] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 17:15:53.363 | [2025-10-19 22:15:53,362] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 17:15:53.364 | [2025-10-19 22:15:53,364] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 17:15:53.364 | [2025-10-19 22:15:53,364] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 17:20:45.194 | [2025-10-19 22:20:45,193] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 17:20:45.194 | [2025-10-19 22:20:45,194] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 17:20:45.196 | [2025-10-19 22:20:45,195] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 17:20:45.196 | [2025-10-19 22:20:45,195] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 17:25:37.008 | [2025-10-19 22:25:37,006] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 17:25:37.008 | [2025-10-19 22:25:37,007] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 17:25:37.009 | [2025-10-19 22:25:37,009] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 17:25:37.009 | [2025-10-19 22:25:37,009] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 17:30:28.874 | [2025-10-19 22:30:28,873] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 17:30:28.874 | [2025-10-19 22:30:28,873] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 17:30:28.876 | [2025-10-19 22:30:28,875] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 17:30:28.876 | [2025-10-19 22:30:28,876] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 17:35:20.749 | [2025-10-19 22:35:20,749] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 17:35:20.749 | [2025-10-19 22:35:20,749] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 17:35:20.751 | [2025-10-19 22:35:20,751] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 17:35:20.752 | [2025-10-19 22:35:20,751] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 17:40:12.659 | [2025-10-19 22:40:12,658] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 17:40:12.659 | [2025-10-19 22:40:12,658] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 17:40:12.660 | [2025-10-19 22:40:12,660] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 17:40:12.660 | [2025-10-19 22:40:12,660] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 17:45:04.479 | [2025-10-19 22:45:04,478] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 17:45:04.479 | [2025-10-19 22:45:04,478] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 17:45:04.481 | [2025-10-19 22:45:04,480] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 17:45:04.481 | [2025-10-19 22:45:04,481] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 17:49:56.380 | [2025-10-19 22:49:56,380] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 17:49:56.380 | [2025-10-19 22:49:56,380] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 17:49:56.381 | [2025-10-19 22:49:56,381] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 17:49:56.381 | [2025-10-19 22:49:56,381] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 17:53:43.517 | [2025-10-19 22:53:43,516] INFO [GroupCoordinator 1]: Dynamic Member with unknown member id joins group realtime-group in Empty state. Created a new member id main.exe@miquel (github.com/segmentio/kafka-go)-a5b54294-e62a-4fe8-bcf6-1c10ec92e193 for this member and add to the group. (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:53:43.519 | [2025-10-19 22:53:43,518] INFO [GroupCoordinator 1]: Preparing to rebalance group realtime-group in state PreparingRebalance with old generation 0 (__consumer_offsets-19) (reason: Adding new member main.exe@miquel (github.com/segmentio/kafka-go)-a5b54294-e62a-4fe8-bcf6-1c10ec92e193 with group instance id None; client reason: not provided) (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:53:43.521 | [2025-10-19 22:53:43,520] INFO [GroupCoordinator 1]: Dynamic Member with unknown member id joins group realtime-group in PreparingRebalance state. Created a new member id main.exe@miquel (github.com/segmentio/kafka-go)-e86c83d7-a894-42ab-ad69-e1c86535eb47 for this member and add to the group. (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:53:43.522 | [2025-10-19 22:53:43,522] INFO [GroupCoordinator 1]: Dynamic Member with unknown member id joins group realtime-group in PreparingRebalance state. Created a new member id main.exe@miquel (github.com/segmentio/kafka-go)-b5011f6c-d06c-4143-8fd4-42d532e41977 for this member and add to the group. (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:53:43.523 | [2025-10-19 22:53:43,522] INFO [GroupCoordinator 1]: Dynamic Member with unknown member id joins group realtime-group in PreparingRebalance state. Created a new member id main.exe@miquel (github.com/segmentio/kafka-go)-cc019bdc-0cb4-4beb-bed5-c6fba4ef559c for this member and add to the group. (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:53:43.523 | [2025-10-19 22:53:43,523] INFO [GroupCoordinator 1]: Dynamic Member with unknown member id joins group realtime-group in PreparingRebalance state. Created a new member id main.exe@miquel (github.com/segmentio/kafka-go)-7a435ee1-6a09-4cb7-bf22-8645ed2db01c for this member and add to the group. (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:53:43.523 | [2025-10-19 22:53:43,523] INFO [GroupCoordinator 1]: Dynamic Member with unknown member id joins group realtime-group in PreparingRebalance state. Created a new member id main.exe@miquel (github.com/segmentio/kafka-go)-5b284ff4-5dd7-47bd-9b66-77b3acd97b21 for this member and add to the group. (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:53:49.530 | [2025-10-19 22:53:49,529] INFO [GroupCoordinator 1]: Stabilized group realtime-group generation 1 (__consumer_offsets-19) with 6 members (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:53:49.619 | [2025-10-19 22:53:49,619] INFO Creating topic orders.events with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
2025-10-19 17:53:49.707 | [2025-10-19 22:53:49,707] INFO Creating topic users.events with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
2025-10-19 17:53:49.713 | [2025-10-19 22:53:49,713] INFO [Controller id=1] New topics: [Set(orders.events)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(orders.events,Some(c02_GFH-Tga8lRMxO5rPAQ),Map(orders.events-0 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=))))] (kafka.controller.KafkaController)
2025-10-19 17:53:49.716 | [2025-10-19 22:53:49,715] INFO [Controller id=1] New partition creation callback for orders.events-0 (kafka.controller.KafkaController)
2025-10-19 17:53:49.721 | [2025-10-19 22:53:49,721] INFO [Controller id=1 epoch=7] Changed partition orders.events-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-19 17:53:49.722 | [2025-10-19 22:53:49,721] INFO [Controller id=1 epoch=7] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-10-19 17:53:49.725 | [2025-10-19 22:53:49,725] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition orders.events-0 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-19 17:53:49.725 | [2025-10-19 22:53:49,725] INFO [Controller id=1 epoch=7] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-10-19 17:53:49.743 | [2025-10-19 22:53:49,743] INFO Creating topic bookings.events with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
2025-10-19 17:53:49.764 | [2025-10-19 22:53:49,763] INFO [Controller id=1 epoch=7] Changed partition orders.events-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-19 17:53:49.764 | [2025-10-19 22:53:49,764] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='orders.events', partitionIndex=0, controllerEpoch=7, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition orders.events-0 (state.change.logger)
2025-10-19 17:53:49.764 | [2025-10-19 22:53:49,764] INFO [Controller id=1 epoch=7] Sending LeaderAndIsr request to broker 1 with 1 become-leader and 0 become-follower partitions (state.change.logger)
2025-10-19 17:53:49.767 | [2025-10-19 22:53:49,767] INFO [Controller id=1 epoch=7] Sending UpdateMetadata request to brokers HashSet(1) for 1 partitions (state.change.logger)
2025-10-19 17:53:49.768 | [2025-10-19 22:53:49,768] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition orders.events-0 from NewReplica to OnlineReplica (state.change.logger)
2025-10-19 17:53:49.768 | [2025-10-19 22:53:49,768] INFO [Controller id=1 epoch=7] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-10-19 17:53:49.771 | [2025-10-19 22:53:49,771] INFO [Controller id=1, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
2025-10-19 17:53:49.772 | [2025-10-19 22:53:49,772] INFO Creating topic reviews.events with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
2025-10-19 17:53:49.783 | [2025-10-19 22:53:49,782] INFO [RequestSendThread controllerId=1] Controller 1 connected to kafka:29092 (id: 1 rack: null) for sending state change requests (kafka.controller.RequestSendThread)
2025-10-19 17:53:49.783 | [2025-10-19 22:53:49,782] INFO [Controller id=1] New topics: [HashSet(users.events, bookings.events)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(bookings.events,Some(rhiZZk6LT3yOn7vyDdflfw),Map(bookings.events-0 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=))), TopicIdReplicaAssignment(users.events,Some(11rNZbzFTs-hn72Nle3iBQ),Map(users.events-0 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=))))] (kafka.controller.KafkaController)
2025-10-19 17:53:49.783 | [2025-10-19 22:53:49,783] INFO [Controller id=1] New partition creation callback for bookings.events-0,users.events-0 (kafka.controller.KafkaController)
2025-10-19 17:53:49.783 | [2025-10-19 22:53:49,783] INFO [Controller id=1 epoch=7] Changed partition bookings.events-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-19 17:53:49.783 | [2025-10-19 22:53:49,783] INFO [Controller id=1 epoch=7] Changed partition users.events-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-19 17:53:49.783 | [2025-10-19 22:53:49,783] INFO [Controller id=1 epoch=7] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-10-19 17:53:49.784 | [2025-10-19 22:53:49,784] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition bookings.events-0 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-19 17:53:49.784 | [2025-10-19 22:53:49,784] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition users.events-0 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-19 17:53:49.784 | [2025-10-19 22:53:49,784] INFO [Controller id=1 epoch=7] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-10-19 17:53:49.789 | [2025-10-19 22:53:49,788] INFO [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 for 1 partitions (state.change.logger)
2025-10-19 17:53:49.789 | [2025-10-19 22:53:49,788] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='orders.events', partitionIndex=0, controllerEpoch=7, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 7 (state.change.logger)
2025-10-19 17:53:49.793 | [2025-10-19 22:53:49,792] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 7 starting the become-leader transition for partition orders.events-0 (state.change.logger)
2025-10-19 17:53:49.794 | [2025-10-19 22:53:49,793] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(orders.events-0) (kafka.server.ReplicaFetcherManager)
2025-10-19 17:53:49.795 | [2025-10-19 22:53:49,794] INFO [Broker id=1] Stopped fetchers as part of LeaderAndIsr request correlationId 3 from controller 1 epoch 7 as part of the become-leader transition for 1 partitions (state.change.logger)
2025-10-19 17:53:49.814 | [2025-10-19 22:53:49,813] INFO [LogLoader partition=orders.events-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 17:53:49.821 | [2025-10-19 22:53:49,821] INFO Created log for partition orders.events-0 in /var/lib/kafka/data/orders.events-0 with properties {} (kafka.log.LogManager)
2025-10-19 17:53:49.825 | [2025-10-19 22:53:49,823] INFO [Partition orders.events-0 broker=1] No checkpointed highwatermark is found for partition orders.events-0 (kafka.cluster.Partition)
2025-10-19 17:53:49.825 | [2025-10-19 22:53:49,825] INFO [Partition orders.events-0 broker=1] Log loaded for partition orders.events-0 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 17:53:49.826 | [2025-10-19 22:53:49,826] INFO [Broker id=1] Leader orders.events-0 with topic id Some(c02_GFH-Tga8lRMxO5rPAQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 17:53:49.828 | [2025-10-19 22:53:49,828] INFO Creating topic restaurants.events with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
2025-10-19 17:53:49.828 | [2025-10-19 22:53:49,828] INFO [Controller id=1 epoch=7] Changed partition bookings.events-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-19 17:53:49.829 | [2025-10-19 22:53:49,828] INFO [Controller id=1 epoch=7] Changed partition users.events-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-19 17:53:49.829 | [2025-10-19 22:53:49,829] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='bookings.events', partitionIndex=0, controllerEpoch=7, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition bookings.events-0 (state.change.logger)
2025-10-19 17:53:49.829 | [2025-10-19 22:53:49,829] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='users.events', partitionIndex=0, controllerEpoch=7, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition users.events-0 (state.change.logger)
2025-10-19 17:53:49.829 | [2025-10-19 22:53:49,829] INFO [Controller id=1 epoch=7] Sending LeaderAndIsr request to broker 1 with 2 become-leader and 0 become-follower partitions (state.change.logger)
2025-10-19 17:53:49.830 | [2025-10-19 22:53:49,829] INFO [Controller id=1 epoch=7] Sending UpdateMetadata request to brokers HashSet(1) for 2 partitions (state.change.logger)
2025-10-19 17:53:49.830 | [2025-10-19 22:53:49,830] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition bookings.events-0 from NewReplica to OnlineReplica (state.change.logger)
2025-10-19 17:53:49.830 | [2025-10-19 22:53:49,830] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition users.events-0 from NewReplica to OnlineReplica (state.change.logger)
2025-10-19 17:53:49.830 | [2025-10-19 22:53:49,830] INFO [Controller id=1 epoch=7] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-10-19 17:53:49.842 | [2025-10-19 22:53:49,841] INFO [Controller id=1] New topics: [HashSet(reviews.events)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(reviews.events,Some(Dd8MArv-T7eIEO2eBfv1Yg),Map(reviews.events-0 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=))))] (kafka.controller.KafkaController)
2025-10-19 17:53:49.842 | [2025-10-19 22:53:49,842] INFO [Controller id=1] New partition creation callback for reviews.events-0 (kafka.controller.KafkaController)
2025-10-19 17:53:49.842 | [2025-10-19 22:53:49,842] INFO [Controller id=1 epoch=7] Changed partition reviews.events-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-19 17:53:49.842 | [2025-10-19 22:53:49,842] INFO [Controller id=1 epoch=7] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-10-19 17:53:49.843 | [2025-10-19 22:53:49,842] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition reviews.events-0 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-19 17:53:49.843 | [2025-10-19 22:53:49,843] INFO [Controller id=1 epoch=7] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-10-19 17:53:49.847 | [2025-10-19 22:53:49,847] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 7 for the become-leader transition for partition orders.events-0 (state.change.logger)
2025-10-19 17:53:49.848 | [2025-10-19 22:53:49,848] INFO [Broker id=1] Finished LeaderAndIsr request in 61ms correlationId 3 from controller 1 for 1 partitions (state.change.logger)
2025-10-19 17:53:49.852 | [2025-10-19 22:53:49,851] TRACE [Controller id=1 epoch=7] Received response LeaderAndIsrResponseData(errorCode=0, partitionErrors=[], topics=[LeaderAndIsrTopicError(topicId=c02_GFH-Tga8lRMxO5rPAQ, partitionErrors=[LeaderAndIsrPartitionError(topicName='', partitionIndex=0, errorCode=0)])]) for request LEADER_AND_ISR with correlation id 3 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-10-19 17:53:49.856 | [2025-10-19 22:53:49,855] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='orders.events', partitionIndex=0, controllerEpoch=7, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition orders.events-0 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 4 (state.change.logger)
2025-10-19 17:53:49.856 | [2025-10-19 22:53:49,856] INFO [Broker id=1] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 4 (state.change.logger)
2025-10-19 17:53:49.857 | [2025-10-19 22:53:49,857] TRACE [Controller id=1 epoch=7] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 4 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-10-19 17:53:49.858 | [2025-10-19 22:53:49,858] INFO [Broker id=1] Handling LeaderAndIsr request correlationId 5 from controller 1 for 2 partitions (state.change.logger)
2025-10-19 17:53:49.858 | [2025-10-19 22:53:49,858] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='users.events', partitionIndex=0, controllerEpoch=7, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 5 from controller 1 epoch 7 (state.change.logger)
2025-10-19 17:53:49.858 | [2025-10-19 22:53:49,858] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='bookings.events', partitionIndex=0, controllerEpoch=7, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 5 from controller 1 epoch 7 (state.change.logger)
2025-10-19 17:53:49.860 | [2025-10-19 22:53:49,859] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 5 from controller 1 epoch 7 starting the become-leader transition for partition users.events-0 (state.change.logger)
2025-10-19 17:53:49.860 | [2025-10-19 22:53:49,860] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 5 from controller 1 epoch 7 starting the become-leader transition for partition bookings.events-0 (state.change.logger)
2025-10-19 17:53:49.860 | [2025-10-19 22:53:49,860] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(users.events-0, bookings.events-0) (kafka.server.ReplicaFetcherManager)
2025-10-19 17:53:49.860 | [2025-10-19 22:53:49,860] INFO Creating topic sections.events with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
2025-10-19 17:53:49.860 | [2025-10-19 22:53:49,860] INFO [Broker id=1] Stopped fetchers as part of LeaderAndIsr request correlationId 5 from controller 1 epoch 7 as part of the become-leader transition for 2 partitions (state.change.logger)
2025-10-19 17:53:49.869 | [2025-10-19 22:53:49,869] INFO [Controller id=1 epoch=7] Changed partition reviews.events-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-19 17:53:49.869 | [2025-10-19 22:53:49,869] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='reviews.events', partitionIndex=0, controllerEpoch=7, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition reviews.events-0 (state.change.logger)
2025-10-19 17:53:49.869 | [2025-10-19 22:53:49,869] INFO [Controller id=1 epoch=7] Sending LeaderAndIsr request to broker 1 with 1 become-leader and 0 become-follower partitions (state.change.logger)
2025-10-19 17:53:49.870 | [2025-10-19 22:53:49,870] INFO [Controller id=1 epoch=7] Sending UpdateMetadata request to brokers HashSet(1) for 1 partitions (state.change.logger)
2025-10-19 17:53:49.871 | [2025-10-19 22:53:49,871] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition reviews.events-0 from NewReplica to OnlineReplica (state.change.logger)
2025-10-19 17:53:49.871 | [2025-10-19 22:53:49,871] INFO [Controller id=1 epoch=7] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-10-19 17:53:49.872 | [2025-10-19 22:53:49,871] INFO [LogLoader partition=users.events-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 17:53:49.873 | [2025-10-19 22:53:49,873] INFO Created log for partition users.events-0 in /var/lib/kafka/data/users.events-0 with properties {} (kafka.log.LogManager)
2025-10-19 17:53:49.874 | [2025-10-19 22:53:49,873] INFO [Partition users.events-0 broker=1] No checkpointed highwatermark is found for partition users.events-0 (kafka.cluster.Partition)
2025-10-19 17:53:49.874 | [2025-10-19 22:53:49,873] INFO [Partition users.events-0 broker=1] Log loaded for partition users.events-0 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 17:53:49.874 | [2025-10-19 22:53:49,873] INFO [Broker id=1] Leader users.events-0 with topic id Some(11rNZbzFTs-hn72Nle3iBQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 17:53:49.879 | [2025-10-19 22:53:49,879] INFO [Controller id=1] New topics: [HashSet(restaurants.events)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(restaurants.events,Some(stgdT8n-Rcy_WL154_Excg),Map(restaurants.events-0 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=))))] (kafka.controller.KafkaController)
2025-10-19 17:53:49.881 | [2025-10-19 22:53:49,879] INFO [Controller id=1] New partition creation callback for restaurants.events-0 (kafka.controller.KafkaController)
2025-10-19 17:53:49.881 | [2025-10-19 22:53:49,880] INFO [Controller id=1 epoch=7] Changed partition restaurants.events-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-19 17:53:49.881 | [2025-10-19 22:53:49,880] INFO [Controller id=1 epoch=7] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-10-19 17:53:49.881 | [2025-10-19 22:53:49,880] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition restaurants.events-0 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-19 17:53:49.881 | [2025-10-19 22:53:49,880] INFO [Controller id=1 epoch=7] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-10-19 17:53:49.908 | [2025-10-19 22:53:49,907] INFO [Controller id=1 epoch=7] Changed partition restaurants.events-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-19 17:53:49.908 | [2025-10-19 22:53:49,908] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='restaurants.events', partitionIndex=0, controllerEpoch=7, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition restaurants.events-0 (state.change.logger)
2025-10-19 17:53:49.908 | [2025-10-19 22:53:49,908] INFO [Controller id=1 epoch=7] Sending LeaderAndIsr request to broker 1 with 1 become-leader and 0 become-follower partitions (state.change.logger)
2025-10-19 17:53:49.909 | [2025-10-19 22:53:49,909] INFO [Controller id=1 epoch=7] Sending UpdateMetadata request to brokers HashSet(1) for 1 partitions (state.change.logger)
2025-10-19 17:53:49.910 | [2025-10-19 22:53:49,910] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition restaurants.events-0 from NewReplica to OnlineReplica (state.change.logger)
2025-10-19 17:53:49.910 | [2025-10-19 22:53:49,910] INFO [Controller id=1 epoch=7] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-10-19 17:53:49.913 | [2025-10-19 22:53:49,912] INFO [LogLoader partition=bookings.events-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 17:53:49.914 | [2025-10-19 22:53:49,913] INFO Created log for partition bookings.events-0 in /var/lib/kafka/data/bookings.events-0 with properties {} (kafka.log.LogManager)
2025-10-19 17:53:49.914 | [2025-10-19 22:53:49,914] INFO [Partition bookings.events-0 broker=1] No checkpointed highwatermark is found for partition bookings.events-0 (kafka.cluster.Partition)
2025-10-19 17:53:49.914 | [2025-10-19 22:53:49,914] INFO [Partition bookings.events-0 broker=1] Log loaded for partition bookings.events-0 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 17:53:49.914 | [2025-10-19 22:53:49,914] INFO [Broker id=1] Leader bookings.events-0 with topic id Some(rhiZZk6LT3yOn7vyDdflfw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 17:53:49.917 | [2025-10-19 22:53:49,917] INFO [Controller id=1] New topics: [HashSet(sections.events)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(sections.events,Some(zMtFhM2HQMS6Vc8Le8c0dA),Map(sections.events-0 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=))))] (kafka.controller.KafkaController)
2025-10-19 17:53:49.917 | [2025-10-19 22:53:49,917] INFO [Controller id=1] New partition creation callback for sections.events-0 (kafka.controller.KafkaController)
2025-10-19 17:53:49.917 | [2025-10-19 22:53:49,917] INFO [Controller id=1 epoch=7] Changed partition sections.events-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-10-19 17:53:49.918 | [2025-10-19 22:53:49,917] INFO [Controller id=1 epoch=7] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-10-19 17:53:49.918 | [2025-10-19 22:53:49,918] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition sections.events-0 from NonExistentReplica to NewReplica (state.change.logger)
2025-10-19 17:53:49.918 | [2025-10-19 22:53:49,918] INFO [Controller id=1 epoch=7] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-10-19 17:53:49.935 | [2025-10-19 22:53:49,935] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 5 from controller 1 epoch 7 for the become-leader transition for partition users.events-0 (state.change.logger)
2025-10-19 17:53:49.935 | [2025-10-19 22:53:49,935] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 5 from controller 1 epoch 7 for the become-leader transition for partition bookings.events-0 (state.change.logger)
2025-10-19 17:53:49.943 | [2025-10-19 22:53:49,940] INFO [GroupCoordinator 1]: Preparing to rebalance group realtime-group in state PreparingRebalance with old generation 1 (__consumer_offsets-19) (reason: Removing member main.exe@miquel (github.com/segmentio/kafka-go)-a5b54294-e62a-4fe8-bcf6-1c10ec92e193 on LeaveGroup; client reason: not provided) (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:53:49.946 | [2025-10-19 22:53:49,945] INFO [Broker id=1] Finished LeaderAndIsr request in 87ms correlationId 5 from controller 1 for 2 partitions (state.change.logger)
2025-10-19 17:53:49.950 | [2025-10-19 22:53:49,948] TRACE [Controller id=1 epoch=7] Received response LeaderAndIsrResponseData(errorCode=0, partitionErrors=[], topics=[LeaderAndIsrTopicError(topicId=rhiZZk6LT3yOn7vyDdflfw, partitionErrors=[LeaderAndIsrPartitionError(topicName='', partitionIndex=0, errorCode=0)]), LeaderAndIsrTopicError(topicId=11rNZbzFTs-hn72Nle3iBQ, partitionErrors=[LeaderAndIsrPartitionError(topicName='', partitionIndex=0, errorCode=0)])]) for request LEADER_AND_ISR with correlation id 5 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-10-19 17:53:49.950 | [2025-10-19 22:53:49,950] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=main.exe@miquel (github.com/segmentio/kafka-go)-a5b54294-e62a-4fe8-bcf6-1c10ec92e193, groupInstanceId=None, clientId=main.exe@miquel (github.com/segmentio/kafka-go), clientHost=/172.18.0.1, sessionTimeoutMs=30000, rebalanceTimeoutMs=30000, supportedProtocols=List(range, roundrobin)) has left group realtime-group through explicit `LeaveGroup`; client reason: not provided (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:53:49.952 | [2025-10-19 22:53:49,951] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='users.events', partitionIndex=0, controllerEpoch=7, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition users.events-0 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 6 (state.change.logger)
2025-10-19 17:53:49.952 | [2025-10-19 22:53:49,952] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='bookings.events', partitionIndex=0, controllerEpoch=7, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition bookings.events-0 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 6 (state.change.logger)
2025-10-19 17:53:49.952 | [2025-10-19 22:53:49,952] INFO [Broker id=1] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 6 (state.change.logger)
2025-10-19 17:53:49.954 | [2025-10-19 22:53:49,953] TRACE [Controller id=1 epoch=7] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 6 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-10-19 17:53:49.956 | [2025-10-19 22:53:49,954] INFO [Broker id=1] Handling LeaderAndIsr request correlationId 7 from controller 1 for 1 partitions (state.change.logger)
2025-10-19 17:53:49.956 | [2025-10-19 22:53:49,954] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='reviews.events', partitionIndex=0, controllerEpoch=7, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 7 from controller 1 epoch 7 (state.change.logger)
2025-10-19 17:53:49.956 | [2025-10-19 22:53:49,955] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 7 from controller 1 epoch 7 starting the become-leader transition for partition reviews.events-0 (state.change.logger)
2025-10-19 17:53:49.956 | [2025-10-19 22:53:49,956] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(reviews.events-0) (kafka.server.ReplicaFetcherManager)
2025-10-19 17:53:49.956 | [2025-10-19 22:53:49,956] INFO [Broker id=1] Stopped fetchers as part of LeaderAndIsr request correlationId 7 from controller 1 epoch 7 as part of the become-leader transition for 1 partitions (state.change.logger)
2025-10-19 17:53:49.966 | [2025-10-19 22:53:49,964] INFO [Controller id=1 epoch=7] Changed partition sections.events-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=1, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-10-19 17:53:49.967 | [2025-10-19 22:53:49,965] TRACE [Controller id=1 epoch=7] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='sections.events', partitionIndex=0, controllerEpoch=7, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition sections.events-0 (state.change.logger)
2025-10-19 17:53:49.967 | [2025-10-19 22:53:49,965] INFO [Controller id=1 epoch=7] Sending LeaderAndIsr request to broker 1 with 1 become-leader and 0 become-follower partitions (state.change.logger)
2025-10-19 17:53:49.967 | [2025-10-19 22:53:49,966] INFO [Controller id=1 epoch=7] Sending UpdateMetadata request to brokers HashSet(1) for 1 partitions (state.change.logger)
2025-10-19 17:53:49.967 | [2025-10-19 22:53:49,966] TRACE [Controller id=1 epoch=7] Changed state of replica 1 for partition sections.events-0 from NewReplica to OnlineReplica (state.change.logger)
2025-10-19 17:53:49.967 | [2025-10-19 22:53:49,966] INFO [Controller id=1 epoch=7] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-10-19 17:53:49.974 | [2025-10-19 22:53:49,973] INFO [LogLoader partition=reviews.events-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 17:53:49.976 | [2025-10-19 22:53:49,975] INFO Created log for partition reviews.events-0 in /var/lib/kafka/data/reviews.events-0 with properties {} (kafka.log.LogManager)
2025-10-19 17:53:49.977 | [2025-10-19 22:53:49,977] INFO [Partition reviews.events-0 broker=1] No checkpointed highwatermark is found for partition reviews.events-0 (kafka.cluster.Partition)
2025-10-19 17:53:49.977 | [2025-10-19 22:53:49,977] INFO [Partition reviews.events-0 broker=1] Log loaded for partition reviews.events-0 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 17:53:49.977 | [2025-10-19 22:53:49,977] INFO [Broker id=1] Leader reviews.events-0 with topic id Some(Dd8MArv-T7eIEO2eBfv1Yg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 17:53:49.987 | [2025-10-19 22:53:49,986] INFO [GroupCoordinator 1]: Stabilized group realtime-group generation 2 (__consumer_offsets-19) with 5 members (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:53:50.000 | [2025-10-19 22:53:49,999] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 7 from controller 1 epoch 7 for the become-leader transition for partition reviews.events-0 (state.change.logger)
2025-10-19 17:53:50.001 | [2025-10-19 22:53:50,000] INFO [Broker id=1] Finished LeaderAndIsr request in 46ms correlationId 7 from controller 1 for 1 partitions (state.change.logger)
2025-10-19 17:53:50.002 | [2025-10-19 22:53:50,001] TRACE [Controller id=1 epoch=7] Received response LeaderAndIsrResponseData(errorCode=0, partitionErrors=[], topics=[LeaderAndIsrTopicError(topicId=Dd8MArv-T7eIEO2eBfv1Yg, partitionErrors=[LeaderAndIsrPartitionError(topicName='', partitionIndex=0, errorCode=0)])]) for request LEADER_AND_ISR with correlation id 7 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-10-19 17:53:50.003 | [2025-10-19 22:53:50,003] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='reviews.events', partitionIndex=0, controllerEpoch=7, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition reviews.events-0 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 8 (state.change.logger)
2025-10-19 17:53:50.004 | [2025-10-19 22:53:50,003] INFO [Broker id=1] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 8 (state.change.logger)
2025-10-19 17:53:50.004 | [2025-10-19 22:53:50,004] TRACE [Controller id=1 epoch=7] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 8 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-10-19 17:53:50.006 | [2025-10-19 22:53:50,005] INFO [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 for 1 partitions (state.change.logger)
2025-10-19 17:53:50.006 | [2025-10-19 22:53:50,006] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='restaurants.events', partitionIndex=0, controllerEpoch=7, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 9 from controller 1 epoch 7 (state.change.logger)
2025-10-19 17:53:50.007 | [2025-10-19 22:53:50,007] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 7 starting the become-leader transition for partition restaurants.events-0 (state.change.logger)
2025-10-19 17:53:50.007 | [2025-10-19 22:53:50,007] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(restaurants.events-0) (kafka.server.ReplicaFetcherManager)
2025-10-19 17:53:50.008 | [2025-10-19 22:53:50,007] INFO [Broker id=1] Stopped fetchers as part of LeaderAndIsr request correlationId 9 from controller 1 epoch 7 as part of the become-leader transition for 1 partitions (state.change.logger)
2025-10-19 17:53:50.016 | [2025-10-19 22:53:50,016] INFO [LogLoader partition=restaurants.events-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 17:53:50.017 | [2025-10-19 22:53:50,017] INFO Created log for partition restaurants.events-0 in /var/lib/kafka/data/restaurants.events-0 with properties {} (kafka.log.LogManager)
2025-10-19 17:53:50.018 | [2025-10-19 22:53:50,017] INFO [Partition restaurants.events-0 broker=1] No checkpointed highwatermark is found for partition restaurants.events-0 (kafka.cluster.Partition)
2025-10-19 17:53:50.018 | [2025-10-19 22:53:50,017] INFO [Partition restaurants.events-0 broker=1] Log loaded for partition restaurants.events-0 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 17:53:50.018 | [2025-10-19 22:53:50,018] INFO [Broker id=1] Leader restaurants.events-0 with topic id Some(stgdT8n-Rcy_WL154_Excg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 17:53:50.040 | [2025-10-19 22:53:50,040] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 7 for the become-leader transition for partition restaurants.events-0 (state.change.logger)
2025-10-19 17:53:50.042 | [2025-10-19 22:53:50,042] INFO [Broker id=1] Finished LeaderAndIsr request in 37ms correlationId 9 from controller 1 for 1 partitions (state.change.logger)
2025-10-19 17:53:50.043 | [2025-10-19 22:53:50,043] TRACE [Controller id=1 epoch=7] Received response LeaderAndIsrResponseData(errorCode=0, partitionErrors=[], topics=[LeaderAndIsrTopicError(topicId=stgdT8n-Rcy_WL154_Excg, partitionErrors=[LeaderAndIsrPartitionError(topicName='', partitionIndex=0, errorCode=0)])]) for request LEADER_AND_ISR with correlation id 9 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-10-19 17:53:50.046 | [2025-10-19 22:53:50,045] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='restaurants.events', partitionIndex=0, controllerEpoch=7, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition restaurants.events-0 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 10 (state.change.logger)
2025-10-19 17:53:50.046 | [2025-10-19 22:53:50,045] INFO [Broker id=1] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 10 (state.change.logger)
2025-10-19 17:53:50.047 | [2025-10-19 22:53:50,047] TRACE [Controller id=1 epoch=7] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 10 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-10-19 17:53:50.049 | [2025-10-19 22:53:50,048] INFO [Broker id=1] Handling LeaderAndIsr request correlationId 11 from controller 1 for 1 partitions (state.change.logger)
2025-10-19 17:53:50.049 | [2025-10-19 22:53:50,048] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='sections.events', partitionIndex=0, controllerEpoch=7, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 11 from controller 1 epoch 7 (state.change.logger)
2025-10-19 17:53:50.050 | [2025-10-19 22:53:50,050] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 11 from controller 1 epoch 7 starting the become-leader transition for partition sections.events-0 (state.change.logger)
2025-10-19 17:53:50.050 | [2025-10-19 22:53:50,050] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(sections.events-0) (kafka.server.ReplicaFetcherManager)
2025-10-19 17:53:50.051 | [2025-10-19 22:53:50,050] INFO [Broker id=1] Stopped fetchers as part of LeaderAndIsr request correlationId 11 from controller 1 epoch 7 as part of the become-leader transition for 1 partitions (state.change.logger)
2025-10-19 17:53:50.064 | [2025-10-19 22:53:50,063] INFO [GroupCoordinator 1]: Preparing to rebalance group realtime-group in state PreparingRebalance with old generation 2 (__consumer_offsets-19) (reason: Removing member main.exe@miquel (github.com/segmentio/kafka-go)-7a435ee1-6a09-4cb7-bf22-8645ed2db01c on LeaveGroup; client reason: not provided) (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:53:50.065 | [2025-10-19 22:53:50,064] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=main.exe@miquel (github.com/segmentio/kafka-go)-7a435ee1-6a09-4cb7-bf22-8645ed2db01c, groupInstanceId=None, clientId=main.exe@miquel (github.com/segmentio/kafka-go), clientHost=/172.18.0.1, sessionTimeoutMs=30000, rebalanceTimeoutMs=30000, supportedProtocols=List(range, roundrobin)) has left group realtime-group through explicit `LeaveGroup`; client reason: not provided (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:53:50.068 | [2025-10-19 22:53:50,065] INFO [LogLoader partition=sections.events-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-10-19 17:53:50.069 | [2025-10-19 22:53:50,067] INFO Created log for partition sections.events-0 in /var/lib/kafka/data/sections.events-0 with properties {} (kafka.log.LogManager)
2025-10-19 17:53:50.069 | [2025-10-19 22:53:50,068] INFO [Partition sections.events-0 broker=1] No checkpointed highwatermark is found for partition sections.events-0 (kafka.cluster.Partition)
2025-10-19 17:53:50.069 | [2025-10-19 22:53:50,068] INFO [Partition sections.events-0 broker=1] Log loaded for partition sections.events-0 with initial high watermark 0 (kafka.cluster.Partition)
2025-10-19 17:53:50.069 | [2025-10-19 22:53:50,068] INFO [Broker id=1] Leader sections.events-0 with topic id Some(zMtFhM2HQMS6Vc8Le8c0dA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader epoch was -1. (state.change.logger)
2025-10-19 17:53:50.094 | [2025-10-19 22:53:50,094] INFO [GroupCoordinator 1]: Stabilized group realtime-group generation 3 (__consumer_offsets-19) with 4 members (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:53:50.097 | [2025-10-19 22:53:50,096] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 11 from controller 1 epoch 7 for the become-leader transition for partition sections.events-0 (state.change.logger)
2025-10-19 17:53:50.102 | [2025-10-19 22:53:50,102] INFO [Broker id=1] Finished LeaderAndIsr request in 52ms correlationId 11 from controller 1 for 1 partitions (state.change.logger)
2025-10-19 17:53:50.104 | [2025-10-19 22:53:50,103] TRACE [Controller id=1 epoch=7] Received response LeaderAndIsrResponseData(errorCode=0, partitionErrors=[], topics=[LeaderAndIsrTopicError(topicId=zMtFhM2HQMS6Vc8Le8c0dA, partitionErrors=[LeaderAndIsrPartitionError(topicName='', partitionIndex=0, errorCode=0)])]) for request LEADER_AND_ISR with correlation id 11 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-10-19 17:53:50.106 | [2025-10-19 22:53:50,105] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='sections.events', partitionIndex=0, controllerEpoch=7, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition sections.events-0 in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 12 (state.change.logger)
2025-10-19 17:53:50.106 | [2025-10-19 22:53:50,105] INFO [Broker id=1] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 7 with correlation id 12 (state.change.logger)
2025-10-19 17:53:50.107 | [2025-10-19 22:53:50,106] TRACE [Controller id=1 epoch=7] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 12 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-10-19 17:53:50.131 | [2025-10-19 22:53:50,130] INFO [GroupCoordinator 1]: Preparing to rebalance group realtime-group in state PreparingRebalance with old generation 3 (__consumer_offsets-19) (reason: Removing member main.exe@miquel (github.com/segmentio/kafka-go)-e86c83d7-a894-42ab-ad69-e1c86535eb47 on LeaveGroup; client reason: not provided) (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:53:50.136 | [2025-10-19 22:53:50,134] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=main.exe@miquel (github.com/segmentio/kafka-go)-e86c83d7-a894-42ab-ad69-e1c86535eb47, groupInstanceId=None, clientId=main.exe@miquel (github.com/segmentio/kafka-go), clientHost=/172.18.0.1, sessionTimeoutMs=30000, rebalanceTimeoutMs=30000, supportedProtocols=List(range, roundrobin)) has left group realtime-group through explicit `LeaveGroup`; client reason: not provided (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:53:50.157 | [2025-10-19 22:53:50,156] INFO [GroupCoordinator 1]: Stabilized group realtime-group generation 4 (__consumer_offsets-19) with 3 members (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:53:50.167 | [2025-10-19 22:53:50,166] INFO [GroupCoordinator 1]: Assignment received from leader main.exe@miquel (github.com/segmentio/kafka-go)-cc019bdc-0cb4-4beb-bed5-c6fba4ef559c for group realtime-group for generation 4. The group has 3 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:53:55.127 | [2025-10-19 22:53:55,126] INFO [GroupCoordinator 1]: Dynamic Member with unknown member id joins group realtime-group in Stable state. Created a new member id main.exe@miquel (github.com/segmentio/kafka-go)-cd23aeb4-738b-44a9-ab8c-2586f66a5b21 for this member and add to the group. (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:53:55.127 | [2025-10-19 22:53:55,127] INFO [GroupCoordinator 1]: Preparing to rebalance group realtime-group in state PreparingRebalance with old generation 4 (__consumer_offsets-19) (reason: Adding new member main.exe@miquel (github.com/segmentio/kafka-go)-cd23aeb4-738b-44a9-ab8c-2586f66a5b21 with group instance id None; client reason: not provided) (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:53:55.260 | [2025-10-19 22:53:55,260] INFO [GroupCoordinator 1]: Dynamic Member with unknown member id joins group realtime-group in PreparingRebalance state. Created a new member id main.exe@miquel (github.com/segmentio/kafka-go)-eb7942d1-ea89-43fa-8fb7-cfde7c0888a0 for this member and add to the group. (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:53:55.297 | [2025-10-19 22:53:55,296] INFO [GroupCoordinator 1]: Dynamic Member with unknown member id joins group realtime-group in PreparingRebalance state. Created a new member id main.exe@miquel (github.com/segmentio/kafka-go)-7e9285e0-7731-40bc-9a95-90fbc46fa27d for this member and add to the group. (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:54:10.412 | [2025-10-19 22:54:10,411] INFO [GroupCoordinator 1]: Dynamic Member with unknown member id joins group realtime-group in PreparingRebalance state. Created a new member id main.exe@miquel (github.com/segmentio/kafka-go)-b6e4b2d9-28c3-4c29-ab0d-1bcbb3e54083 for this member and add to the group. (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:54:10.413 | [2025-10-19 22:54:10,412] INFO [GroupCoordinator 1]: Dynamic Member with unknown member id joins group realtime-group in PreparingRebalance state. Created a new member id main.exe@miquel (github.com/segmentio/kafka-go)-a2cb0097-c335-4b93-8bfa-014f6aa7db49 for this member and add to the group. (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:54:10.413 | [2025-10-19 22:54:10,413] INFO [GroupCoordinator 1]: Dynamic Member with unknown member id joins group realtime-group in PreparingRebalance state. Created a new member id main.exe@miquel (github.com/segmentio/kafka-go)-71ad6476-c528-4c34-affe-92564d4580a8 for this member and add to the group. (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:54:10.414 | [2025-10-19 22:54:10,413] INFO [GroupCoordinator 1]: Dynamic Member with unknown member id joins group realtime-group in PreparingRebalance state. Created a new member id main.exe@miquel (github.com/segmentio/kafka-go)-3827b8b0-976f-4bec-a8fb-09909b746f53 for this member and add to the group. (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:54:10.418 | [2025-10-19 22:54:10,418] INFO [GroupCoordinator 1]: Dynamic Member with unknown member id joins group realtime-group in PreparingRebalance state. Created a new member id main.exe@miquel (github.com/segmentio/kafka-go)-3b65e2d1-cc43-4a18-8f47-f2067f6775ef for this member and add to the group. (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:54:10.419 | [2025-10-19 22:54:10,418] INFO [GroupCoordinator 1]: Dynamic Member with unknown member id joins group realtime-group in PreparingRebalance state. Created a new member id main.exe@miquel (github.com/segmentio/kafka-go)-4602063c-9fa1-4123-a72a-a0d6c089b54b for this member and add to the group. (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:54:24.335 | [2025-10-19 22:54:24,335] INFO [GroupCoordinator 1]: Group realtime-group removed dynamic members who haven't joined: Set(main.exe@miquel (github.com/segmentio/kafka-go)-cc019bdc-0cb4-4beb-bed5-c6fba4ef559c, main.exe@miquel (github.com/segmentio/kafka-go)-b5011f6c-d06c-4143-8fd4-42d532e41977, main.exe@miquel (github.com/segmentio/kafka-go)-5b284ff4-5dd7-47bd-9b66-77b3acd97b21) (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:54:24.341 | [2025-10-19 22:54:24,341] INFO [GroupCoordinator 1]: Stabilized group realtime-group generation 5 (__consumer_offsets-19) with 9 members (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:54:24.353 | [2025-10-19 22:54:24,353] INFO [GroupCoordinator 1]: Assignment received from leader main.exe@miquel (github.com/segmentio/kafka-go)-a2cb0097-c335-4b93-8bfa-014f6aa7db49 for group realtime-group for generation 5. The group has 9 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:54:48.081 | [2025-10-19 22:54:48,081] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-10-19 17:54:48.081 | [2025-10-19 22:54:48,081] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-10-19 17:54:48.083 | [2025-10-19 22:54:48,083] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-10-19 17:54:48.083 | [2025-10-19 22:54:48,083] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-10-19 17:54:53.484 | [2025-10-19 22:54:53,483] INFO [GroupCoordinator 1]: Member main.exe@miquel (github.com/segmentio/kafka-go)-7e9285e0-7731-40bc-9a95-90fbc46fa27d in group realtime-group has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:54:53.485 | [2025-10-19 22:54:53,484] INFO [GroupCoordinator 1]: Preparing to rebalance group realtime-group in state PreparingRebalance with old generation 5 (__consumer_offsets-19) (reason: removing member main.exe@miquel (github.com/segmentio/kafka-go)-7e9285e0-7731-40bc-9a95-90fbc46fa27d on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:54:53.485 | [2025-10-19 22:54:53,484] INFO [GroupCoordinator 1]: Member main.exe@miquel (github.com/segmentio/kafka-go)-cd23aeb4-738b-44a9-ab8c-2586f66a5b21 in group realtime-group has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:54:53.485 | [2025-10-19 22:54:53,485] INFO [GroupCoordinator 1]: Member main.exe@miquel (github.com/segmentio/kafka-go)-eb7942d1-ea89-43fa-8fb7-cfde7c0888a0 in group realtime-group has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:54:53.487 | [2025-10-19 22:54:53,487] ERROR [GroupCoordinator 1]: Received unexpected notification of sync expiration after group realtime-group already transitioned to the PreparingRebalance state. (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:54:59.637 | [2025-10-19 22:54:59,636] INFO [GroupCoordinator 1]: Stabilized group realtime-group generation 6 (__consumer_offsets-19) with 6 members (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:54:59.644 | [2025-10-19 22:54:59,644] INFO [GroupCoordinator 1]: Assignment received from leader main.exe@miquel (github.com/segmentio/kafka-go)-a2cb0097-c335-4b93-8bfa-014f6aa7db49 for group realtime-group for generation 6. The group has 6 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:55:38.098 | [2025-10-19 22:55:38,098] INFO [GroupCoordinator 1]: Member main.exe@miquel (github.com/segmentio/kafka-go)-3827b8b0-976f-4bec-a8fb-09909b746f53 in group realtime-group has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:55:38.099 | [2025-10-19 22:55:38,098] INFO [GroupCoordinator 1]: Preparing to rebalance group realtime-group in state PreparingRebalance with old generation 6 (__consumer_offsets-19) (reason: removing member main.exe@miquel (github.com/segmentio/kafka-go)-3827b8b0-976f-4bec-a8fb-09909b746f53 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:55:38.099 | [2025-10-19 22:55:38,099] INFO [GroupCoordinator 1]: Member main.exe@miquel (github.com/segmentio/kafka-go)-4602063c-9fa1-4123-a72a-a0d6c089b54b in group realtime-group has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:55:38.099 | [2025-10-19 22:55:38,099] INFO [GroupCoordinator 1]: Member main.exe@miquel (github.com/segmentio/kafka-go)-71ad6476-c528-4c34-affe-92564d4580a8 in group realtime-group has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:55:38.100 | [2025-10-19 22:55:38,099] INFO [GroupCoordinator 1]: Member main.exe@miquel (github.com/segmentio/kafka-go)-3b65e2d1-cc43-4a18-8f47-f2067f6775ef in group realtime-group has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:55:38.100 | [2025-10-19 22:55:38,100] INFO [GroupCoordinator 1]: Member main.exe@miquel (github.com/segmentio/kafka-go)-a2cb0097-c335-4b93-8bfa-014f6aa7db49 in group realtime-group has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:55:38.100 | [2025-10-19 22:55:38,100] INFO [GroupCoordinator 1]: Member main.exe@miquel (github.com/segmentio/kafka-go)-b6e4b2d9-28c3-4c29-ab0d-1bcbb3e54083 in group realtime-group has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
2025-10-19 17:55:38.101 | [2025-10-19 22:55:38,101] INFO [GroupCoordinator 1]: Group realtime-group with generation 7 is now empty (__consumer_offsets-19) (kafka.coordinator.group.GroupCoordinator)